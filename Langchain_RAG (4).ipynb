{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nNDu86-NtA0"
      },
      "source": [
        "#Langchain PDF Q/A RAG System:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community"
      ],
      "metadata": {
        "id": "tsVHLOJlFzpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6b6b2e56-b3ac-4f9b-d6c8-73bc5dd49302"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n",
            "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.23.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.14 langchain-community-0.3.14 langchain-core-0.3.29 marshmallow-3.23.3 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "TQavCRZPJeu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "953023db-520b-4294-f834-c2914dd5809e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/298.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I uploaded a book \"Code Complete by Steve McConnell\" as a pdf document"
      ],
      "metadata": {
        "id": "mP74-jDPLRpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_loader = PyPDFLoader(\"/content/Steve McConnell - Code Complete (2nd edition).pdf\")\n",
        "\n",
        "pages = pdf_loader.load_and_split()"
      ],
      "metadata": {
        "id": "vlm4hfIYJs7F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "id": "Sgq1qa6zKahA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20bc7bcc-878f-447c-8883-5f6bfc62ba98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 1}, page_content='PUBLISHED BY\\nMicrosoft Press\\nA Division of Microsoft Corporation\\nOne Microsoft Way\\nRedmond, Washington 98052-6399\\nCopyright © 2004 by Steven C. McConnell\\nAll rights reserved. No part of the contents of this book may be reproduced or transmitted in any form or by \\nany means without the written permission of the publisher.\\nLibrary of Congress Cataloging-in-Publication Data\\nMcConnell, Steve\\nCode Complete / Steve McConnell.--2nd ed.\\np.  cm.\\nIncludes index.\\nISBN 0-7356-1967-0\\n1. Computer Software--Development--Handbooks, manuals, etc. I. Title.\\nQA76.76.D47M39 2004\\n005.1--dc22 2004049981\\nPrinted and bound in the United States of America.\\n15 16 17 18 19 20 21 22 23 24 QGT 6 5 4 3 2 1\\nDistributed in Canada by H.B. Fenn and Company Ltd. A CIP catalogue record for this book is available from \\nthe British Library.\\nMicrosoft Press books are available through booksellers and distributors worldwide. For further information \\nabout international editions, contact your local Microsoft Corporation office or contact Microsoft Press Inter-\\nnational directly at fax (425) 936-7329. Visit our Web site at www.microsoft.com/mspress. Send comments \\nto mspinput@microsoft.com.\\nMicrosoft, Microsoft Press, PowerPoint, Visual Basic, Windows, and Windows NT are either registered trade-\\nmarks or trademarks of Microsoft Corporation in the United States and/or other countries. Other product and \\ncompany names mentioned herein may be the trademarks of their respective owners.\\nThe example companies, organizations, products, domain names, e-mail addresses, logos, people, places, and \\nevents depicted herein are fictitious. No association with any real company, organization, product, domain \\nname, e-mail address, logo, person, place, or event is intended or should be inferred.\\nThis book expresses the author’s views and opinions. The information contained in this book is provided with-\\nout any express, statutory, or implied warranties. Neither the authors, Microsoft Corporation, nor its resellers, \\nor distributors will be held liable for any damages caused or alleged to be caused either directly or indirectly \\nby this book.\\nAcquisitions Editors: Linda Engelman and Robin Van Steenburgh\\nProject Editor: Devon Musgrave\\nIndexer: Bill Myers\\nPrincipal Desktop Publisher: Carl Diltz\\nBody Part No. X10-53130\\nA03L619670.fm  Page iv  Thursday, April 7, 2011  5:54 PM\\nDownload from Wow! eBook <www.wowebook.com>'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 2}, page_content=\"To my wife, Ashlie, who doesn't have much to do with computer programming \\nbut who has everything to do with enriching the rest of my life \\nin more ways than I could possibly describe\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 3}, page_content=\"Further Praise for\\nCode Complete\\n“An excellent guide to programming style and software construction.”\\n—Martin Fowler, Refactoring\\n“Steve McConnell’s Code Complete . . . provides a fast track to wisdom for programmers. . . . \\nHis books are fun to read, and you never forget that he is speaking from hard-won personal \\nexperience.” —Jon Bentley, Programming Pearls, 2d ed.\\n“This is simply the best book on software construction that I've ever read. Every developer \\nshould own a copy and read it cover to cover every year. After reading it annually for nine \\nyears, I'm still learning things from this book!”\\n—John Robbins, Debugging Applications for Microsoft .NET and Microsoft Windows\\n“Today’s software must be robust and resilient, and secure code starts with disciplined software \\nconstruction. After ten years, there is still no better authority than Code Complete.”\\n—Michael Howard, Security Engineering, Microsoft Corporation; Coauthor, Writing Secure Code \\n“A comprehensive examination of the tactical issues that go into crafting a well-engineered \\nprogram. McConnell’s work covers such diverse topics as architecture, coding standards, \\ntesting, integration, and the nature of software craftsmanship.”\\n—Grady Booch, Object Solutions\\n“The ultimate encyclopedia for the software developer is Code Complete by Steve McConnell. \\nSubtitled ‘A Practical Handbook of Software Construction,’ this 850-page book is exactly \\nthat. Its stated goal is to narrow the gap between the knowledge of ‘industry gurus and pro-\\nfessors’ (Yourdon and Pressman, for example) and common commercial practice, and ‘to \\nhelp you write better programs in less time with fewer headaches.’ . . . Every developer should \\nown a copy of McConnell's book. Its style and content are thoroughly practical.”\\n—Chris Loosley, High-Performance Client/Server\\n“Steve McConnell’s seminal book Code Complete is one of the most accessible works discuss-\\ning in detail software development methods. . . .”\\n—Erik Bethke, Game Development and Production\\n“A mine of useful information and advice on the broader issues in designing and producing \\ngood software.”\\n—John Dempster, The Laboratory Computer: A Practical Guide for Physiologists and Neuroscien-\\ntists\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 4}, page_content='“If you are serious about improving your programming skills, you should get Code Complete \\nby Steve McConnell.”\\n—Jean J. Labrosse, Embedded Systems Building Blocks: Complete and Ready-To-Use Modules in C\\n“Steve McConnell has written one of the best books on software development independent \\nof computer environment . . . Code Complete.”\\n—Kenneth Rosen, Unix: The Complete Reference\\n“Every half an age or so, you come across a book that short-circuits the school of experience \\nand saves you years of purgatory. . . . I cannot adequately express how good this book really \\nis.  Code Complete is a pretty lame title for a work of brilliance.”\\n—Jeff Duntemann, PC Techniques\\n“Microsoft Press has published what I consider to be the definitive book on software con-\\nstruction. This is a book that belongs on every software developer’s shelf.”\\n—Warren Keuffel, Software Development\\n“Every programmer should read this outstanding book.” —T. L. (Frank) Pappas, Computer\\n“If you aspire to be a professional programmer, this may be the wisest $35 investment you’ll \\never make. Don’t stop to read the rest of this review: just run out and buy it. McConnell’s stat-\\ned purpose is to narrow the gap between the knowledge of industry gurus and common com-\\nmercial practice. . . . The amazing thing is that he succeeds.”\\n—Richard Mateosian, IEEE Micro\\n“Code Complete should be required reading for anyone . . . in software development.”\\n—Tommy Usher, C Users Journal\\n“I’m encouraged to stick my neck out a bit further than usual and recommend, without res-\\nervation, Steve McConnell’s Code Complete. . . . My copy has replaced my API reference man-\\nuals as the book that’s closest to my keyboard while I work.”\\n—Jim Kyle, Windows Tech Journal\\n“This well-written but massive tome is arguably the best single volume ever written on the \\npractical aspects of software implementation.”\\n—Tommy Usher, Embedded Systems Programming\\n“This is the best book on software engineering that I have yet read.”\\n—Edward Kenworth, .EXE Magazine\\n“This book deserves to become a classic, and should be compulsory reading for all develop-\\ners, and those responsible for managing them.” —Peter Wright, Program Now'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 5}, page_content='Code Complete, Second Edition\\n0-7356-1967-0\\nSteve McConnell'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 6}, page_content='vii\\nContents at a Glance\\nPart I Laying the Foundation\\n1 Welcome to Software Construction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3\\n2 Metaphors for a Richer Understanding of Software Development . . . . .9\\n 3 Measure Twice, Cut Once: Upstream Prerequisites. . . . . . . . . . . . . . . . . 23\\n 4 Key Construction Decisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\\nPart II Creating High-Quality Code\\n 5 Design in Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\n 6 Working Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\n 7 High-Quality Routines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\\n 8 Defensive Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\\n 9 The Pseudocode Programming Process . . . . . . . . . . . . . . . . . . . . . . . . . 215\\nPart III Variables\\n 10 General Issues in Using Variables. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\n11 The Power of Variable Names  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\n 12 Fundamental Data Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291\\n 13 Unusual Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\\nPart IV Statements\\n14 Organizing Straight-Line Code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\n 15 Using Conditionals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355\\n 16 Controlling Loops  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367\\n 17 Unusual Control Structures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 391\\n 18 Table-Driven Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411\\n19 General Control Issues. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 7}, page_content='viii Table of Contents\\nPart V Code Improvements\\n 20 The Software-Quality Landscape. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463\\n 21 Collaborative Construction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 479\\n 22 Developer Testing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499\\n 23 Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 535\\n 24 Refactoring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563\\n 25 Code-Tuning Strategies. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587\\n 26 Code-Tuning Techniques  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609\\nPart VI System Considerations\\n 27 How Program Size Affects Construction . . . . . . . . . . . . . . . . . . . . . . . . 649\\n 28 Managing Construction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 661\\n 29 Integration  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 689\\n 30 Programming Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 709\\nPart VII Software Craftsmanship\\n31 Layout and Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 729\\n 32 Self-Documenting Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 777\\n 33 Personal Character . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 819\\n34 Themes in Software Craftsmanship. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 837\\n 35 Where to Find More Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 855'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 8}, page_content='ix\\nWhat do you think of this book?\\nWe want to hear from you!\\nMicrosoft is interested in hearing your feedback about this publication so we can \\ncontinually improve our books and learning resources for you. To participate in a brief \\nonline survey, please visit: www.microsoft.com/learning/booksurvey/\\n Table of Contents\\nPreface  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xix\\nAcknowledgments. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .x xvii\\nList of Checklists  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxix\\nList of Tables. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxxi\\nList of Figures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xxxiii\\nPart I Laying the Foundation\\n1 Welcome to Software Construction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3\\n1.1 What Is Software Construction?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.2 Why Is Software Construction Important? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n1.3 How to Read This Book. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n2 Metaphors for a Richer Understanding of Software Development . . . . .9\\n2.1 The Importance of Metaphors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n2.2 How to Use Software Metaphors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n2.3 Common Software Metaphors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n 3 Measure Twice, Cut Once: Upstream Prerequisites. . . . . . . . . . . . . . . . . 23\\n3.1 Importance of Prerequisites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n3.2 Determine the Kind of Software You’re Working On. . . . . . . . . . . . . . . . . . . . . . . . 31\\n3.3 Problem-Definition Prerequisite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\n3.4 Requirements Prerequisite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\\n3.5 Architecture Prerequisite  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n3.6 Amount of Time to Spend on Upstream Prerequisites . . . . . . . . . . . . . . . . . . . . . . 55\\n 4 Key Construction Decisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\\n4.1 Choice of Programming Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\\n4.2 Programming Conventions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\n4.3 Your Location on the Technology Wave . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\n4.4 Selection of Major Construction Practices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 9}, page_content='x Table of Contents\\nPart II Creating High-Quality Code\\n 5 Design in Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\n5.1 Design Challenges. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\n5.2 Key Design Concepts  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n5.3 Design Building Blocks: Heuristics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\n5.4 Design Practices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\\n5.5 Comments on Popular Methodologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\n 6 Working Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\n6.1 Class Foundations: Abstract Data Types (ADTs) . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\n6.2 Good Class Interfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\n6.3 Design and Implementation Issues. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\n6.4 Reasons to Create a Class. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\n6.5 Language-Specific Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\\n6.6 Beyond Classes: Packages  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\\n 7 High-Quality Routines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161\\n7.1 Valid Reasons to Create a Routine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\\n7.2 Design at the Routine Level. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168\\n7.3 Good Routine Names . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\\n7.4 How Long Can a Routine Be? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\n7.5 How to Use Routine Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n7.6 Special Considerations in the Use of Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 181\\n7.7 Macro Routines and Inline Routines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\\n 8 Defensive Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\\n8.1 Protecting Your Program from Invalid Inputs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\n8.2 Assertions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\n8.3 Error-Handling Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\n8.4 Exceptions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n8.5 Barricade Your Program to Contain the Damage Caused by Errors . . . . . . . . . . 203\\n8.6 Debugging Aids. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\n8.7 Determining How Much Defensive Programming to Leave in \\nProduction Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\\n8.8 Being Defensive About Defensive Programming. . . . . . . . . . . . . . . . . . . . . . . . . . 210'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 10}, page_content='Table of Contents xi\\n 9 The Pseudocode Programming Process . . . . . . . . . . . . . . . . . . . . . . . . . 215\\n9.1 Summary of Steps in Building Classes and Routines . . . . . . . . . . . . . . . . . . . . . . . 216\\n9.2 Pseudocode for Pros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218\\n9.3 Constructing Routines by Using the PPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\n9.4 Alternatives to the PPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nPart III Variables\\n 10 General Issues in Using Variables. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\n10.1 Data Literacy. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  .2 3 8\\n10.2 Making Variable Declarations Easy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239\\n10.3 Guidelines for Initializing Variables. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\\n10.4 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\n10.5 Persistence  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\\n10.6 Binding Time. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2 5 2\\n10.7 Relationship Between Data Types and Control Structures . . . . . . . . . . . . . . . . . 254\\n10.8 Using Each Variable for Exactly One Purpose . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\\n11 The Power of Variable Names  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\n11.1 Considerations in Choosing Good Names . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\n11.2 Naming Specific Types of Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\\n11.3 The Power of Naming Conventions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\n11.4 Informal Naming Conventions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\\n11.5 Standardized Prefixes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\\n11.6 Creating Short Names That Are Readable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\n11.7 Kinds of Names to Avoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\\n 12 Fundamental Data Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291\\n12.1 Numbers in General. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\n12.2 Integers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . 293\\n12.3 Floating-Point Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295\\n12.4 Characters and Strings  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\\n12.5 Boolean Variables  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301\\n12.6 Enumerated Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\\n12.7 Named Constants  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307\\n12.8 Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\\n12.9 Creating Your Own Types (Type Aliasing) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 11}, page_content='PUBLISHED BY\\nMicrosoft Press\\nA Division of Microsoft Corporation\\nOne Microsoft Way\\nRedmond, Washington 98052-6399\\nCopyright © 2004 by Steven C. McConnell\\nAll rights reserved. No part of the contents of this book may be reproduced or transmitted in any form or by \\nany means without the written permission of the publisher.\\nLibrary of Congress Cataloging-in-Publication Data\\nMcConnell, Steve\\nCode Complete / Steve McConnell.--2nd ed.\\np.  cm.\\nIncludes index.\\nISBN 0-7356-1967-0\\n1. Computer Software--Development--Handbooks, manuals, etc. I. Title.\\nQA76.76.D47M39 2004\\n005.1--dc22 2004049981\\nPrinted and bound in the United States of America.\\n15 16 17 18 19 20 21 22 23 24 QGT 6 5 4 3 2 1\\nDistributed in Canada by H.B. Fenn and Company Ltd. A CIP catalogue record for this book is available from \\nthe British Library.\\nMicrosoft Press books are available through booksellers and distributors worldwide. For further information \\nabout international editions, contact your local Microsoft Corporation office or contact Microsoft Press Inter-\\nnational directly at fax (425) 936-7329. Visit our Web site at www.microsoft.com/mspress. Send comments \\nto mspinput@microsoft.com.\\nMicrosoft, Microsoft Press, PowerPoint, Visual Basic, Windows, and Windows NT are either registered trade-\\nmarks or trademarks of Microsoft Corporation in the United States and/or other countries. Other product and \\ncompany names mentioned herein may be the trademarks of their respective owners.\\nThe example companies, organizations, products, domain names, e-mail addresses, logos, people, places, and \\nevents depicted herein are fictitious. No association with any real company, organization, product, domain \\nname, e-mail address, logo, person, place, or event is intended or should be inferred.\\nThis book expresses the author’s views and opinions. The information contained in this book is provided with-\\nout any express, statutory, or implied warranties. Neither the authors, Microsoft Corporation, nor its resellers, \\nor distributors will be held liable for any damages caused or alleged to be caused either directly or indirectly \\nby this book.\\nAcquisitions Editors: Linda Engelman and Robin Van Steenburgh\\nProject Editor: Devon Musgrave\\nIndexer: Bill Myers\\nPrincipal Desktop Publisher: Carl Diltz\\nBody Part No. X10-53130\\nA03L619670.fm  Page iv  Thursday, April 7, 2011  5:54 PM\\nDownload from Wow! eBook <www.wowebook.com>'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 12}, page_content='Table of Contents xiii\\n19.3 Null Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444\\n19.4 Taming Dangerously Deep Nesting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445\\n19.5 A Programming Foundation: Structured Programming . . . . . . . . . . . . . . . . . . . 454\\n19.6 Control Structures and Complexity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 456\\nPart V Code Improvements\\n 20 The Software-Quality Landscape . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463\\n20.1 Characteristics of Software Quality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463\\n20.2 Techniques for Improving Software Quality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 466\\n20.3 Relative Effectiveness of Quality Techniques. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469\\n20.4 When to Do Quality Assurance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 473\\n20.5 The General Principle of Software Quality. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 474\\n 21 Collaborative Construction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 479\\n21.1 Overview of Collaborative Development Practices  . . . . . . . . . . . . . . . . . . . . . . . 480\\n21.2 Pair Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483\\n21.3 Formal Inspections. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 485\\n21.4 Other Kinds of Collaborative Development Practices . . . . . . . . . . . . . . . . . . . . . 492\\n 22 Developer Testing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499\\n22.1 Role of Developer Testing in Software Quality . . . . . . . . . . . . . . . . . . . . . . . . . . . 500\\n22.2 Recommended Approach to Developer Testing  . . . . . . . . . . . . . . . . . . . . . . . . . 503\\n22.3 Bag of Testing Tricks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 505\\n22.4 Typical Errors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5 1 7\\n22.5 Test-Support Tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 523\\n22.6 Improving Your Testing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 528\\n22.7 Keeping Test Records . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 529\\n 23 Debugging  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 535\\n23.1 Overview of Debugging Issues  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 535\\n23.2 Finding a Defect. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 540\\n23.3 Fixing a Defect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5 5 0\\n23.4 Psychological Considerations in Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 554\\n23.5 Debugging Tools—Obvious and Not-So-Obvious. . . . . . . . . . . . . . . . . . . . . . . . 556'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 13}, page_content='xiv Table of Contents\\n 24 Refactoring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 563\\n24.1 Kinds of Software Evolution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 564\\n24.2 Introduction to Refactoring. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 565\\n24.3 Specific Refactorings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 571\\n24.4 Refactoring Safely . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 579\\n24.5 Refactoring Strategies  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 582\\n 25 Code-Tuning Strategies. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587\\n25.1 Performance Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 588\\n25.2 Introduction to Code Tuning  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 591\\n25.3 Kinds of Fat and Molasses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 597\\n25.4 Measurement. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 603\\n25.5 Iteration  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605\\n25.6 Summary of the Approach to Code Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 606\\n 26 Code-Tuning Techniques  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609\\n26.1 Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 610\\n26.2 Loops. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . 616\\n26.3 Data Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 624\\n26.4 Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 630\\n26.5 Routines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . 639\\n26.6 Recoding in a Low-Level Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 640\\n26.7 The More Things Change, the More They Stay the Same  . . . . . . . . . . . . . . . . . 643\\nPart VI System Considerations\\n 27 How Program Size Affects Construction . . . . . . . . . . . . . . . . . . . . . . . . 649\\n27.1 Communication and Size . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 650\\n27.2 Range of Project Sizes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 651\\n27.3 Effect of Project Size on Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 651\\n27.4 Effect of Project Size on Productivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 653\\n27.5 Effect of Project Size on Development Activities . . . . . . . . . . . . . . . . . . . . . . . . . 654'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 14}, page_content='Table of Contents xv\\n 28 Managing Construction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 661\\n28.1 Encouraging Good Coding. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 662\\n28.2 Configuration Management. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 664\\n28.3 Estimating a Construction Schedule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 671\\n28.4 Measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 677\\n28.5 Treating Programmers as People  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 680\\n28.6 Managing Your Manager . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 686\\n 29 Integration  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 689\\n29.1 Importance of the Integration Approach. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 689\\n29.2 Integration Frequency—Phased or Incremental? . . . . . . . . . . . . . . . . . . . . . . . . . 691\\n29.3 Incremental Integration Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 694\\n29.4 Daily Build and Smoke Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 702\\n 30 Programming Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 709\\n30.1 Design Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .7 1 0\\n30.2 Source-Code Tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 710\\n30.3 Executable-Code Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 716\\n30.4 Tool-Oriented Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 720\\n30.5 Building Your Own Programming Tools  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 721\\n30.6 Tool Fantasyland . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 722\\nPart VII Software Craftsmanship\\n31 Layout and Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 729\\n31.1 Layout Fundamentals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 730\\n31.2 Layout Techniques. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 736\\n31.3 Layout Styles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .7 3 8\\n31.4 Laying Out Control Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 745\\n31.5 Laying Out Individual Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 753\\n31.6 Laying Out Comments  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 763\\n31.7 Laying Out Routines  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 766\\n31.8 Laying Out Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 768'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 15}, page_content='xvi Table of Contents\\n 32 Self-Documenting Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 777\\n32.1 External Documentation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 777\\n32.2 Programming Style as Documentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 778\\n32.3 To Comment or Not to Comment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 781\\n32.4 Keys to Effective Comments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 785\\n32.5 Commenting Techniques. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 792\\n32.6 IEEE Standards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 813\\n 33 Personal Character . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 819\\n33.1 Isn’t Personal Character Off the Topic? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 820\\n33.2 Intelligence and Humility. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 821\\n33.3 Curiosity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 822\\n33.4 Intellectual Honesty  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 826\\n33.5 Communication and Cooperation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 828\\n33.6 Creativity and Discipline. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 829\\n33.7 Laziness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 830\\n33.8 Characteristics That Don’t Matter As Much As You Might Think  . . . . . . . . . . . 830\\n33.9 Habits  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 833\\n34 Themes in Software Craftsmanship. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 837\\n34.1 Conquer Complexity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 837\\n34.2 Pick Your Process. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 839\\n34.3 Write Programs for People First, Computers Second . . . . . . . . . . . . . . . . . . . . . 841\\n34.4 Program into Your Language, Not in It . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 843\\n34.5 Focus Your Attention with the Help of Conventions. . . . . . . . . . . . . . . . . . . . . . 844\\n34.6 Program in Terms of the Problem Domain. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 845\\n34.7 Watch for Falling Rocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 848\\n34.8 Iterate, Repeatedly, Again and Again  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 850\\n34.9 Thou Shalt Rend Software and Religion Asunder  . . . . . . . . . . . . . . . . . . . . . . . . 851'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 16}, page_content='Table of Contents xvii\\nWhat do you think of this book?\\nWe want to hear from you!\\nMicrosoft is interested in hearing your feedback about this publication so we can \\ncontinually improve our books and learning resources for you. To participate in a brief \\nonline survey, please visit: www.microsoft.com/learning/booksurvey/\\n 35 Where to Find More Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 855\\n35.1 Information About Software Construction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 856\\n35.2 Topics Beyond Construction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 857\\n35.3 Periodicals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 859\\n35.4 A Software Developer’s Reading Plan. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 860\\n35.5 Joining a Professional Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 862\\nBibliography. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . 863\\nIndex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 885'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 18}, page_content='xix\\nPreface\\nThe gap between the best software engineering practice and the average practice \\nis very wide—perhaps wider than in any other engineering discipline. A tool that \\ndisseminates good practice would be important.\\n—Fred Brooks\\nMy primary concern in writing this book has been to narrow the gap between the \\nknowledge of industry gurus and professors on the one hand and common commer-\\ncial practice on the other. Many powerful programming techniques hide in journals \\nand academic papers for years before trickling down to the programming public.\\nAlthough leading-edge software-development practice has advanced rapidly in recent \\nyears, common practice hasn’t. Many programs are still buggy, late, and over budget, \\nand many fail to satisfy the needs of their users. Researchers in both the software \\nindustry and academic settings have discovered effective practices that eliminate most \\nof the programming problems that have been prevalent since the 1970s. Because \\nthese practices aren’t often reported outside the pages of highly specialized technical \\njournals, however, most programming organizations aren’t yet using them today. \\nStudies have found that it typically takes 5 to 15 years or more for a research develop-\\nment to make its way into commercial practice (Raghavan and Chand 1989, Rogers \\n1995, Parnas 1999). This handbook shortcuts the process, making key discoveries \\navailable to the average programmer now.\\nWho Should Read This Book?\\nThe research and programming experience collected in this handbook will help you \\nto create higher-quality software and to do your work more quickly and with fewer \\nproblems. This book will give you insight into why you’ve had problems in the past \\nand will show you how to avoid problems in the future. The programming practices \\ndescribed here will help you keep big projects under control and help you maintain \\nand modify software successfully as the demands of your projects change.\\nExperienced Programmers\\nThis handbook serves experienced programmers who want a comprehensive, easy-to-\\nuse guide to software development. Because this book focuses on construction, the \\nmost familiar part of the software life cycle, it makes powerful software development \\ntechniques understandable to self-taught programmers as well as to programmers \\nwith formal training.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 19}, page_content='xx Preface\\nTechnical Leads\\nMany technical leads have used Code Complete to educate less-experienced program-\\nmers on their teams. You can also use it to fill your own knowledge gaps. If you’re an \\nexperienced programmer, you might not agree with all my conclusions (and I would be \\nsurprised if you did), but if you read this book and think about each issue, only rarely \\nwill someone bring up a construction issue that you haven’t previously considered.\\nSelf-Taught Programmers\\nIf you haven’t had much formal training, you’re in good company. About 50,000 new \\ndevelopers enter the profession each year (BLS 2004, Hecker 2004), but only about \\n35,000 software-related degrees are awarded each year (NCES 2002). From these fig-\\nures it’s a short hop to the conclusion that many programmers don’t receive a formal \\neducation in software development. Self-taught programmers are found in the emerg-\\ning group of professionals—engineers, accountants, scientists, teachers, and small-\\nbusiness owners—who program as part of their jobs but who do not necessarily view \\nthemselves as programmers. Regardless of the extent of your programming educa-\\ntion, this handbook can give you insight into effective programming practices.\\nStudents\\nThe counterpoint to the programmer with experience but little formal training is the \\nfresh college graduate. The recent graduate is often rich in theoretical knowledge but \\npoor in the practical know-how that goes into building production programs. The \\npractical lore of good coding is often passed down slowly in the ritualistic tribal \\ndances of software architects, project leads, analysts, and more-experienced program-\\nmers. Even more often, it’s the product of the individual programmer’s trials and \\nerrors. This book is an alternative to the slow workings of the traditional intellectual \\npotlatch. It pulls together the helpful tips and effective development strategies previ-\\nously available mainly by hunting and gathering from other people’s experience. It’s a \\nhand up for the student making the transition from an academic environment to a \\nprofessional one.\\nWhere Else Can You Find This Information?\\nThis book synthesizes construction techniques from a variety of sources. In addition \\nto being widely scattered, much of the accumulated wisdom about construction has \\nresided outside written sources for years (Hildebrand 1989, McConnell 1997a). \\nThere is nothing mysterious about the effective, high-powered programming tech-\\nniques used by expert programmers. In the day-to-day rush of grinding out the latest \\nproject, however, few experts take the time to share what they have learned. Conse-'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 20}, page_content='Preface xxi\\nquently, programmers may have difficulty finding a good source of programming \\ninformation.\\nThe techniques described in this book fill the void after introductory and advanced \\nprogramming texts. After you have read Introduction to Java, Advanced Java, and \\nAdvanced Advanced Java, what book do you read to learn more about programming? \\nYou could read books about the details of Intel or Motorola hardware, Microsoft Win-\\ndows or Linux operating-system functions, or another programming language—you \\ncan’t use a language or program in an environment without a good reference to such \\ndetails. But this is one of the few books that discusses programming per se. Some of \\nthe most beneficial programming aids are practices that you can use regardless of the \\nenvironment or language you’re working in. Other books generally neglect such prac-\\ntices, which is why this book concentrates on them.\\nThe information in this book is distilled from many sources, as shown below. The \\nonly other way to obtain the information you’ll find in this handbook would be to \\nplow through a mountain of books and a few hundred technical journals and then \\nadd a significant amount of real-world experience. If you’ve already done all that, you \\ncan still benefit from this book’s collecting the information in one place for easy refer-\\nence.\\nKey Benefits of This Handbook\\nWhatever your background, this handbook can help you write better programs in less \\ntime and with fewer headaches.\\nComplete software-construction reference This handbook discusses general aspects \\nof construction such as software quality and ways to think about programming. It gets \\ninto nitty-gritty construction details such as  steps in building classes, ins and outs of \\nusing data and control structures, debugging, refactoring, and code-tuning tech-\\nniques and strategies. You don’t need to read it cover to cover to learn about these top-\\nics. The book is designed to make it easy to find the specific information that interests \\nyou.\\nProfessional \\nexperience\\nOther software \\nbooks\\nProgramming \\nlanguage books\\nMagazine \\narticlesTechnology \\nreferences\\nConstruction'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 21}, page_content='xxii Preface\\nReady-to-use checklists This book includes dozens of checklists you can use to \\nassess your software architecture, design approach, class and routine quality, variable \\nnames, control structures, layout, test cases, and much more.\\nState-of-the-art information This handbook describes some of the most up-to-date \\ntechniques available, many of which have not yet made it into common use. Because \\nthis book draws from both practice and research, the techniques it describes will \\nremain useful for years.\\nLarger perspective on software development This book will give you a chance to rise \\nabove the fray of day-to-day fire fighting and figure out what works and what doesn’t. \\nFew practicing programmers have the time to read through the hundreds of books \\nand journal articles that have been distilled into this handbook. The research and real-\\nworld experience gathered into this handbook will inform and stimulate your think-\\ning about your projects, enabling you to take strategic action so that you don’t have to \\nfight the same battles again and again.\\nAbsence of hype Some software books contain 1 gram of insight swathed in 10 \\ngrams of hype. This book presents balanced discussions of each technique’s strengths \\nand weaknesses. You know the demands of your particular project better than anyone \\nelse. This book provides the objective information you need to make good decisions \\nabout your specific circumstances.  \\nConcepts applicable to most common languages This book describes techniques \\nyou can use to get the most out of whatever language you’re using, whether it’s C++, \\nC#, Java, Microsoft Visual Basic, or other similar languages.\\nNumerous code examples The book contains almost 500 examples of good and bad \\ncode. I’ve included so many examples because, personally, I learn best from exam-\\nples. I think other programmers learn best that way too.\\nThe examples are in multiple languages because mastering more than one language is \\noften a watershed in the career of a professional programmer. Once a programmer \\nrealizes that programming principles transcend the syntax of any specific language, \\nthe doors swing open to knowledge that truly makes a difference in quality and pro-\\nductivity.\\nTo make the multiple-language burden as light as possible, I’ve avoided esoteric lan-\\nguage features except where they’re specifically discussed. You don’t need to under-\\nstand every nuance of the code fragments to understand the points they’re making. If \\nyou focus on the point being illustrated, you’ll find that you can read the code regard-\\nless of the language. I’ve tried to make your job even easier by annotating the signifi-\\ncant parts of the examples.\\nAccess to other sources of information This book collects much of the available \\ninformation on software construction, but it’s hardly the last word. Throughout the'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 22}, page_content='Preface xxiii\\nchapters, “Additional Resources” sections describe other books and articles you can \\nread as you pursue the topics you find most interesting.\\ncc2e.com/1234 Book website Updated checklists, books, magazine articles, Web links, and other \\ncontent are provided on a companion website at cc2e.com. To access information \\nrelated to Code Complete, 2d ed., enter cc2e.com/ followed by a four-digit code, an \\nexample of which is shown here in the left margin. These website references appear \\nthroughout the book.\\nWhy This Handbook Was Written\\nThe need for development handbooks that capture knowledge about effective devel-\\nopment practices is well recognized in the software-engineering community. A report \\nof the Computer Science and Technology Board stated that the biggest gains in soft-\\nware-development quality and productivity will come from codifying, unifying, and \\ndistributing existing knowledge about effective software-development practices \\n(CSTB 1990, McConnell 1997a). The board concluded that the strategy for spreading \\nthat knowledge should be built on the concept of software-engineering handbooks.\\nThe Topic of Construction Has Been Neglected \\nAt one time, software development and coding were thought to be one and the same. \\nBut as distinct activities in the software-development life cycle have been identified, \\nsome of the best minds in the field have spent their time analyzing and debating meth-\\nods of project management, requirements, design, and testing. The rush to study \\nthese newly identified areas has left code construction as the ignorant cousin of soft-\\nware development.\\nDiscussions about construction have also been hobbled by the suggestion that treat-\\ning construction as a distinct software development activity implies that construction \\nmust also be treated as a distinct phase. In reality, software activities and phases don’t \\nhave to be set up in any particular relationship to each other, and it’s useful to discuss \\nthe activity of construction regardless of whether other software activities are per-\\nformed in phases, in iterations, or in some other way.\\nConstruction Is Important\\nAnother reason construction has been neglected by researchers and writers is the mis-\\ntaken idea that, compared to other software-development activities, construction is a \\nrelatively mechanical process that presents little opportunity for improvement. Noth-\\ning could be further from the truth.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 23}, page_content='xxiv Preface\\nCode construction typically makes up about 65 percent of the effort on small projects \\nand 50 percent on medium projects. Construction accounts for about 75 percent of \\nthe errors on small projects and 50 to 75 percent on medium and large projects. Any \\nactivity that accounts for 50 to 75 percent of the errors presents a clear opportunity \\nfor improvement. (Chapter 27 contains more details on these statistics.)\\nSome commentators have pointed out that although construction errors account for a \\nhigh percentage of total errors, construction errors tend to be less expensive to fix \\nthan those caused by requirements and architecture, the suggestion being that they \\nare therefore less important. The claim that construction errors cost less to fix is true \\nbut misleading because the cost of not fixing them can be incredibly high. Researchers \\nhave found that small-scale coding errors account for some of the most expensive soft-\\nware errors of all time, with costs running into hundreds of millions of dollars (Wein-\\nberg 1983, SEN 1990). An inexpensive cost to fix obviously does not imply that fixing \\nthem should be a low priority.\\nThe irony of the shift in focus away from construction is that construction is the only \\nactivity that’s guaranteed to be done. Requirements can be assumed rather than devel-\\noped; architecture can be shortchanged rather than designed; and testing can be \\nabbreviated or skipped rather than fully planned and executed. But if there’s going to \\nbe a program, there has to be construction, and that makes construction a uniquely \\nfruitful area in which to improve development practices.\\nNo Comparable Book Is Available\\nIn light of construction’s obvious importance, I was sure when I conceived this book \\nthat someone else would already have written a book on effective construction prac-\\ntices. The need for a book about how to program effectively seemed obvious. But I \\nfound that only a few books had been written about construction and then only on \\nparts of the topic. Some had been written 15 years or more earlier and employed rel-\\natively esoteric languages such as ALGOL, PL/I, Ratfor, and Smalltalk. Some were \\nwritten by professors who were not working on production code. The professors \\nwrote about techniques that worked for student projects, but they often had little idea \\nof how the techniques would play out in full-scale development environments. Still \\nother books trumpeted the authors’ newest favorite methodologies but ignored the \\nhuge repository of mature practices that have proven their effectiveness over time.\\nWhen art critics get together \\nthey talk about Form and \\nStructure and Meaning. \\nWhen artists get together \\nthey talk about where you \\ncan buy cheap turpentine. \\n—Pablo Picasso\\nIn short, I couldn’t find any book that had even attempted to capture the body of prac-\\ntical techniques available from professional experience, industry research, and aca-\\ndemic work. The discussion needed to be brought up to date for current \\nprogramming languages, object-oriented programming, and leading-edge develop-\\nment practices. It seemed clear that a book about programming needed to be written \\nby someone who was knowledgeable about the theoretical state of the art but who \\nwas also building enough production code to appreciate the state of the practice. I'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 24}, page_content='Preface xxv\\nconceived this book as a full discussion of code construction—from one programmer \\nto another.\\nAuthor Note\\nI welcome your inquiries about the topics discussed in this book, your error reports, \\nor other related subjects. Please contact me at stevemcc@construx.com, or visit my \\nwebsite at www.stevemcconnell.com.\\nBellevue, Washington\\nMemorial Day, 2004\\nMicrosoft Learning Technical Support\\nEvery effort has been made to ensure the accuracy of this book. Microsoft Press \\nprovides corrections for books through the World Wide Web at the following \\naddress:\\nhttp://www.microsoft.com/learning/support/\\nTo connect directly to the Microsoft Knowledge Base and enter a query regard-\\ning a question or issue that you may have, go to: \\nhttp://www.microsoft.com/learning/support/search.asp\\nIf you have comments, questions, or ideas regarding this book, please send \\nthem to Microsoft Press using either of the following methods: \\nPostal Mail: \\nMicrosoft Press  \\nAttn: Code Complete 2E Editor  \\nOne Microsoft Way  \\nRedmond, WA 98052-6399\\nE-mail:\\nmspinput@microsoft.com'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 26}, page_content=\"xxvii\\nAcknowledgments\\nA book is never really written by one person (at least none of my books are). A second edition \\nis even more a collective undertaking. \\nI’d like to thank the people who contributed review comments on significant portions of the \\nbook: Hákon Ágústsson, Scott Ambler, Will Barns, William D. Bartholomew, Lars Bergstrom, \\nIan Brockbank, Bruce Butler, Jay Cincotta, Alan Cooper, Bob Corrick, Al Corwin, Jerry Deville, \\nJon Eaves, Edward Estrada, Steve Gouldstone, Owain Griffiths, Matthew Harris, Michael \\nHoward, Andy Hunt, Kevin Hutchison, Rob Jasper, Stephen Jenkins, Ralph Johnson and his \\nSoftware Architecture Group at the University of Illinois, Marek Konopka, Jeff Langr, Andy \\nLester, Mitica Manu, Steve Mattingly, Gareth McCaughan, Robert McGovern, Scott Meyers, \\nGareth Morgan, Matt Peloquin, Bryan Pflug, Jeffrey Richter, Steve Rinn, Doug Rosenberg, \\nBrian St. Pierre, Diomidis Spinellis, Matt Stephens, Dave Thomas, Andy Thomas-Cramer, John \\nVlissides, Pavel Vozenilek, Denny Williford, Jack Woolley, and Dee Zsombor. \\nHundreds of readers sent comments about the first edition, and many more sent individual \\ncomments about the second edition. Thanks to everyone who took time to share their reac-\\ntions to the book in its various forms. \\nSpecial thanks to the Construx Software reviewers who formally inspected the entire manu-\\nscript: Jason Hills, Bradey Honsinger, Abdul Nizar, Tom Reed, and Pamela Perrott. I was truly \\namazed at how thorough their review was, especially considering how many eyes had scruti-\\nnized the book before they began working on it. Thanks also to Bradey, Jason, and Pamela for \\ntheir contributions to the cc2e.com website. \\nWorking with Devon Musgrave, project editor for this book, has been a special treat. I’ve \\nworked with numerous excellent editors on other projects, and Devon stands out as espe-\\ncially conscientious and easy to work with. Thanks, Devon! Thanks to Linda Engleman who \\nchampioned the second edition; this book wouldn’t have happened without her. Thanks also \\nto the rest of the Microsoft Press staff, including Robin Van Steenburgh, Elden Nelson, Carl \\nDiltz, Joel Panchot, Patricia Masserman, Bill Myers, Sandi Resnick, Barbara Norfleet, James \\nKramer, and Prescott Klassen.\\nI’d like to remember the Microsoft Press staff that published the first edition: Alice Smith, \\nArlene Myers, Barbara Runyan, Carol Luke, Connie Little, Dean Holmes, Eric Stroo, Erin \\nO'Connor, Jeannie McGivern, Jeff Carey, Jennifer Harris, Jennifer Vick, Judith Bloch, \\nKatherine Erickson, Kim Eggleston, Lisa Sandburg, Lisa Theobald, Margarite Hargrave, Mike \\nHalvorson, Pat Forgette, Peggy Herman, Ruth Pettis, Sally Brunsman, Shawn Peck, Steve Mur-\\nray, Wallis Bolz, and Zaafar Hasnain.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 27}, page_content='xxviii Acknowledgments\\nThanks to the reviewers who contributed so significantly to the first edition: Al Corwin, Bill \\nKiestler, Brian Daugherty, Dave Moore, Greg Hitchcock, Hank Meuret, Jack Woolley, Joey \\nWyrick, Margot Page, Mike Klein, Mike Zevenbergen, Pat Forman, Peter Pathe, Robert L. \\nGlass, Tammy Forman, Tony Pisculli, and Wayne Beardsley. Special thanks to Tony Garland \\nfor his exhaustive review: with 12 years’ hindsight, I appreciate more than ever how excep-\\ntional Tony’s several thousand review comments really were.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 28}, page_content='xxix\\nChecklists\\nRequirements 42\\nArchitecture 54\\nUpstream Prerequisites 59\\nMajor Construction Practices 69\\nDesign in Construction 122\\nClass Quality 157\\nHigh-Quality Routines 185\\nDefensive Programming 211\\nThe Pseudocode Programming Process 233\\nGeneral Considerations In Using Data 257\\nNaming Variables 288\\nFundamental Data 316\\nConsiderations in Using Unusual Data Types 343\\nOrganizing Straight-Line Code 353\\nUsing Conditionals 365\\nLoops 388\\nUnusual Control Structures 410\\nTable-Driven Methods 429\\nControl-Structure Issues 459\\nA Quality-Assurance Plan 476\\nEffective Pair Programming 484\\nEffective Inspections 491\\nTest Cases 532\\nDebugging Reminders 559\\nReasons to Refactor 570\\nSummary of Refactorings 577\\nRefactoring Safely 584\\nCode-Tuning Strategies 607\\nCode-Tuning Techniques 642'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 29}, page_content='xxx Checklists\\nConfiguration Management 669\\nIntegration 707\\nProgramming Tools 724\\nLayout 773\\nSelf-Documenting Code 780\\nGood Commenting Technique 816'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 30}, page_content='xxxi\\nTables\\nTable 3-1 Average Cost of Fixing Defects Based on When They’re Introduced and \\nDetected 29\\nTable 3-2 Typical Good Practices for Three Common Kinds of Software Projects 31\\nTable 3-3 Effect of Skipping Prerequisites on Sequential and Iterative Projects 33\\nTable 3-4 Effect of Focusing on Prerequisites on Sequential and Iterative Projects 34\\nTable 4-1 Ratio of High-Level-Language Statements to Equivalent C Code 62\\nTable 5-1 Popular Design Patterns 104\\nTable 5-2 Design Formality and Level of Detail Needed 116\\nTable 6-1 Variations on Inherited Routines 145\\nTable 8-1 Popular-Language Support for Exceptions 198\\nTable 11-1 Examples of Good and Bad Variable Names 261\\nTable 11-2 Variable Names That Are Too Long, Too Short, or Just Right 262\\nTable 11-3 Sample Naming Conventions for C++ and Java 277\\nTable 11-4 Sample Naming Conventions for C 278\\nTable 11-5 Sample Naming Conventions for Visual Basic 278\\nTable 11-6 Sample of UDTs for a Word Processor 280\\nTable 11-7 Semantic Prefixes 280\\nTable 12-1 Ranges for Different Types of Integers 294\\nTable 13-1 Accessing Global Data Directly and Through Access Routines 341\\nTable 13-2 Parallel and Nonparallel Uses of Complex Data 342\\nTable 16-1 The Kinds of Loops 368\\nTable 19-1 Transformations of Logical Expressions Under DeMorgan’s Theorems 436\\nTable 19-2 Techniques for Counting the Decision Points in a Routine 458\\nTable 20-1 Team Ranking on Each Objective 469\\nTable 20-2 Defect-Detection Rates 470\\nTable 20-3 Extreme Programming’s Estimated Defect-Detection Rate 472\\nTable 21-1 Comparison of Collaborative Construction Techniques 495\\nTable 23-1 Examples of Psychological Distance Between Variable Names 556\\nTable 25-1 Relative Execution Time of Programming Languages 600\\nTable 25-2 Costs of Common Operations 601'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 31}, page_content='xxxii Tables\\nTable 27-1 Project Size and Typical Error Density 652\\nTable 27-2 Project Size and Productivity 653\\nTable 28-1 Factors That Influence Software-Project Effort 674\\nTable 28-2 Useful Software-Development Measurements 678\\nTable 28-3 One View of How Programmers Spend Their Time 681'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 32}, page_content='xxxiii\\nFigures\\nFigure 1-1 Construction activities are shown inside the gray circle. Construction \\nfocuses on coding and debugging but also includes detailed design, unit \\ntesting, integration testing, and other activities. 4\\nFigure 1-2 This book focuses on coding and debugging, detailed design, construction \\nplanning, unit testing, integration, integration testing, and other activities in \\nroughly these proportions. 5\\nFigure 2-1 The letter-writing metaphor suggests that the software process relies on \\nexpensive trial and error rather than careful planning and design. 14\\nFigure 2-2 It’s hard to extend the farming metaphor to software development \\nappropriately. 15\\nFigure 2-3 The penalty for a mistake on a simple structure is only a little time and \\nmaybe some embarrassment. 17\\nFigure 2-4 More complicated structures require more careful planning. 18\\nFigure 3-1 The cost to fix a defect rises dramatically as the time from when it’s intro-\\nduced to when it’s detected increases. This remains true whether the \\nproject is highly sequential (doing 100 percent of requirements and design \\nup front) or highly iterative (doing  5 percent of requirements and design \\nup front). 30\\nFigure 3-2 Activities will overlap to some degree on most projects, even those that are \\nhighly sequential. 35\\nFigure 3-3 On other projects, activities will overlap for the duration of the project. One \\nkey to successful construction is understanding the degree to which prereq-\\nuisites have been completed and adjusting your approach accordingly. 35\\nFigure 3-4 The problem definition lays the foundation for the rest of the programming \\nprocess. 37\\nFigure 3-5 Be sure you know what you’re aiming at before you shoot. 38\\nFigure 3-6 Without good requirements, you can have the right general problem but \\nmiss the mark on specific aspects of the problem. 39\\nFigure 3-7 Without good software architecture, you may have the right problem but the \\nwrong solution. It may be impossible to have successful construction. 44\\nFigure 5-1 The Tacoma Narrows bridge—an example of a wicked problem. 75'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 33}, page_content='xxxiv Figures\\nFigure 5-2 The levels of design in a program. The system (1) is first organized into sub-\\nsystems (2). The subsystems are further divided into classes (3), and the \\nclasses are divided into routines and data (4). The inside of each routine is \\nalso designed (5). 82\\nFigure 5-3 An example of a system with six subsystems. 83\\nFigure 5-4 An example of what happens with no restrictions on intersubsystem \\ncommunications. 83\\nFigure 5-5 With a few communication rules, you can simplify subsystem interactions \\nsignificantly. 84\\nFigure 5-6 This billing system is composed of four major objects. The objects have been \\nsimplified for this example. 88\\nFigure 5-7 Abstraction allows you to take a simpler view of a complex concept. 90\\nFigure 5-8 Encapsulation says that, not only are you allowed to take a simpler view of a \\ncomplex concept, you are not allowed to look at any of the details of the \\ncomplex concept. What you see is what you get—it’s all you get! 91\\nFigure 5-9 A good class interface is like the tip of an iceberg, leaving most of the class \\nunexposed. 93\\nFigure 5-10 G. Polya developed an approach to problem solving in mathematics that’s \\nalso useful in solving problems in software design (Polya 1957). 109\\nFigure 8-1 Part of the Interstate-90 floating bridge in Seattle sank during a storm \\nbecause the flotation tanks were left uncovered, they filled with water, and \\nthe bridge became too heavy to float. During construction, protecting your-\\nself against the small stuff matters more than you might think. 189\\nFigure 8-2 Defining some parts of the software that work with dirty data and some that \\nwork with clean data can be an effective way to relieve the majority of the \\ncode of the responsibility for checking for bad data. 204\\nFigure 9-1 Details of class construction vary, but the activities generally occur in the \\norder shown here. 216\\nFigure 9-2 These are the major activities that go into constructing a routine. They’re \\nusually performed in the order shown. 217\\nFigure 9-3 You’ll perform all of these steps as you design a routine but not necessarily \\nin any particular order. 225\\nFigure 10-1 “Long live time” means that a variable is live over the course of many state-\\nments. “Short live time” means it’s live for only a few statements. “Span” \\nrefers to how close together the references to a variable are. 246\\nFigure 10-2 Sequential data is data that’s handled in a defined order. 254\\nFigure 10-3 Selective data allows you to use one piece or the other, but not both. 255'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 34}, page_content='Figures xxxv\\nFigure 10-4 Iterative data is repeated. 255\\nFigure 13-1 The amount of memory used by each data type is shown by double \\nlines. 324\\nFigure 13-2 An example of a picture that helps us think through the steps involved in \\nrelinking pointers. 329\\nFigure 14-1 If the code is well organized into groups, boxes drawn around related sec-\\ntions don’t overlap. They might be nested. 352\\nFigure 14-2 If the code is organized poorly, boxes drawn around related sections \\noverlap. 353\\nFigure 17-1 Recursion can be a valuable tool in the battle against complexity—when used \\nto attack suitable problems. 394\\nFigure 18-1 As the name suggests, a direct-access table allows you to access the table ele-\\nment you’re interested in directly. 413\\nFigure 18-2 Messages are stored in no particular order, and each one is identified with a \\nmessage ID. 417\\nFigure 18-3 Aside from the Message ID, each kind of message has its own format. 418\\nFigure 18-4 Rather than being accessed directly, an indexed access table is accessed via \\nan intermediate index. 425\\nFigure 18-5 The stair-step approach categorizes each entry by determining the level at \\nwhich it hits a “staircase.” The “step” it hits determines its category. 426\\nFigure 19-1 Examples of using number-line ordering for boolean tests. 440\\nFigure 20-1 Focusing on one external characteristic of software quality can affect other \\ncharacteristics positively, adversely, or not at all. 466\\nFigure 20-2 Neither the fastest nor the slowest development approach produces the soft-\\nware with the most defects. 475\\nFigure 22-1 As the size of the project increases, developer testing consumes a smaller \\npercentage of the total development time. The effects of program size are \\ndescribed in more detail in Chapter 27, “How Program Size Affects \\nConstruction.” 502\\nFigure 22-2 As the size of the project increases, the proportion of errors committed dur-\\ning construction decreases. Nevertheless, construction errors account for \\n45–75% of all errors on even the largest projects. 521\\nFigure 23-1 Try to reproduce an error several different ways to determine its exact \\ncause. 545\\nFigure 24-1 Small changes tend to be more error-prone than larger changes (Weinberg \\n1983). 581'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 35}, page_content='xxxvi Figures\\nFigure 24-2 Your code doesn’t have to be messy just because the real world is messy. \\nConceive your system as a combination of ideal code, interfaces from the \\nideal code to the messy real world, and the messy real world. 583\\nFigure 24-3 One strategy for improving production code is to refactor poorly written leg-\\nacy code as you touch it, so as to move it to the other side of the “interface to \\nthe messy real world.” 584\\nFigure 27-1 The number of communication paths increases proportionate to the square \\nof the number of people on the team. 650\\nFigure 27-2 As project size increases, errors usually come more from requirements and \\ndesign. Sometimes they still come primarily from construction (Boehm \\n1981, Grady 1987, Jones 1998). 652\\nFigure 27-3 Construction activities dominate small projects. Larger projects require \\nmore architecture, integration work, and system testing to succeed. Require-\\nments work is not shown on this diagram because requirements effort is not \\nas directly a function of program size as other activities are (Albrecht 1979; \\nGlass 1982; Boehm, Gray, and Seewaldt 1984; Boddie 1987; Card 1987; \\nMcGarry, Waligora, and McDermott 1989; Brooks 1995; Jones 1998; Jones \\n2000; Boehm et al. 2000). 654\\nFigure 27-4 The amount of software construction work is a near-linear function of \\nproject size. Other kinds of work increase nonlinearly as project size \\nincreases. 655\\nFigure 28-1 This chapter covers the software-management topics related to \\nconstruction. 661\\nFigure 28-2 Estimates created early in a project are inherently inaccurate. As the project \\nprogresses, estimates can become more accurate. Reestimate periodically \\nthroughout a project, and use what you learn during each activity to improve \\nyour estimate for the next activity. 673\\nFigure 29-1 The football stadium add-on at the University of Washington collapsed \\nbecause it wasn’t strong enough to support itself during construction. It \\nlikely would have been strong enough when completed, but it was con-\\nstructed in the wrong order—an integration error. 690\\nFigure 29-2 Phased integration is also called “big bang” integration for a good \\nreason! 691\\nFigure 29-3 Incremental integration helps a project build momentum, like a snowball \\ngoing down a hill. 692'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 36}, page_content='Figures xxxvii\\nFigure 29-4 In phased integration, you integrate so many components at once that it’s \\nhard to know where the error is. It might be in any of the components or in \\nany of their connections. In incremental integration, the error is usually \\neither in the new component or in the connection between the new compo-\\nnent and the system. 693\\nFigure 29-5 In top-down integration, you add classes at the top first, at the bottom \\nlast. 695\\nFigure 29-6 As an alternative to proceeding strictly top to bottom, you can integrate from \\nthe top down in vertical slices. 696\\nFigure 29-7 In bottom-up integration, you integrate classes at the bottom first, at the top \\nlast. 697\\nFigure 29-8 As an alternative to proceeding purely bottom to top, you can integrate from \\nthe bottom up in sections. This blurs the line between bottom-up integration \\nand feature-oriented integration, which is described later in this \\nchapter. 698\\nFigure 29-9 In sandwich integration, you integrate top-level and widely used bottom-\\nlevel classes first and you save middle-level classes for last. 698\\nFigure 29-10 In risk-oriented integration, you integrate classes that you expect to be most \\ntroublesome first; you implement easier classes later. 699\\nFigure 29-11 In feature-oriented integration, you integrate classes in groups that make up \\nidentifiable features—usually, but not always, multiple classes at a \\ntime. 700\\nFigure 29-12 In T-shaped integration, you build and integrate a deep slice of the system to \\nverify architectural assumptions and then you build and integrate the \\nbreadth of the system to provide a framework for developing the remaining \\nfunctionality. 701\\nFigure 34-1 Programs can be divided into levels of abstraction. A good design will allow \\nyou to spend much of your time focusing on only the upper layers and ignor-\\ning the lower layers. 846'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 37}, page_content='Part I\\nLaying the Foundation\\nIn this part:\\nChapter 1: Welcome to Software Construction . . . . . . . . . . . . . . . . . . . . . . .3\\nChapter 2: Metaphors for a Richer Understanding of \\nSoftware Development . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9\\nChapter 3: Measure Twice, Cut Once: Upst ream Prerequisites  . . . . . . . . .23\\nChapter 4: Key Construction Decisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .61'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 39}, page_content='3\\nChapter 1\\nWelcome to Software \\nConstruction\\ncc2e.com/0178 Contents\\n■ 1.1 What Is Software Construction?: page 3\\n■ 1.2 Why Is Software Construction Important?: page 6\\n■ 1.3 How to Read This Book: page 8\\nRelated Topics\\n■ Who should read this book: Preface \\n■ Benefits of reading the book: Preface \\n■ Why the book was written: Preface\\nYou know what “construction” means when it’s used outside software development. \\n“Construction” is the work “construction workers” do when they build a house, a \\nschool, or a skyscraper. When you were younger, you built things out of “construction \\npaper.” In common usage, “construction” refers to the process of building. The con-\\nstruction process might include some aspects of planning, designing, and checking \\nyour work, but mostly “construction” refers to the hands-on part of creating something.\\n1.1 What Is Software Construction?\\nDeveloping computer software can be a complicated process, and in the last 25 years, \\nresearchers have identified numerous distinct activities that go into software develop-\\nment. They include\\n■ Problem definition\\n■ Requirements development \\n■ Construction planning\\n■ Software architecture, or high-level design\\n■ Detailed design\\n■ Coding and debugging \\n■ Unit testing'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 40}, page_content='4 Chapter 1: Welcome to Software Construction\\n■ Integration testing\\n■ Integration\\n■ System testing\\n■ Corrective maintenance\\nIf you’ve worked on informal projects, you might think that this list represents a lot of \\nred tape. If you’ve worked on projects that are too formal, you know that this list rep-\\nresents a lot of red tape! It’s hard to strike a balance between too little and too much \\nformality, and that’s discussed later in the book.\\nIf you’ve taught yourself to program or worked mainly on informal projects, you might \\nnot have made distinctions among the many activities that go into creating a software \\nproduct. Mentally, you might have grouped all of these activities together as “program-\\nming.” If you work on informal projects, the main activity you think of when you think \\nabout creating software is probably the activity the researchers refer to as “construction.”\\nThis intuitive notion of “construction” is fairly accurate, but it suffers from a lack of \\nperspective. Putting construction in its context with other activities helps keep the \\nfocus on the right tasks during construction and appropriately emphasizes important \\nnonconstruction activities. Figure 1-1 illustrates construction’s place related to other \\nsoftware-development activities.\\nFigure 1-1 Construction activities are shown inside the gray circle. Construction focuses on \\ncoding and debugging but also includes detailed design, unit testing, integration testing, \\nand other activities.\\nProblem\\nDefinition\\nRequirements\\nDevelopment\\nSoftware\\nArchitecture System\\nTesting\\nDetailed\\nDesign\\nCoding and\\nDebuggingConstruction\\nPlanning\\nIntegration\\nCorrective\\nMaintenance\\nUnit\\nTesting\\nIntegration\\nTesting'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 41}, page_content='1.1 What Is Software Construction? 5\\nAs the figure indicates, construction is mostly coding and debugging but also involves \\ndetailed design, construction planning, unit testing, integration, integration testing, \\nand other activities. If this were a book about all aspects of software development, it \\nwould feature nicely balanced discussions of all activities in the development process. \\nBecause this is a handbook of construction techniques, however, it places a lopsided \\nemphasis on construction and only touches on related topics. If this book were a dog, \\nit would nuzzle up to construction, wag its tail at design and testing, and bark at the \\nother development activities.\\nConstruction is also sometimes known as “coding” or “programming.” “Coding” isn’t \\nreally the best word because it implies the mechanical translation of a preexisting \\ndesign into a computer language; construction is not at all mechanical and involves \\nsubstantial creativity and judgment. Throughout the book, I use “programming” inter-\\nchangeably with “construction.”\\nIn contrast to Figure 1-1’s flat-earth view of software development, Figure 1-2 shows \\nthe round-earth perspective of this book.\\nFigure 1-2 This book focuses on coding and debugging, detailed design, construction \\nplanning, unit testing, integration, integration testing, and other activities in roughly these \\nproportions.\\nFigure 1-1 and Figure 1-2 are high-level views of construction activities, but what \\nabout the details? Here are some of the specific tasks involved in construction:\\n■ Verifying that the groundwork has been laid so that construction can proceed \\nsuccessfully\\n■ Determining how your code will be tested\\nKEY POINT\\nDetailed \\nDesign\\nIntegration\\nUnit \\nTesting\\nIntegration \\nTesting\\nRequirements \\nDevelopment\\nProblem \\nDefinition\\nSoftware \\nArchitecture\\nSystem \\nTesting\\nCorrective \\nMaintenance\\nConstruction \\nPlanning\\nCoding and \\nDebugging'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 42}, page_content='6 Chapter 1: Welcome to Software Construction\\n■ Designing and writing classes and routines \\n■ Creating and naming variables and named constants\\n■ Selecting control structures and organizing blocks of statements\\n■ Unit testing, integration testing, and debugging your own code\\n■ Reviewing other team members’ low-level designs and code and having them \\nreview yours\\n■ Polishing code by carefully formatting and commenting it\\n■ Integrating software components that were created separately\\n■ Tuning code to make it faster and use fewer resources\\nFor an even fuller list of construction activities, look through the chapter titles in the \\ntable of contents.\\nWith so many activities at work in construction, you might say, “OK, Jack, what activ-\\nities are not part of construction?” That’s a fair question. Important nonconstruction \\nactivities include management, requirements development, software architecture, \\nuser-interface design, system testing, and maintenance. Each of these activities affects \\nthe ultimate success of a project as much as construction—at least the success of any \\nproject that calls for more than one or two people and lasts longer than a few weeks. \\nYou can find good books on each activity; many are listed in the “Additional \\nResources” sections throughout the book and in Chapter 35, “Where to Find More \\nInformation,” at the end of the book.\\n1.2 Why Is Software Construction Important?\\nSince you’re reading this book, you probably agree that improving software quality \\nand developer productivity is important. Many of today’s most exciting projects use \\nsoftware extensively. The Internet, movie special effects, medical life-support systems, \\nspace programs, aeronautics, high-speed financial analysis, and scientific research are \\na few examples. These projects and more conventional projects can all benefit from \\nimproved practices because many of the fundamentals are the same. \\nIf you agree that improving software development is important in general, the question \\nfor you as a reader of this book becomes, Why is construction an important focus?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 43}, page_content='1.2 Why Is Software Construction Important? 7\\nHere’s why:\\nCross-Reference For details \\non the relationship between \\nproject size and the percent-\\nage of time consumed by \\nconstruction, see “Activity \\nProportions and Size” in Sec-\\ntion 27.5.\\nConstruction is a large part of software development Depending on the size of the \\nproject, construction typically takes 30 to 80 percent of the total time spent on a \\nproject. Anything that takes up that much project time is bound to affect the success \\nof the project.\\nConstruction is the central activity in software development Requirements and \\narchitecture are done before construction so that you can do construction effectively. \\nSystem testing (in the strict sense of independent testing) is done after construction \\nto verify that construction has been done correctly. Construction is at the center of the \\nsoftware-development process.\\nCross-Reference For data on \\nvariations among program-\\nmers, see “Individual Varia-\\ntion” in Section 28.5.\\nWith a focus on construction, the individual programmer’s productivity can improve \\nenormously A classic study by Sackman, Erikson, and Grant showed that the pro-\\nductivity of individual programmers varied by a factor of 10 to 20 during construction \\n(1968). Since their study, their results have been confirmed by numerous other stud-\\nies (Curtis 1981, Mills 1983, Curtis et al. 1986, Card 1987, Valett and McGarry 1989, \\nDeMarco and Lister 1999, Boehm et al. 2000). This book helps all programmers learn \\ntechniques that are already used by the best programmers. \\nConstruction’s product, the source code, is often the only accurate description of the \\nsoftware In many projects, the only documentation available to programmers is the \\ncode itself. Requirements specifications and design documents can go out of date, but \\nthe source code is always up to date. Consequently, it’s imperative that the source \\ncode be of the highest possible quality. Consistent application of techniques for \\nsource-code improvement makes the difference between a Rube Goldberg contraption \\nand a detailed, correct, and therefore informative program. Such techniques are most \\neffectively applied during construction.\\nConstruction is the only activity that’s guaranteed to be done The ideal software \\nproject goes through careful requirements development and architectural design \\nbefore construction begins. The ideal project undergoes comprehensive, statistically \\ncontrolled system testing after construction. Imperfect, real-world projects, however, \\noften skip requirements and design to jump into construction. They drop testing \\nbecause they have too many errors to fix and they’ve run out of time. But no matter \\nhow rushed or poorly planned a project is, you can’t drop construction; it’s where the \\nrubber meets the road. Improving construction is thus a way of improving any soft-\\nware-development effort, no matter how abbreviated.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 44}, page_content='8 Chapter 1: Welcome to Software Construction\\n1.3 How to Read This Book\\nThis book is designed to be read either cover to cover or by topic. If you like to read \\nbooks cover to cover, you might simply dive into Chapter 2, “Metaphors for a Richer \\nUnderstanding of Software Development.” If you want to get to specific programming \\ntips, you might begin with Chapter 6, “Working Classes,” and then follow the cross ref-\\nerences to other topics you find interesting. If you’re not sure whether any of this applies \\nto you, begin with Section 3.2, “Determine the Kind of Software You’re Working On.”\\nKey Points\\n■ Software construction is the central activity in software development; construc-\\ntion is the only activity that’s guaranteed to happen on every project. \\n■ The main activities in construction are detailed design, coding, debugging, inte-\\ngration, and developer testing (unit testing and integration testing).\\n■ Other common terms for construction are “coding” and “programming.”\\n■ The quality of the construction substantia lly affects the quality of the software.\\n■ In the final analysis, your understanding of how to do construction determines \\nhow good a programmer you are, and that’s the subject of the rest of the book.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 45}, page_content='9\\nChapter 2\\nMetaphors for a Richer \\nUnderstanding of Software \\nDevelopment\\ncc2e.com/0278 Contents\\n■ 2.1 The Importance of Metaphors: page 9\\n■ 2.2 How to Use Software Metaphors: page 11\\n■ 2.3 Common Software Metaphors: page 13\\nRelated Topic\\n■ Heuristics in design: “Design Is a Heuristic Process” in Section 5.1 \\nComputer science has some of the most colorful language of any field. In what other \\nfield can you walk into a sterile room, carefully controlled at 68°F, and find viruses, \\nTrojan horses, worms, bugs, bombs, crashes, flames, twisted sex changers, and fatal \\nerrors?\\nThese graphic metaphors describe specific software phenomena. Equally vivid meta-\\nphors describe broader phenomena, and you can use them to improve your under-\\nstanding of the software-development process.\\nThe rest of the book doesn’t directly depend on the discussion of metaphors in this \\nchapter. Skip it if you want to get to the practical suggestions. Read it if you want to \\nthink about software development more clearly.\\n2.1 The Importance of Metaphors\\nImportant developments often arise out of analogies. By comparing a topic you under-\\nstand poorly to something similar you understand better, you can come up with \\ninsights that result in a better understanding of the less-familiar topic. This use of met-\\naphor is called “modeling.”\\nThe history of science is full of discoveries based on exploiting the power of meta-\\nphors. The chemist Kekulé had a dream in which he saw a snake grasp its tail in its \\nmouth. When he awoke, he realized that a molecular structure based on a similar ring \\nshape would account for the properties of benzene. Further experimentation con-\\nfirmed the hypothesis (Barbour 1966).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 46}, page_content='10 Chapter 2: Metaphors for a Richer Understanding of Software Development\\nThe kinetic theory of gases was based on a “billiard-ball” model. Gas molecules were \\nthought to have mass and to collide elastically, as billiard balls do, and many useful \\ntheorems were developed from this model.\\nThe wave theory of light was developed largely by exploring similarities between light \\nand sound. Light and sound have amplitude (brightness, loudness), frequency (color, \\npitch), and other properties in common. The comparison between the wave theories \\nof sound and light was so productive that scientists spent a great deal of effort looking \\nfor a medium that would propagate light the way air propagates sound. They even \\ngave it a name —“ether”—but they never found the medium. The analogy that had been \\nso fruitful in some ways proved to be misleading in this case.\\nIn general, the power of models is that they’re vivid and can be grasped as conceptual \\nwholes. They suggest properties, relationships, and additional areas of inquiry. Some-\\ntimes a model suggests areas of inquiry that are misleading, in which case the meta-\\nphor has been overextended. When the scientists looked for ether, they overextended \\ntheir model.\\nAs you might expect, some metaphors are better than others. A good metaphor is sim-\\nple, relates well to other relevant metaphors, and explains much of the experimental \\nevidence and other observed phenomena.\\nConsider the example of a heavy stone swinging back and forth on a string. Before \\nGalileo, an Aristotelian looking at the swinging stone thought that a heavy object \\nmoved naturally from a higher position to a state of rest at a lower one. The Aristote-\\nlian would think that what the stone was really doing was falling with difficulty. When \\nGalileo saw the swinging stone, he saw a pendulum. He thought that what the stone \\nwas really doing was repeating the same motion again and again, almost perfectly.\\nThe suggestive powers of the two models are quite different. The Aristotelian who saw \\nthe swinging stone as an object falling would observe the stone’s weight, the height to \\nwhich it had been raised, and the time it took to come to rest. For Galileo’s pendulum \\nmodel, the prominent factors were different. Galileo observed the stone’s weight, the \\nradius of the pendulum’s swing, the angular displacement, and the time per swing. \\nGalileo discovered laws the Aristotelians could not discover because their model led \\nthem to look at different phenomena and ask different questions.\\nMetaphors contribute to a greater understanding of software-development issues in \\nthe same way that they contribute to a greater understanding of scientific questions. \\nIn his 1973 Turing Award lecture, Charles Bachman described the change from the \\nprevailing earth-centered view of the universe to a sun-centered view. Ptolemy’s earth-\\ncentered model had lasted without serious challenge for 1400 years. Then in 1543, \\nCopernicus introduced a heliocentric theory, the idea that the sun rather than the \\nearth was the center of the universe. This change in mental models led ultimately to \\nthe discovery of new planets, the reclassification of the moon as a satellite rather than \\nas a planet, and a different understanding of humankind’s place in the universe.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 47}, page_content='2.2 How to Use Software Metaphors 11\\nThe value of metaphors \\nshould not be underesti-\\nmated. Metaphors have the \\nvirtue of an expected behav-\\nior that is understood by all. \\nUnnecessary communication \\nand misunderstandings are \\nreduced. Learning and edu-\\ncation are quicker. In effect, \\nmetaphors are a way of \\ninternalizing and abstracting \\nconcepts, allowing one’s \\nthinking to be on a higher \\nplane and low-level mistakes \\nto be avoided.\\n—Fernando J. Corbató\\nBachman compared the Ptolemaic-to-Copernican change in astronomy to the change \\nin computer programming in the early 1970s. When Bachman made the comparison \\nin 1973, data processing was changing from a computer-centered view of information \\nsystems to a database-centered view. Bachman pointed out that the ancients of data \\nprocessing wanted to view all data as a sequential stream of cards flowing through a \\ncomputer (the computer-centered view). The change was to focus on a pool of data on \\nwhich the computer happened to act (a database-oriented view).\\nToday it’s difficult to imagine anyone thinking that the sun moves around the earth. \\nSimilarly, it’s difficult to imagine a programmer thinking that all data could be viewed \\nas a sequential stream of cards. In both cases, once the old theory has been discarded, \\nit seems incredible that anyone ever believed it at all. More fantastically, people who \\nbelieved the old theory thought the new theory was just as ridiculous then as you \\nthink the old theory is now.\\nThe earth-centered view of the universe hobbled astronomers who clung to it after a \\nbetter theory was available. Similarly, the computer-centered view of the computing \\nuniverse hobbled computer scientists who held on to it after the database-centered \\ntheory was available.\\nIt’s tempting to trivialize the power of metaphors. To each of the earlier examples, the \\nnatural response is to say, “Well, of course the right metaphor is more useful. The \\nother metaphor was wrong!” Though that’s a natural reaction, it’s simplistic. The his-\\ntory of science isn’t a series of switches from the “wrong” metaphor to the “right” one. \\nIt’s a series of changes from “worse” metaphors to “better” ones, from less inclusive to \\nmore inclusive, from suggestive in one area to suggestive in another.\\nIn fact, many models that have been replaced by better models are still useful. Engineers \\nstill solve most engineering problems by using Newtonian dynamics even though, the-\\noretically, Newtonian dynamics have been supplanted by Einsteinian theory.\\nSoftware development is a younger field than most other sciences. It’s not yet mature \\nenough to have a set of standard metaphors. Consequently, it has a profusion of com-\\nplementary and conflicting metaphors. Some are better than others. Some are worse. \\nHow well you understand the metaphors determines how well you understand soft-\\nware development.\\n2.2 How to Use Software Metaphors\\nA software metaphor is more like a searchlight than a road map. It doesn’t tell you \\nwhere to find the answer; it tells you how to look for it. A metaphor serves more as a \\nheuristic than it does as an algorithm.\\nAn algorithm is a set of well-defined instructions for carrying out a particular task. An \\nalgorithm is predictable, deterministic, and not subject to chance. An algorithm tells \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 48}, page_content='12 Chapter 2: Metaphors for a Richer Understanding of Software Development\\nyou how to go from point A to point B with no detours, no side trips to points D, E, \\nand F, and no stopping to smell the roses or have a cup of joe.\\nA heuristic is a technique that helps you look for an answer. Its results are subject to \\nchance because a heuristic tells you only how to look, not what to find. It doesn’t tell \\nyou how to get directly from point A to point B; it might not even know where point A \\nand point B are. In effect, a heuristic is an algorithm in a clown suit. It’s less predict-\\nable, it’s more fun, and it comes without a 30-day, money-back guarantee.\\nHere is an algorithm for driving to someone’s house: Take Highway 167 south to Puy-\\nallup. Take the South Hill Mall exit and drive 4.5 miles up the hill. Turn right at the \\nlight by the grocery store, and then take the first left. Turn into the driveway of the \\nlarge tan house on the left, at 714 North Cedar.\\nCross-Reference For details \\non how to use heuristics in \\ndesigning software, see \\n“Design Is a Heuristic Pro-\\ncess” in Section 5.1.\\nHere’s a heuristic for getting to someone’s house: Find the last letter we mailed you. \\nDrive to the town in the return address. When you get to town, ask someone where \\nour house is. Everyone knows us—someone will be glad to help you. If you can’t find \\nanyone, call us from a public phone, and we’ll come get you.\\nThe difference between an algorithm and a heuristic is subtle, and the two terms over-\\nlap somewhat. For the purposes of this book, the main difference between the two is \\nthe level of indirection from the solution. An algorithm gives you the instructions \\ndirectly. A heuristic tells you how to discover the instructions for yourself, or at least \\nwhere to look for them.\\nHaving directions that told you exactly how to solve your programming problems \\nwould certainly make programming easier and the results more predictable. But pro-\\ngramming science isn’t yet that advanced and may never be. The most challenging \\npart of programming is conceptualizing the problem, and many errors in program-\\nming are conceptual errors. Because each program is conceptually unique, it’s difficult \\nor impossible to create a general set of directions that lead to a solution in every case. \\nThus, knowing how to approach problems in general is at least as valuable as knowing \\nspecific solutions for specific problems.\\nHow do you use software metaphors? Use them to give you insight into your program-\\nming problems and processes. Use them to help you think about your programming \\nactivities and to help you imagine better ways of doing things. You won’t be able to \\nlook at a line of code and say that it violates one of the metaphors described in this \\nchapter. Over time, though, the person who uses metaphors to illuminate the soft-\\nware-development process will be perceived as someone who has a better understand-\\ning of programming and produces better code faster than people who don’t use them.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 49}, page_content='2.3 Common Software Metaphors 13\\n2.3 Common Software Metaphors\\nA confusing abundance of metaphors has grown up around software development. \\nDavid Gries says writing software is a science (1981). Donald Knuth says it’s an art \\n(1998). Watts Humphrey says it’s a process (1989). P. J. Plauger and Kent Beck say it’s \\nlike driving a car, although they draw nearly opposite conclusions (Plauger 1993, \\nBeck 2000). Alistair Cockburn says it’s a game (2002). Eric Raymond says it’s like a \\nbazaar (2000). Andy Hunt and Dave Thomas say it’s like gardening. Paul Heckel says \\nit’s like filming Snow White and the Seven Dwarfs (1994). Fred Brooks says that it’s like \\nfarming, hunting werewolves, or drowning with dinosaurs in a tar pit (1995). Which \\nare the best metaphors? \\nSoftware Penmanship: Writing Code\\nThe most primitive metaphor for software development grows out of the expression \\n“writing code.” The writing metaphor suggests that developing a program is like writing \\na casual letter—you sit down with pen, ink, and paper and write it from start to finish. It \\ndoesn’t require any formal planning, and you figure out what you want to say as you go.\\nMany ideas derive from the writing metaphor. Jon Bentley says you should be able to \\nsit down by the fire with a glass of brandy, a good cigar, and your favorite hunting dog \\nto enjoy a “literate program” the way you would a good novel. Brian Kernighan and \\nP. J. Plauger named their programming-style book The Elements of Programming Style \\n(1978) after the writing-style book The Elements of Style (Strunk and White 2000). \\nProgrammers often talk about “program readability.”\\nFor an individual’s work or for small-scale projects, the letter-writing metaphor works \\nadequately, but for other purposes it leaves the party early—it doesn’t describe soft-\\nware development fully or adequately. Writing is usually a one-person activity, \\nwhereas a software project will most likely involve many people with many different \\nresponsibilities. When you finish writing a letter, you stuff it into an envelope and mail \\nit. You can’t change it anymore, and for all intents and purposes it’s complete. Soft-\\nware isn’t as difficult to change and is hardly ever fully complete. As much as 90 per-\\ncent of the development effort on a typical software system comes after its initial \\nrelease, with two-thirds being typical (Pigoski 1997). In writing, a high premium is \\nplaced on originality. In software construction, trying to create truly original work is \\noften less effective than focusing on the reuse of design ideas, code, and test cases \\nfrom previous projects. In short, the writing metaphor implies a software-develop-\\nment process that’s too simple and rigid to be healthy.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 50}, page_content='14 Chapter 2: Metaphors for a Richer Understanding of Software Development\\nPlan to throw one away; you \\nwill, anyhow. \\n—Fred Brooks\\nIf you plan to throw one \\naway, you will throw away \\ntwo.\\n —Craig Zerouni\\nUnfortunately, the letter-writing metaphor has been perpetuated by one of the most \\npopular software books on the planet, Fred Brooks’s The Mythical Man-Month (Brooks \\n1995). Brooks says, “Plan to throw one away; you will, anyhow.” This conjures up an \\nimage of a pile of half-written drafts thrown into a wastebasket, as shown in Figure 2-1.\\nFigure 2-1 The letter-writing metaphor suggests that the software process relies on expen-\\nsive trial and error rather than careful planning and design.\\nPlanning to throw one away might be practical when you’re writing a polite how-do-\\nyou-do to your aunt. But extending the metaphor of “writing” software to a plan to \\nthrow one away is poor advice for software development, where a major system \\nalready costs as much as a 10-story office building or an ocean liner. It’s easy to grab \\nthe brass ring if you can afford to sit on your favorite wooden pony for an unlimited \\nnumber of spins around the carousel. The trick is to get it the first time around—or to \\ntake several chances when they’re cheapest. Other metaphors better illuminate ways \\nof attaining such goals.\\nSoftware Farming: Growing a System\\nIn contrast to the rigid writing metaphor, some software developers say you should \\nenvision creating software as something like planting seeds and growing crops. You \\ndesign a piece, code a piece, test a piece, and add it to the system a little bit at a time. \\nBy taking small steps, you minimize the trouble you can get into at any one time.\\nSometimes a good technique is described with a bad metaphor. In such cases, try to \\nkeep the technique and come up with a better metaphor. In this case, the incremental \\ntechnique is valuable, but the farming metaphor is terrible. \\nFurther Reading For an \\nillustration of a different \\nfarming metaphor, one that’s \\napplied to software mainte-\\nnance, see the chapter “On \\nthe Origins of Designer Intu-\\nition” in Rethinking Systems \\nAnalysis and Design (Wein-\\nberg 1988).\\nThe idea of doing a little bit at a time might bear some resemblance to the way crops \\ngrow, but the farming analogy is weak and uninformative, and it’s easy to replace with \\nthe better metaphors described in the following sections. It’s hard to extend the farm-\\ning metaphor beyond the simple idea of doing things a little bit at a time. If you buy \\ninto the farming metaphor, imagined in Figure 2-2, you might find yourself talking \\nabout fertilizing the system plan, thinning the detailed design, increasing code yields \\nthrough effective land management, and harvesting the code itself. You’ll talk about \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 51}, page_content='2.3 Common Software Metaphors 15\\nrotating in a crop of C++ instead of barley, of letting the land rest for a year to increase \\nthe supply of nitrogen in the hard disk.\\nThe weakness in the software-farming metaphor is its suggestion that you don’t have \\nany direct control over how the software develops. You plant the code seeds in the \\nspring. Farmer’s Almanac and the Great Pumpkin willing, you’ll have a bumper crop of \\ncode in the fall.\\nFigure 2-2 It’s hard to extend the farming metaphor to software development \\nappropriately. \\nSoftware Oyster Farming: System Accretion\\nSometimes people talk about growing software when they really mean software accre-\\ntion. The two metaphors are closely related, but software accretion is the more insight-\\nful image. “Accretion,” in case you don’t have a dictionary handy, means any growth or \\nincrease in size by a gradual external addition or inclusion. Accretion describes the \\nway an oyster makes a pearl, by gradually adding small amounts of calcium carbonate. \\nIn geology, “accretion” means a slow addition to land by the deposit of waterborne \\nsediment. In legal terms, “accretion” means an increase of land along the shores of a \\nbody of water by the deposit of waterborne sediment.\\nCross-Reference For details \\non how to apply incremental \\nstrategies to system integra-\\ntion, see Section 29.2, “Inte-\\ngration Frequency—Phased \\nor Incremental?”\\nThis doesn’t mean that you have to learn how to make code out of waterborne sedi-\\nment; it means that you have to learn how to add to your software systems a small \\namount at a time. Other words closely related to accretion are “incremental,” “itera-\\ntive,” “adaptive,” and “evolutionary.” Incremental designing, building, and testing are \\nsome of the most powerful software-development concepts available. \\nIn incremental development, you first make the simplest possible version of the sys-\\ntem that will run. It doesn’t have to accept realistic input, it doesn’t have to perform \\nrealistic manipulations on data, it doesn’t have to produce realistic output—it just has \\nto be a skeleton strong enough to hold the real system as it’s developed. It might call \\ndummy classes for each of the basic functions you have identified. This basic begin-\\nning is like the oyster’s beginning a pearl with a small grain of sand.\\nAfter you’ve formed the skeleton, little by little you lay on the muscle and skin. You \\nchange each of the dummy classes to real classes. Instead of having your program'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 52}, page_content='16 Chapter 2: Metaphors for a Richer Understanding of Software Development\\npretend to accept input, you drop in code that accepts real input. Instead of having \\nyour program pretend to produce output, you drop in code that produces real output. \\nYou add a little bit of code at a time until you have a fully working system.\\nThe anecdotal evidence in favor of this approach is impressive. Fred Brooks, who in \\n1975 advised building one to throw away, said that nothing in the decade after he \\nwrote his landmark book The Mythical Man-Month  so radically changed his own \\npractice or its effectivenes s as incremental development (1995). Tom Gilb made the \\nsame point in his breakthrough book, Principles of Software Engineering Management \\n(1988), which introduced Evolutionary Delivery and laid the groundwork for much \\nof today’s Agile programming approach. Numerous current methodologies are based \\non this idea (Beck 2000, Cockburn 2002,  Highsmith 2002, Reifer 2002, Martin \\n2003, Larman 2004).\\nAs a metaphor, the strength of the incremental metaphor is that it doesn’t overpromise. \\nIt’s harder than the farming metaphor to extend inappropriately. The image of an oyster \\nforming a pearl is a good way to visualize incremental development, or accretion.\\nSoftware Construction: Building Software\\nThe image of “building” software is more useful than that of “writing” or “growing” \\nsoftware. It’s compatible with the idea of software accretion and provides more \\ndetailed guidance. Building software implies various stages of planning, preparation, \\nand execution that vary in kind and degree depending on what’s being built. When \\nyou explore the metaphor, you find many other parallels.\\nBuilding a four-foot tower requires a steady hand, a level surface, and 10 undamaged \\nbeer cans. Building a tower 100 times that size doesn’t merely require 100 times as \\nmany beer cans. It requires a different kind of planning and construction altogether.\\nIf you’re building a simple structure—a doghouse, say—you can drive to the lumber \\nstore and buy some wood and nails. By the end of the afternoon, you’ll have a new \\nhouse for Fido. If you forget to provide for a door, as shown in Figure 2-3, or make \\nsome other mistake, it’s not a big problem; you can fix it or even start over from the \\nbeginning. All you’ve wasted is part of an afternoon. This loose approach is appropri-\\nate for small software projects too. If you use the wrong design for 1000 lines of code, \\nyou can refactor or start over completely without losing much. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 53}, page_content='2.3 Common Software Metaphors 17\\nFigure 2-3 The penalty for a mistake on a simple structure is only a little time and maybe \\nsome embarrassment.\\nIf you’re building a house, the building process is more complicated, and so are the \\nconsequences of poor design. First you have to decide what kind of house you want to \\nbuild—analogous in software development to problem definition. Then you and an \\narchitect have to come up with a general design and get it approved. This is similar to \\nsoftware architectural design. You draw detailed blueprints and hire a contractor. This \\nis similar to detailed software design. You prepare the building site, lay a foundation, \\nframe the house, put siding and a roof on it, and plumb and wire it. This is similar to \\nsoftware construction. When most of the house is done, the landscapers, painters, \\nand decorators come in to make the best of your property and the home you’ve built. \\nThis is similar to software optimization. Throughout the process, various inspectors \\ncome to check the site, foundation, frame, wiring, and other inspectables. This is sim-\\nilar to software reviews and inspections.\\nGreater complexity and size imply greater consequences in both activities. In building \\na house, materials are somewhat expensive, but the main expense is labor. Ripping \\nout a wall and moving it six inches is expensive not because you waste a lot of nails \\nbut because you have to pay the people for the extra time it takes to move the wall. You \\nhave to make the design as good as possible, as suggested by Figure 2-4, so that you \\ndon’t waste time fixing mistakes that could have been avoided. In building a software \\nproduct, materials are even less expensive, but labor costs just as much. Changing a \\nreport format is just as expensive as moving a wall in a house because the main cost \\ncomponent in both cases is people’s time.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 54}, page_content='18 Chapter 2: Metaphors for a Richer Understanding of Software Development\\nFigure 2-4 More complicated structures require more careful planning.\\nWhat other parallels do the two activities share? In building a house, you won’t try to \\nbuild things you can buy already built. You’ll buy a washer and dryer, dishwasher, \\nrefrigerator, and freezer. Unless you’re a mechanical wizard, you won’t consider build-\\ning them yourself. You’ll also buy prefabricated cabinets, counters, windows, doors, \\nand bathroom fixtures. If you’re building a software system, you’ll do the same thing. \\nYou’ll make extensive use of high-level language features rather than writing your own \\noperating-system-level code. You might also use prebuilt libraries of container classes, \\nscientific functions, user interface classes, and database-manipulation classes. It gen-\\nerally doesn’t make sense to code things you can buy ready-made.\\nIf you’re building a fancy house with first-class furnishings, however, you might have \\nyour cabinets custom-made. You might have a dishwasher, refrigerator, and freezer \\nbuilt in to look like the rest of your cabinets. You might have windows custom-made in \\nunusual shapes and sizes. This customization has parallels in software development. \\nIf you’re building a first-class software product, you might build your own scientific \\nfunctions for better speed or accuracy. You might build your own container classes, \\nuser interface classes, and database classes to give your system a seamless, perfectly \\nconsistent look and feel.\\nBoth building construction and software construction benefit from appropriate levels \\nof planning. If you build software in the wrong order, it’s hard to code, hard to test, \\nand hard to debug. It can take longer to complete, or the project can fall apart because \\neveryone’s work is too complex and therefore too confusing when it’s all combined. \\nCareful planning doesn’t necessarily mean exhaustive planning or over-planning. You \\ncan plan out the structural supports and decide later whether to put in hardwood \\nfloors or carpeting, what color to paint the walls, what roofing material to use, and so'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 55}, page_content='2.3 Common Software Metaphors 19\\non. A well-planned project improves your ability to change your mind later about \\ndetails. The more experience you have with the kind of software you’re building, the \\nmore details you can take for granted. You just want to be sure that you plan enough \\nso that lack of planning doesn’t create major problems later.\\nThe construction analogy also helps explain why different software projects benefit \\nfrom different development approaches. In building, you’d use different levels of plan-\\nning, design, and quality assurance if you’re building a warehouse or a toolshed than if \\nyou’re building a medical center or a nuclear reactor. You’d use still different approaches \\nfor building a school, a skyscraper, or a three-bedroom home. Likewise, in software you \\nmight generally use flexible, lightweight development approaches, but sometimes you’ll \\nneed rigid, heavyweight approaches to achieve safety goals and other goals. \\nMaking changes in the software brings up another parallel with building construc-\\ntion. To move a wall six inches costs more if the wall is load-bearing than if it’s merely \\na partition between rooms. Similarly, making structural changes in a program costs \\nmore than adding or deleting peripheral features.\\nFinally, the construction analogy provides insight into extremely large software projects. \\nBecause the penalty for failure in an extremely large structure is severe, the structure has \\nto be over-engineered. Builders make and inspect their plans carefully. They build in \\nmargins of safety; it’s better to pay 10 percent more for stronger material than to have a \\nskyscraper fall over. A great deal of attention is paid to timing. When the Empire State \\nBuilding was built, each delivery truck had a 15-minute margin in which to make its \\ndelivery. If a truck wasn’t in place at the right time, the whole project was delayed.\\nLikewise, for extremely large software projects, planning of a higher order is needed \\nthan for projects that are merely large. Capers Jones reports that a software system \\nwith one million lines of code requires an average of 69 kinds of documentation \\n(1998). The requirements specification for such a system would typically be about \\n4000–5000 pages long, and the design documentation can easily be two or three \\ntimes as extensive as the requirements. It’s unlikely that an individual would be able \\nto understand the complete design for a project of this size—or even read it. A greater \\ndegree of preparation is appropriate. \\nWe build software projects comparable in economic size to the Empire State Building, \\nand technical and managerial controls of similar stature are needed. \\nFurther Reading For some \\ngood comments about \\nextending the construction \\nmetaphor, see “What Sup-\\nports the Roof?” (Starr 2003). \\nThe building-construction metaphor could be extended in a variety of other directions, \\nwhich is why the metaphor is so powerful. Many terms common in software develop-\\nment derive from the building metaphor: software architecture, scaffolding, construc-\\ntion, foundation classes, and tearing code apart. You’ll probably hear many more.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 56}, page_content='20 Chapter 2: Metaphors for a Richer Understanding of Software Development\\nApplying Software Techniques: The Intellectual Toolbox \\nPeople who are effective at developing high-quality software have spent years accumu-\\nlating dozens of techniques, tricks, and magic incantations. The techniques are not \\nrules; they are analytical tools. A good craftsman knows the right tool for the job and \\nknows how to use it correctly. Programmers do, too. The more you learn about pro-\\ngramming, the more you fill your mental toolbox with analytical tools and the knowl-\\nedge of when to use them and how to use them correctly.\\nCross-Reference For details \\non selecting and combining \\nmethods in design, see Sec-\\ntion 5.3, “Design Building \\nBlocks: Heuristics.”\\nIn software, consultants sometimes tell you to buy into certain software-development \\nmethods to the exclusion of other methods. That’s unfortunate because if you buy \\ninto any single methodology 100 percent, you’ll see the whole world in terms of that \\nmethodology. In some instances, you’ll miss opportunities to use other methods bet-\\nter suited to your current problem. The toolbox metaphor helps to keep all the meth-\\nods, techniques, and tips in perspective—ready for use when appropriate.\\nCombining Metaphors\\nBecause metaphors are heuristic rather than algorithmic, they are not mutually exclu-\\nsive. You can use both the accretion and the construction metaphors. You can use \\nwriting if you want to, and you can combine writing with driving, hunting for were-\\nwolves, or drowning in a tar pit with dinosaurs. Use whatever metaphor or combina-\\ntion of metaphors stimulates your own thinking or communicates well with others on \\nyour team. \\nUsing metaphors is a fuzzy business. You have to extend them to benefit from the \\nheuristic insights they provide. But if you extend them too far or in the wrong direc-\\ntion, they’ll mislead you. Just as you can misuse any powerful tool, you can misuse \\nmetaphors, but their power makes them a valuable part of your intellectual toolbox.\\nAdditional Resources\\ncc2e.com/0285 Among general books on metaphors, models, and paradigms, the touchstone book is \\nby Thomas Kuhn.\\nKuhn, Thomas S. The Structure of Scientific Revolutions, 3d ed. Chicago, IL: The Univer-\\nsity of Chicago Press, 1996. Kuhn’s book on how scientific theories emerge, evolve, and \\nsuccumb to other theories in a Darwinian cycle set the philosophy of science on its ear \\nwhen it was first published in 1962. It’s clear and short, and it’s loaded with interesting \\nexamples of the rise and fall of metaphors, models, and paradigms in science. \\nFloyd, Robert W. “The Paradigms of Programming.” 1978 Turing Award Lecture. \\nCommunications of the ACM , August 1979, pp. 455–60. Th is is a fascinating discus-\\nsion of models in software development, and Floyd applies Kuhn’s ideas to the topic.\\nKEY POINT\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 57}, page_content='Key Points 21\\nKey Points\\n■ Metaphors are heuristics, not algorithms. As such, they tend to be a little sloppy.\\n■ Metaphors help you understand the software-development process by relating it \\nto other activities you already know about.\\n■ Some metaphors are better than others.\\n■ Treating software construction as similar to building construction suggests that \\ncareful preparation is needed and illuminates the difference between large and \\nsmall projects.\\n■ Thinking of software-development practices as tools in an intellectual toolbox \\nsuggests further that every programmer has many tools and that no single tool \\nis right for every job. Choosing the right tool for each problem is one key to \\nbeing an effective programmer.\\n■ Metaphors are not mutually exclusive. Use the combination of metaphors that \\nworks best for you.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 59}, page_content='23\\nChapter 3\\nMeasure Twice, Cut Once: \\nUpstream Prerequisites\\ncc2e.com/0309 Contents\\n■ 3.1 Importance of Prerequisites: page 24\\n■ 3.2 Determine the Kind of Software You’re Working On: page 31\\n■ 3.3 Problem-Definition Prerequisite: page 36\\n■ 3.4 Requirements Prerequisite: page 38\\n■ 3.5 Architecture Prerequisite: page 43\\n■ 3.6 Amount of Time to Spend on Upstream Prerequisites: page 55\\nRelated Topics\\n■ Key construction decisions: Chapter 4\\n■ Effect of project size on construction and prerequisites: Chapter 27\\n■ Relationship between quality goals and construction activities: Chapter 20\\n■ Managing construction: Chapter 28\\n■ Design: Chapter 5\\nBefore beginning construction of a house, a builder reviews blueprints, checks that all \\npermits have been obtained, and surveys the house’s foundation. A builder prepares \\nfor building a skyscraper one way, a housing development a different way, and a dog-\\nhouse a third way. No matter what the project, the preparation is tailored to the \\nproject’s specific needs and done conscientiously before construction begins.\\nThis chapter describes the work that must be done to prepare for software construc-\\ntion. As with building construction, much of the success or failure of the project has \\nalready been determined before construction begins. If the foundation hasn’t been \\nlaid well or the planning is inadequate, the best you can do during construction is to \\nkeep damage to a minimum.\\nThe carpenter’s saying, “Measure twice, cut once” is highly relevant to the construc-\\ntion part of software development, which can account for as much as 65 percent of the \\ntotal project costs. The worst software projects end up doing construction two or'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 60}, page_content='24 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nthree times or more. Doing the most expensive part of the project twice is as bad an \\nidea in software as it is in any other line of work. \\nAlthough this chapter lays the groundwork for successful software construction, it \\ndoesn’t discuss construction directly. If yo u’re feeling carnivorous or you’re already \\nwell versed in the software-engineering lif e cycle, look for the construction meat \\nbeginning in Chapter 5, “Des ign in Construction.” If you don’t like the idea of pre-\\nrequisites to construction, review Sectio n 3.2, “Determine the Kind of Software \\nYou’re Working On,” to see how prerequisites apply to your situation, and then take \\na look at the data in Section 3.1, which describes the cost of not doing prerequisites.\\n3.1 Importance of Prerequisites\\nCross-Reference Paying \\nattention to quality is also \\nthe best way to improve pro-\\nductivity. For details, see \\nSection 20.5, “The General \\nPrinciple of Software \\nQuality.”\\nA common denominator of programmers who build high-quality software is their use \\nof high-quality practices. Such practices emphasize quality at the beginning, middle, \\nand end of a project.\\nIf you emphasize quality at the end of a project, you emphasize system testing. Testing \\nis what many people think of when they think of software quality assurance. Testing, \\nhowever, is only one part of a complete quality-assurance strategy, and it’s not the \\nmost influential part. Testing can’t detect a flaw such as building the wrong product or \\nbuilding the right product in the wrong way. Such flaws must be worked out earlier \\nthan in testing—before construction begins.\\nIf you emphasize quality in the middle of the project, you emphasize construction \\npractices. Such practices are the focus of most of this book.\\nIf you emphasize quality at the beginning of the project, you plan for, require, and \\ndesign a high-quality product. If you start the process with designs for a Pontiac Aztek, \\nyou can test it all you want to, and it will never turn into a Rolls-Royce. You might \\nbuild the best possible Aztek, but if you want a Rolls-Royce, you have to plan from the \\nbeginning to build one. In software development, you do such planning when you \\ndefine the problem, when you specify the solution, and when you design the solution.\\nSince construction is in the middle of a software project, by the time you get to con-\\nstruction, the earlier parts of the project have already laid some of the groundwork for \\nsuccess or failure. During construction, however, you should at least be able to deter-\\nmine how good your situation is and to back up if you see the black clouds of failure \\nlooming on the horizon. The rest of this chapter describes in detail why proper prep-\\naration is important and tells you how to determine whether you’re really ready to \\nbegin construction.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 61}, page_content='3.1 Importance of Prerequisites 25\\nDo Prerequisites Apply to Modern Software Projects? \\nThe methodology used \\nshould be based on choice of \\nthe latest and best, and not \\nbased on ignorance. It \\nshould also be laced liberally \\nwith the old and dependable.\\n —Harlan Mills\\nSome people have asserted that upstream activities such as architecture, design, and \\nproject planning aren’t useful on modern software projects. In the main, such asser-\\ntions are not well supported by research, past or present, or by current data. (See the \\nrest of this chapter for details.) Opponents of prerequisites typically show examples of \\nprerequisites that have been done poorly and then point out that such work isn’t \\neffective. Upstream activities can be done well, however, and industry data from the \\n1970s to the present day indicates that projects will run best if appropriate prepara-\\ntion activities are done before construction begins in earnest. \\nThe overarching goal of preparation is risk reduction: a good project planner clears \\nmajor risks out of the way as early as possible so that the bulk of the project can pro-\\nceed as smoothly as possible. By far the most common project risks in software devel-\\nopment are poor requirements and poor project planning, thus preparation tends to \\nfocus on improving requirements and project plans. \\nPreparation for construction is not an exact science, and the specific approach to risk \\nreduction must be decided project by project. Details can vary greatly among projects. \\nFor more on this, see Section 3.2.\\nCauses of Incomplete Preparation\\nYou might think that all professional programmers know about the importance of \\npreparation and check that the prerequisites have been satisfied before jumping into \\nconstruction. Unfortunately, that isn’t so.\\nFurther Reading For a \\ndescription of a professional \\ndevelopment program that \\ncultivates these skills, see \\nChapter 16 of Professional \\nSoftware Development \\n(McConnell 2004).\\ncc2e.com/0316\\nA common cause of incomplete preparation is that the developers who are assigned to \\nwork on the upstream activities do not have the expertise to carry out their assignments. \\nThe skills needed to plan a project, create a compelling business case, develop compre-\\nhensive and accurate requirements, and create high-quality architectures are far from \\ntrivial, but most developers have not received training in how to perform these activities. \\nWhen developers don’t know how to do upstream work, the recommendation to “do \\nmore upstream work” sounds like nonsense: If the work isn’t being done well in the first \\nplace, doing more of it will not be useful! Explaining how to perform these activities is \\nbeyond the scope of this book, but the “Additional Resources” sections at the end of this \\nchapter provide numerous options for gaining that expertise.\\nSome programmers do know how to perform upstream activities, but they don’t prepare \\nbecause they can’t resist the urge to begin coding as soon as possible. If you feed your \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 62}, page_content='26 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nhorse at this trough, I have two suggestions. Suggestion 1: Read the argument in the next \\nsection. It may tell you a few things you haven’t thought of. Suggestion 2: Pay attention to \\nthe problems you experience. It takes only a few large programs to learn that you can \\navoid a lot of stress by planning ahead. Let your own experience be your guide.\\nA final reason that programmers don’t prepare is that managers are notoriously \\nunsympathetic to programmers who spend time on construction prerequisites. Peo-\\nple like Barry Boehm, Grady Booch, and Karl Wiegers have been banging the require-\\nments and design drums for 25 years, and you’d expect that managers would have \\nstarted to understand that software development is more than coding.\\nFurther Reading For many \\nentertaining variations on \\nthis theme, read Gerald \\nWeinberg’s classic, The Psy-\\nchology of Computer Pro-\\ngramming (Weinberg 1998).\\nA few years ago, however, I was working on a Department of Defense project that was \\nfocusing on requirements development when the Army general in charge of the \\nproject came for a visit. We told him that we were developing requirements and that \\nwe were mainly talking to our customer, capturing requirements, and outlining the \\ndesign. He insisted on seeing code anyway. We told him there was no code, but he \\nwalked around a work bay of 100 people, determined to catch someone program-\\nming. Frustrated by seeing so many people away from their desks or working on \\nrequirements and design, the large, round man with the loud voice finally pointed to \\nthe engineer sitting next to me and bellowed, “What’s he doing? He must be writing \\ncode!” In fact, the engineer was working on a document-formatting utility, but the gen-\\neral wanted to find code, thought it looked like code, and wanted the engineer to be \\nworking on code, so we told him it was code.\\nThis phenomenon is known as the WISCA or WIMP syndrome: Why Isn’t Sam Cod-\\ning Anything? or Why Isn’t Mary Programming?\\nIf the manager of your project pretends to be a brigadier general and orders you to \\nstart coding right away, it’s easy to say, “Yes, Sir!” (What’s the harm? The old guy must \\nknow what he’s talking about.) This is a bad response, and you have several better \\nalternatives. First, you can flatly refuse to do work in an ineffective order. If your rela-\\ntionships with your boss and your bank account are healthy enough for you to be able \\nto do this, good luck.\\nA second questionable alternative is pretending to be coding when you’re not. Put an \\nold program listing on the corner of your desk. Then go right ahead and develop your \\nrequirements and architecture, with or without your boss’s approval. You’ll do the \\nproject faster and with higher-quality results. Some people find this approach ethi-\\ncally objectionable, but from your boss’s perspective, ignorance will be bliss. \\nThird, you can educate your boss in the nuances of technical projects. This is a good \\napproach because it increases the number of enlightened bosses in the world. The \\nnext subsection presents an extended rationale for taking the time to do prerequisites \\nbefore construction.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 63}, page_content='3.1 Importance of Prerequisites 27\\nFinally, you can find another job. Despite economic ups and downs, good program-\\nmers are perennially in short supply (BLS 2002), and life is too short to work in an \\nunenlightened programming shop when plenty of better alternatives are available.\\nUtterly Compelling and Foolproof Argument for Doing Prerequisites \\nBefore Construction \\nSuppose you’ve already been to the mountain of problem definition, walked a mile \\nwith the man of requirements, shed your soiled garments at the fountain of architec-\\nture, and bathed in the pure waters of preparedness. Then you know that before you \\nimplement a system, you need to understand what the system is supposed to do and \\nhow it’s supposed to do it.\\nPart of your job as a technical employee is to educate the nontechnical people around \\nyou about the development process. This section will help you deal with managers \\nand bosses who have not yet seen the light. It’s an extended argument for doing \\nrequirements and architecture—getting the critical aspects right—before you begin cod-\\ning, testing, and debugging. Learn the argument, and then sit down with your boss \\nand have a heart-to-heart talk about the programming process.\\nAppeal to Logic\\nOne of the key ideas in effective programming is that preparation is important. It \\nmakes sense that before you start working on a big project, you should plan the \\nproject. Big projects require more planning; small projects require less. From a man-\\nagement point of view, planning means determining the amount of time, number of \\npeople, and number of computers the project will need. From a technical point of \\nview, planning means understanding what you want to build so that you don’t waste \\nmoney building the wrong thing. Sometimes users aren’t entirely sure what they want \\nat first, so it might take more effort than seems ideal to find out what they really want. \\nBut that’s cheaper than building the wrong thing, throwing it away, and starting over.\\nIt’s also important to think about how to build the system before you begin to build it. \\nYou don’t want to spend a lot of time and money going down blind alleys when \\nthere’s no need to, especially when that increases costs. \\nAppeal to Analogy\\nBuilding a software system is like any other project that takes people and money. If \\nyou’re building a house, you make architectural drawings and blueprints before you \\nbegin pounding nails. You’ll have the blueprints reviewed and approved before you \\npour any concrete. Having a technical plan counts just as much in software.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 64}, page_content='28 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nYou don’t start decorating the Christmas tree until you’ve put it in the stand. You don’t \\nstart a fire until you’ve opened the flue. You don’t go on a long trip with an empty tank \\nof gas. You don’t get dressed before you take a shower, and you don’t put your shoes \\non before your socks. You have to do things in the right order in software, too.\\nProgrammers are at the end of the software food chain. The architect consumes the \\nrequirements; the designer consumes the architecture; and the coder consumes \\nthe design.\\nCompare the software food chain to a real food chain. In an ecologically sound envi-\\nronment, seagulls eat fresh salmon. That’s nourishing to them because the salmon ate \\nfresh herring, and they in turn ate fresh water bugs. The result is a healthy food chain. \\nIn programming, if you have healthy food at each stage in the food chain, the result is \\nhealthy code written by happy programmers.\\nIn a polluted environment, the water bugs have been swimming in nuclear waste, the \\nherring are contaminated by PCBs, and the salmon that eat the herring swam through \\noil spills. The seagulls are, unfortunately, at the end of the food chain, so they don’t eat \\njust the oil in the bad salmon. They also eat the PCBs and the nuclear waste from the \\nherring and the water bugs. In programming, if your requirements are contaminated, \\nthey contaminate the architecture, and the architecture in turn contaminates con-\\nstruction. This leads to grumpy, malnourished programmers and radioactive, pol-\\nluted software that’s riddled with defects.\\nIf you are planning a highly iterative project, you will need to identify the critical \\nrequirements and architectural elements that apply to each piece you’re constructing \\nbefore you begin construction. A builder who is building a housing development \\ndoesn’t need to know every detail of every house in the development before begin-\\nning construction on the first house. But the builder will survey the site, map out \\nsewer and electrical lines, and so on. If the builder doesn’t prepare well, construction \\nmay be delayed when a sewer line needs to be dug under a house that’s already been \\nconstructed. \\nAppeal to Data\\nStudies over the last 25 years have proven conclusively that it pays to do things right \\nthe first time. Unnecessary changes are expensive.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 65}, page_content='3.1 Importance of Prerequisites 29\\nResearchers at Hewlett-Packard, IBM, Hughes Aircraft, TRW, and other organizations \\nhave found that purging an error by the beginning of construction allows rework to be \\ndone 10 to 100 times less expensively than when it’s done in the last part of the pro-\\ncess, during system test or after release (Fagan 1976; Humphrey, Snyder, and Willis \\n1991; Leffingwell 1997; Willis et al. 1998; Grady 1999; Shull et al. 2002; Boehm and \\nTurner 2004). \\nIn general, the principle is to find an error as close as possible to the time at which it \\nwas introduced. The longer the defect stays in the software food chain, the more dam-\\nage it causes further down the chain. Since requirements are done first, requirements \\ndefects have the potential to be in the system longer and to be more expensive. Defects \\ninserted into the software upstream also tend to have broader effects than those \\ninserted further downstream. That also makes early defects more expensive.\\nTable 3-1 shows the relative expense of fixing defects depending on when they’re \\nintroduced and when they’re found.\\nThe data in Table 3-1 shows that, for example, an architecture defect that costs $1000 \\nto fix when the architecture is being created can cost $15,000 to fix during system \\ntest. Figure 3-1 illustrates the same phenomenon.\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA\\nTable 3-1 Average Cost of Fixing Defects Based on When They’re Introduced and Detected\\nTime Detected\\nTime Introduced Requirements Architecture Constr uction System Test Post-Release\\nRequirements 135 –10 1 0 1 0–100\\nArchitecture — 1 10 15 25–100\\nConstruction — — 1 10 10–25\\nSource: Adapted from “Design and Code Inspections to Reduce Errors in Program Development” (Fagan 1976), Software Defect Removal \\n(Dunn 1984), “Software Process Improvement at Hughes Aircraft” (Humphrey, Snyder, and Willis 1991), “Calculating the Return on \\nInvestment from More Effective Requirements Management” (Leffingwell 1997), “Hughes Aircraft’s Widespread Deployment of a \\nContinuously Improving Software Process” (Willis et al. 1998), “An Economic Release Decision Model: Insights into Software Project \\nManagement” (Grady 1999),  “What We Have Learned About Fighting Defects” (Shull et al. 2002), and Balancing Agility and Discipline: \\nA Guide for the Perplexed (Boehm and Turner 2004).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 66}, page_content='30 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nFigure 3-1 The cost to fix a defect rises dramatically as the time from when it’s introduced \\nto when it’s detected increases. This remains true whether the project is highly sequential \\n(doing 100 percent of requirements and design up front) or highly iterative (doing 5 percent \\nof requirements and design up front). \\nThe average project still exerts most of its defect-correction effort on the right side of Fig-\\nure 3-1, which means that debugging and associated rework takes about 50 percent of \\nthe time spent in a typical software development cycle (Mills 1983; Boehm 1987a; Coo-\\nper and Mullen 1993; Fishman 1996; Haley 1996; Wheeler, Brykczynski, and Meeson \\n1996; Jones 1998; Shull et al. 2002; Wiegers 2002). Dozens of companies have found \\nthat simply focusing on correcting defects earlier rather than later in a project can cut \\ndevelopment costs and schedules by factors of two or more (McConnell 2004). This is \\na healthy incentive to find and fix your problems as early as you can.\\nBoss-Readiness Test\\nWhen you think your boss understands the importance of working on prerequisites \\nbefore moving into construction, try the test below to be sure. \\nWhich of these statements are self-fulfilling prophecies?\\n■ We’d better start coding right away because we’re going to have a lot of debug-\\nging to do.\\n■ We haven’t planned much time for testing because we’re not going to find many \\ndefects.\\nPhase in Which a \\nDefect Is Introduced\\nRequirements\\nArchitecture\\nConstruction\\nSystem TestRequirements Architecture Construction Post-Release\\nPhase in Which a Defect Is Detected\\nCost\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 67}, page_content='3.2 Determine the Kind of Software You’re Working On 31\\n■ We’ve investigated requirements and design so much that I can’t think of any \\nmajor problems we’ll run into during coding or debugging.\\nAll of these statements are self-fulfilling prophecies. Aim for the last one. \\nIf you’re still not convinced that prerequisites apply to your project, the next section \\nwill help you decide. \\n3.2 Determine the Kind of Software You’re Working On\\nCapers Jones, Chief Scientist at Software Productivity Research, summarized 20 years \\nof software research by pointing out that he and his colleagues have seen 40 different \\nmethods for gathering requirements, 50 variations in working on software designs, \\nand 30 kinds of testing applied to projects in more than 700 different programming \\nlanguages (Jones 2003). \\nDifferent kinds of software projects call for different balances between preparation \\nand construction. Every project is unique, but projects do tend to fall into general \\ndevelopment styles. Table 3-2 shows three of the most common kinds of projects and \\nlists the practices that are typically best suited to each kind of project. \\nTable 3-2 Typical Good Practices for Three Common Kinds of Software Projects \\nKind of Software\\nBusiness Systems\\nMission-Critical \\nSystems\\nEmbedded \\nLife-Critical Systems\\nTypical \\napplications\\nInternet site \\nIntranet site\\nInventory \\nmanagement\\nGames\\nManagement \\ninformation systems\\nPayroll system\\nEmbedded software\\nGames\\nInternet site\\nPackaged software\\nSoftware tools\\nWeb services\\nAvionics software\\nEmbedded software \\nMedical devices\\nOperating systems\\nPackaged software\\nLife-cycle \\nmodels\\nAgile development \\n(Extreme Program-\\nming, Scrum, time-\\nbox development, \\nand so on)\\nEvolutionary \\nprototyping\\nStaged delivery \\nEvolutionary \\ndelivery\\nSpiral development\\nStaged delivery\\nSpiral development\\nEvolutionary delivery'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 68}, page_content='32 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nOn real projects, you’ll find infinite variations on the three themes presented in this \\ntable; however, the generalities in the table are illuminating. Business systems projects \\ntend to benefit from highly iterative approaches, in which planning, requirements, \\nBusiness Systems\\nMission-Critical \\nSystems\\nEmbedded \\nLife-Critical Systems\\nPlanning and \\nmanagement\\nIncremental project \\nplanning\\nAs-needed test and \\nQA planning\\nInformal change \\ncontrol\\nBasic up-front \\nplanning\\nBasic test planning \\nAs-needed QA \\nplanning\\nFormal change \\ncontrol\\nExtensive up-front \\nplanning \\nExtensive test \\nplanning \\nExtensive QA \\nplanning\\nRigorous change \\ncontrol\\nRequirements Informal require-\\nments specification\\nSemiformal require-\\nments specification\\nAs-needed require-\\nments reviews\\nFormal requirements \\nspecification \\nFormal requirements \\ninspections\\nDesign Design and coding \\nare combined\\nArchitectural design \\nInformal detailed \\ndesign\\nAs-needed design \\nreviews\\nArchitectural design \\nFormal architecture \\ninspections \\nFormal detailed \\ndesign\\nFormal detailed \\ndesign inspections\\nConstruction Pair programming \\nor individual coding\\nInformal check-in \\nprocedure or no \\ncheck-in procedure\\nPair programming \\nor individual coding\\nInformal check-in \\nprocedure\\nAs-needed code \\nreviews\\nPair programming or \\nindividual coding \\nFormal check-in \\nprocedure\\nFormal code \\ninspections\\nTesting \\nand QA\\nDevelopers test \\ntheir own code\\nTest-first \\ndevelopment\\nLittle or no testing \\nby a separate test \\ngroup\\nDevelopers test \\ntheir own code \\nTest-first \\ndevelopment \\nSeparate testing \\ngroup\\nDevelopers test their \\nown code \\nTest-first \\ndevelopment\\nSeparate testing \\ngroup \\nSeparate QA group\\nDeployment Informal deploy-\\nment procedure\\nFormal deployment \\nprocedure\\nFormal deployment \\nprocedure\\nTable 3-2 Typical Good Practices for Three Common Kinds of Software Projects \\nKind of Software'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 69}, page_content='3.2 Determine the Kind of Software You’re Working On 33\\nand architecture are interleaved with construction, system testing, and quality-assur-\\nance activities. Life-critical systems tend to require more sequential approaches—\\nrequirements stability is part of what’s needed to ensure ultrahigh levels of reliability. \\nIterative Approaches’ Effect on Prerequisites\\nSome writers have asserted that projects that use iterative techniques don’t need to \\nfocus on prerequisites much at all, but that point of view is misinformed. Iterative \\napproaches tend to reduce the impact of inadequate upstream work, but they don’t \\neliminate it. Consider the examples shown in Table 3-3 of projects that don’t focus on \\nprerequisites. One project is conducted sequentially and relies solely on testing to dis-\\ncover defects; the other is conducted iteratively and discovers defects as it progresses. \\nThe first approach delays most defect correction work to the end of the project, making \\nthe costs higher, as noted in Table 3-1. The iterative approach absorbs rework piecemeal \\nover the course of the project, which makes the total cost lower. The data in this table \\nand the next is for purposes of illustration only, but the relative costs of the two general \\napproaches are well supported by the research described earlier in this chapter.\\nThe iterative project that abbreviates or e liminates prerequisites will differ in two \\nways from a sequential project that does the same thing. First, average defect correc-\\ntion costs will be lower because defects will tend to be de tected closer to the time \\nthey were inserted into the software. Howe ver, the defects will st ill be detected late \\nin each iteration, and correcting them will require parts of the software to be \\nredesigned, recoded, and retested—which makes the defect-correction cost higher \\nthan it needs to be. \\nTable 3-3 Effect of Skipping Prerequisites on Sequential and Iterative Projects\\nApproach #1: Sequential \\nApproach Without \\nPrerequisites\\nApproach #2: Iterative \\nApproach Without \\nPrerequisites\\nProject Completion \\nStatus Cost of Work\\nCost of \\nRework Cost of Work\\nCost of \\nRework\\n20% $100,000 $0 $100,000 $75,000\\n40% $100,000 $0 $100,000 $75,000\\n60% $100,000 $0 $100,000 $75,000\\n80% $100,000 $0 $100,000 $75,000\\n100% $100,000 $0 $100,000 $75,000\\nEnd-of-Project \\nRework $0 $500,000 $0 $0\\nTOTAL $500,000 $500,000 $500,000 $375,000\\nGRAND TOTAL $1,000,000 $875,000'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 70}, page_content='34 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nSecond, with iterative approaches costs will be absorbed piecemeal, throughout the \\nproject, rather than being clustered at the end. When all the dust settles, the total cost \\nwill be similar but it won’t seem as high because the price will have been paid in small \\ninstallments over the course of the project, rather than paid all at once at the end. \\nAs Table 3-4 illustrates, a focus on prerequisites can reduce costs regardless of \\nwhether you use an iterative or a sequential approach. Iterative approaches are usually \\na better option for many reasons, but an iterative approach that ignores prerequisites \\ncan end up costing significantly more than a sequential project that pays close atten-\\ntion to prerequisites. \\nAs Table 3-4 suggested, most projects are neither completely sequential nor com-\\npletely iterative. It isn’t practical to specify 100 percent of the requirements or design \\nup front, but most projects find value in identifying at least the most critical require-\\nments and architectural elements early. \\nCross-Reference For details \\non how to adapt your devel-\\nopment approach for pro-\\ngrams of different sizes, see \\nChapter 27, “How Program \\nSize Affects Construction.”\\nOne common rule of thumb is to plan to specify about 80 percent of the requirements \\nup front, allocate time for additional requirements to be specified later, and then prac-\\ntice systematic change control to accept only the most valuable new requirements as \\nthe project progresses. Another alternative is to specify only the most important 20 \\npercent of the requirements up front and plan to develop the rest of the software in \\nsmall increments, specifying additional requirements and designs as you go. Figures \\n3-2 and 3-3 reflect these different approaches.\\nTable 3-4 Effect of Focusing on Prerequisites on Sequential and Iterative \\nProjects \\nApproach #3: Sequential \\nApproach with Prerequisites\\nApproach #4: Iterative \\nApproach with Prerequisites\\nProject completion \\nstatus Cost of Work\\nCost of \\nRework Cost of Work\\nCost of \\nRework\\n20% $100,000 $20,000 $100,000 $10,000\\n40% $100,000 $20,000 $100,000 $10,000\\n60% $100,000 $20,000 $100,000 $10,000\\n80% $100,000 $20,000 $100,000 $10,000\\n100% $100,000 $20,000 $100,000 $10,000\\nEnd-of-Project \\nRework $0 $0 $0 $0\\nTOTAL $500,000 $100,000 $500,000 $50,000\\nGRAND TOTAL $600,000 $550,000\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 71}, page_content='3.2 Determine the Kind of Software You’re Working On 35\\nFigure 3-2 Activities will overlap to some degree on most projects, even those that are \\nhighly sequential. \\nFigure 3-3 On other projects, activities will overlap for the duration of the project. One key \\nto successful construction is understanding the degree to which prerequisites have been \\ncompleted and adjusting your approach accordingly.\\nChoosing Between Iterative and Sequential Approaches\\nThe extent to which prerequisites need to be satisfied up front will vary with the \\nproject type indicated in Table 3-2, project formality, technical environment, staff \\ncapabilities, and project business goals. You might choose a more sequential (up-\\nfront) approach when \\n■ The requirements are fairly stable.\\n■ The design is straightforward and fairly well understood.\\n■ The development team is familiar with the applications area.\\nQuality Assurance/System Testing\\nRequirements\\nArchitecture\\nDetailed Design\\nConstruction\\nTime\\nTime\\nQuality Assurance/System Testing\\nRequirements\\nDetailed DesignArchitecture\\nDetailed Design\\nConstruction'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 72}, page_content='36 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\n■ The project contains little risk.\\n■ Long-term predictability is important.\\n■ The cost of changing requirements, design, and code downstream is likely to be \\nhigh.\\nYou might choose a more iterative (as-you-go) approach when\\n■ The requirements are not well understood or you expect them to be unstable for \\nother reasons.\\n■ The design is complex, challenging, or both.\\n■ The development team is unfamiliar with the applications area.\\n■ The project contains a lot of risk.\\n■ Long-term predictability is not important.\\n■ The cost of changing requirements, design, and code downstream is likely to be \\nlow.\\nSoftware being what it is, iterative approaches are useful much more often than \\nsequential approaches are. You can adapt the prerequisites to your specific project by \\nmaking them more or less formal and more or less complete, as you see fit. For a \\ndetailed discussion of different approaches to large and small projects (also known as \\nthe different approaches to formal and informal projects), see Chapter 27.\\nThe net impact on construction prerequisites is that you should first determine what \\nconstruction prerequisites are well suited to your project. Some projects spend too lit-\\ntle time on prerequisites, which exposes construction to an unnecessarily high rate of \\ndestabilizing changes and prevents the project from making consistent progress. \\nSome projects do too much up front; they doggedly adhere to requirements and plans \\nthat have been invalidated by downstream discoveries, and that can also impede \\nprogress during construction. \\nNow that you’ve studied Table 3-2 and determined what prerequisites are appropriate \\nfor your project, the rest of this chapter describes how to determine whether each spe-\\ncific construction prerequisite has been “prereq’d” or “prewrecked.”\\n3.3 Problem-Definition Prerequisite\\nIf the “box” is the boundary \\nof constraints and condi-\\ntions, then the trick is to find \\nthe box.... Don’t think out-\\nside the box—find the box.\\n—Andy Hunt and Dave \\nThomas\\nThe first prerequisite you need to fulfill before beginning construction is a clear state-\\nment of the problem that the system is supposed to solve. This is sometimes called \\n“product vision,” “vision statement,” “mission statement,” or “product definition.” \\nHere it’s called “problem definition.” Since this book is about construction, this sec-\\ntion doesn’t tell you how to write a problem definition; it tells you how to recognize \\nwhether one has been written at all and whether the one that’s written will form a \\ngood foundation for construction.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 73}, page_content='3.3 Problem-Definition Prerequisite 37\\nA problem definition defines what the problem is without any reference to possible \\nsolutions. It’s a simple statement, maybe one or two pages, and it should sound like a \\nproblem. The statement “We can’t keep up with orders for the Gigatron” sounds like \\na problem and is a good problem definition. The statement “We need to optimize our \\nautomated data-entry system to keep up with orders for the Gigatron” is a poor prob-\\nlem definition. It doesn’t sound like a problem; it sounds like a solution.\\nAs shown in Figure 3-4, problem definition comes before detailed requirements work, \\nwhich is a more in-depth investigation of the problem.\\nFigure 3-4 The problem definition lays the foundation for the rest of the programming \\nprocess.\\nThe problem definition should be in user language, and the problem should be \\ndescribed from a user’s point of view. It usually should not be stated in technical com-\\nputer terms. The best solution might not be a computer program. Suppose you need \\na report that shows your annual profit. You already have computerized reports that \\nshow quarterly profits. If you’re locked into the programmer mindset, you’ll reason \\nthat adding an annual report to a system that already does quarterly reports should be \\neasy. Then you’ll pay a programmer to write and debug a time-consuming program \\nthat calculates annual profits. If you’re not locked into the programmer mindset, \\nyou’ll pay your secretary to create the annual figures by taking one minute to add up \\nthe quarterly figures on a pocket calculator.\\nThe exception to this rule applies when the problem is with the computer: compile \\ntimes are too slow or the programming tools are buggy. Then it’s appropriate to state \\nthe problem in computer or programmer terms.\\nAs Figure 3-5 suggests, without a good problem definition, you might put effort into \\nsolving the wrong problem.\\nProblem Definition\\nRequirements\\nArchitecture\\nConstruction\\nSystem testing\\nFuture \\nImprovements'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 74}, page_content='38 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nFigure 3-5 Be sure you know what you’re aiming at before you shoot.  \\nThe penalty for failing to define the problem is that you can waste a lot of time solving \\nthe wrong problem. This is a double-barreled penalty because you also don’t solve the \\nright problem.\\n3.4 Requirements Prerequisite\\nRequirements describe in detail what a software system is supposed to do, and they \\nare the first step toward a solution. The requirements activity is also known as \\n“requirements development,” “requirements analysis,” “analysis,” “requirements defi-\\nnition,” “software requirements,” “specification,” “functional spec,” and “spec.” \\nWhy Have Official Requirements?\\nAn explicit set of requirements is important for several reasons.\\nExplicit requirements help to ensure that the user rather than the programmer drives \\nthe system’s functionality. If the requirements are explicit, the user can review them \\nand agree to them. If they’re not, the programmer usually ends up making require-\\nments decisions during programming. Explicit requirements keep you from guessing \\nwhat the user wants.\\nExplicit requirements also help to avoid arguments. You decide on the scope of the \\nsystem before you begin programming. If you have a disagreement with another pro-\\ngrammer about what the program is supposed to do, you can resolve it by looking at \\nthe written requirements.\\nPaying attention to requirements helps to minimize changes to a system after develop-\\nment begins. If you find a coding error during coding, you change a few lines of code \\nand work goes on. If you find a requirements error during coding, you have to alter \\nthe design to meet the changed requirement. You might have to throw away part of the \\nold design, and because it has to accommodate code that’s already written, the new \\ndesign will take longer than it would have in the first place. You also have to discard \\nKEY POINT\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 75}, page_content='3.4 Requirements Prerequisite 39\\ncode and test cases affected by the requirement change and write new code and test \\ncases. Even code that’s otherwise unaffected must be retested so that you can be sure \\nthe changes in other areas haven’t introduced any new errors.\\nAs Table 3-1 reported, data from numerous organizations indicates that on large \\nprojects an error in requirements detected during the architecture stage is typically 3 \\ntimes as expensive to correct as it would be if it were detected during the requirements \\nstage. If detected during coding, it’s 5–10 times as expensive; during system test, 10 \\ntimes; and post-release, a whopping 10–100 times as expensive as it would be if it were \\ndetected during requirements development. On smaller projects with lower adminis-\\ntrative costs, the multiplier post-release is closer to 5–10 than 100 (Boehm and Turner \\n2004). In either case, it isn’t money you’d want to have taken out of your salary.\\nSpecifying requirements adequately is a key to project success, perhaps even more \\nimportant than effective construction techniques. (See Figure 3-6.) Many good books \\nhave been written about how to specify requirements well. Consequently, the next few \\nsections don’t tell you how to do a good job of specifying requirements, they tell you \\nhow to determine whether the requirements have been done well and how to make \\nthe best of the requirements you have.\\nFigure 3-6 Without good requirements, you can have the right general problem but miss \\nthe mark on specific aspects of the problem.\\nThe Myth of Stable Requirements\\nRequirements are like water. \\nThey’re easier to build on \\nwhen they’re frozen. \\n—Anonoymous\\nStable requirements are the holy grail of software development. With stable require-\\nments, a project can proceed from architecture to design to coding to testing in a way \\nthat’s orderly, predictable, and calm. This is software heaven! You have predictable \\nexpenses, and you never have to worry about a feature costing 100 times as much to \\nimplement as it would otherwise because your user didn’t think of it until you were \\nfinished debugging.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 76}, page_content='40 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nIt’s fine to hope that once your customer has accepted a requirements document, no \\nchanges will be needed. On a typical project, however, the customer can’t reliably \\ndescribe what is needed before the code is written. The problem isn’t that the custom-\\ners are a lower life form. Just as the more you work with the project, the better you \\nunderstand it, the more they work with it, the better they understand it. The develop-\\nment process helps customers better understand their own needs, and this is a major \\nsource of requirements changes (Curtis, Krasner, and Iscoe 1988; Jones 1998; Wieg-\\ners 2003). A plan to follow the requirements rigidly is actually a plan not to respond \\nto your customer.\\nHow much change is typical? Studies at IBM and other companies have found that the \\naverage project experiences about a 25 percent change in requirements during devel-\\nopment (Boehm 1981, Jones 1994, Jones 2000), which accounts for 70 to 85 percent \\nof the rework on a typical project (Leffingwell 1997, Wiegers 2003).\\nMaybe you think the Pontiac Aztek was the greatest car ever made, belong to the Flat \\nEarth Society, and make a pilgrimage to the alien landing site at Roswell, New Mexico, \\nevery four years. If you do, go ahead and believe that requirements won’t change on \\nyour projects. If, on the other hand, you’ve stopped believing in Santa Claus and the \\nTooth Fairy, or at least have stopped admitting it, you can take several steps to mini-\\nmize the impact of requirements changes.\\nHandling Requirements Changes During Construction\\nHere are several things you can do to make the best of changing requirements during \\nconstruction:\\nUse the requirements checklist at the end of the section to assess the quality of your \\nrequirements If your requirements aren’t good enough, stop work, back up, and \\nmake them right before you proceed. Sure, it feels like you’re getting behind if you stop \\ncoding at this stage. But if you’re driving from Chicago to Los Angeles, is it a waste of \\ntime to stop and look at a road map when you see signs for New York? No. If you’re \\nnot heading in the right direction, stop and check your course.\\nMake sure everyone knows the cost of requirements changes Clients get excited \\nwhen they think of a new feature. In their excitement, their blood thins and runs to \\ntheir medulla oblongata and they become giddy, forgetting all the meetings you had to \\ndiscuss requirements, the signing ceremony, and the completed requirements docu-\\nment. The easiest way to handle such feature-intoxicated people is to say, “Gee, that \\n1\\n2\\n3\\nHARD DATA\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 77}, page_content='3.4 Requirements Prerequisite 41\\nsounds like a great idea. Since it’s not in the requirements document, I’ll work up a \\nrevised schedule and cost estimate so that you can decide whether you want to do it \\nnow or later.” The words “schedule” and “cost” are more sobering than coffee and a \\ncold shower, and many “must haves” will quickly turn into “nice to haves.”\\nIf your organization isn’t sensitive to the importance of doing requirements first, point \\nout that changes at requirements time are much cheaper than changes later. Use this \\nchapter’s “Utterly Compelling and Foolproof Argument for Doing Prerequisites Before \\nConstruction.”\\nCross-Reference For details \\non handling changes to \\ndesign and code, see Section \\n28.2, “Configuration \\nManagement.”\\nSet up a change-control procedure If your client’s excitement persists, consider \\nestablishing a formal change-control board to review such proposed changes. It’s all \\nright for customers to change their minds and to realize that they need more capabil-\\nities. The problem is their suggesting changes so frequently that you can’t keep up. \\nHaving a built-in procedure for controlling changes makes everyone happy. You’re \\nhappy because you know that you’ll have to work with changes only at specific times. \\nYour customers are happy because they know that you have a plan for handling their \\ninput.\\nCross-Reference For details \\non iterative development \\napproaches, see “Iterate” in \\nSection 5.4 and Section 29.3, \\n“Incremental Integration \\nStrategies.” \\nUse development approaches that accommodate changes Some development \\napproaches maximize your ability to respond to changing requirements. An evolution-\\nary prototyping approach helps you explore a system’s requirements before you send \\nyour forces in to build it. Evolutionary delivery is an approach that delivers the system \\nin stages. You can build a little, get a little feedback from your users, adjust your design \\na little, make a few changes, and build a little more. The key is using short develop-\\nment cycles so that you can respond to your users quickly.\\nFurther Reading For details \\non development approaches \\nthat support flexible require-\\nments, see Rapid Develop-\\nment (McConnell 1996). \\nDump the project If the requirements are especially bad or volatile and none of the \\nsuggestions above are workable, cancel the project. Even if you can’t really cancel the \\nproject, think about what it would be like to cancel it. Think about how much worse it \\nwould have to get before you would cancel it. If there’s a case in which you would dump \\nit, at least ask yourself how much difference there is between your case and that case.\\nCross-Reference For details \\non the differences between \\nformal and informal projects \\n(often caused by differences \\nin project size), see Chapter \\n27, “How Program Size \\nAffects Construction.”\\nKeep your eye on the business case for the project Many requirements issues disap-\\npear before your eyes when you refer back to the business reason for doing the project. \\nRequirements that seemed like good ideas when considered as “features” can seem like \\nterrible ideas when you evaluate the “incremental business value.” Programmers who \\nremember to consider the business impact of their decisions are worth their weight in \\ngold—although I’ll be happy to receive my commission for this advice in cash.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 78}, page_content='42 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\ncc2e.com/0323 Checklist: Requirements\\nThe requirements checklist contains a list of questions to ask yourself about \\nyour project’s requirements. This book doesn’t tell you how to do good require-\\nments development, and the list won’t tell you how to do one either. Use the list \\nas a sanity check at construction time to determine how solid the ground that \\nyou’re standing on is—where you are on the requirements Richter scale.\\nNot all of the checklist questions will apply to your project. If you’re working on \\nan informal project, you’ll find some that you don’t even need to think about. \\nYou’ll find others that you need to think about but don’t need to answer for-\\nmally. If you’re working on a large, formal project, however, you may need to \\nconsider every one. \\nSpecific Functional Requirements\\n❑ Are all the inputs to the system specified, including their source, accuracy, \\nrange of values, and frequency?\\n❑ Are all the outputs from the system specified, including their destination, \\naccuracy, range of values, frequency, and format?\\n❑ Are all output formats specified for Web pages, reports, and so on?\\n❑ Are all the external hardware and software interfaces specified?\\n❑ Are all the external communication interfaces specified, including hand-\\nshaking, error-checking, and communication protocols?\\n❑ Are all the tasks the user wants to perform specified?\\n❑ Is the data used in each task and the data resulting from each task specified?\\nSpecific Nonfunctional (Quality) Requirements\\n❑ Is the expected response time, from the user’s point of view, specified for \\nall necessary operations?\\n❑ Are other timing considerations specified, such as processing time, data-\\ntransfer rate, and system throughput?\\n❑ Is the level of security specified?\\n❑ Is the reliability specified, including the consequences of software failure, \\nthe vital information that needs to be protected from failure, and the strat-\\negy for error detection and recovery?\\n❑ Are minimum machine memory and free disk space specified?\\n❑ Is the maintainability of the system specified, including its ability to adapt \\nto changes in specific functionality, changes in the operating environment, \\nand changes in its interfaces with other software?\\n❑ Is the definition of success included? Of failure?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 79}, page_content='3.5 Architecture Prerequisite 43\\nRequirements Quality\\n❑ Are the requirements written in the user’s language? Do the users think \\nso? \\n❑ Does each requirement avoid conflicts with other requirements?\\n❑ Are acceptable tradeoffs between competing attributes specified—for \\nexample, between robustness and correctness?\\n❑ Do the requirements avoid specifying the design?\\n❑ Are the requirements at a fairly consistent level of detail? Should any \\nrequirement be specified in more detail? Should any requirement be spec-\\nified in less detail?\\n❑ Are the requirements clear enough to be turned over to an independent \\ngroup for construction and still be understood? Do the developers think \\nso?\\n❑ Is each item relevant to the problem and its solution? Can each item be \\ntraced to its origin in the problem environment?\\n❑ Is each requirement testable? Will it be possible for independent testing to \\ndetermine whether each requirement has been satisfied?\\n❑ Are all possible changes to the requirements specified, including the like-\\nlihood of each change?\\nRequirements Completeness\\n❑ Where information isn’t available before development begins, are the \\nareas of incompleteness specified?\\n❑ Are the requirements complete in the sense that if the product satisfies \\nevery requirement, it will be acceptable?\\n❑ Are you comfortable with all the requirements? Have you eliminated \\nrequirements that are impossible to implement and included just to \\nappease your customer or your boss?\\n3.5 Architecture Prerequisite\\nCross-Reference For more \\ninformation on design at all \\nlevels, see Chapters 5 \\nthrough 9.\\nSoftware architecture is the high-level part of software design, the frame that holds the \\nmore detailed parts of the design (Buschman et al. 1996; Fowler 2002; Bass Clements, \\nKazman 2003; Clements et al. 2003). Architecture is also known as “system architec-\\nture,” “high-level design,” and “top-level design.” Typically, the architecture is \\ndescribed in a single document referred to as the “architecture specification” or “top-\\nlevel design.” Some people make a distinction between architecture and high-level'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 80}, page_content='44 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\ndesign—architecture refers to design constraints that apply systemwide, whereas high-\\nlevel design refers to design constraints that apply at the subsystem or multiple-class \\nlevel, but not necessarily systemwide.\\nBecause this book is about construction, this section doesn’t tell you how to develop \\na software architecture; it focuses on how to determine the quality of an existing archi-\\ntecture. Because architecture is one step closer to construction than requirements, \\nhowever, the discussion of architecture is more detailed than the discussion of \\nrequirements.\\nWhy have architecture as a prerequisite? Because the quality of the architecture deter-\\nmines the conceptual integrity of the system. That in turn determines the ultimate \\nquality of the system. A well-thought-out architecture provides the structure needed to \\nmaintain a system’s conceptual integrity from the top levels down to the bottom. It \\nprovides guidance to programmers—at a level of detail appropriate to the skills of the \\nprogrammers and to the job at hand. It partitions the work so that multiple develop-\\ners or multiple development teams can work independently.\\nGood architecture makes construction easy. Bad architecture makes construction \\nalmost impossible. Figure 3-7 illustrates another problem with bad architecture.\\nFigure 3-7 Without good software architecture, you may have the right problem but the \\nwrong solution. It may be impossible to have successful construction.\\nArchitectural changes are expensive to make during construction or later. The time \\nneeded to fix an error in a software architecture is on the same order as that needed to \\nfix a requirements error—that is, more than that needed to fix a coding error (Basili \\nand Perricone 1984, Willis 1998). Architecture changes are like requirements changes \\nin that seemingly small changes can be far-reaching. Whether the architectural \\nchanges arise from the need to fix errors or the need to make improvements, the ear-\\nlier you can identify the changes, the better.\\nKEY POINT\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 81}, page_content='3.5 Architecture Prerequisite 45\\nTypical Architectural Components\\nCross-Reference For details \\non lower-level program \\ndesign, see Chapters 5 \\nthrough 9.\\nMany components are common to good system architectures. If you’re building the \\nwhole system yourself, your work on the architecture will overlap your work on the \\nmore detailed design. In such a case, you should at least think about each architec-\\ntural component. If you’re working on a system that was architected by someone else, \\nyou should be able to find the important components without a bloodhound, a deer-\\nstalker cap, and a magnifying glass. In either case, here are the architectural compo-\\nnents to consider.\\nProgram Organization\\nIf you can’t explain some-\\nthing to a six-year-old, you \\nreally don’t understand it \\nyourself.\\n—Albert Einstein\\nA system architecture first needs an overview that describes the system in broad \\nterms. Without such an overview, you’ll have a hard time building a coherent picture \\nfrom a thousand details or even a dozen individual classes. If the system were a little \\n12-piece jigsaw puzzle, your one-year-old could solve it between spoonfuls of strained \\nasparagus. A puzzle of 12 subsystems is harder to put together, and if you can’t put it \\ntogether, you won’t understand how a class you’re developing contributes to the sys-\\ntem.\\nIn the architecture, you should find evidence that alternatives to the final organization \\nwere considered and find the reasons for choosing the final organization over its alterna-\\ntives. It’s frustrating to work on a class when it seems as if the class’s role in the system \\nhas not been clearly conceived. By describing the organizational alternatives, the architec-\\nture provides the rationale for the system organization and shows that each class has \\nbeen carefully considered. One review of design practices found that the design rationale \\nis at least as important for maintenance as the design itself (Rombach 1990).\\nCross-Reference For details \\non different size building \\nblocks in design, see “Levels \\nof Design” in Section 5.2.\\nThe architecture should define the major building blocks in a program. Depending on \\nthe size of the program, each building block might be a single class or it might be a \\nsubsystem consisting of many classes. Each building block is a class, or it’s a collec-\\ntion of classes or routines that work together on high-level functions such as interact-\\ning with the user, displaying Web pages, interpreting commands, encapsulating \\nbusiness rules, or accessing data. Every feature listed in the requirements should be \\ncovered by at least one building block. If a function is claimed by two or more building \\nblocks, their claims should cooperate, not conflict.\\nCross-Reference Minimiz-\\ning what each building block \\nknows about other building \\nblocks is a key part of infor-\\nmation hiding. For details, \\nsee “Hide Secrets (Informa-\\ntion Hiding)” in Section 5.3.\\nWhat each building block is responsible for should be well defined. A building block \\nshould have one area of responsibility, and it should know as little as possible about \\nother building blocks’ areas of responsibility. By minimizing what each building block \\nknows about the other building blocks, you localize information about the design into \\nsingle building blocks.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 82}, page_content='46 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nThe communication rules for each building block should be well defined. The archi-\\ntecture should describe which other building blocks the building block can use \\ndirectly, which it can use indirectly, and which it shouldn’t use at all. \\nMajor Classes\\nCross-Reference For details \\non class design, see Chapter \\n6, “Working Classes.”\\nThe architecture should specify the major classes to be used. It should identify the \\nresponsibilities of each major class and how the class will interact with other classes. \\nIt should include descriptions of the class hierarchies, of state transitions, and of \\nobject persistence. If the system is large enough, it should describe how classes are \\norganized into subsystems. \\nThe architecture should describe other class designs that were considered and give \\nreasons for preferring the organization that was chosen. The architecture doesn’t need \\nto specify every class in the system. Aim for the 80/20 rule: specify the 20 percent of \\nthe classes that make up 80 percent of the system’s behavior (Jacobsen, Booch, and \\nRumbaugh 1999; Kruchten 2000). \\nData Design\\nCross-Reference For details \\non working with variables, \\nsee Chapters 10 through 13. \\nThe architecture should describe the major files and table designs to be used. It \\nshould describe alternatives that were considered and justify the choices that were \\nmade. If the application maintains a list of customer IDs and the architects have cho-\\nsen to represent the list of IDs using a sequential-access list, the document should \\nexplain why a sequential-access list is better than a random-access list, stack, or hash \\ntable. During construction, such information gives you insight into the minds of the \\narchitects. During maintenance, the same insight is an invaluable aid. Without it, \\nyou’re watching a foreign movie with no subtitles. \\nData should normally be accessed directly by only one subsystem or class, except \\nthrough access classes or routines that allow access to the data in controlled and \\nabstract ways. This is explained in more detail in “Hide Secrets (Information Hiding)” \\nin Section 5.3.\\nThe architecture should specify the high-level organization and contents of any data-\\nbases used. The architecture should explain why a single database is preferable to \\nmultiple databases (or vice versa), explain why a database is preferable to flat files, \\nidentify possible interactions with other programs that access the same data, explain \\nwhat views have been created on the data, and so on. \\nBusiness Rules\\nIf the architecture depends on specific business rules, it should identify them and \\ndescribe the impact the rules have on the system’s design. For example, suppose the \\nsystem is required to follow a business rule that customer information should be no'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 83}, page_content='3.5 Architecture Prerequisite 47\\nmore than 30 seconds out of date. In that case, the impact that rule has on the archi-\\ntecture’s approach to keeping customer information up to date and synchronized \\nshould be described. \\nUser Interface Design\\nThe user interface is often specified at requirements time. If it isn’t, it should be spec-\\nified in the software architecture. The architecture should specify major elements of \\nWeb page formats, GUIs, command line interfaces, and so on. Careful architecture of \\nthe user interface makes the difference between a well-liked program and one that’s \\nnever used.\\nThe architecture should be modularized so that a new user interface can be substi-\\ntuted without affecting the business rules and output parts of the program. For exam-\\nple, the architecture should make it fairly easy to lop off a group of interactive interface \\nclasses and plug in a group of command line classes. This ability is often useful, espe-\\ncially since command line interfaces are convenient for software testing at the unit or \\nsubsystem level.\\ncc2e.com/0393 The design of user interfaces deserves its own book-length discussion but is outside \\nthe scope of this book.\\nResource Management\\nThe architecture should describe a plan for managing scarce resources such as data-\\nbase connections, threads, and handles. Memory management is another important \\narea for the architecture to treat in memory-constrained applications areas such as \\ndriver development and embedded systems. The architecture should estimate the \\nresources used for nominal and extreme cases. In a simple case, the estimates should \\nshow that the resources needed are well within the capabilities of the intended imple-\\nmentation environment. In a more complex case, the application might be required to \\nmore actively manage its own resources. If it is, the resource manager should be archi-\\ntected as carefully as any other part of the system.\\ncc2e.com/0330 Security\\nFurther Reading For an \\nexcellent discussion of soft-\\nware security, see Writing \\nSecure Code, 2d Ed. (Howard \\nand LeBlanc 2003) as well as \\nthe January 2002 issue of \\nIEEE Software.\\nThe architecture should describe the approach to design-level and code-level security. If a \\nthreat model has not previously been built, it should be built at architecture time. Coding \\nguidelines should be developed with security implications in mind, including \\napproaches to handling buffers, rules for handling untrusted data (data input from users, \\ncookies, configuration data, and other external interfaces), encryption, level of detail con-\\ntained in error messages, protecting secret data that’s in memory, and other issues.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 84}, page_content='48 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nPerformance\\nFurther Reading For addi-\\ntional information on design-\\ning systems for performance, \\nsee Connie Smith’s Perfor-\\nmance Engineering of \\nSoftware Systems (1990).\\nIf performance is a concern, performance goals should be specified in the require-\\nments. Performance goals can include resource use, in which case the goals should \\nalso specify priorities among resources, including speed vs. memory vs. cost. \\nThe architecture should provide estimates and explain why the architects believe the \\ngoals are achievable. If certain areas are at risk of failing to meet their goals, the archi-\\ntecture should say so. If certain areas require the use of specific algorithms or data \\ntypes to meet their performance goals, the architecture should say that. The architec-\\nture can also include space and time budgets for each class or object.\\nScalability\\nScalability is the ability of a system to grow to meet future demands. The architecture \\nshould describe how the system will address growth in number of users, number of \\nservers, number of network nodes, number of database records, size of database \\nrecords, transaction volume, and so on. If the system is not expected to grow and scal-\\nability is not an issue, the architecture should make that assumption explicit. \\nInteroperability\\nIf the system is expected to share data or resources with other software or hardware, \\nthe architecture should describe how that will be accomplished. \\nInternationalization/Localization\\n“Internationalization” is the technical activity of preparing a program to support mul-\\ntiple locales. Internationalization is often known as “I18n” because the first and last \\ncharacters in “internationalization” are “I” and “N” and because there are 18 letters in \\nthe middle of the word. “Localization” (known as “L10n” for the same reason) is the \\nactivity of translating a program to support a specific local language. \\nInternationalization issues deserve attention in the architecture for an interactive sys-\\ntem. Most interactive systems contain dozens or hundreds of prompts, status dis-\\nplays, help messages, error messages, and so on. Resources used by the strings should \\nbe estimated. If the program is to be used commercially, the architecture should show \\nthat the typical string and character-set issues have been considered, including char-\\nacter set used (ASCII, DBCS, EBCDIC, MBCS, Unicode, ISO 8859, and so on), kinds \\nof strings used (C strings, Visual Basic strings, and so on), maintaining the strings \\nwithout changing code, and translating the strings into foreign languages with mini-\\nmal impact on the code and the user interface. The architecture can decide to use \\nstrings in line in the code where they’re needed, keep the strings in a class and refer-\\nence them through the class interface, or store the strings in a resource file. The archi-\\ntecture should explain which option was chosen and why.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 85}, page_content='3.5 Architecture Prerequisite 49\\nInput/Output\\nInput/output (I/O) is another area that deserves attention in the architecture. The \\narchitecture should specify a look-ahead, look-behind, or just-in-time reading scheme. \\nAnd it should describe the level at which I/O errors are detected: at the field, record, \\nstream, or file level.\\nError Processing\\nError processing is turning out to be one of the thorniest problems of modern com-\\nputer science, and you can’t afford to deal with it haphazardly. Some people have esti-\\nmated that as much as 90 percent of a program’s code is written for exceptional, error-\\nprocessing cases or housekeeping, implying that only 10 percent is written for nomi-\\nnal cases (Shaw in Bentley 1982). With so much code dedicated to handling errors, a \\nstrategy for handling them consistently should be spelled out in the architecture. \\nError handling is often treated as a coding-convention-level issue, if it’s treated at all. \\nBut because it has systemwide implications, it is best treated at the architectural level. \\nHere are some questions to consider:\\n■ Is error processing corrective or merely detective? If corrective, the program can \\nattempt to recover from errors. If it’s merely detective, the program can continue \\nprocessing as if nothing had happened, or it can quit. In either case, it should \\nnotify the user that it detected an error.\\n■ Is error detection active or passive? The system can actively anticipate errors—for \\nexample, by checking user input for validity—or it can passively respond to them \\nonly when it can’t avoid them—for example, when a combination of user input \\nproduces a numeric overflow. It can clear the way or clean up the mess. Again, in \\neither case, the choice has user-interface implications.\\n■ How does the program propagate errors? Once it detects an error, it can imme-\\ndiately discard the data that caused the error, it can treat the error as an error \\nand enter an error-processing state, or it can wait until all processing is complete \\nand notify the user that errors were detected (somewhere).\\n■ What are the conventions for handling error messages? If the architecture \\ndoesn’t specify a single, consistent strategy, the user interface will appear to be a \\nconfusing macaroni-and-dried-bean collage of different interfaces in different \\nparts of the program. To avoid such an appearance, the architecture should \\nestablish conventions for error messages.\\n■ How will exceptions be handled? The architecture should address when the \\ncode can throw exceptions, where they will be caught, how they will be logged, \\nhow they will be documented, and so on. \\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 86}, page_content='50 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nCross-Reference A consis-\\ntent method of handling bad \\nparameters is another aspect \\nof error-processing strategy \\nthat should be addressed \\narchitecturally. For examples, \\nsee Chapter 8, “Defensive \\nProgramming.”\\n■ Inside the program, at what level are errors handled? You can handle them at \\nthe point of detection, pass them off to an error-handling class, or pass them up \\nthe call chain.\\n■ What is the level of responsibility of each class for validating its input data? Is \\neach class responsible for validating its own data, or is there a group of classes \\nresponsible for validating the system’s data? Can classes at any level assume that \\nthe data they’re receiving is clean?\\n■ Do you want to use your environment’s built-in exception-handling mechanism \\nor build your own? The fact that an environment has a particular error-handling \\napproach doesn’t mean that it’s the best approach for your requirements.\\nFault Tolerance\\nFurther Reading For a good \\nintroduction to fault toler-\\nance, see the July 2001 issue \\nof IEEE Software. In addition \\nto providing a good intro-\\nduction, the articles cite \\nmany key books and key \\narticles on the topic. \\nThe architecture should also indicate the kind of fault tolerance expected. Fault toler-\\nance is a collection of techniques that increase a system’s reliability by detecting \\nerrors, recovering from them if possible, and containing their bad effects if not.\\nFor example, a system could make the computation of the square root of a number \\nfault tolerant in any of several ways:\\n■ The system might back up and try again when it detects a fault. If the first \\nanswer is wrong, it would back up to a point at which it knew everything was all \\nright and continue from there.\\n■ The system might have auxiliary code to use if it detects a fault in the primary \\ncode. In the example, if the first answer appears to be wrong, the system \\nswitches over to an alternative square-root routine and uses it instead.\\n■ The system might use a voting algorithm. It might have three square-root classes \\nthat each use a different method. Each class computes the square root, and then \\nthe system compares the results. Depending on the kind of fault tolerance built \\ninto the system, it then uses the mean, the median, or the mode of the three \\nresults.\\n■ The system might replace the erroneous value with a phony value that it knows \\nto have a benign effect on the rest of the system.\\nOther fault-tolerance approaches include having the system change to a state of par-\\ntial operation or a state of degraded functionality when it detects an error. It can shut \\nitself down or automatically restart itself. These examples are necessarily simplistic. \\nFault tolerance is a fascinating and complex subject—unfortunately, it’s one that’s out-\\nside the scope of this book.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 87}, page_content='3.5 Architecture Prerequisite 51\\nArchitectural Feasibility\\nThe designers might have concerns about a system’s ability to meet its performance \\ntargets, work within resource limitations, or be adequately supported by the imple-\\nmentation environments. The architecture should demonstrate that the system is \\ntechnically feasible. If infeasibility in any area could render the project unworkable, \\nthe architecture should indicate how those issues have been investigated—through \\nproof-of-concept prototypes, research, or other means. These risks should be resolved \\nbefore full-scale construction begins. \\nOverengineering\\nRobustness is the ability of a system to continue to run after it detects an error. Often \\nan architecture specifies a more robust system than that specified by the require-\\nments. One reason is that a system composed of many parts that are minimally robust \\nmight be less robust than is required overall. In software, the chain isn’t as strong as \\nits weakest link; it’s as weak as all the weak links multiplied together. The architecture \\nshould clearly indicate whether programmers should err on the side of overengineer-\\ning or on the side of doing the simplest thing that works. \\nSpecifying an approach to overengineering is particularly important because many \\nprogrammers overengineer their classes automatically, out of a sense of professional \\npride. By setting expectations explicitly in the architecture, you can avoid the phe-\\nnomenon in which some classes are exceptionally robust and others are barely ade-\\nquate.\\nBuy-vs.-Build Decisions\\nCross-Reference For a list of \\nkinds of commercially avail-\\nable software components \\nand libraries, see “Code \\nLibraries” in Section 30.3.\\nThe most radical solution to building software is not to build it at all—to buy it instead \\nor to download open-source software for free. You can buy GUI controls, database \\nmanagers, image processors, graphics and charting components, Internet communi-\\ncations components, security and encryption components, spreadsheet tools, text-\\nprocessing tools—the list is nearly endless. One of the greatest advantages of program-\\nming in modern GUI environments is the amount of functionality you get automati-\\ncally: graphics classes, dialog box managers, keyboard and mouse handlers, code that \\nworks automatically with any printer or monitor, and so on.\\nIf the architecture isn’t using off-the-shel f components, it should explain the ways \\nin which it expects custom-built components to surpass ready-made libraries and \\ncomponents.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 88}, page_content='52 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nReuse Decisions\\nIf the plan calls for using preexisting software, test cases, data formats, or other mate-\\nrials, the architecture should explain how the reused software will be made to con-\\nform to the other architectural goals—if it will be made to conform.\\nChange Strategy\\nCross-Reference For details \\non handling changes sys-\\ntematically, see Section 28.2, \\n“Configuration Management.”\\nBecause building a software product is a learning process for both the programmers \\nand the users, the product is likely to change throughout its development. Changes \\narise from volatile data types and file formats, changed functionality, new features, and \\nso on. The changes can be new capabilities likely to result from planned enhance-\\nments, or they can be capabilities that didn’t make it into the first version of the sys-\\ntem. Consequently, one of the major challenges facing a software architect is making \\nthe architecture flexible enough to accommodate likely changes.\\nDesign bugs are often subtle \\nand occur by evolution with \\nearly assumptions being for-\\ngotten as new features or \\nuses are added to a system. \\n—Fernando J. Corbató\\nThe architecture should clearly describe a strategy for handling changes. The architec-\\nture should show that possible enhancements have been considered and that the \\nenhancements most likely are also the easiest to implement. If changes are likely in \\ninput or output formats, style of user interaction, or processing requirements, the \\narchitecture should show that the changes have all been anticipated and that the \\neffects of any single change will be limited to a small number of classes. The architec-\\nture’s plan for changes can be as simple as one to put version numbers in data files, \\nreserve fields for future use, or design files so that you can add new tables. If a code \\ngenerator is being used, the architecture should show that the anticipated changes are \\nwithin the capabilities of the code generator.\\nCross-Reference For a full \\nexplanation of delaying \\ncommitment, see “Choose \\nBinding Time Consciously” in \\nSection 5.3.\\nThe architecture should indicate the strategies that are used to delay commitment. For \\nexample, the architecture might specify that a table-driven technique be used rather \\nthan hard-coded if tests. It might specify that data for the table is to be kept in an exter-\\nnal file rather than coded inside the program, thus allowing changes in the program \\nwithout recompiling.\\nGeneral Architectural Quality\\nCross-Reference For more \\ninformation about how qual-\\nity attributes interact, see \\nSection 20.1, “Characteristics \\nof Software Quality.”\\nA good architecture specification is characterized by discussions of the classes in the \\nsystem, of the information that’s hidden in each class, and of the rationales for includ-\\ning and excluding all possible design alternatives.\\nThe architecture should be a polished conceptual whole with few ad hoc additions. \\nThe central thesis of the most popular software-engineering book ever, The Mythical \\nMan-Month, is that the essential problem with large systems is maintaining their con-\\nceptual integrity (Brooks 1995). A good architecture should fit the problem. When \\nyou look at the architecture, you should be pleased by how natural and easy the solu-\\ntion seems. It shouldn’t look as if the problem and the architecture have been forced \\ntogether with duct tape.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 89}, page_content='3.5 Architecture Prerequisite 53\\nYou might know of ways in which the architecture was changed during its develop-\\nment. Each change should fit in cleanly with the overall concept. The architecture \\nshouldn’t look like a U.S. Congress appropriations bill complete with pork-barrel, \\nboondoggle riders for each representative’s home district.\\nThe architecture’s objectives should be clearly stated. A design for a system with a pri-\\nmary goal of modifiability will be different from one with a goal of uncompromised \\nperformance, even if both systems have the same function. \\nThe architecture should describe the motivations for all major decisions. Be wary of \\n“we’ve always done it that way” justifications. One story goes that Beth wanted to \\ncook a pot roast according to an award-winning pot roast recipe handed down in her \\nhusband’s family. Her husband, Abdul, said that his mother had taught him to sprin-\\nkle it with salt and pepper, cut both ends off, put it in the pan, cover it, and cook it. \\nBeth asked, “Why do you cut both ends off?” Abdul said, “I don’t know. I’ve always \\ndone it that way. Let me ask my mother.” He called her, and she said, “I don’t know. \\nI’ve always done it that way. Let me ask your grandmother.” She called his grand-\\nmother, who said, “I don’t know why you do it that way. I did it that way because it \\nwas too big to fit in my pan.”\\nGood software architecture is largely machine- and language-independent. Admit-\\ntedly, you can’t ignore the construction environment. By being as independent of the \\nenvironment as possible, however, you avoid the temptation to overarchitect the sys-\\ntem or to do a job that you can do better during construction. If the purpose of a pro-\\ngram is to exercise a specific machine or language, this guideline doesn’t apply.\\nThe architecture should tread the line between underspecifying and overspecifying \\nthe system. No part of the architecture should receive more attention than it deserves, \\nor be overdesigned. Designers shouldn’t pay attention to one part at the expense of \\nanother. The architecture should address all requirements without gold-plating (with-\\nout containing elements that are not required). \\nThe architecture should explicitly identify risky areas. It should explain why they’re \\nrisky and what steps have been taken to minimize the risk.\\nThe architecture should contain multiple views. Plans for a house will include eleva-\\ntions, floor plan, framing plan, electrical diagrams, and other views of the house.  Soft-\\nware architecture descriptions also benefit from providing different views of the \\nsystem that flush out errors and inconsistencies and help programmers fully under-\\nstand the system’s design (Kruchten 1995). \\nFinally, you shouldn’t be uneasy about any parts of the architecture. It shouldn’t con-\\ntain anything just to please the boss. It shouldn’t contain anything that’s hard for you \\nto understand. You’re the one who’ll implement it; if it doesn’t make sense to you, how \\ncan you implement it?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 90}, page_content='54 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\ncc2e.com/0337 Checklist: Architecture\\nHere’s a list of issues that a good architecture should address. The list isn’t \\nintended to be a comprehensive guide to architecture but to be a pragmatic way \\nof evaluating the nutritional content of what you get at the programmer’s end of \\nthe software food chain. Use this checklist as a starting point for your own \\nchecklist. As with the requirements checklist, if you’re working on an informal \\nproject, you’ll find some items that you don’t even need to think about. If you’re \\nworking on a larger project, most of the items will be useful.\\nSpecific Architectural Topics\\n❑ Is the overall organization of the program clear, including a good architec-\\ntural overview and justification?\\n❑ Are major building blocks well defined, including their areas of responsi-\\nbility and their interfaces to other building blocks?\\n❑ Are all the functions listed in the requirements covered sensibly, by neither \\ntoo many nor too few building blocks?\\n❑ Are the most critical classes described and justified?\\n❑ Is the data design described and justified?\\n❑ Is the database organization and content specified?\\n❑ Are all key business rules identified and their impact on the system \\ndescribed? \\n❑ Is a strategy for the user interface design described?\\n❑ Is the user interface modularized so that changes in it won’t affect the rest \\nof the program?\\n❑ Is a strategy for handling I/O described and justified?\\n❑ Are resource-use estimates and a strategy for resource management \\ndescribed and justified for scarce resources like threads, database connec-\\ntions, handles, network bandwidth, and so on?\\n❑ Are the architecture’s security requirements described? \\n❑ Does the architecture set space and speed budgets for each class, sub-\\nsystem, or functionality area? \\n❑ Does the architecture describe how scalability will be achieved? \\n❑ Does the architecture address interoperability?\\n❑ Is a strategy for internationalization/localization described? \\n❑ Is a coherent error-handling strategy provided?\\n❑ Is the approach to fault tolerance defined (if any is needed)?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 91}, page_content='3.6 Amount of Time to Spend on Upstream Prerequisites 55\\n❑ Has technical feasibility of all parts of the system been established? \\n❑ Is an approach to overengineering specified?\\n❑ Are necessary buy-vs.-build decisions included?\\n❑ Does the architecture describe how reused code will be made to conform \\nto other architectural objectives? \\n❑ Is the architecture designed to accommodate likely changes? \\nGeneral Architectural Quality\\n❑ Does the architecture account for all the requirements? \\n❑ Is any part overarchitected or underarchitected? Are expectations in this \\narea set out explicitly?\\n❑ Does the whole architecture hang together conceptually?\\n❑ Is the top-level design independent of the machine and language that will \\nbe used to implement it?\\n❑ Are the motivations for all major decisions provided?\\n❑ Are you, as a programmer who will implement the system, comfortable \\nwith the architecture?\\n3.6 Amount of Time to Spend on Upstream Prerequisites\\nCross-Reference The \\namount of time you spend \\non prerequisites will depend \\non your project type. For \\ndetails on adapting prereq-\\nuisites to your specific \\nproject, see Section 3.2, \\n“Determine the Kind of Soft-\\nware You’re Working On,” \\nearlier in this chapter. \\nThe amount of time to spend on problem definition, requirements, and software architec-\\nture varies according to the needs of your project. Generally, a well-run project devotes \\nabout 10 to 20 percent of its effort and about 20 to 30 percent of its schedule to require-\\nments, architecture, and up-front planning (McConnell 1998, Kruchten 2000). These fig-\\nures don’t include time for detailed design—that’s part of construction.\\nIf requirements are unstable and you’re working on a large, formal project, you’ll prob-\\nably have to work with a requirements analyst to resolve requirements problems that \\nare identified early in construction. Allow time to consult with the requirements ana-\\nlyst and for the requirements analyst to revise the requirements before you’ll have a \\nworkable version of the requirements.\\nIf requirements are unstable and you’re working on a small, informal project, you’ll prob-\\nably need to resolve requirements issues yourself. Allow time for defining the require-\\nments well enough that their volatility will have a minimal impact on construction.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 92}, page_content='56 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\nCross-Reference For \\napproaches to handling \\nchanging requirements, see \\n“Handling Requirements \\nChanges During Construc-\\ntion” in Section 3.4, earlier in \\nthis chapter. \\nIf the requirements are unstable on any project—formal or informal—treat require-\\nments work as its own project. Estimate the time for the rest of the project after you’ve \\nfinished the requirements. This is a sensible approach since no one can reasonably \\nexpect you to estimate your schedule before you know what you’re building. It’s as if \\nyou were a contractor called to work on a house. Your customer says, “What will it cost \\nto do the work?” You reasonably ask, “What do you want me to do?” Your customer \\nsays, “I can’t tell you, but how much will it cost?” You reasonably thank the customer \\nfor wasting your time and go home.\\nWith a building, it’s clear that it’s unreasonable for clients to ask for a bid before tell-\\ning you what you’re going to build. Your clients wouldn’t want you to show up with \\nwood, hammer, and nails and start spending their money before the architect had fin-\\nished the blueprints. People tend to understand software development less than they \\nunderstand two-by-fours and sheetrock, however, so the clients you work with might \\nnot immediately understand why you want to plan requirements development as a \\nseparate project. You might need to explain your reasoning to them.\\nWhen allocating time for software architecture, use an approach similar to the one for \\nrequirements development. If the software is a kind that you haven’t worked with \\nbefore, allow more time for the uncertainty of designing in a new area. Ensure that the \\ntime you need to create a good architecture won’t take away from the time you need \\nfor good work in other areas. If necessary, plan the architecture work as a separate \\nproject, too.\\nAdditional Resources\\ncc2e.com/0344 Following are more resources on requirements:\\ncc2e.com/0351 Requirements\\nHere are a few books that give much more detail on requirements development: \\nWiegers, Karl. Software Requirements, 2d ed. Redmond, WA: Microsoft Press, 2003. \\nThis is a practical, practitioner-focused book that describes the nuts and bolts of \\nrequirements activities, including requirements elicitation, requirements analysis, \\nrequirements specification, requirements validation, and requirements management. \\nRobertson, Suzanne and James Robertson. Mastering the Requirements Process. Read-\\ning, MA: Addison-Wesley, 1999. This is a good alternative to Wiegers’ book for the \\nmore advanced requirements practitioner.\\ncc2e.com/0358\\nGilb, Tom. Competitive Engineering. Reading, MA: Addison-Wesley, 2004. This book \\ndescribes Gilb’s requirements language, known as “Planguage.” The book covers \\nGilb’s specific approach to requirements engineering, design and design evaluation, \\nand evolutionary project management. This book can be downloaded from Gilb’s \\nwebsite at www.gilb.com.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 93}, page_content='Additional Resources 57\\nIEEE Std 830-1998. IEEE Recommended Practice for Software Requirements Specifications. \\nLos Alamitos, CA: IEEE Computer Society Press. This document is the IEEE-ANSI \\nguide for writing software-requirements specifications. It describes what should be \\nincluded in the specification document and shows several alternative outlines for one. \\ncc2e.com/0365\\nAbran, Alain, et al. Swebok: Guide to the Software Engineering Body of Knowledge. Los \\nAlamitos, CA: IEEE Computer Society Press, 2001. This contains a detailed descrip-\\ntion of the body of software-requirements knowledge. It can also be downloaded from \\nwww.swebok.org.\\nOther good alternatives include the following:\\nLauesen, Soren. Software Requirements: Styles and Techniques. Boston, MA: Addison-\\nWesley, 2002. \\nKovitz, Benjamin L. Practical Software Requirements: A Manual of Content and Style. \\nManning Publications Company, 1998. \\nCockburn, Alistair. Writing Effective Use Cases. Boston, MA: Addison-Wesley, 2000. \\ncc2e.com/0372 Software Architecture\\nNumerous books on software architecture have been published in the past few years. \\nHere are some of the best: \\nBass, Len, Paul Clements, and Rick Kazman. Software Architecture in Practice, 2d ed. \\nBoston, MA: Addison-Wesley, 2003. \\nBuschman, Frank, et al. Pattern-Oriented Software Architecture, Volume 1: A System of \\nPatterns. New York, NY: John Wiley & Sons, 1996. \\nClements, Paul, ed. Documenting Software Architectures: Views and Beyond. Boston, MA: \\nAddison-Wesley, 2003. \\nClements, Paul, Rick Kazman, and Mark Klein. Evaluating Software Architectures: Meth-\\nods and Case Studies. Boston, MA: Addison-Wesley, 2002. \\nFowler, Martin. Patterns of Enterprise Application Architecture. Boston, MA: Addison-\\nWesley, 2002. \\nJacobson, Ivar, Grady Booch, and James Rumbaugh. The Unified Software Development \\nProcess. Reading, MA: Addison-Wesley, 1999.\\nIEEE Std 1471-2000. Recommended Practice for Architectural Description of Software-\\nIntensive Systems. Los Alamitos, CA: IEEE Computer So ciety Press. This document is \\nthe IEEE-ANSI guide for creating software-architecture specifications.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 94}, page_content='58 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\ncc2e.com/0379 General Software-Development Approaches\\nMany books are available that map out different approaches to conducting a software \\nproject. Some are more sequential, and some are more iterative. \\nMcConnell, Steve. Software Project Survival Guide. Redmond, WA: Microsoft Press, \\n1998. This book presents one particular way to conduct a project. The approach pre-\\nsented emphasizes deliberate up-front planning, requirements development, and \\narchitecture work followed by careful project execution. It provides long-range pre-\\ndictability of costs and schedules, high quality, and a moderate amount of flexibility. \\nKruchten, Philippe. The Rational Unified Process: An Introduction, 2d ed. Reading, MA: \\nAddison-Wesley, 2000. This book presents a project approach that is “architecture-\\ncentric and use-case driven.” Like Software Project Survival Guide, it focuses on up-front \\nwork that provides good long-range predictability of costs and schedules, high quality, \\nand moderate flexibility. This book’s approach requires somewhat more sophisticated \\nuse than the approaches described in Software Project Survival Guide and Extreme Pro-\\ngramming Explained: Embrace Change. \\nJacobson, Ivar, Grady Booch, and James Rumbaugh. The Unified Software Development \\nProcess. Reading, MA: Addison-Wesley, 1999. This book is a more in-depth treatment \\nof the topics covered in The Rational Unified Process: An Introduction, 2d ed. \\nBeck, Kent. Extreme Programming Explained: Embrace Change. Reading, MA: Addison-\\nWesley, 2000. Beck describes a highly iterative approach that focuses on developing \\nrequirements and designs iteratively, in conjunction with construction. The Extreme \\nProgramming approach offers little long-range predictability but provides a high \\ndegree of flexibility. \\nGilb, Tom. Principles of Software Engineering Management. Wokingham, England: \\nAddison-Wesley, 1988. Gilb’s approach explores critical planning, requirements, and \\narchitecture issues early in a project and then continuously adapts the project plans as \\nthe project progresses. This approach provides a combination of long-range predict-\\nability, high quality, and a high degree of flexibility. It requires more sophistication \\nthan the approaches described in Software Project Survival Guide and Extreme Program-\\nming Explained: Embrace Change.\\nMcConnell, Steve. Rapid Development. Redmond, WA: Microsoft Press, 1996. This \\nbook presents a toolbox approach to project planning. An experienced project plan-\\nner can use the tools presented in this book to create a project plan that is highly \\nadapted to a project’s unique needs. \\nBoehm, Barry and Richard Turner. Balancing Agility and Discipline: A Guide for the Per-\\nplexed. Boston, MA: Addison-Wesley, 2003. This book explores the contrast between \\nagile development and plan-driven development styles. Chapter 3 has four especially'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 95}, page_content='Key Points 59\\nrevealing sections: “A Typical Day using PSP/TSP,” “A Typical Day using Extreme Pro-\\ngramming,” “A Crisis Day using PSP/TSP,” and “A Crisis Day using Extreme Program-\\nming.” Chapter 5 is on using risk to balance agility, which provides incisive guidance \\nfor selecting between agile and plan-driven methods. Chapter 6, “Conclusions,” is also \\nwell balanced and gives great perspective. Appendix E is a gold mine of empirical data \\non agile practices. \\nLarman, Craig. Agile and Iterative Development: A Manager’s Guide. Boston, MA: Addi-\\nson Wesley, 2004. This is a well-researched introduction to flexible, evolutionary \\ndevelopment styles. It overviews Scrum, Extreme Programming, the Unified Process, \\nand Evo. \\ncc2e.com/0386 Checklist: Upstream Prerequisites\\n❑ Have you identified the kind of software project you’re working on and tai-\\nlored your approach appropriately? \\n❑ Are the requirements sufficiently well defined and stable enough to begin \\nconstruction? (See the requirements checklist for details.)\\n❑ Is the architecture sufficiently well defined to begin construction? (See the \\narchitecture checklist for details.)\\n❑ Have other risks unique to your particular project been addressed, such \\nthat construction is not exposed to more risk than necessary? \\nKey Points\\n■ The overarching goal of preparing for construction is risk reduction. Be sure \\nyour preparation activities are reducing risks, not increasing them. \\n■ If you want to develop high-quality software, attention to quality must be part of \\nthe software-development process from the beginning to the end. Attention to \\nquality at the beginning has a greater influence on product quality than atten-\\ntion at the end.\\n■ Part of a programmer’s job is to educate bosses and coworkers about the soft-\\nware-development process, including the importance of adequate preparation \\nbefore programming begins.\\n■ The kind of project you’re working on significantly affects construction prereq-\\nuisites—many projects should be highly iterative, and some should be more \\nsequential. \\n■ If a good problem definition hasn’t been specified, you might be solving the \\nwrong problem during construction.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 96}, page_content='60 Chapter 3: Measure Twice, Cut Once: Upstream Prerequisites\\n■ If  good requirements work hasn’t been done, you might have missed important \\ndetails of the problem. Requirements changes cost 20 to 100 times as much in \\nthe stages following construction as they do earlier, so be sure the requirements \\nare right before you start programming.\\n■ If a good architectural design hasn’t been done, you might be solving the right \\nproblem the wrong way during construction. The cost of architectural changes \\nincreases as more code is written for the wrong architecture, so be sure the archi-\\ntecture is right, too.\\n■ Understand what approach has been taken to the construction prerequisites on \\nyour project, and choose your construction approach accordingly.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 97}, page_content='61\\nChapter 4\\nKey Construction Decisions\\ncc2e.com/0489 Contents\\n■ 4.1 Choice of Programming Language: page 61\\n■ 4.2 Programming Conventions: page 66\\n■ 4.3 Your Location on the Technology Wave: page 66\\n■ 4.4 Selection of Major Construction Practices: page 69\\nRelated Topics\\n■ Upstream prerequisites: Chapter 3\\n■ Determine the kind of software you’re working on: Section 3.2\\n■ How program size affects construction: Chapter 27\\n■ Managing construction: Chapter 28\\n■ Software design: Chapter 5, and Chapters 6 through 9\\nOnce you’re sure an appropriate groundwork has been laid for construction, prepara-\\ntion turns toward more construction-specific decisions. Chapter 3, “Measure Twice, \\nCut Once: Upstream Prerequisites,” discussed the software equivalent of blueprints \\nand construction permits. You might not have had much control over those prepara-\\ntions, so the focus of that chapter was on assessing what you have to work with when \\nconstruction begins. This chapter focuses on preparations that individual program-\\nmers and technical leads are responsible for, directly or indirectly. It discusses the soft-\\nware equivalent of how to select specific tools for your tool belt and how to load your \\ntruck before you head out to the job site. \\nIf you feel you’ve read enough about construction preparations already, you might \\nskip ahead to Chapter 5, “Design in Construction.” \\n4.1 Choice of Programming Language\\nBy relieving the brain of all unnecessary work, a good notation sets it free to con-\\ncentrate on more advanced problems, and in effect increases the mental power of \\nthe race. Before the introduction of the Arabic notation, multiplication was dif-\\nficult, and the division even of integers called into play the highest mathematical \\nfaculties. Probably nothing in the modern world would have more astonished a \\nGreek mathematician than to learn that ... a huge proportion of the population'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 98}, page_content='62 Chapter 4: Key Construction Decisions\\nof Western Europe could perform the operation of division for the largest num-\\nbers. This fact would have seemed to him a sheer impossibility.... Our modern \\npower of easy reckoning with decimal fractions is the almost miraculous result of \\nthe gradual discovery of a perfect notation.\\n—Alfred North Whitehead\\nThe programming language in which the system will be implemented should be of \\ngreat interest to you since you will be immersed in it from the beginning of construc-\\ntion to the end.\\nStudies have shown that the programming-language choice affects productivity and \\ncode quality in several ways.\\nProgrammers are more productive using a familiar language than an unfamiliar one. \\nData from the Cocomo II estimation model shows that programmers working in a lan-\\nguage they’ve used for three years or more are about 30 percent more productive than \\nprogrammers with equivalent experience who are new to a language (Boehm et al. \\n2000). An earlier study at IBM found that programmers who had extensive experience \\nwith a programming language were more than three times as productive as those with \\nminimal experience (Walston and Felix 1977). (Cocomo II is more careful to isolate \\neffects of individual factors, which accounts for the different results of the two studies.)\\nProgrammers working with high-level languages achieve better productivity and quality \\nthan those working with lower-level languages. Languages such as C++, Java, Smalltalk, \\nand Visual Basic have been credited with improving productivity, reliability, simplicity, \\nand comprehensibility by factors of 5 to 15 over low-level languages such as assembly \\nand C (Brooks 1987, Jones 1998, Boehm 2000). You save time when you don’t need to \\nhave an awards ceremony every time a C statement does what it’s supposed to. More-\\nover, higher-level languages are more expressive than lower-level languages. Each line of \\ncode says more. Table 4-1 shows typical ratios of source statements in several high-level \\nlanguages to the equivalent code in C. A higher ratio means that each line of code in the \\nlanguage listed accomplishes more than does each line of code in C. \\nTable 4-1 Ratio of High-Level-Language Statements to Equivalent C Code\\nLanguage Level Relative to C\\nC1\\nC++ 2.5\\nFortran 95 2\\nJava 2.5\\nPerl 6\\nPython 6\\nSmalltalk 6\\nMicrosoft Visual Basic 4.5\\nSource: Adapted from Estimating Software Costs (Jones 1998), Software Cost Estimation with Cocomo II \\n(Boehm 2000), and “An Empirical Comparison of Seven Programming Languages” (Prechelt 2000). \\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 99}, page_content='4.1 Choice of Programming Language 63\\nSome languages are better at expressing programming concepts than others. You can \\ndraw a parallel between natural languages such as English and programming lan-\\nguages such as Java and C++. In the case of natural languages, the linguists Sapir and \\nWhorf hypothesize a relationship between the expressive power of a language and the \\nability to think certain thoughts. The Sapir-Whorf hypothesis says that your ability to \\nthink a thought depends on knowing words capable of expressing the thought. If you \\ndon’t know the words, you can’t express the thought and you might not even be able \\nto formulate it (Whorf 1956).\\nProgrammers may be similarly influenced by their languages. The words available in a \\nprogramming language for expressing your programming thoughts certainly deter-\\nmine how you express your thoughts and might even determine what thoughts you \\ncan express.\\nEvidence of the effect of programming languages on programmers’ thinking is com-\\nmon. A typical story goes like this: “We were writing a new system in C++, but most of \\nour programmers didn’t have much experience in C++. They came from Fortran back-\\ngrounds. They wrote code that compiled in C++, but they were really writing dis-\\nguised Fortran. They stretched C++ to emulate Fortran’s bad features (such as gotos \\nand global data) and ignored C++’s rich set of object-oriented capabilities.” This phe-\\nnomenon has been reported throughout the industry for many years (Hanson 1984, \\nYourdon 1986a).\\nLanguage Descriptions\\nThe development histories of some languages are interesting, as are their general capa-\\nbilities. Here are descriptions of the most common languages in use today.\\nAda\\nAda is a general-purpose, high-level programming language based on Pascal. It was \\ndeveloped under the aegis of the Department of Defense and is especially well suited \\nto real-time and embedded systems. Ada emphasizes data abstraction and informa-\\ntion hiding and forces you to differentiate between the public and private parts of each \\nclass and package. “Ada” was chosen as the name of the language in honor of Ada \\nLovelace, a mathematician who is considered to have been the world’s first program-\\nmer. Today, Ada is used primarily in military, space, and avionics systems.\\nAssembly Language\\nAssembly language, or “assembler,” is a kind of low-level language in which each state-\\nment corresponds to a single machine instruction. Because the statements use spe-\\ncific machine instructions, an assembly language is specific to a particular processor—\\nfor example, specific Intel or Motorola CPUs. Assembler is regarded as the second-\\ngeneration language. Most programmers avoid it unless they’re pushing the limits in \\nexecution speed or code size.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 100}, page_content='64 Chapter 4: Key Construction Decisions\\nC\\nC is a general-purpose, mid-level language that was originally associated with the \\nUNIX operating system. C has some high-level language features, such as structured \\ndata, structured control flow, machine independence, and a rich set of operators. It \\nhas also been called a “portable assembly language” because it makes extensive use of \\npointers and addresses, has some low-level constructs such as bit manipulation, and \\nis weakly typed.\\nC was developed in the 1970s at Bell Labs. It was originally designed for and used on \\nthe DEC PDP-11—whose operating system, C compiler, and UNIX application pro-\\ngrams were all written in C. In 1988, an ANSI standard was issued to codify C, which \\nwas revised in 1999. C was the de facto standard for microcomputer and workstation \\nprogramming in the 1980s and 1990s.\\nC++\\nC++, an object-oriented language founded on C, was developed at Bell Laboratories in \\nthe 1980s. In addition to being compatible with C, C++ provides classes, polymor-\\nphism, exception handling, templates, and it provides more robust type checking \\nthan C does. It also provides an extensive and powerful standard library. \\nC#\\nC# is a general-purpose, object-oriented language and programming environment \\ndeveloped by Microsoft with syntax similar to C, C++, and Java, and it provides exten-\\nsive tools that aid development on Microsoft platforms. \\nCobol\\nCobol is an English-like programming language that was originally developed in \\n1959–1961 for use by the Department of Defense. Cobol is used primarily for busi-\\nness applications and is still one of the most widely used languages today, second \\nonly to Visual Basic in popularity (Feiman and Driver 2002). Cobol has been updated \\nover the years to include mathematical functions and object-oriented capabilities. The \\nacronym “Cobol” stands for COmmon Business-Oriented Language. \\nFortran\\nFortran was the first high-level computer language, introducing the ideas of variables \\nand high-level loops. “Fortran” stands for FORmula TRANslation. Fortran was origi-\\nnally developed in the 1950s and has seen several significant revisions, including For-\\ntran 77 in 1977, which added block-structured if-then-else statements and character-\\nstring manipulations. Fortran 90 added user-defined data types, pointers, classes, and \\na rich set of operations on arrays. Fortran is used mainly in scientific and engineering \\napplications.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 101}, page_content='4.1 Choice of Programming Language 65\\nJava\\nJava is an object-oriented language with syntax similar to C and C++ that was devel-\\noped by Sun Microsystems, Inc. Java was designed to run on any platform by convert-\\ning Java source code to byte code, which is then run in each platform within an \\nenvironment known as a virtual machine. Java is in widespread use for programming \\nWeb applications. \\nJavaScript\\nJavaScript is an interpreted scripting language that was originally loosely related to \\nJava. It is used primarily for client-side programming such as adding simple functions \\nand online applications to Web pages. \\nPerl\\nPerl is a string-handling language that is based on C and several UNIX utilities. Perl is \\noften used for system administration tasks, such as creating build scripts, as well as \\nfor report generation and processing. It’s also used to create Web applications such as \\nSlashdot. The acronym “Perl” stands for Practical Extraction and Report Language. \\nPHP\\nPHP is an open-source scripting language with a simple syntax similar to Perl, Bourne \\nShell, JavaScript, and C. PHP runs on all major operating systems to execute server-\\nside interactive functions. It can be embedded in Web pages to access and present \\ndatabase information. The acronym “PHP” originally stood for Personal Home Page \\nbut now stands for PHP: Hypertext Processor. \\nPython\\nPython is an interpreted, interactive, object-oriented language that runs in numerous \\nenvironments. It is used most commonly for writing scripts and small Web applica-\\ntions and also contains some support for creating larger programs. \\nSQL\\nSQL is the de facto standard language for querying, updating, and managing rela-\\ntional databases. “SQL” stands for Structured Query Language. Unlike other lan-\\nguages listed in this section, SQL is a “declarative language,” meaning that it does not \\ndefine a sequence of operations, but rather the result of some operations. \\nVisual Basic\\nThe original version of Basic was a high-level language developed at Dartmouth Col-\\nlege in the 1960s. The acronym BASIC stands for Beginner’s All-purpose Symbolic \\nC04619670.fm  Page 65  Tuesday, April 12, 2011  2:25 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 102}, page_content='66 Chapter 4: Key Construction Decisions\\nInstruction Code. Visual Basic is a high-level, object-oriented, visual programming \\nversion of Basic developed by Microsoft that  was originally designed for creating \\nMicrosoft Windows applications. It has since been extended to support customiza-\\ntion of desktop applications such as Microsoft Office, creation of Web programs, \\nand other applications. Experts report that  by the early 2000s more professional \\ndevelopers were working in Visual Basic than in any other language (Feiman and \\nDriver 2002). \\n4.2 Programming Conventions\\nCross-Reference For more \\ndetails on the power of con-\\nventions, see Sections 11.3 \\nthrough 11.5. \\nIn high-quality software, you can see a relationship between the conceptual integrity \\nof the architecture and its low-level implementation. The implementation must be \\nconsistent with the architecture that guides it and consistent internally. That’s the \\npoint of construction guidelines for variable names, class names, routine names, for-\\nmatting conventions, and commenting conventions.\\nIn a complex program, architectural guidelines give the program structural balance \\nand construction guidelines provide low-level harmony, articulating each class as a \\nfaithful part of a comprehensive design. Any large program requires a controlling \\nstructure that unifies its programming-language details. Part of the beauty of a large \\nstructure is the way in which its detailed parts bear out the implications of its architec-\\nture. Without a unifying discipline, your creation will be a jumble of sloppy variations \\nin style. Such variations tax your brain—and only for the sake of understanding cod-\\ning-style differences that are essentially arbitrary. One key to successful programming \\nis avoiding arbitrary variations so that your brain can be free to focus on the variations \\nthat are really needed. For more on this, see “Software’s Primary Technical Imperative: \\nManaging Complexity” in Section 5.2.\\nWhat if you had a great design for a painting, but one part was classical, one impres-\\nsionist, and one cubist? It wouldn’t have conceptual integrity no matter how closely \\nyou followed its grand design. It would look like a collage. A program needs low-level \\nintegrity, too.\\nBefore construction begins, spell out the programming conventions you’ll use. Cod-\\ning-convention details are at such a level of precision that they’re nearly impossible to \\nretrofit into software after it’s written. Details of such conventions are provided \\nthroughout the book.\\n4.3 Your Location on the Technology Wave \\nDuring my career I’ve seen the PC’s star rise while the mainframe’s star dipped toward \\nthe horizon. I’ve seen GUI programs replace character-based programs. And I’ve seen \\nthe Web ascend while Windows declines. I can only assume that by the time you read \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 103}, page_content='4.3 Your Location on the Technology Wave 67\\nthis some new technology will be in ascendance, and Web programming as I know it \\ntoday (2004) will be on its way out. These technology cycles, or waves, imply different \\nprogramming practices depending on where you find yourself on the wave. \\nIn mature technology environments—the end of the wave, such as Web programming \\nin the mid-2000s—we benefit from a rich software development infrastructure. Late-\\nwave environments provide numerous programming language choices, comprehen-\\nsive error checking for code written in those languages, powerful debugging tools, \\nand automatic, reliable performance optimization. The compilers are nearly bug-free. \\nThe tools are well documented in vendor literature, in third-party books and articles, \\nand in extensive Web resources. Tools are integrated, so you can do UI, database, \\nreports, and business logic from within a single environment. If you do run into prob-\\nlems, you can readily find quirks of the tools described in FAQs. Many consultants \\nand training classes are also available.\\nIn early-wave environments—Web programming in the mid-1990s, for example—the \\nsituation is the opposite. Few programming language choices are available, and those \\nlanguages tend to be buggy and poorly documented. Programmers spend significant \\namounts of time simply trying to figure out how the language works instead of writing \\nnew code. Programmers also spend countless hours working around bugs in the lan-\\nguage products, underlying operating system, and other tools. Programming tools in \\nearly-wave environments tend to be primitive. Debuggers might not exist at all, and \\ncompiler optimizers are still only a gleam in some programmer’s eye. Vendors revise \\ntheir compiler version often, and it seems that each new version breaks significant \\nparts of your code. Tools aren’t integrated, and so you tend to work with different \\ntools for UI, database, reports, and business logic. The tools tend not to be very com-\\npatible, and you can expend a significant amount of effort just to keep existing func-\\ntionality working against the onslaught of compiler and library releases. If you run \\ninto trouble, reference literature exists on the Web in some form, but it isn’t always \\nreliable and, if the available literature is any guide, every time you encounter a prob-\\nlem it seems as though you’re the first one to do so. \\nThese comments might seem like a recommendation to avoid early-wave program-\\nming, but that isn’t their intent. Some of th e most innovative applications arise from \\nearly-wave programs, like Turbo Pascal, Lotus 123, Microsoft Word, and the Mosaic \\nbrowser. The point is that how you spend your programming days will depend on \\nwhere you are on the technology wave. If you’re in the late part of the wave, you can \\nplan to spend most of your day steadily writing new functionality. If you’re in the early \\npart of the wave, you can assume that you’ll spend a sizeable portion of your time try-\\ning to figure out your programming language’s undocumented features, debugging \\nerrors that turn out to be defects in the library code, revising code so that it will work \\nwith a new release of some vendor’s library, and so on. \\nWhen you find yourself working in a primitive environment, realize that the program-\\nming practices described in this book can help you even more than they can in mature'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 104}, page_content='68 Chapter 4: Key Construction Decisions\\nenvironments. As David Gries pointed out, your programming tools don’t have to \\ndetermine how you think about programming (1981). Gries makes a distinction \\nbetween programming in a language vs. programming into a language. Programmers \\nwho program “in” a language limit their thoughts to constructs that the language \\ndirectly supports. If the language tools are primitive, the programmer’s thoughts will \\nalso be primitive. \\nProgrammers who program “into” a language first decide what thoughts they want to \\nexpress, and then they determine how to express those thoughts using the tools pro-\\nvided by their specific language. \\nExample of Programming into a Language\\nIn the early days of Visual Basic, I was frustrated because I wanted to keep the busi-\\nness logic, the UI, and the database separa te in the product I was developing, but \\nthere wasn’t any built-in way to do that in the language. I knew that if I wasn’t careful, \\nover time some of my Visual Basic “forms” would end up containing business logic, \\nsome forms would contain database code, and some would contain neither—I would \\nend up never being able to remember which code was located in which place. I had \\njust completed a C++ project that had done a poor job of separating those issues, and \\nI didn’t want to experience déjà vu of those headaches in a different language.\\nConsequently, I adopted a design convention that the .frm file (the form file) was \\nallowed only to retrieve data from the database and store data back into the database. \\nIt wasn’t allowed to communicate that data directly to other parts of the program. \\nEach form supported an IsFormCompleted() routine, which was used by the calling \\nroutine to determine whether the form that had been activated had saved its data. \\nIsFormCompleted() was the only public routine that forms were allowed to have. \\nForms also weren’t allowed to contain any business logic. All other code had to be \\ncontained in an associated .bas file, including validity checks for entries in the form.\\nVisual Basic did not encourage this kind of approach. It encouraged programmers to \\nput as much code into the .frm file as possible, and it didn’t make it easy for the .frm \\nfile to call back into an associated .bas file. \\nThis convention was pretty simple, but as I got deeper into my project, I found that it \\nhelped me avoid numerous cases in which I would have been writing convoluted code \\nwithout the convention. I would have been loading forms but keeping them hidden so \\nthat I could call the data-validity-checking routines inside them, or I would have been \\ncopying code from the forms into other locations and then maintaining parallel code \\nin multiple places. The IsFormCompleted() convention also kept things simple. \\nBecause every form worked exactly the same way, I never had to second-guess the \\nsemantics of IsFormCompleted()—it meant the same thing every time it was used.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 105}, page_content='4.4 Selection of Major Construction Practices 69\\nVisual Basic didn’t support this convention directly, but my use of a simple program-\\nming convention—programming into the language—made up for the language’s lack of \\nstructure at that time and helped keep the project intellectually manageable. \\nUnderstanding the distinction between programming in a language and program-\\nming into one is critical to understanding this book. Most of the important program-\\nming principles depend not on specific languages but on the way you use them. If \\nyour language lacks constructs that you want to use or is prone to other kinds of prob-\\nlems, try to compensate for them. Invent your own coding conventions, standards, \\nclass libraries, and other augmentations.\\n4.4 Selection of Major Construction Practices\\nPart of preparing for construction is deciding which of the many available good prac-\\ntices you’ll emphasize. Some projects use pair programming and test-first develop-\\nment, while others use solo development and formal inspections. Either combination \\nof techniques can work well, depending on specific circumstances of the project. \\nThe following checklist summarizes the specific practices you should consciously \\ndecide to include or exclude during construction. Details of these practices are con-\\ntained throughout the book. \\ncc2e.com/0496 Checklist: Major Construction Practices\\nCoding \\n❑ Have you defined how much design will be done up front and how much \\nwill be done at the keyboard, while the code is being written? \\n❑ Have you defined coding conventions for names, comments, and layout?\\n❑ Have you defined specific coding practices that are implied by the architec-\\nture, such as how error conditions will be handled, how security will be \\naddressed, what conventions will be used for class interfaces, what stan-\\ndards will apply to reused code, how much to consider performance while \\ncoding, and so on? \\n❑ Have you identified your location on the technology wave and adjusted \\nyour approach to match? If necessary, have you identified how you will \\nprogram into the language rather than being limited by programming in it?\\nTeamwork \\n❑ Have you defined an integration procedure—that is, have you defined the \\nspecific steps a programmer must go through before checking code into \\nthe master sources?\\n❑ Will programmers program in pairs, or individually, or some combination \\nof the two? \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 106}, page_content='70 Chapter 4: Key Construction Decisions\\nCross-Reference For more \\ndetails on quality assurance, \\nsee Chapter 20, “The Soft-\\nware-Quality Landscape.”\\nQuality Assurance \\n❑ Will programmers write test cases for their code before writing the code \\nitself? \\n❑ Will programmers write unit tests for their code regardless of whether \\nthey write them first or last? \\n❑ Will programmers step through their code in the debugger before they \\ncheck it in? \\n❑ Will programmers integration-test their code before they check it in? \\n❑ Will programmers review or inspect each other’s code? \\nCross-Reference For more \\ndetails on tools, see Chapter \\n30, “Programming Tools.”\\nTools\\n❑ Have you selected a revision control tool? \\n❑ Have you selected a language and language version or compiler version? \\n❑ Have you selected a framework such as J2EE or Microsoft .NET or explic-\\nitly decided not to use a framework? \\n❑ Have you decided whether to allow use of nonstandard language features? \\n❑ Have you identified and acquired other tools you’ll be using—editor, refac-\\ntoring tool, debugger, test framework, syntax checker, and so on? \\nKey Points\\n■ Every programming language has strengths and weaknesses. Be aware of the \\nspecific strengths and weaknesses of the language you’re using. \\n■ Establish programming conventions before you begin programming. It’s nearly \\nimpossible to change code to match them later.\\n■ More construction practices exist than you can use on any single project. Con-\\nsciously choose the practices that are best suited to your project. \\n■ Ask yourself whether the programming practices you’re using are a response to \\nthe programming language you’re using or controlled by it. Remember to pro-\\ngram into the language, rather than programming in it. \\n■ Your position on the technology wave determines what approaches will be effec-\\ntive—or even possible. Identify where you are on the technology wave, and \\nadjust your plans and expectations accordingly.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 107}, page_content='Part II\\nCreating High-Quality Code\\nIn this part:\\nChapter 5: Design in Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .73\\nChapter 6: Working Classes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .125\\nChapter 7: High-Quality Routines  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .161\\nChapter 8: Defensive Programming. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .187\\nChapter 9: The Pseudocode Programming Process. . . . . . . . . . . . . . . . . .215'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 109}, page_content='73\\nChapter 5\\nDesign in Construction\\ncc2e.com/0578 Contents\\n■ 5.1 Design Challenges: page 74\\n■ 5.2 Key Design Concepts: page 77\\n■ 5.3 Design Building Blocks: Heuristics: page 87\\n■ 5.4 Design Practices: page 110\\n■ 5.5 Comments on Popular Methodologies: page 118\\nRelated Topics\\n■ Software architecture: Section 3.5\\n■ Working classes: Chapter 6\\n■ Characteristics of high-quality routines: Chapter 7\\n■ Defensive programming: Chapter 8\\n■ Refactoring: Chapter 24\\n■ How program size affects construction: Chapter 27\\nSome people might argue that design isn’t really a construction activity, but on small \\nprojects, many activities are thought of as construction, often including design. On \\nsome larger projects, a formal architecture might address only the system-level issues \\nand much design work might intentionally be left for construction. On other large \\nprojects, the design might be intended to be detailed enough for coding to be fairly \\nmechanical, but design is rarely that complete—the programmer usually designs part \\nof the program, officially or otherwise.\\nCross-Reference For details \\non the different levels of for-\\nmality required on large and \\nsmall projects, see Chapter \\n27, “How Program Size \\nAffects Construction.”\\nOn small, informal projects, a lot of design is done while the programmer sits at the \\nkeyboard. “Design” might be just writing a class interface in pseudocode before writ-\\ning the details. It might be drawing diagrams of a few class relationships before coding \\nthem. It might be asking another programmer which design pattern seems like a bet-\\nter choice. Regardless of how it’s done, small projects benefit from careful design just \\nas larger projects do, and recognizing design as an explicit activity maximizes the ben-\\nefit you will receive from it.\\nDesign is a huge topic, so only a few aspects of it are considered in this chapter. A large \\npart of good class or routine design is determined by the system architecture, so be'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 110}, page_content='74 Chapter 5: Design in Construction\\nsure that the architecture prerequisite discussed in Section 3.5 has been satisfied. \\nEven more design work is done at the level of individual classes and routines, \\ndescribed in Chapter 6, “Working Classes,” and Chapter 7, “High-Quality Routines.”\\nIf you’re already familiar with software design topics, you might want to just hit the \\nhighlights in the sections about design challenges in Section 5.1 and key heuristics in \\nSection 5.3.\\n5.1 Design Challenges\\nCross-Reference The differ-\\nence between heuristic and \\ndeterministic processes is \\ndescribed in Chapter 2, \\n“Metaphors for a Richer \\nUnderstanding of Software \\nDevelopment.”\\nThe phrase “software design” means the conception, invention, or contrivance of a \\nscheme for turning a specification for computer software into operational software. \\nDesign is the activity that links requirements to coding and debugging. A good top-\\nlevel design provides a structure that can safely contain multiple lower-level designs. \\nGood design is useful on small projects and indispensable on large projects. \\nDesign is also marked by numerous challenges, which are outlined in this section. \\nDesign Is a Wicked Problem\\nThe picture of the software \\ndesigner deriving his design \\nin a rational, error-free way \\nfrom a statement of require-\\nments is quite unrealistic. No \\nsystem has ever been devel-\\noped in that way, and proba-\\nbly none ever will. Even the \\nsmall program develop-\\nments shown in textbooks \\nand papers are unreal. They \\nhave been revised and pol-\\nished until the author has \\nshown us what he wishes he \\nhad done, not what actually \\ndid happen.\\n—David Parnas and \\nPaul Clements\\nHorst Rittel and Melvin Webber defined a “wicked” problem as one that could be \\nclearly defined only by solving it, or by solving part of it (1973). This paradox implies, \\nessentially, that you have to “solve” the problem once in order to clearly define it and \\nthen solve it again to create a solution that works. This process has been motherhood \\nand apple pie in software development for decades (Peters and Tripp 1976).\\nIn my part of the world, a dramatic example of such a wicked problem was the design \\nof the original Tacoma Narrows bridge. At the time the bridge was built, the main con-\\nsideration in designing a bridge was that it be strong enough to support its planned \\nload. In the case of the Tacoma Narrows bridge, wind created an unexpected, side-to-\\nside harmonic ripple. One blustery day in 1940, the ripple grew uncontrollably until \\nthe bridge collapsed, as shown in Figure 5-1.\\nThis is a good example of a wicked problem because, until the bridge collapsed, its \\nengineers didn’t know that aerodynamics needed to be considered to such an extent. \\nOnly by building the bridge (solving the problem) could they learn about the addi-\\ntional consideration in the problem that allowed them to build another bridge that \\nstill stands.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 111}, page_content='5.1 Design Challenges 75\\nFigure 5-1 The Tacoma Narrows bridge—an example of a wicked problem.\\nOne of the main differences between programs you develop in school and those you \\ndevelop as a professional is that the design problems solved by school programs are \\nrarely, if ever, wicked. Programming assignments in school are devised to move you in a \\nbeeline from beginning to end. You’d probably want to tar and feather a teacher who gave \\nyou a programming assignment, then changed the assignment as soon as you finished \\nthe design, and then changed it again just as you were about to turn in the completed pro-\\ngram. But that very process is an everyday reality in professional programming.\\nDesign Is a Sloppy Process (Even If it Produces a Tidy Result)\\nThe finished software design should look well organized and clean, but the process \\nused to develop the design isn’t nearly as tidy as the end result.\\nFurther Reading For a fuller \\nexploration of this viewpoint, \\nsee “A Rational Design Pro-\\ncess: How and Why to Fake \\nIt” (Parnas and Clements \\n1986).\\nDesign is sloppy because you take many false steps and go down many blind alleys—\\nyou make a lot of mistakes. Indeed, making mistakes is the point of design—it’s \\ncheaper to make mistakes and correct designs than it would be to make the same mis-\\ntakes, recognize them after coding, and have to correct full-blown code. Design is \\nsloppy because a good solution is often only subtly different from a poor one. \\nMorning News Tribune'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 112}, page_content='76 Chapter 5: Design in Construction\\nCross-Reference For a better \\nanswer to this question, see \\n“How Much Design is \\nEnough?” in Section 5.4 later \\nin this chapter. \\nDesign is also sloppy because it’s hard to know when your design is “good enough.” \\nHow much detail is enough? How much design should be done with a formal design \\nnotation, and how much should be left to be done at the keyboard? When are you \\ndone? Since design is open-ended, the most common answer to that question is \\n“When you’re out of time.”\\nDesign Is About Tradeoffs and Priorities\\nIn an ideal world, every system could run instantly, consume zero storage space, use \\nzero network bandwidth, never contain any errors, and cost nothing to build. In the real \\nworld, a key part of the designer’s job is to weigh competing design characteristics and \\nstrike a balance among those characteristics. If a fast response rate is more important \\nthan minimizing development time, a designer will choose one design. If minimizing \\ndevelopment time is more important, a good designer will craft a different design.\\nDesign Involves Restrictions\\nThe point of design is partly to create possibilities and partly to restrict possibilities. If \\npeople had infinite time, resources, and space to build physical structures, you would \\nsee incredible sprawling buildings with one room for each shoe and hundreds of rooms. \\nThis is how software can turn out without deliberately imposed restrictions. The con-\\nstraints of limited resources for constructing buildings force simplifications of the solu-\\ntion that ultimately improve the solution. The goal in software design is the same.\\nDesign Is Nondeterministic\\nIf you send three people away to design the same program, they can easily return with \\nthree vastly different designs, each of which could be perfectly acceptable. There \\nmight be more than one way to skin a cat, but there are usually dozens of ways to \\ndesign a computer program.\\nDesign Is a Heuristic Process\\nBecause design is nondeterministic, design techniques tend to be heuristics—“rules of \\nthumb” or “things to try that sometimes work”—rather than repeatable processes that \\nare guaranteed to produce predictable results. Design involves trial and error. A \\ndesign tool or technique that worked well on one job or on one aspect of a job might \\nnot work as well on the next project. No tool is right for everything. \\nDesign Is Emergent\\ncc2e.com/0539 A tidy way of summarizing these attributes of design is to say that design is \\n“emergent.” Designs don’t spring fully formed directly from someone’s brain. They \\nevolve and improve through design reviews, informal discussions, experience writing \\nthe code itself, and experience revising the code.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 113}, page_content='5.2 Key Design Concepts 77\\nFurther Reading Software \\nisn’t the only kind of struc-\\nture that changes over time. \\nPhysical structures evolve, \\ntoo—see How Buildings \\nLearn (Brand 1995). \\nVirtually all systems undergo some degree of design changes during their initial devel-\\nopment, and then they typically change to a greater extent as they’re extended into \\nlater versions. The degree to which change is beneficial or acceptable depends on the \\nnature of the software being built.\\n5.2 Key Design Concepts\\nGood design depends on understanding a handful of key concepts. This section dis-\\ncusses the role of complexity, desirable characteristics of designs, and levels of design. \\nSoftware’s Primary Technical Imperative: Managing Complexity \\nCross-Reference For discus-\\nsion of the way complexity \\naffects programming issues \\nother than design, see \\nSection 34.1, “Conquer \\nComplexity.”\\nTo understand the importance of managing complexity, it’s useful to refer to Fred \\nBrooks’s landmark paper, “No Silver Bullets: Essence and Accidents of Software Engi-\\nneering” (1987). \\nAccidental and Essential Difficulties\\nBrooks argues that software development is made difficult because of two different \\nclasses of problems—the essential and the accidental. In referring to these two terms, \\nBrooks draws on a philosophical tradition going back to Aristotle. In philosophy, the \\nessential properties are the properties that a thing must have in order to be that thing. \\nA car must have an engine, wheels, and doors to be a car. If it doesn’t have any of those \\nessential properties, it isn’t really a car. \\nAccidental properties are the properties a thing just happens to have, properties that \\ndon’t really bear on whether the thing is what it is. A car could have a V8, a turbo-\\ncharged 4-cylinder, or some other kind of engine and be a car regardless of that detail. \\nA car could have two doors or four; it could have skinny wheels or mag wheels. All \\nthose details are accidental properties. You could also think of accidental properties \\nas incidental, discretionary, optional, and happenstance. \\nCross-Reference Accidental \\ndifficulties are more promi-\\nnent in early-wave develop-\\nment than in late-wave \\ndevelopment. For details, \\nsee Section 4.3, “Your Loca-\\ntion on the Technology \\nWave.”\\nBrooks observes that the major accidental difficulties in software were addressed long \\nago. For example, accidental difficulties related to clumsy language syntaxes were \\nlargely eliminated in the evolution from assembly language to third-generation lan-\\nguages and have declined in significance incrementally since then. Accidental difficul-\\nties related to noninteractive computers were resolved when time-share operating \\nsystems replaced batch-mode systems. Integrated programming environments fur-\\nther eliminated inefficiencies in programming work arising from tools that worked \\npoorly together.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 114}, page_content='78 Chapter 5: Design in Construction\\nBrooks argues that progress on software’s remaining essential difficulties is bound to \\nbe slower. The reason is that, at its essence, software development consists of working \\nout all the details of a highly intricate, interlocking set of concepts. The essential \\ndifficulties arise from the necessity of interfacing with the complex, disorderly real \\nworld; accurately and completely identifying the dependencies and exception cases; \\ndesigning solutions that can’t be just approximately correct but that must be exactly \\ncorrect; and so on. Even if we could invent a programming language that used the \\nsame terminology as the real-world problem we’re trying to solve, programming \\nwould still be difficult because of the challenge in determining precisely how the real \\nworld works. As software addresses ever-larger real-world problems, the interactions \\namong the real-world entities become increasingly intricate, and that in turn increases \\nthe essential difficulty of the software solutions. \\nThe root of all these essential difficulties is complexity—both accidental and essential. \\nImportance of Managing Complexity\\nThere are two ways of con-\\nstructing a software design: \\none way is to make it so sim-\\nple that there are obviously \\nno deficiencies, and the \\nother is to make it so compli-\\ncated that there are no obvi-\\nous deficiencies.\\n—C. A. R. Hoare\\nWhen software-project surveys report causes of project failure, they rarely identify \\ntechnical reasons as the primary causes of project failure. Projects fail most often \\nbecause of poor requirements, poor planning, or poor management. But when \\nprojects do fail for reasons that are primarily technical, the reason is often uncon-\\ntrolled complexity. The software is allowed to grow so complex that no one really \\nknows what it does. When a project reaches the point at which no one completely \\nunderstands the impact that code changes in one area will have on other areas, \\nprogress grinds to a halt. \\nManaging complexity is the most important technical topic in software development. \\nIn my view, it’s so important that Software’s Primary Technical Imperative has to be \\nmanaging complexity.\\nComplexity is not a new feature of software development. Computing pioneer Edsger \\nDijkstra pointed out that computing is the only profession in which a single mind is \\nobliged to span the distance from a bit to a few hundred megabytes, a ratio of 1 to 109, \\nor nine orders of magnitude (Dijkstra 1989). This gigantic ratio is staggering. Dijkstra \\nput it this way: “Compared to that number of semantic levels, the average mathemati-\\ncal theory is almost flat. By evoking the need for deep conceptual hierarchies, the \\nautomatic computer confronts us with a radically new intellectual challenge that has \\nno precedent in our history.” Of course software has become even more complex \\nsince 1989, and Dijkstra’s ratio of 1 to 109 could easily be more like 1 to 1015 today. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 115}, page_content='5.2 Key Design Concepts 79\\nOne symptom that you have \\nbogged down in complexity \\noverload is when you find \\nyourself doggedly applying a \\nmethod that is clearly irrele-\\nvant, at least to any outside \\nobserver. It is like the \\nmechanically inept person \\nwhose car breaks down—so \\nhe puts water in the battery \\nand empties the ashtrays.\\n—P.  J .  P l a u g e r\\nDijkstra pointed out that no one’s skull is really big enough to contain a modern com-\\nputer program (Dijkstra 1972), which means that we as software developers \\nshouldn’t try to cram whole programs into our skulls at once; we should try to orga-\\nnize our programs in such a way that we can safely focus on one part of it at a time. \\nThe goal is to minimize the amount of a program you have to think about at any one \\ntime. You might think of this as mental juggling—the more mental balls the program \\nrequires you to keep in the air at once, the more likely you’ll drop one of the balls, \\nleading to a design or coding error. \\nAt the software-architecture level, the complexity of a problem is reduced by dividing \\nthe system into subsystems. Humans have an easier time comprehending several sim-\\nple pieces of information than one complicated piece. The goal of all software-design \\ntechniques is to break a complicated problem into simple pieces. The more indepen-\\ndent the subsystems are, the more you make it safe to focus on one bit of complexity \\nat a time. Carefully defined objects separate concerns so that you can focus on one \\nthing at a time. Packages provide the same benefit at a higher level of aggregation.\\nKeeping routines short helps reduce your mental workload. Writing programs in \\nterms of the problem domain, rather than in terms of low-level implementation \\ndetails, and working at the highest level of abstraction reduce the load on your brain. \\nThe bottom line is that programmers wh o compensate for inherent human limita-\\ntions write code that’s easier for themselves and others to understand and that has \\nfewer errors.\\nHow to Attack Complexity\\nOverly costly, ineffective designs arise from three sources:\\n■ A complex solution to a simple problem\\n■ A simple, incorrect solution to a complex problem\\n■ An inappropriate, complex solution to a complex problem\\nAs Dijkstra pointed out, modern software is inherently complex, and no matter how \\nhard you try, you’ll eventually bump into some level of complexity that’s inherent in the \\nreal-world problem itself. This suggests a two-prong approach to managing complexity: \\n■ Minimize the amount of essential complexity that anyone’s brain has to deal \\nwith at any one time. \\n■ Keep accidental complexity from needlessly proliferating. \\nOnce you understand that all other technical goals in software are secondary to man-\\naging complexity, many design considerations become straightforward. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 116}, page_content='80 Chapter 5: Design in Construction\\nDesirable Characteristics of a Design\\nWhen I am working on a \\nproblem I never think about \\nbeauty. I think only how to \\nsolve the problem. But when \\nI have finished, if the solu-\\ntion is not beautiful, I know it \\nis wrong.\\n—R. Buckminster Fuller\\nA high-quality design has several general characteristics. If you could achieve all these \\ngoals, your design would be very good indeed. Some goals contradict other goals, but \\nthat’s the challenge of design—creating a good set of tradeoffs from competing \\nobjectives. Some characteristics of design quality are also characteristics of a good \\nprogram: reliability, performance, and so on . Others are internal characteristics of \\nthe design.\\nCross-Reference These \\ncharacteristics are related to \\ngeneral software-quality \\nattributes. For details on \\ngeneral attributes, see Sec-\\ntion 20.1, “Characteristics of \\nSoftware Quality.”\\nHere’s a list of internal design characteristics:\\nMinimal complexity The primary goal of design should be to minimize complexity \\nfor all the reasons just described. Avoid making “clever” designs. Clever designs are \\nusually hard to understand. Instead make “simple” and “easy-to-understand” designs. \\nIf your design doesn’t let you safely ignore most other parts of the program when \\nyou’re immersed in one specific part, the design isn’t doing its job. \\nEase of maintenance Ease of maintenance means designing for the maintenance \\nprogrammer. Continually imagine the questions a maintenance programmer would \\nask about the code you’re writing. Think of the maintenance programmer as your \\naudience, and then design the system to be self-explanatory.\\nLoose coupling Loose coupling means designing so that you hold connections \\namong different parts of a program to a minimum. Use the principles of  good abstrac-\\ntions in class interfaces, encapsulation, and information hiding to design classes with \\nas few interconnections as possible. Minimal connectedness minimizes work during \\nintegration, testing, and maintenance.\\nExtensibilityExtensibility means that you can enhance a system without causing \\nviolence to the underlying structure. You can change a piece of a system without \\naffecting other pieces. The most likely changes cause the system the least trauma.\\nReusability Reusability means designing the system so that you can reuse pieces of \\nit in other systems.\\nHigh fan-in High fan-in refers to having a high number of classes that use a given \\nclass. High fan-in implies that a system has been designed to make good use of utility \\nclasses at the lower levels in the system.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 117}, page_content='5.2 Key Design Concepts 81\\nLow-to-medium fan-out Low-to-medium fan-out means having a given class use a \\nlow-to-medium number of other classes. High fan-out (more than about seven) indi-\\ncates that a class uses a large number of other classes and may therefore be overly \\ncomplex. Researchers have found that the principle of low fan-out is beneficial \\nwhether you’re considering the number of routines called from within a routine or the \\nnumber of classes used within a class (Card and Glass 1990; Basili, Briand, and Melo \\n1996). \\nPortability Portability means designing the system so that you can easily move it to \\nanother environment.\\nLeanness Leanness means designing the system so that it has no extra parts (Wirth \\n1995, McConnell 1997). Voltaire said that a book is finished not when nothing more \\ncan be added but when nothing more can be taken away. In software, this is especially \\ntrue because extra code has to be developed, reviewed, tested, and considered when \\nthe other code is modified. Future versions of the software must remain backward-\\ncompatible with the extra code. The fatal question is “It’s easy, so what will we hurt by \\nputting it in?”\\nStratification Stratification means trying to keep the levels of decomposition strati-\\nfied so that you can view the system at any single level and get a consistent view. \\nDesign the system so that you can view it at one level without dipping into other levels. \\nCross-Reference For more \\non working with old systems, \\nsee Section 24.5, “Refactor-\\ning Strategies.”\\nFor example, if you’re writing a modern system that has to use a lot of older, poorly \\ndesigned code, write a layer of the new system that’s responsible for interfacing with \\nthe old code. Design the layer so that it hides the poor quality of the old code, present-\\ning a consistent set of services to the newer layers. Then have the rest of the system \\nuse those classes rather than the old code. The beneficial effects of stratified design in \\nsuch a case are (1) it compartmentalizes the messiness of the bad code and (2) if \\nyou’re ever allowed to jettison the old code or refactor it, you won’t need to modify any \\nnew code except the interface layer.\\nCross-Reference An espe-\\ncially valuable kind of stan-\\ndardization is the use of \\ndesign patterns, which are \\ndiscussed in “Look for Com-\\nmon Design Patterns” in \\nSection 5.3.\\nStandard techniques The more a system relies on exotic pieces, the more intimidat-\\ning it will be for someone trying to understand it the first time. Try to give the whole \\nsystem a familiar feeling by using standardized, common approaches.\\nC05619670.fm  Page 81  Tuesday, April 12, 2011  2:30 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 118}, page_content='82 Chapter 5: Design in Construction\\nLevels of Design\\nDesign is needed at several different levels of detail in a software system. Some design tech-\\nniques apply at all levels, and some apply at only one or two. Figure 5-2 illustrates the levels.\\nFigure 5-2 The levels of design in a program. The system (1) is first organized into sub-\\nsystems (2). The subsystems are further divided into classes (3), and the classes are divided \\ninto routines and data (4). The inside of each routine is also designed (5).\\nLevel 1: Software System\\nIn other words—and this is \\nthe rock-solid principle on \\nwhich the whole of the Cor-\\nporation’s Galaxywide suc-\\ncess is founded—their \\nfundamental design flaws \\nare completely hidden by \\ntheir superficial design flaws. \\n—Douglas Adams\\nThe first level is the entire system. Some programmers jump right from the system \\nlevel into designing classes, but it’s usually beneficial to think through higher level \\ncombinations of classes, such as subsystems or packages. \\nLevel 2: Division into Subsystems or Packages\\nThe main product of design at this level is the identification of all major subsystems. The \\nsubsystems can be big: database, user interface, business rules, command interpreter, \\nDivision into subsystems/packages2\\nDivision into classes within packages3\\nSoftware system1\\nDivision into data and routines within classes4\\nInternal routine design5'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 119}, page_content='5.2 Key Design Concepts 83\\nreport engine, and so on. The major design activity at this level is deciding how to parti-\\ntion the program into major subsystems and defining how each subsystem is allowed to \\nuse each other subsystem. Division at this level is typically needed on any project that \\ntakes longer than a few weeks. Within each subsystem, different methods of design \\nmight be used—choosing the approach that best fits each part of the system. In Figure 5-\\n2, design at this level is marked with a 2.\\nOf particular importance at this level are the rules about how the various subsystems \\ncan communicate. If all subsystems can communicate with all other subsystems, you \\nlose the benefit of separating them at all. Make each subsystem meaningful by restrict-\\ning communications. \\nSuppose for example that you define a system with six subsystems, as shown in Fig-\\nure 5-3. When there are no rules, the second law of thermodynamics will come into \\nplay and the entropy of the system will increase. One way in which entropy increases \\nis that, without any restrictions on communications among subsystems, communica-\\ntion will occur in an unrestricted way, as in Figure 5-4.\\nFigure 5-3 An example of a system with six subsystems. \\nFigure 5-4 An example of what happens with no  restrictions on intersubsystem \\ncommunications. \\nUser Interface\\nData Storage Application \\nLevel Classes\\nEnterprise-Level \\nTools\\nBusiness \\nRules\\nGraphics\\nUser Interface\\nData Storage Application \\nLevel Classes\\nEnterprise-Level \\nTools\\nBusiness \\nRules\\nGraphics'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 120}, page_content='84 Chapter 5: Design in Construction\\nAs you can see, every subsystem ends up communicating directly with every other \\nsubsystem, which raises some important questions:\\n■ How many different parts of the system does a developer need to understand at \\nleast a little bit to change something in the graphics subsystem?\\n■ What happens when you try to use the business rules in another system?\\n■ What happens when you want to put a new user interface on the system, per-\\nhaps a command-line UI for test purposes?\\n■ What happens when you want to put data storage on a remote machine? \\nYou might think of the lines between subsystems as being hoses with water running \\nthrough them. If you want to reach in and pull out a subsystem, that subsystem is \\ngoing to have some hoses attached to it. The more hoses you have to disconnect and \\nreconnect, the more wet you’re going to get. You want to architect your system so that \\nif you pull out a subsystem to use elsewhere, you won’t have many hoses to reconnect \\nand those hoses will reconnect easily. \\nWith forethought, all of these issues can be addressed with little extra work. Allow \\ncommunication between subsystems only on a “need to know” basis—and it had bet-\\nter be a good reason. If in doubt, it’s easier to restrict communication early and relax it \\nlater than it is to relax it early and then try to tighten it up after you’ve coded several \\nhundred intersubsystem calls. Figure 5-5 shows how a few communication guidelines \\ncould change the system depicted in Figure 5-4. \\nFigure 5-5 With a few communication rules, you can simplify subsystem interactions sig-\\nnificantly. \\nTo keep the connections easy to understand and maintain, err on the side of simple \\nintersubsystem relations. The simplest relationship is to have one subsystem call rou-\\ntines in another. A more involved relationship is to have one subsystem contain \\nclasses from another. The most involved relationship is to have classes in one sub-\\nsystem inherit from classes in another. \\nUser Interface\\nData Storage Application \\nLevel Classes\\nEnterprise-Level \\nTools\\nBusiness \\nRules\\nGraphics'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 121}, page_content='5.2 Key Design Concepts 85\\nA good general rule is that a system-level diagram like Figure 5-5 should be an acyclic \\ngraph. In other words, a program shouldn’t contain any circular relationships in \\nwhich Class A uses Class B, Class B uses Class C, and Class C uses Class A. \\nOn large programs and families of programs, design at the subsystem level makes a \\ndifference. If you believe that your program is small enough to skip subsystem-level \\ndesign, at least make the decision to skip that level of design a conscious one.\\nCommon Subsystems Some kinds of subsystems appear again and again in differ-\\nent systems. Here are some of the usual suspects. \\nCross-Reference For more \\non simplifying business logic \\nby expressing it in tables, see \\nChapter 18, \"Table-Driven \\nMethods.\"\\nBusiness rules Business rules are the laws, regula tions, policies, and procedures \\nthat you encode into a computer system. If you’re writing a payroll system, you \\nmight encode rules from the IRS about th e number of allowable withholdings and \\nthe estimated tax rate. Additional rules for a payroll system might come from a \\nunion contract specifying overtime rates, vacation and holiday pay, and so on. If \\nyou’re writing a program to quote automo bile insurance rates, rules might come \\nfrom government regulations on required lia bility coverages, actuarial rate tables, or \\nunderwriting restrictions\\nUser interface Create a subsystem to isolate user-interface components so that the \\nuser interface can evolve without damaging the rest of the program. In most cases, a \\nuser-interface subsystem uses several subordinate subsystems or classes for the GUI \\ninterface, command line interface, menu operations, window management, help sys-\\ntem, and so forth.\\nDatabase access You can hide the implementation details of accessing a database so \\nthat most of the program doesn’t need to worry about the messy details of manipulat-\\ning low-level structures and can deal with the data in terms of how it’s used at the \\nbusiness-problem level. Subsystems that hide implementation details provide a valu-\\nable level of abstraction that reduces a program’s complexity. They centralize data-\\nbase operations in one place and reduce the chance of errors in working with the data. \\nThey make it easy to change the database design structure without changing most of \\nthe program.\\nSystem dependencies Package operating-system dependencies into a subsystem for \\nthe same reason you package hardware dependencies. If you’re developing a pro-\\ngram for Microsoft Windows, for example, why limit yourself to the Windows envi-\\nronment? Isolate the Windows calls in a Windows-interface subsystem. If you later \\nwant to move your program to Mac OS or Linux, all you’ll have to change is the \\ninterface subsystem. An interface subsystem can be too extensive for you to imple-\\nment on your own, but such subsystems are readily available in any of several com-\\nmercial code libraries.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 122}, page_content='86 Chapter 5: Design in Construction\\nLevel 3: Division into Classes\\nFurther Reading For a good \\ndiscussion of database \\ndesign, see Agile Database \\nTechniques (Ambler 2003). \\nDesign at this level includes identifying all classes in the system. For example, a data-\\nbase-interface subsystem might be further partitioned into data access classes and \\npersistence framework classes as well as database metadata. Figure 5-2, Level 3, \\nshows how one of Level 2’s subsystems might be divided into classes, and it implies \\nthat the other three subsystems shown at Level 2 are also decomposed into classes.\\nDetails of the ways in which each class interacts with the rest of the system are also \\nspecified as the classes are specified. In particular, the class’s interface is defined. \\nOverall, the major design activity at this level is making sure that all the subsystems \\nhave been decomposed to a level of detail fine enough that you can implement their \\nparts as individual classes.\\nCross-Reference For details \\non characteristics of high-\\nquality classes, see Chapter \\n6, “Working Classes.”\\nThe division of subsystems into classes is typically needed on any project that takes \\nlonger than a few days. If the project is large, the division is clearly distinct from the \\nprogram partitioning of Level 2. If the project is very small, you might move directly \\nfrom the whole-system view of Level 1 to the classes view of Level 3. \\nClasses vs. Objects A key concept in object-oriented design is the differentiation \\nbetween objects and classes. An object is any specific entity that exists in your pro-\\ngram at run time. A class is the static thing you look at in the program listing. An \\nobject is the dynamic thing with specific values and attributes you see when you run \\nthe program. For example, you could declare a class Person that had attributes of \\nname, age, gender, and so on. At run time you would have the objects nancy, hank, \\ndiane, tony, and so on—that is, specific instances of the class. If you’re familiar with \\ndatabase terms, it’s the same as the distinction between “schema” and “instance.” You \\ncould think of the class as the cookie cutter and the object as the cookie. This book \\nuses the terms informally and generally refers to classes and objects more or less inter-\\nchangeably. \\nLevel 4: Division into Routines\\nDesign at this level includes dividing each class into routines. The class interface \\ndefined at Level 3 will define some of the routines. Design at Level 4 will detail the \\nclass’s private routines. When you examine the details of the routines inside a class, \\nyou can see that many routines are simple boxes but a few are composed of hierarchi-\\ncally organized routines, which require still more design. \\nThe act of fully defining the class’s routines often results in a better understanding of \\nthe class’s interface, and that causes corresponding changes to the interface—that is, \\nchanges back at Level 3. \\nThis level of decomposition and design is often left up to the individual programmer, \\nand it’s needed on any project that takes more than a few hours. It doesn’t need to be \\ndone formally, but it at least needs to be done mentally.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 123}, page_content='5.3 Design Building Blocks: Heuristics 87\\nLevel 5: Internal Routine Design\\nCross-Reference For details \\non creating high-quality rou-\\ntines, see Chapter 7, “High-\\nQuality Routines,” and Chap-\\nter 8, “Defensive Program-\\nming.”\\nDesign at the routine level consists of laying out the detailed functionality of the indi-\\nvidual routines. Internal routine design is typically left to the individual programmer \\nworking on an individual routine. The design consists of activities such as writing \\npseudocode, looking up algorithms in reference books, deciding how to organize the \\nparagraphs of code in a routine, and writing programming-language code. This level \\nof design is always done, though sometimes it’s done unconsciously and poorly \\nrather than consciously and well. In Figure 5-2, design at this level is marked with a 5.\\n5.3 Design Building Blocks: Heuristics\\nSoftware developers tend to like our answers cut and dried: “Do A, B, and C, and X, Y, \\nZ will follow every time.” We take pride in learning arcane sets of steps that produce \\ndesired effects, and we become annoyed when instructions don’t work as advertised. \\nThis desire for deterministic behavior is highly appropriate to detailed computer pro-\\ngramming, where that kind of strict attention to detail makes or breaks a program. But \\nsoftware design is a much different story. \\nBecause design is nondeterministic, skillful application of an effective set of heuristics \\nis the core activity in good software design. The following subsections describe a num-\\nber of heuristics—ways to think about a design that sometime produce good design \\ninsights. You might think of heuristics as the guides for the trials in “trial and error.” \\nYou undoubtedly have run across some of these before. Consequently, the following \\nsubsections describe each of the heuristics in terms of Software’s Primary Technical \\nImperative: managing complexity. \\nFind Real-World Objects\\nAsk not first what the system \\ndoes; ask WHAT it does it to! \\n—Bertrand Meyer\\nThe first and most popular approach to identifying design alternatives is the “by the \\nbook” object-oriented approach, which focuses on identifying real-world and syn-\\nthetic objects. \\nThe steps in designing with objects are\\nCross-Reference For more \\ndetails on designing using \\nclasses, see Chapter 6, \\n“Working Classes.”\\n■ Identify the objects and their attributes (methods and data).\\n■ Determine what can be done to each object.\\n■ Determine what each object is allowed to do to other objects.\\n■ Determine the parts of each object that  will be visible to other objects—which \\nparts will be public and which will be private.\\n■ Define each object’s public interface.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 124}, page_content='88 Chapter 5: Design in Construction\\nThese steps aren’t necessarily performed in order, and they’re often repeated. Iteration \\nis important. Each of these steps is summarized below.\\nIdentify the objects and their attributes Computer programs are usually based on \\nreal-world entities. For example, you could base a time-billing system on real-world \\nemployees, clients, timecards, and bills. Figure 5-6 shows an object-oriented view of \\nsuch a billing system.\\nFigure 5-6 This billing system is composed of four major objects. The objects have been \\nsimplified for this example. \\nIdentifying the objects’ attributes is no more complicated than identifying the objects \\nthemselves. Each object has characteristics that are relevant to the computer program. \\nFor example, in the time-billing system, an employee object has a name, a title, and a \\nbilling rate. A client object has a name, a billing address, and an account balance. A bill \\nobject has a billing amount, a client name, a billing date, and so on.\\nObjects in a graphical user interface system would include windows, dialog boxes, \\nbuttons, fonts, and drawing tools. Further examination of the problem domain might \\nproduce better choices for software objects than a one-to-one mapping to real-world \\nobjects, but the real-world objects are a good place to start.\\nDetermine what can be done to each object A variety of operations can be per-\\nformed on each object. In the billing system shown in Figure 5-6, an employee object \\ncould have a change in title or billing rate, a client object could have its name or billing \\naddress changed, and so on.\\nDetermine what each object is allowed to do to other objects This step is just what it \\nsounds like. The two generic things objects can do to each other are containment and \\ninheritance. Which objects can contain which other objects? Which objects can inherit \\nEmployee\\nname\\ntitle\\nbillingRate\\nbillingEmployee\\nbillingRecords\\nclientToBill\\nclientToBill\\nbills\\nGetHoursForMonth()\\n...\\nClient\\nname\\nbillingAddress\\naccountBalance\\ncurrentBillingAmount\\nEnterPayment()\\n...\\nTimecard\\nhours\\ndate\\nprojectCode\\n11 1\\n**\\n* 0..1\\n*\\n...\\nBill\\nbillDate\\nBillForClient()\\n...'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 125}, page_content='5.3 Design Building Blocks: Heuristics 89\\nfrom which other objects? In Figure 5-6, a timecard object can contain an employee \\nobject and a client object, and a bill can contain one or more timecards. In addition, a \\nbill can indicate that a client has been billed, and a client can enter payments against \\na bill. A more complicated system would include additional interactions.\\nCross-Reference For details \\non classes and information \\nhiding, see “Hide Secrets \\n(Information Hiding)” in \\nSection 5.3.\\nDetermine the parts of each object that will be visible to other objects One of the key \\ndesign decisions is identifying the parts of an object that should be made public and those \\nthat should be kept private. This decision has to be made for both data and methods.\\nDefine each object’s interfaces Define the formal, syntactic, programming-language-\\nlevel interfaces to each object. The data and methods the object exposes to every other \\nobject is called the object’s “public interface.” The parts of the object that it exposes to \\nderived objects via inheritance is called the object’s “protected interface.” Think about \\nboth kinds of interfaces.\\nWhen you finish going through the steps to achieve a top-level object-oriented system \\norganization, you’ll iterate in two ways. You’ll iterate on the top-level system organiza-\\ntion to get a better organization of classes. You’ll also iterate on each of the classes \\nyou’ve defined, driving the design of each class to a more detailed level.\\nForm Consistent Abstractions\\nAbstraction is the ability to engage with a concept while safely ignoring some of its \\ndetails—handling different details at different levels. Any time you work with an aggre-\\ngate, you’re working with an abstraction. If you refer to an object as a “house” rather \\nthan a combination of glass, wood, and nails, you’re making an abstraction. If you \\nrefer to a collection of houses as a “town,” you’re making another abstraction.\\nBase classes are abstractions that allow you to focus on common attributes of a set of \\nderived classes and ignore the details of the specific classes while you’re working on \\nthe base class. A good class interface is an abstraction that allows you to focus on the \\ninterface without needing to worry about the internal workings of the class. The inter-\\nface to a well-designed routine provides the same benefit at a lower level of detail, and \\nthe interface to a well-designed package or subsystem provides that benefit at a higher \\nlevel of detail. \\nFrom a complexity point of view, the principal benefit of abstraction is that it allows \\nyou to ignore irrelevant details. Most real-world objects are already abstractions of \\nsome kind. As just mentioned, a house is an abstraction of windows, doors, siding, \\nwiring, plumbing, insulation, and a particular way of organizing them. A door is in \\nturn an abstraction of a particular arrangement of a rectangular piece of material with \\nhinges and a doorknob. And the doorknob is an abstraction of a particular formation \\nof brass, nickel, iron, or steel.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 126}, page_content='90 Chapter 5: Design in Construction\\nPeople use abstraction continuously. If you had to deal with individual wood fibers, \\nvarnish molecules, and steel molecules every time you used your front door, you’d \\nhardly make it in or out of your house each day. As Figure 5-7 suggests, abstraction is \\na big part of how we deal with complexity in the real world. \\nFigure 5-7 Abstraction allows you to take a simpler view of a complex concept. \\nCross-Reference For more \\ndetails on abstraction in \\nclass design, see “Good \\nAbstraction” in Section 6.2.\\nSoftware developers sometimes build systems at the wood-fiber, varnish-molecule, \\nand steel-molecule level. This makes the systems overly complex and intellectually \\nhard to manage. When programmers fail to provide larger programming abstractions, \\nthe system itself sometimes fails to make it through the front door. \\nGood programmers create abstractions at the routine-interface level, class-interface \\nlevel, and package-interface level—in other words, the doorknob level, door level, and \\nhouse level—and that supports faster and safer programming. \\nEncapsulate Implementation Details\\nEncapsulation picks up where abstraction leaves off. Abstraction says, “You’re allowed \\nto look at an object at a high level of detail.” Encapsulation says, “Furthermore, you \\naren’t allowed to look at an object at any other level of detail.” \\nContinuing with the housing-materials analogy: encapsulation is a way of saying that \\nyou can look at the outside of the house but you can’t get close enough to make out \\nthe door’s details. You are allowed to know that there’s a door, and you’re allowed to \\nknow whether the door is open or closed, but you’re not allowed to know whether the \\ndoor is made of wood, fiberglass, steel, or some other material, and you’re certainly \\nnot allowed to look at each individual wood fiber. \\nAs Figure 5-8 suggests, encapsulation helps to manage complexity by forbidding you \\nto look at the complexity. The section titled “Good Encapsulation” in Section 6.2 pro-\\nvides more background on encapsulation as it applies to class design.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 127}, page_content='5.3 Design Building Blocks: Heuristics 91\\nFigure 5-8 Encapsulation says that, not only are you allowed to take a simpler view of a \\ncomplex concept, you are not allowed to look at any of the details of the complex concept. \\nWhat you see is what you get—it’s all you get!\\nInherit—When Inheritance Simplifies the Design\\nIn designing a software system, you’ll often find objects that are much like other \\nobjects, except for a few differences. In an accounting system, for instance, you might \\nhave both full-time and part-time employees. Most of the data associated with both \\nkinds of employees is the same, but some is different. In object-oriented program-\\nming, you can define a general type of employee and then define full-time employees \\nas general employees, except for a few differences, and part-time employees also as \\ngeneral employees, except for a few differences. When an operation on an employee \\ndoesn’t depend on the type of employee, the operation is handled as if the employee \\nwere just a general employee. When the operation depends on whether the employee \\nis full-time or part-time, the operation is handled differently.\\nDefining similarities and differences among such objects is called “inheritance” \\nbecause the specific part-time and full-time employees inherit characteristics from the \\ngeneral-employee type.\\nThe benefit of inheritance is that it works synergistically with the notion of abstrac-\\ntion. Abstraction deals with objects at different levels of detail. Recall the door that \\nwas a collection of certain kinds of molecules at one level, a collection of wood fibers \\nat the next, and something that keeps burglars out of your house at the next level. \\nWood has certain properties—for example, you can cut it with a saw or glue it with \\nwood glue—and two-by-fours or cedar shingles have the general properties of wood as \\nwell as some specific properties of their own.\\nInheritance simplifies programming because you write a general routine to handle \\nanything that depends on a door’s general properties and then write specific routines \\nto handle specific operations on specific kinds of doors. Some operations, such as'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 128}, page_content='92 Chapter 5: Design in Construction\\nOpen() or Close(), might apply regardless of whether the door is a solid door, interior \\ndoor, exterior door, screen door, French door, or sliding glass door. The ability of a \\nlanguage to support operations like Open() or Close() without knowing until run time \\nwhat kind of door you’re dealing with is called “polymorphism.” Object-oriented lan-\\nguages such as C++, Java, and later versions of Microsoft Visual Basic support inherit-\\nance and polymorphism.\\nInheritance is one of object-oriented programming’s most powerful tools. It can pro-\\nvide great benefits when used well, and it can do great damage when used naively. For \\ndetails, see “Inheritance (“is a” Relationships)” in Section 6.3.\\nHide Secrets (Information Hiding)\\nInformation hiding is part of the foundation of both structured design and object-ori-\\nented design. In structured design, the notion of “black boxes” comes from informa-\\ntion hiding. In object-oriented design, it gives rise to the concepts of encapsulation \\nand modularity and it is associated with the concept of abstraction. Information hid-\\ning is one of the seminal ideas in software development, and so this subsection \\nexplores it in depth. \\nInformation hiding first came to public attention in a paper published by David Par-\\nnas in 1972 called “On the Criteria to Be Used in Decomposing Systems Into Mod-\\nules.” Information hiding is characterized by the idea of “secrets,” design and \\nimplementation decisions that a software developer hides in one place from the rest of \\na program. \\nIn the 20th Anniversary edition of The Mythical Man Month, Fred Brooks concluded \\nthat his criticism of information hiding was one of the few ways in which the first edi-\\ntion of his book was wrong. “Parnas was right, and I was wrong about information \\nhiding,” he proclaimed (Brooks 1995). Barry Boehm reported that information hiding \\nwas a powerful technique for eliminating rework, and he pointed out that it was par-\\nticularly effective in incremental, high-change environments (Boehm 1987).\\nInformation hiding is a particularly powerful heuristic for Software’s Primary Techni-\\ncal Imperative because, beginning with its name and throughout its details, it empha-\\nsizes hiding complexity.\\nSecrets and the Right to Privacy\\nIn information hiding, each class (or package or routine) is characterized by the \\ndesign or construction decisions that it hides from all other classes. The secret might \\nbe an area that’s likely to change, the format of a file, the way a data type is imple-\\nmented, or an area that needs to be walled off from the rest of the program so that \\nerrors in that area cause as little damage as possible. The class’s job is to keep this \\ninformation hidden and to protect its own right to privacy. Minor changes to a system'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 129}, page_content='5.3 Design Building Blocks: Heuristics 93\\nmight affect several routines within a class, but they should not ripple beyond the \\nclass interface.\\nStrive for class interfaces \\nthat are complete and mini-\\nmal.\\n—Scott Meyers\\nOne key task in designing a class is deciding which features should be known outside \\nthe class and which should remain secret. A class might use 25 routines and expose \\nonly 5 of them, using the other 20 internally. A class might use several data types and \\nexpose no information about them. This aspect of class design is also known as “visi-\\nbility” since it has to do with which features of the class are “visible” or “exposed” out-\\nside the class.\\nThe interface to a class should reveal as little as possible about its inner workings. As \\nshown in Figure 5-9, a class is a lot like an iceberg: seven-eighths is under water, and \\nyou can see only the one-eighth that’s above the surface.\\nFigure 5-9 A good class interface is like the tip of an iceberg, leaving most of the class \\nunexposed.\\nDesigning the class interface is an iterative process just like any other aspect of design. \\nIf you don’t get the interface right the first time, try a few more times until it stabilizes. \\nIf it doesn’t stabilize, you need to try a different approach.\\nAn Example of Information Hiding\\nSuppose you have a program in which each object is supposed to have a unique ID \\nstored in a member variable called id. One design approach would be to use integers \\nfor the IDs and to store the highest ID assigned so far in a global variable called \\ng_maxId. As each new object is allocated, perhaps in each object’s constructor, you \\ncould simply use the id = ++g_maxId statement, which would guarantee a unique id, \\nand it would add the absolute minimum of code in each place an object is created. \\nWhat could go wrong with that?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 130}, page_content='94 Chapter 5: Design in Construction\\nA lot of things could go wrong. What if you want to reserve ranges of IDs for special \\npurposes? What if you want to use nonsequential IDs to improve security? What if you \\nwant to be able to reuse the IDs of objects that have been destroyed? What if you want \\nto add an assertion that fires when you allocate more IDs than the maximum number \\nyou’ve anticipated? If you allocated IDs by spreading id = ++g_maxId statements \\nthroughout your program, you would have to change code associated with every one \\nof those statements. And, if your program is multithreaded, this approach won’t be \\nthread-safe.\\nThe way that new IDs are created is a design decision that you should hide. If you use \\nthe phrase ++g_maxId throughout your program, you expose the way a new ID is cre-\\nated, which is simply by incrementing g_maxId. If instead you put the id = NewId() \\nstatement throughout your program, you hide the information about how new IDs are \\ncreated. Inside the NewId() routine you might still have just one line of code, return \\n( ++g_maxId ) or its equivalent, but if you later decide to reserve certain ranges of IDs \\nfor special purposes or to reuse old IDs, you could make those changes within the \\nNewId() routine itself—without touching dozens or hundreds of id = NewId() state-\\nments. No matter how complicated the revisions inside NewId() might become, they \\nwouldn’t affect any other part of the program.\\nNow suppose you discover you need to change the type of the ID from an integer to a \\nstring. If you’ve spread variable declarations like int id throughout your program, your \\nuse of the NewId() routine won’t help. You’ll still have to go through your program \\nand make dozens or hundreds of changes.\\nAn additional secret to hide is the ID’s type. By exposing the fact that IDs are inte-\\ngers, you encourage programmers to perform integer operations like >, <, = on them. \\nIn C++, you could use a simple typedef to declare your IDs to be of IdType—a user-\\ndefined type that resolves to int—rather than directly decl aring them to be of type \\nint. Alternatively, in C++ and other languages you could create a simple IdType class. \\nOnce again, hiding a design decision makes a huge difference in the amount of code \\naffected by a change. \\nInformation hiding is useful at all levels of design, from the use of named constants \\ninstead of literals, to creation of data types, to class design, routine design, and sub-\\nsystem design. \\nTwo Categories of Secrets\\nSecrets in information hiding fall into two general camps:\\n■ Hiding complexity so that your brain doesn’t have to deal with it unless you’re \\nspecifically concerned with it\\n■ Hiding sources of change so that when change occurs, the effects are localized\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 131}, page_content='5.3 Design Building Blocks: Heuristics 95\\nSources of complexity include complicated data types, file structures, boolean tests, \\ninvolved algorithms, and so on. A comprehensive list of sources of change is described \\nlater in this chapter. \\nBarriers to Information Hiding\\nFurther Reading Parts of \\nthis section are adapted \\nfrom “Designing Software \\nfor Ease of Extension and \\nContraction” (Parnas 1979).\\nIn a few instances, information hiding is truly impossible, but most of the barriers to \\ninformation hiding are mental blocks built up from the habitual use of other techniques.\\nExcessive distribution of information One common barrier to information hiding is \\nan excessive distribution of information throughout a system. You might have hard-\\ncoded the literal 100 throughout a system. Using 100 as a literal decentralizes refer-\\nences to it. It’s better to hide the information in one place, in a constant \\nMAX_EMPLOYEES perhaps, whose value is changed in only one place.\\nAnother example of excessive information distribution is interleaving interaction with \\nhuman users throughout a system. If the mode of interaction changes—say, from a \\nGUI interface to a command line interface—virtually all the code will have to be mod-\\nified. It’s better to concentrate user interaction in a single class, package, or subsystem \\nyou can change without affecting the whole system.\\nCross-Reference For more \\non accessing global data \\nthrough class interfaces, see \\n“Using Access Routines \\nInstead of Global Data” in \\nSection 13.3. \\nYet another example would be a global data element—perhaps an array of employee \\ndata with 1000 elements maximum that’s accessed throughout a program. If the pro-\\ngram uses the global data directly, information about the data item’s implementa-\\ntion—such as the fact that it’s an array and has a maximum of 1000 elements—will be \\nspread throughout the program. If the program uses the data only through access rou-\\ntines, only the access routines will know the implementation details.\\nCircular dependencies A more subtle barrier to information hiding is circular depen-\\ndencies, as when a routine in class A calls a routine in class B, and a routine in class B \\ncalls a routine in class A. \\nAvoid such dependency loops. They make it hard to test a system because you can’t \\ntest either class A or class B until at least part of the other is ready. \\nClass data mistaken for global data If you’re a conscientious programmer, one of \\nthe barriers to effective information hiding might be thinking of class data as global \\ndata and avoiding it because you want to avoid the problems associated with global \\ndata. While the road to programming hell is paved with global variables, class data \\npresents far fewer risks.\\nGlobal data is generally subject to two problems: routines operate on global data without \\nknowing that other routines are operating on it, and routines are aware that other rou-\\ntines are operating on the global data but they don’t know exactly what they’re doing to \\nit. Class data isn’t subject to either of these problems. Direct access to the data is \\nrestricted to a few routines organized into a single class. The routines are aware that other \\nroutines operate on the data, and they know exactly which other routines they are.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 132}, page_content='96 Chapter 5: Design in Construction\\nOf course, this whole discussion assumes that your system makes use of well-\\ndesigned, small classes. If your program is designed to use huge classes that contain \\ndozens of routines each, the distinction between class data and global data will begin \\nto blur and class data will be subject to many of the same problems as global data. \\nCross-Reference Code-level \\nperformance optimizations \\nare discussed in Chapter 25, \\n“Code-Tuning Strategies” \\nand Chapter 26, “Code-Tun-\\ning Techniques.”\\nPerceived performance penalties A final barrier to information hiding can be an \\nattempt to avoid performance penalties at both the architectural and the coding levels. \\nYou don’t need to worry at either level. At the architectural level, the worry is unnec-\\nessary because architecting a system for information hiding doesn’t conflict with \\narchitecting it for performance. If you keep both information hiding and performance \\nin mind, you can achieve both objectives.\\nThe more common worry is at the coding level. The concern is that accessing data \\nitems indirectly incurs run-time performance penalties for additional levels of object \\ninstantiations, routine calls, and so on. This concern is premature. Until you can mea-\\nsure the system’s performance and pinpoint the bottlenecks, the best way to prepare \\nfor code-level performance work is to create a highly modular design. When you \\ndetect hot spots later, you can optimize individual classes and routines without affect-\\ning the rest of the system.\\nValue of Information Hiding\\nInformation hiding is one of the few theoretical techniques that has indisputably proven \\nits value in practice, which has been true for a long time (Boehm 1987a). Large pro-\\ngrams that use information hiding were found years ago to be easier to modify—by a fac-\\ntor of 4—than programs that don’t (Korson and Vaishnavi 1986). Moreover, information \\nhiding is part of the foundation of both structured design and object-oriented design.\\nInformation hiding has unique heuristic power, a unique ability to inspire effective \\ndesign solutions. Traditional object-oriented design provides the heuristic power of \\nmodeling the world in objects, but object thinking wouldn’t help you avoid declaring \\nthe ID as an int instead of an IdType. The object-oriented designer would ask, “Should \\nan ID be treated as an object?” Depending on the project’s coding standards, a “Yes” \\nanswer might mean that the programmer has to write a constructor, destructor, copy \\noperator, and assignment operator; comment it all; and place it under configuration \\ncontrol. Most programmers would decide, “No, it isn’t worth creating a whole class \\njust for an ID. I’ll just use ints.” \\nNote what just happened. A useful design alternative, that of simply hiding the ID’s \\ndata type, was not even considered. If, instead, the designer had asked, “What about \\nthe ID should be hidden?” he might well have decided to hide its type behind a simple \\ntype declaration that substitutes IdType for int. The difference between object-oriented \\ndesign and information hiding in this example is more subtle than a clash of explicit \\nrules and regulations. Object-oriented design would approve of this design decision \\nas much as information hiding would. Rather, the difference is one of heuristics—\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 133}, page_content='5.3 Design Building Blocks: Heuristics 97\\nthinking about information hiding inspires and promotes design decisions that think-\\ning about objects does not. \\nInformation hiding can also be useful in designing a class’s public interface. The gap \\nbetween theory and practice in class design is wide, and among many class designers \\nthe decision about what to put into a class’s public interface amounts to deciding \\nwhat interface would be the most convenient to use, which usually results in exposing \\nas much of the class as possible. From what I’ve seen, some programmers would \\nrather expose all of a class’s private data than write 10 extra lines of code to keep the \\nclass’s secrets intact. \\nAsking “What does this class need to hide?” cuts to the heart of the interface-design \\nissue. If you can put a function or data into the class’s public interface without com-\\npromising its secrets, do. Otherwise, don’t. \\nAsking about what needs to be hidden supports good design decisions at all levels. It \\npromotes the use of named constants instead of literals at the construction level. It \\nhelps in creating good routine and parameter names inside classes. It guides decisions \\nabout class and subsystem decompositions and interconnections at the system level. \\nGet into the habit of asking “What should I hide?” You’ll be surprised at how many dif-\\nficult design issues dissolve before your eyes.\\nIdentify Areas Likely to Change\\nFurther Reading The \\napproach described in this \\nsection is adapted from \\n“Designing Software for Ease \\nof Extension and Contrac-\\ntion” (Parnas 1979).\\nA study of great designers found that one attribute they had in common was their abil-\\nity to anticipate change (Glass 1995). Accommodating changes is one of the most \\nchallenging aspects of good program design. The goal is to isolate unstable areas so \\nthat the effect of a change will be limited to one routine, class, or package. Here are the \\nsteps you should follow in preparing for such perturbations.\\n1. Identify items that seem likely to change.  If the requirements have been done \\nwell, they include a list of potential changes and the likelihood of each change. \\nIn such a case, identifying the likely changes is easy. If the requirements don’t \\ncover potential changes, see the discussion that follows of areas that are likely to \\nchange on any project.\\n2. Separate items that are likely to change.  Compartmentalize each volatile com-\\nponent identified in step 1 into its own class or into a class with other volatile \\ncomponents that are likely to change at the same time.\\n3. Isolate items that seem likely to change.  Design the interclass interfaces to be \\ninsensitive to the potential changes. Design the interfaces so that changes are \\nlimited to the inside of the class and the outside remains unaffected. Any other \\nclass using the changed class should be unaware that the change has occurred. \\nThe class’s interface should protect its secrets.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 134}, page_content='98 Chapter 5: Design in Construction\\nHere are a few areas that are likely to change:\\nCross-Reference One of the \\nmost powerful techniques \\nfor anticipating change is to \\nuse table-driven methods. \\nFor details, see Chapter 18, \\n“Table-Driven Methods. ” \\nBusiness rules Business rules tend to be the source of frequent software changes. \\nCongress changes the tax structure, a union renegotiates its contract, or an insurance \\ncompany changes its rate tables. If you follow the principle of information hiding, \\nlogic based on these rules won’t be strewn throughout your program. The logic will \\nstay hidden in a single dark corner of the system until it needs to be changed.\\nHardware dependencies Examples of hardware dependencies include interfaces to \\nscreens, printers, keyboards, mice, disk drives, sound facilities, and communications \\ndevices. Isolate hardware dependencies in their own subsystem or class. Isolating \\nsuch dependencies helps when you move the program to a new hardware environ-\\nment. It also helps initially when you’re developing a program for volatile hardware. \\nYou can write software that simulates interaction with specific hardware, have the \\nhardware-interface subsystem use the simulator as long as the hardware is unstable or \\nunavailable, and then unplug the hardware-interface subsystem from the simulator \\nand plug the subsystem into the hardware when it’s ready to use.\\nInput and output At a slightly higher level of design than raw hardware interfaces, \\ninput/output is a volatile area. If your application creates its own data files, the file for-\\nmat will probably change as your application becomes more sophisticated. User-level \\ninput and output formats will also change—the positioning of fields on the page, the \\nnumber of fields on each page, the sequence of fields, and so on. In general, it’s a good \\nidea to examine all external interfaces for possible changes.\\nNonstandard language features Most language implementations contain handy, \\nnonstandard extensions. Using the extensions is a double-edged sword because they \\nmight not be available in a different environment, whether the different environment \\nis different hardware, a different vendor’s implementation of the language, or a new \\nversion of the language from the same vendor. \\nIf you use nonstandard extensions to your programming language, hide those exten-\\nsions in a class of their own so that you can replace them with your own code when \\nyou move to a different environment. Likewise, if you use library routines that aren’t \\navailable in all environments, hide the actual library routines behind an interface that \\nworks just as well in another environment.\\nDifficult design and construction areas It’s a good idea to hide difficult design and \\nconstruction areas because they might be done poorly and you might need to do them \\nagain. Compartmentalize them and minimize the impact their bad design or construc-\\ntion might have on the rest of the system.\\nStatus variablesStatus variables indicate the state of a program and tend to be \\nchanged more frequently than most other data. In a typical scenario, you might origi-\\nnally define an error-status variable as a boolean variable and decide later that it'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 135}, page_content='5.3 Design Building Blocks: Heuristics 99\\nwould be better implemented as an enumerated type with the values ErrorType_None, \\nErrorType_Warning, and ErrorType_Fatal.\\nYou can add at least two levels of flexibility and readability to your use of status vari-\\nables:\\n■ Don’t use a boolean variable as a status variable. Use an enumerated type \\ninstead. It’s common to add a new state to a status variable, and adding a new \\ntype to an enumerated type requires a mere recompilation rather than a major \\nrevision of every line of code that checks the variable.\\n■ Use access routines rather than checking the variable directly. By checking the \\naccess routine rather than the variable, you allow for the possibility of more \\nsophisticated state detection. For example, if you wanted to check combinations \\nof an error-state variable and a current-function-state variable, it would be easy \\nto do if the test were hidden in a routine and hard to do if it were a complicated \\ntest hard-coded throughout the program.\\nData-size constraints When you declare an array of size 100, you’re exposing infor-\\nmation to the world that the world doesn’t need to see. Defend your right to privacy! \\nInformation hiding isn’t always as complicated as a whole class. Sometimes it’s as sim-\\nple as using a named constant such as MAX_EMPLOYEES to hide a 100.\\nAnticipating Different Degrees of Change\\nCross-Reference This sec-\\ntion’s approach to anticipat-\\ning change does not involve \\ndesigning ahead or coding \\nahead. For a discussion of \\nthose practices, see “A pro-\\ngram contains code that \\nseems like it might be needed \\nsomeday” in Section 24.2.\\nWhen thinking about potential changes to a system, design the system so that the \\neffect or scope of the change is proportional to the chance that the change will occur. \\nIf a change is likely, make sure that the system can accommodate it easily. Only \\nextremely unlikely changes should be allowed to have drastic consequences for more \\nthan one class in a system. Good designers also factor in the cost of anticipating \\nchange. If a change is not terribly likely but easy to plan for, you should think harder \\nabout anticipating it than if it isn’t very likely and is difficult to plan for. \\nFurther Reading This dis-\\ncussion draws on the \\napproach described in “On \\nthe design and development \\nof program families” (Parnas \\n1976). \\nA good technique for identifying areas likely to change is first to identify the minimal \\nsubset of the program that might be of use to the user. The subset makes up the core \\nof the system and is unlikely to change. Next, define minimal increments to the sys-\\ntem. They can be so small that they seem trivial. As you consider functional changes, \\nbe sure also to consider qualitative changes: making the program thread-safe, making \\nit localizable, and so on. These areas of potential improvement constitute potential \\nchanges to the system; design these areas using the principles of information hiding. \\nBy identifying the core first, you can see which components are really add-ons and \\nthen extrapolate and hide improvements from there.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 136}, page_content='100 Chapter 5: Design in Construction\\nKeep Coupling Loose\\nCoupling describes how tightly a class or routine is related to other classes or rou-\\ntines. The goal is to create classes and routines with small, direct, visible, and flexible \\nrelations to other classes and routines, which is known as “loose coupling.” The con-\\ncept of coupling applies equally to classes and routines, so for the rest of this discus-\\nsion I’ll use the word “module” to refer to both classes and routines. \\nGood coupling between modules is loose enough that one module can easily be used \\nby other modules. Model railroad cars are coupled by opposing hooks that latch \\nwhen pushed together. Connecting two cars is easy—you just push the cars together. \\nImagine how much more difficult it would be if you had to screw things together, or \\nconnect a set of wires, or if you could connect only certain kinds of cars to certain \\nother kinds of cars. The coupling of model railroad cars works because it’s as simple \\nas possible. In software, make the connections among modules as simple as possible.\\nTry to create modules that depend little on other modules. Make them detached, as \\nbusiness associates are, rather than attached, as Siamese twins are. A routine like sin() \\nis loosely coupled because everything it needs to know is passed in to it with one \\nvalue representing an angle in degrees. A routine such as InitVars( var 1, var2, var3, ..., \\nvarN ) is more tightly coupled because, with all the variables it must pass, the calling \\nmodule practically knows what is happening inside InitVars(). Two classes that \\ndepend on each other’s use of the same global data are even more tightly coupled.\\nCoupling Criteria\\nHere are several criteria to use in evaluating coupling between modules: \\nSize Size refers to the number of connections between modules. With coupling, \\nsmall is beautiful because it’s less work to connect other modules to a module that has \\na smaller interface. A routine that takes one parameter is more loosely coupled to \\nmodules that call it than a routine that ta kes six parameters. A class with four well-\\ndefined public methods is more loosely coupled to modules that use it than a class \\nthat exposes 37 public methods. \\nVisibility Visibility refers to the prominence of the connection between two mod-\\nules. Programming is not like being in the CIA; you don’t get credit for being sneaky. \\nIt’s more like advertising; you get lots of credit for making your connections as blatant \\nas possible. Passing data in a parameter list is making an obvious connection and is \\ntherefore good. Modifying global data so that another module can use that data is a \\nsneaky connection and is therefore bad. Documenting the global-data connection \\nmakes it more obvious and is slightly better.\\nFlexibility Flexibility refers to how easily you can change the connections between \\nmodules. Ideally, you want something more like the USB connector on your computer \\nthan like bare wire and a soldering gun. Flexibility is partly a product of the other'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 137}, page_content='5.3 Design Building Blocks: Heuristics 101\\ncoupling characteristics, but it’s a little different too. Suppose you have a routine that \\nlooks up the amount of vacation an employee receives each year, given a hiring date and \\na job classification. Name the routine LookupVacationBenefit(). Suppose in another \\nmodule you have an employee object that contains the hiring date and the job classifica-\\ntion, among other things, and that module passes the object to LookupVacationBenefit().\\nFrom the point of view of the other criteria, the two modules would look loosely cou-\\npled. The employee connection between the two modules is visible, and there’s only \\none connection. Now suppose that you need to use the LookupVacationBenefit() mod-\\nule from a third module that doesn’t have an employee object but that does have a hir-\\ning date and a job classification. Suddenly LookupVacationBenefit() looks less friendly, \\nunwilling to associate with the new module.\\nFor the third module to use LookupVacationBenefit(), it has to know about the \\nEmployee class. It could dummy up an employee object with only two fields, but that \\nwould require internal knowledge of LookupVacationBenefit(), namely that those are \\nthe only fields it uses. Such a solution would be a kludge, and an ugly one. The second \\noption would be to modify LookupVacationBenefit() so that it would take hiring date \\nand job classification instead of employee. In either case, the original module turns out \\nto be a lot less flexible than it seemed to be at first.\\nThe happy ending to the story is that an unfriendly module can make friends if it’s \\nwilling to be flexible—in this case, by changing to take hiring date and job classifica-\\ntion specifically instead of employee.\\nIn short, the more easily other modules can call a module, the more loosely coupled \\nit is, and that’s good because it’s more flexible and maintainable. In creating a system \\nstructure, break up the program along the lines of minimal interconnectedness. If a \\nprogram were a piece of wood, you would try to split it with the grain.\\nKinds of Coupling\\nHere are the most common kinds of coupling you’ll encounter. \\nSimple-data-parameter coupling Two modules are simple-data-parameter coupled if \\nall the data passed between them are of primitive data types and all the data is passed \\nthrough parameter lists. This kind of coupling is normal and acceptable. \\nSimple-object coupling A module is simple-object coupled to an object if it instanti-\\nates that object. This kind of coupling is fine. \\nObject-parameter couplingTwo modules are object-parameter coupled to each \\nother if Object1 requires Object2 to pass it an Object3. This kind of coupling is tighter \\nthan Object1 requiring Object2 to pass it only primitive data types because it requires \\nObject2 to know about Object3.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 138}, page_content='102 Chapter 5: Design in Construction\\nSemantic coupling The most insidious kind of coupling occurs when one module \\nmakes use not of some syntactic element of another module but of some semantic \\nknowledge of another module’s inner workings. Here are some examples:\\n■ Module1 passes a control flag to Module2 that tells Module2 what to do. This \\napproach requires Module1 to make assumptions about the internal workings of \\nModule2, namely what Module2 is going to do with the control flag. If Module2 \\ndefines a specific data type for the control flag (enumerated type or object), this \\nusage is probably OK.\\n■ Module2 uses global data after the global data has been modified by Module1. \\nThis approach requires Module2 to assume that Module1 has modified the data \\nin the ways Module2 needs it to be modified, and that Module1 has been called at \\nthe right time.\\n■ Module1’s interface states that its Module1.Initialize() routine should be called \\nbefore its Module1.Routine() is called. Module2 knows that Module1.Routine() \\ncalls Module1.Initialize() anyway, so it just instantiates Module1 and calls \\nModule1.Routine() without calling Module1.Initialize() first.\\n■ Module1 passes Object to Module2. Because Module1 knows that Module2 uses \\nonly three of Object’s seven methods, it initializes Object only partially—with the \\nspecific data those three methods need.\\n■ Module1 passes BaseObject to Module2. Because Module2 knows that Module1 is \\nreally passing it DerivedObject, it casts BaseObject to DerivedObject and calls \\nmethods that are specific to DerivedObject.\\nSemantic coupling is dangerous because changing code in the used module can break \\ncode in the using module in ways that are completely undetectable by the compiler. \\nWhen code like this breaks, it breaks in subtle ways that seem unrelated to the change \\nmade in the used module, which turns debugging into a Sisyphean task. \\nThe point of loose coupling is that an effective module provides an additional level of \\nabstraction—once you write it, you can take it for granted. It reduces overall program \\ncomplexity and allows you to focus on one thing at a time. If using a module requires \\nyou to focus on more than one thing at once—knowledge of its internal workings, \\nmodification to global data, uncertain functionality—the abstractive power is lost and \\nthe module’s ability to help manage complexity is reduced or eliminated. \\nClasses and routines are first and foremost intellectual tools for reducing complexity. \\nIf they’re not making your job simpler, they’re not doing their jobs. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 139}, page_content='5.3 Design Building Blocks: Heuristics 103\\nLook for Common Design Patterns\\ncc2e.com/0585 Design patterns provide the cores of ready-made solutions that can be used to solve \\nmany of software’s most common problems. Some software problems require solutions \\nthat are derived from first principles. But most problems are similar to past problems, \\nand those can be solved using similar solutions, or patterns. Common patterns include \\nAdapter, Bridge, Decorator, Facade, Factory Method, Observor, Singleton, Strategy, and \\nTemplate Method. The book Design Patterns by Erich Gamma, Richard Helm, Ralph \\nJohnson, and John Vlissides (1995) is the definitive description of design patterns. \\nPatterns provide several benefits that fully custom design doesn’t: \\nPatterns reduce complexity by providing ready-made abstractions If you say, “This \\ncode uses a Factory Method to create instances of derived classes,” other program-\\nmers on your project will understand that your code involves a fairly rich set of inter-\\nrelationships and programming protocols, all of which are invoked when you refer to \\nthe design pattern of Factory Method.\\nThe Factory Method is a pattern that allows you to instantiate any class derived  from \\na specific base class without needing to keep track of the individual derived classes \\nanywhere but the Factory Method. For a good discussion of the Factory Method pat-\\ntern, see “Replace Constructor with Factory Method” in Refactoring (Fowler 1999). \\nYou don’t have to spell out every line of code for other programmers to understand \\nthe design approach found in your code. \\nPatterns reduce errors by institutionalizing details of common solutions Software \\ndesign problems contain nuances that emerge fully only after the problem has been \\nsolved once or twice (or three times, or four times, or...). Because patterns represent \\nstandardized ways of solving common problems, they embody the wisdom accumu-\\nlated from years of attempting to solve those problems, and they also embody the cor-\\nrections to the false attempts that people have made in solving those problems. \\nUsing a design pattern is thus conceptually similar to using library code instead of \\nwriting your own. Sure, everybody has written a custom Quicksort a few times, but \\nwhat are the odds that your custom version will be fully correct on the first try? Simi-\\nlarly, numerous design problems are similar enough to past problems that you’re bet-\\nter off using a prebuilt design solution than creating a novel solution. \\nPatterns provide heuristic value by suggesting design alternatives A designer who’s \\nfamiliar with common patterns can easily run through a list of patterns and ask \\n“Which of these patterns fits my design problem?” Cycling through a set of familiar \\nalternatives is immeasurably easier than creating a custom design solution out of \\nwhole cloth. And the code arising from a familiar pattern will also be easier for readers \\nof the code to understand than fully custom code would be.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 140}, page_content='104 Chapter 5: Design in Construction\\nPatterns streamline communication by moving the design dialog to a higher level In \\naddition to their complexity-management benefit, design patterns can accelerate \\ndesign discussions by allowing designers to think and discuss at a larger level of gran-\\nularity. If you say “I can’t decide whether I should use a Creator or a Factory Method \\nin this situation,” you’ve communicated a great deal with just a few words—as long as \\nyou and your listener are both familiar with those patterns. Imagine how much longer \\nit would take you to dive into the details of the code for a Creator pattern and the code \\nfor a Factory Method pattern and then compare and contrast the two approaches. \\nIf you’re not already familiar with design patterns, Table 5-1 summarizes some of the \\nmost common patterns to stimulate your interest. \\nIf you haven’t seen design patterns before, your reaction to the descriptions in Table 5-\\n1 might be “Sure, I already know most of these ideas.” That reaction is a big part of \\nwhy design patterns are valuable. Patterns are familiar to most experienced program-\\nmers, and assigning recognizable names to them supports efficient and effective com-\\nmunication about them. \\nTable 5-1 Popular Design Patterns\\nPattern Description\\nAbstract Factory Supports creation of sets of related objects by specifying the kind \\nof set but not the kinds of each specific object.\\nAdapter Converts the interface of a class to a different interface.\\nBridge Builds an interface and an implementation in such a way that \\neither can vary without the other varying.\\nComposite Consists of an object that contains additional objects of its own \\ntype so that client code can interact with the top-level object and \\nnot concern itself with all the detailed objects. \\nDecorator Attaches responsibilities to an object dynamically, without creating \\nspecific subclasses for each possible configuration of responsibilities.\\nFacade Provides a consistent interface to code that wouldn’t otherwise \\noffer a consistent interface.\\nFactory Method Instantiates classes derived  from a specific base class without \\nneeding to keep track of the individual derived classes anywhere \\nbut the Factory Method. \\nIterator A server object that provides access to each element in a set \\nsequentially.\\nObserver Keeps multiple objects in synch with one another by making an \\nobject responsible for notifying the set of related objects about \\nchanges to any member of the set.\\nSingleton Provides global access to a class that has one and only one instance.\\nStrategy Defines a set of algorithms or behaviors that are dynamically \\ninterchangeable with each other.\\nTemplate Method Defines the structure of an algorithm but leaves some of the \\ndetailed implementation to subclasses.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 141}, page_content='5.3 Design Building Blocks: Heuristics 105\\nOne potential trap with patterns is force-fitting code to use a pattern. In some cases, shift-\\ning code slightly to conform to a well-recognized pattern will improve understandability \\nof the code. But if the code has to be shifted too far, forcing it to look like a standard pat-\\ntern can sometimes increase complexity.\\nAnother potential trap with patterns is feature-itis: using a pattern because of a desire \\nto try out a pattern rather than because the pattern is an appropriate design solution. \\nOverall, design patterns are a powerful tool for managing complexity. You can read more \\ndetailed descriptions in any of the good books that are listed at the end of this chapter. \\nOther Heuristics\\nThe preceding sections describe the major software design heuristics. Following are a few \\nother heuristics that might not be useful quite as often but are still worth mentioning.\\nAim for Strong Cohesion\\nCohesion arose from structured design and is usually discussed in the same context \\nas coupling. Cohesion refers to how closely all the routines in a class or all the code in \\na routine support a central purpose—how focused the class is. Classes that contain \\nstrongly related functionality are described as having strong cohesion, and the heuris-\\ntic goal is to make cohesion as strong as possible. Cohesion is a useful tool for manag-\\ning complexity because the more that code in a class supports a central purpose, the \\nmore easily your brain can remember everything the code does. \\nThinking about cohesion at the routine level has been a useful heuristic for decades \\nand is still useful today. At the class level, the heuristic of cohesion has largely been \\nsubsumed by the broader heuristic of well-defined abstractions, which was discussed \\nearlier in this chapter and in Chapter 6. Abstractions are useful at the routine level, \\ntoo, but on a more even footing with cohesion at that level of detail.\\nBuild Hierarchies\\nA hierarchy is a tiered information structure in which the most general or abstract rep-\\nresentation of concepts is contained at the top of the hierarchy, with increasingly \\ndetailed, specialized represen tations at the hierarchy’s lower levels. In software, \\nhierarchies are found in class hierarchies, and, as Level 4 in Figure 5-2 illustrated, in \\nroutine-calling hierarchies as well. \\nHierarchies have been an important tool for managing complex sets of information for \\nat least 2000 years. Aristotle used a hierarchy to organize the animal kingdom. \\nHumans frequently use outlines to organize complex information (like this book). \\nResearchers have found that people generally find hierarchies to be a natural way to \\norganize complex information. When they draw a complex object such as a house, \\nthey draw it hierarchically. First they draw the outline of the house, then the windows'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 142}, page_content='106 Chapter 5: Design in Construction\\nand doors, and then more details. They don’t draw the house brick by brick, shingle \\nby shingle, or nail by nail (Simon 1996). \\nHierarchies are a useful tool for achieving Software’s Primary Technical Imperative \\nbecause they allow you to focus on only the level of detail you’re currently concerned \\nwith. The details don’t go away completely; they’re simply pushed to another level so \\nthat you can think about them when you want to rather than thinking about all the \\ndetails all of the time.\\nFormalize Class Contracts\\nCross-Reference For more \\non contracts, see “Use asser-\\ntions to document and verify \\npreconditions and postcon-\\nditions” in Section 8.2.\\nAt a more detailed level, thinking of each class’s interface as a contract with the rest of \\nthe program can yield good insights. Typically, the contract is something like “If you \\npromise to provide data x, y, and z and you promise they’ll have characteristics a, b, \\nand c, I promise to perform operations 1, 2, and 3 within constraints 8, 9, and 10.” The \\npromises the clients of the class make to the class are typically called “preconditions,” \\nand the promises the object makes to its clients are called the “postconditions.” \\nContracts are useful for managing complexity because, at least in theory, the object can \\nsafely ignore any noncontractual behavior. In practice, this issue is much more difficult. \\nAssign Responsibilities\\nAnother heuristic is to think through how responsibilities should be assigned to \\nobjects. Asking what each object should be responsible for is similar to asking what \\ninformation it should hide, but I think it can produce broader answers, which gives \\nthe heuristic unique value. \\nDesign for Test\\nA thought process that can yield interesting design insights is to ask what the system will \\nlook like if you design it to facilitate testing. Do you need to separate the user interface \\nfrom the rest of the code so that you can exercise it independently? Do you need to orga-\\nnize each subsystem so that it minimizes dependencies on other subsystems? Designing \\nfor test tends to result in more formalized class interfaces, which is generally beneficial. \\nAvoid Failure\\nCivil engineering professor Henry Petroski wrote an interesting book, Design Paradigms: \\nCase Histories of Error and Judgment in Engineering (Petroski 1994), that chronicles the \\nhistory of failures in bridge design. Petroski argues that many spectacular bridge failures \\nhave occurred because of focusing on previous successes and not adequately consider-\\ning possible failure modes. He concludes that failures like the Tacoma Narrows bridge \\ncould have been avoided if the designers had carefully considered the ways the bridge \\nmight fail and not just copied the attributes of other successful designs.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 143}, page_content='5.3 Design Building Blocks: Heuristics 107\\nThe high-profile security lapses of various well-known systems the past few years \\nmake it hard to disagree that we should find ways to apply Petroski’s design-failure \\ninsights to software. \\nChoose Binding Time Consciously\\nCross-Reference For more \\non binding time, see Section \\n10.6, “Binding Time.” \\nBinding time refers to the time a specific value is bound to a variable. Code that binds \\nearly tends to be simpler, but it also tends to be less flexible. Sometimes you can get a \\ngood design insight from asking questions like these: What if I bound these values \\nearlier? What if I bound these values later? What if I initialized this table right here in \\nthe code? What if I read the value of this variable from the user at run time?\\nMake Central Points of Control\\nP.J. Plauger says his major concern is “The Principle of One Right Place—there should \\nbe One Right Place to look for any nontrivial piece of code, and One Right Place to \\nmake a likely maintenance change” (Plauger 1993). Control can be centralized in \\nclasses, routines, preprocessor macros, #include files—even a named constant is an \\nexample of a central point of control.\\nThe reduced-complexity benefit is that the fewer places you have to look for some-\\nthing, the easier and safer it will be to change. \\nConsider Using Brute Force\\nWhen in doubt, use brute \\nforce. \\n—Butler Lampson\\nOne powerful heuristic tool is brute force. Don’t underestimate it. A brute-force solu-\\ntion that works is better than an elegant solution that doesn’t work. It can take a long \\ntime to get an elegant solution to work. In describing the history of searching algo-\\nrithms, for example, Donald Knuth pointed out that even though the first description \\nof a binary search algorithm was published in 1946, it took another 16 years for some-\\none to publish an algorithm that correctly searched lists of all sizes (Knuth 1998). A \\nbinary search is more elegant, but a brute-force, sequential search is often sufficient. \\nDraw a Diagram\\nDiagrams are another powerful heuristic tool. A picture is worth 1000 words—kind of. \\nYou actually want to leave out most of the 1000 words because one point of using a \\npicture is that a picture can represent the problem at a higher level of abstraction. \\nSometimes you want to deal with the problem in detail, but other times you want to be \\nable to work with more generality.\\nKeep Your Design Modular\\nModularity’s goal is to make each routine or class like a “black box”: You know what \\ngoes in, and you know what comes out, but you don’t know what happens inside. A'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 144}, page_content='108 Chapter 5: Design in Construction\\nblack box has such a simple interface and such well-defined functionality that for any \\nspecific input you can accurately predict the corresponding output. \\nThe concept of modularity is related to information hiding, encapsulation, and other \\ndesign heuristics. But sometimes thinking about how to assemble a system from a set \\nof black boxes provides insights that information hiding and encapsulation don’t, so \\nthe concept is worth having in your back pocket.\\nSummary of Design Heuristics\\nMore alarming, the same \\nprogrammer is quite capa-\\nble of doing the same task \\nhimself in two or three \\nways, sometimes uncon-\\nsciously, but quite often \\nsimply for a change, or to \\nprovide elegant variation. \\n—A. R. Brown and W. A. \\nSampson\\nHere’s a summary of major design heuristics:\\n■ Find Real-World Objects\\n■ Form Consistent Abstractions\\n■ Encapsulate Implementation Details\\n■ Inherit When Possible\\n■ Hide Secrets (Information Hiding)\\n■ Identify Areas Likely to Change\\n■ Keep Coupling Loose\\n■ Look for Common Design Patterns\\nThe following heuristics are sometimes useful too: \\n■ Aim for Strong Cohesion\\n■ Build Hierarchies\\n■ Formalize Class Contracts\\n■ Assign Responsibilities\\n■ Design for Test\\n■ Avoid Failure\\n■ Choose Binding Time Consciously\\n■ Make Central Points of Control\\n■ Consider Using Brute Force\\n■ Draw a Diagram\\n■ Keep Your Design Modular'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 145}, page_content=\"5.3 Design Building Blocks: Heuristics 109\\nGuidelines for Using Heuristics\\nApproaches to design in software can learn from approaches to design in other fields. \\nOne of the original books on heuristics in problem solving was G. Polya’s How to Solve \\nIt (1957). Polya’s generalized problem-solving approach focuses on problem solving \\nin mathematics. Figure 5-10 is a summary of his approach, adapted from a similar \\nsummary in his book (emphases his).\\ncc2e.com/0592\\nFigure 5-10 G. Polya developed an approach to problem solving in mathematics that’s also \\nuseful in solving problems in software design (Polya 1957). \\n1. Understanding the Problem. You have to understand the problem.\\n What is the unknown? What are the data? What is the condition? Is it possible to satisfy \\nthe condition? Is the condition sufficient to determine the unknown? Or is it \\ninsufficient? Or redundant? Or contradictory? \\n Draw a figure. Introduce suitable notation. Separate the various parts of the \\ncondition. Can you write them down?\\n2. Devising a Plan. Find the connection between the data and the unknown. You \\nmight be obliged to consider auxiliary problems if you can't find an intermediate \\nconnection. You should eventually come up with a plan of the solution.\\n Have you seen the problem before? Or have you seen the same problem in a \\nslightly different form? Do you know a related problem? Do you know a theorem that \\ncould be useful? \\n Look at the unknown! And try to think of a familiar problem having the same or a \\nsimilar unknown. Here is a problem related to yours and solved before. Can you use it? \\nCan you use its result? Can you use its method? Should you introduce some auxiliary \\nelement in order to make its use possible? \\n Can you restate the problem? Can you restate it still differently? Go back to \\ndefinitions. \\n If you cannot solve the proposed problem, try to solve some related problem first. \\nCan you imagine a more accessible related problem? A more general problem? A \\nmore special problem? An analogous problem? Can you solve a part of the problem? \\nKeep only a part of the condition, drop the other part; how far is the unknown then \\ndetermined, how can it vary? Can you derive something useful from the data? Can \\nyou think of other data appropriate for determining the unknown? Can you change \\nthe unknown or the data, or both if necessary , so that the new unknown and the new \\ndata are nearer to each other? \\n Did you use all the data? Did you use the whole condition? Have you taken into \\naccount all essential notions involved in the problem?\\n3. Carrying out the Plan. Carry out your plan.\\n Carrying out your plan of the solution, check each step. Can you see clearly that the \\nstep is correct? Can you prove that it's correct?\\n4. Looking Back. Examine the solution.\\n Can you check the result? Can you check the argument? Can you derive the result \\ndifferently? Can you see it at a glance? \\n Can you use the result, or the method, for some other problem?\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 146}, page_content='110 Chapter 5: Design in Construction\\nOne of the most effective guidelines is not to get stuck on a single approach. If dia-\\ngramming the design in UML isn’t working, write it in English. Write a short test pro-\\ngram. Try a completely different approach. Think of a brute-force solution. Keep \\noutlining and sketching with your pencil, and your brain will follow. If all else fails, \\nwalk away from the problem. Literally go for a walk, or think about something else \\nbefore returning to the problem. If you’ve given it your best and are getting nowhere, \\nputting it out of your mind for a time often produces results more quickly than sheer \\npersistence can.\\nYou don’t have to solve the whole design problem at once. If you get stuck, remember \\nthat a point needs to be decided but recognize that you don’t yet have enough infor-\\nmation to resolve that specific issue. Why fight your way through the last 20 percent \\nof the design when it will drop into place easily the next time through? Why make bad \\ndecisions based on limited experience with the design when you can make good deci-\\nsions based on more experience with it later? Some people are uncomfortable if they \\ndon’t come to closure after a design cycle, but after you have created a few designs \\nwithout resolving issues prematurely, it will seem natural to leave issues unresolved \\nuntil you have more information (Zahniser 1992, Beck 2000).\\n5.4 Design Practices\\nThe preceding section focused on heuristics related to design attributes—what you \\nwant the completed design to look like. This section describes design practice heuris-\\ntics, steps you can take that often produce good results. \\nIterate\\nYou might have had an experience in which you learned so much from writing a pro-\\ngram that you wished you could write it again, armed with the insights you gained \\nfrom writing it the first time. The same phenomenon applies to design, but the design \\ncycles are shorter and the effects downstream are bigger, so you can afford to whirl \\nthrough the design loop a few times.\\nDesign is an iterative process. You don’t usually go from point A only to point B; you \\ngo from point A to point B and back to point A. \\nAs you cycle through candidate designs and try different approaches, you’ll look at \\nboth high-level and low-level views. The big picture you get from working with high-\\nlevel issues will help you to put the low-le vel details in perspect ive. The details you \\nget from working with low-level issues will provide a foundation in solid reality for \\nthe high-level decisions. The tug and pull between top-level and bottom-level \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 147}, page_content='5.4 Design Practices 111\\nconsiderations is a healthy dynamic; it creates a stressed structure that’s more stable \\nthan one built wholly from th e top down or the bottom up.\\nMany programmers—many people, for that matter—have trouble ranging between high-\\nlevel and low-level considerations. Switching from one view of a system to another is \\nmentally strenuous, but it’s essential to creating effective designs. For entertaining exer-\\ncises to enhance your mental flexibility, read Conceptual Blockbusting (Adams 2001), \\ndescribed in the “Additional Resources” section at the end of the chapter.\\nCross-Reference Refactor-\\ning is a safe way to try differ-\\nent alternatives in code. For \\nmore on this, see Chapter \\n24, \"Refactoring.\"\\nWhen you come up with a first design attempt that seems good enough, don’t stop! \\nThe second attempt is nearly always better than the first, and you learn things on each \\nattempt that can improve your overall design. After trying a thousand different mate-\\nrials for a light bulb filament with no success, Thomas Edison was reportedly asked if \\nhe felt his time had been wasted since he had discovered nothing. “Nonsense,” Edison \\nis supposed to have replied. “I have discovered a thousand things that don’t work.” In \\nmany cases, solving the problem with one approach will produce insights that will \\nenable you to solve the problem using another approach that’s even better.\\nDivide and Conquer\\nAs Edsger Dijkstra pointed out, no one’s skull is big enough to contain all the details \\nof a complex program, and that applies just as well to design. Divide the program into \\ndifferent areas of concern, and then tackle each of those areas individually. If you run \\ninto a dead end in one of the areas, iterate! \\nIncremental refinement is a powerful tool for managing complexity. As Polya recom-\\nmended in mathematical problem solving, understand the problem, devise a plan, \\ncarry out the plan, and then look back to see how you did (Polya 1957). \\nTop-Down and Bottom-Up Design Approaches\\n“Top down” and “bottom up” might have an old-fashioned sound, but they provide \\nvaluable insight into the creation of object-oriented designs. Top-down design begins \\nat a high level of abstraction. You define base classes or other nonspecific design ele-\\nments. As you develop the design, you increase the level of detail, identifying derived \\nclasses, collaborating classes, and other detailed design elements. \\nBottom-up design starts with specifics and works toward generalities. It typically \\nbegins by identifying concrete objects and then generalizes aggregations of objects \\nand base classes from those specifics. \\nSome people argue vehemently that starting with generalities and working toward \\nspecifics is best, and some argue that you can’t really identify general design principles \\nuntil you’ve worked out the significant details. Here are the arguments on both sides.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 148}, page_content='112 Chapter 5: Design in Construction\\nArgument for Top Down\\nThe guiding principle behind the top-down approach is the idea that the human brain \\ncan concentrate on only a certain amount of detail at a time. If you start with general \\nclasses and decompose them into more specialized classes step by step, your brain \\nisn’t forced to deal with too many details at once. \\nThe divide-and-conquer process is iterative in a couple of senses. First, it’s iterative \\nbecause you usually don’t stop after one level of decomposition. You keep going for \\nseveral levels. Second, it’s iterative because you don’t usually settle for your first \\nattempt. You decompose a program one way. At various points in the decomposition, \\nyou’ll have choices about which way to partition the subsystems, lay out the inherit-\\nance tree, and form compositions of objects. You make a choice and see what hap-\\npens. Then you start over and decompose it another way and see whether that works \\nbetter. After several attempts, you’ll have a good idea of what will work and why.\\nHow far do you decompose a program? Continue decomposing until it seems as if it \\nwould be easier to code the next level than to decompose it. Work until you become \\nsomewhat impatient at how obvious and easy the design seems. At that point, you’re \\ndone. If it’s not clear, work some more. If the solution is even slightly tricky for you \\nnow, it’ll be a bear for anyone who works on it later.\\nArgument for Bottom Up\\nSometimes the top-down approach is so abstract that it’s hard to get started. If you \\nneed to work with something more tangible, try the bottom-up design approach. Ask \\nyourself, “What do I know this system needs to do?” Undoubtedly, you can answer \\nthat question. You might identify a few low-level responsibilities that you can assign to \\nconcrete classes. For example, you might know that a system needs to format a partic-\\nular report, compute data for that report, center its headings, display the report on the \\nscreen, print the report on a printer, and so on. After you identify several low-level \\nresponsibilities, you’ll usually start to feel comfortable enough to look at the top again.\\nIn some other cases, major attributes of the design problem are dictated from the bot-\\ntom. You might have to interface with hardware devices whose interface requirements \\ndictate large chunks of your design. \\nHere are some things to keep in mind as you do bottom-up composition:\\n■ Ask yourself what you know the system needs to do.\\n■ Identify concrete objects and responsibilities from that question.\\n■ Identify common objects, and group them using subsystem organization, pack-\\nages, composition within objects, or inheritance, whichever is appropriate.\\n■ Continue with the next level up, or go back to the top and try again to work down.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 149}, page_content='5.4 Design Practices 113\\nNo Argument, Really\\nThe key difference between top-down and bottom-up strategies is that one is a decom-\\nposition strategy and the other is a composition strategy. One starts from the general \\nproblem and breaks it into manageable pieces; the other starts with manageable \\npieces and builds up a general solution. Both approaches have strengths and weak-\\nnesses that you’ll want to consider as you apply them to your design problems.\\nThe strength of top-down design is that it’s easy. People are good at breaking some-\\nthing big into smaller components, and programmers are especially good at it. \\nAnother strength of top-down design is that you can defer construction details. Since \\nsystems are often perturbed by changes in construction details (for example, changes \\nin a file structure or a report format), it’s useful to know early on that those details \\nshould be hidden in classes at the bottom of the hierarchy.\\nOne strength of the bottom-up approach is that it typically results in early identifica-\\ntion of needed utility functionality, which results in a compact, well-factored design. If \\nsimilar systems have already been built, the bottom-up approach allows you to start \\nthe design of the new system by looking at pieces of the old system and asking “What \\ncan I reuse?”\\nA weakness of the bottom-up composition approach is that it’s hard to use exclusively. \\nMost people are better at taking one big concept and breaking it into smaller concepts \\nthan they are at taking small concepts and making one big one. It’s like the old assem-\\nble-it-yourself problem: I thought I was done, so why does the box still have parts in it? \\nFortunately, you don’t have to use the bottom-up composition approach exclusively.\\nAnother weakness of the bottom-up design strategy is that sometimes you find that \\nyou can’t build a program from the pieces you’ve started with. You can’t build an air-\\nplane from bricks, and you might have to work at the top before you know what kinds \\nof pieces you need at the bottom.\\nTo summarize, top down tends to start simple, but sometimes low-level complexity \\nripples back to the top, and those ripples can make things more complex than they \\nreally needed to be. Bottom up tends to start complex, but identifying that complexity \\nearly on leads to better design of the higher-level classes—if the complexity doesn’t tor-\\npedo the whole system first!\\nIn the final analysis, top-down and bottom-up design aren’t competing strategies—\\nthey’re mutually beneficial. Design is a heuristic process, which means that no solu-\\ntion is guaranteed to work every time. Design contains elements of trial and error. Try \\na variety of approaches until you find one that works well.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 150}, page_content='114 Chapter 5: Design in Construction\\nExperimental Prototyping\\ncc2e.com/0599 Sometimes you can’t really know whether a design will work until you better under-\\nstand some implementation detail. You might not know if a particular database orga-\\nnization will work until you know whether it will meet your performance goals. You \\nmight not know whether a particular subsystem design will work until you select the \\nspecific GUI libraries you’ll be working with. These are examples of the essential \\n“wickedness” of software design—you can’t fully define the design problem until \\nyou’ve at least partially solved it. \\nA general technique for addressing these questions at low cost is experimental proto-\\ntyping. The word “prototyping” means lots of different things to different people \\n(McConnell 1996). In this context, prototyping means writing the absolute minimum \\namount of throwaway code that’s needed to answer a specific design question. \\nPrototyping works poorly when developers aren’t disciplined about writing the abso-\\nlute minimum of code needed to answer a question. Suppose the design question is, \\n“Can the database framework we’ve selected support the transaction volume we \\nneed?” You don’t need to write any production code to answer that question. You \\ndon’t even need to know the database specifics. You just need to know enough to \\napproximate the problem space—number of tables, number of entries in the tables, \\nand so on. You can then write very simple prototyping code that uses tables with \\nnames like Table1, Table2, and Column1, and Column2, populate the tables with junk \\ndata, and do your performance testing. \\nPrototyping also works poorly when the design question is not specific enough. A \\ndesign question like “Will this database framework work?” does not provide enough \\ndirection for prototyping. A design question like “Will this database framework sup-\\nport 1,000 transactions per second under assumptions X, Y, and Z?” provides a more \\nsolid basis for prototyping. \\nA final risk of prototyping arises when developers do not treat the code as throwaway \\ncode. I have found that it is not possible for people to write the absolute minimum \\namount of code to answer a question if they believe that the code will eventually end \\nup in the production system. They end up implementing the system instead of proto-\\ntyping. By adopting the attitude that once the question is answered the code will be \\nthrown away, you can minimize this risk. One way to avoid this problem is to create \\nprototypes in a different technology than the production code. You could prototype a \\nJava design in Python or mock up a user interface in Microsoft PowerPoint. If you do \\ncreate prototypes using the production technology, a practical standard that can help \\nis requiring that class names or package names for prototype code be prefixed with \\nprototype. That at least makes a programmer think twice before trying to extend pro-\\ntotype code (Stephens 2003).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 151}, page_content='5.4 Design Practices 115\\nUsed with discipline, prototyping is the workhorse tool a designer has to combat design \\nwickedness. Used without discipline, prototyping adds some wickedness of its own. \\nCollaborative Design\\nCross-Reference For more \\ndetails on collaborative devel-\\nopment, see Chapter 21, \\n“Collaborative Construction.”\\nIn design, two heads are often better than one, whether those two heads are organized \\nformally or informally. Collaboration can take any of several forms:\\n■ You informally walk over to a co-worker’s desk and ask to bounce some ideas \\naround.\\n■ You and your co-worker sit together in a conference room and draw design alter-\\nnatives on a whiteboard.\\n■ You and your co-worker sit together at the keyboard and do detailed design in \\nthe programming language you’re using—that is, you can use pair programming, \\ndescribed in Chapter 21, “Collaborative Construction.” \\n■ You schedule a meeting to walk through your design ideas with one or more co-\\nworkers.\\n■ You schedule a formal inspection with all the structure described in Chapter 21.\\n■ You don’t work with anyone who can review your work, so you do some initial \\nwork, put it into a drawer, and come back to it a week later. You will have forgot-\\nten enough that you should be able to give yourself a fairly good review.\\n■ You ask someone outside your company for help: send questions to a special-\\nized forum or newsgroup. \\nIf the goal is quality assurance, I tend to recommend the most structured review prac-\\ntice, formal inspections, for the reasons described in Chapter 21. But if the goal is to \\nfoster creativity and to increase the number of design alternatives generated, not just \\nto find errors, less structured approaches work better. After you’ve settled on a specific \\ndesign, switching to a more formal inspection might be appropriate, depending on \\nthe nature of your project. \\nHow Much Design Is Enough?\\nWe try to solve the problem \\nby rushing through the \\ndesign process so that \\nenough time is left at the \\nend of the project to uncover \\nthe errors that were made \\nbecause we rushed through \\nthe design process. \\n—Glenford Myers\\nSometimes only the barest sketch of an ar chitecture is mapped out before coding \\nbegins. Other times, teams create designs at such a level of detail that coding \\nbecomes a mostly mechanical exercise. How much design should you do before you \\nbegin coding? \\nA related question is how formal to make the design. Do you need formal, polished \\ndesign diagrams, or would digital snapshots of a few drawings on a whiteboard be \\nenough?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 152}, page_content='116 Chapter 5: Design in Construction\\nDeciding how much design to do before beginning full-scale coding and how much \\nformality to use in documenting that design is hardly an exact science. The experience \\nof the team, expected lifetime of the system, desired level of reliability, and size of \\nproject and team should all be considered. Table 5-2 summarizes how each of these \\nfactors influence the design approach. \\nTwo or more of these factors might come into play on any specific project, and in \\nsome cases the factors might provide contradictory advice. For example, you might \\nhave a highly experienced team working on safety critical software. In that case, you’d \\nprobably want to err on the side of the higher level of design detail and formality. In \\nsuch cases, you’ll need to weigh the significance of each factor and make a judgment \\nabout what matters most. \\nIf the level of design is left to each individual, then, when the design descends to the \\nlevel of a task that you’ve done before or to a simple modification or extension of such \\na task, you’re probably ready to stop designing and begin coding. \\nTable 5-2 Design Formality and Level of Detail Needed\\nFactor\\nLevel of Detail Needed \\nin Design Before \\nConstruction\\nDocumentation \\nFormality\\nDesign/construction team \\nhas deep experience in \\napplications area.\\nLow Detail Low Formality\\nDesign/construction team \\nhas deep experience but \\nis inexperienced in the \\napplications area.\\nMedium Detail Medium Formality\\nDesign/construction team \\nis inexperienced.\\nMedium to High Detail Low-Medium Formality\\nDesign/construction team \\nhas moderate-to-high \\nturnover.\\nMedium Detail —\\nApplication is \\nsafety-critical.\\nHigh Detail High Formality\\nApplication is \\nmission-critical.\\nMedium Detail Medium-High Formality\\nProject is small. Low Detail Low Formality\\nProject is large. Medium Detail Medium Formality\\nSoftware is expected to \\nhave a short lifetime \\n(weeks or months).\\nLow Detail Low Formality\\nSoftware is expected to \\nhave a long lifetime \\n(months or years).\\nMedium Detail Medium Formality'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 153}, page_content=\"5.4 Design Practices 117\\nIf I can’t decide how deeply to investigate a design before I begin coding, I tend to err \\non the side of going into more detail. The biggest design errors arise from cases in \\nwhich I thought I went far enough, but it later turns out that I didn’t go far enough to \\nrealize there were additional design challenges. In other words, the biggest design \\nproblems tend to arise not from areas I knew were difficult and created bad designs \\nfor, but from areas I thought were easy and didn’t create any designs for at all. I rarely \\nencounter projects that are suffering from having done too much design work. \\nI've never met a human \\nbeing who would want to \\nread 17,000 pages of docu-\\nmentation, and if there was, \\nI'd kill him to get him out of \\nthe gene pool. \\n—Joseph Costello\\nOn the other hand, occasionally I have seen projects that are suffering from too much \\ndesign documentation. Gresham’s Law states that “programmed activity tends to drive \\nout nonprogrammed activity” (Simon 1965). A premature rush to polish a design \\ndescription is a good example of that law. I would rather see 80 percent of the design \\neffort go into creating and exploring numerous design alternatives and 20 percent go \\ninto creating less polished documentation than to have 20 percent go into creating \\nmediocre design alternatives and 80 percent go into polishing documentation of \\ndesigns that are not very good. \\nCapturing Your Design Work\\ncc2e.com/0506 The traditional approach to capturing design work is to write up the designs in a for-\\nmal design document. However, you can capture designs in numerous alternative \\nways that work well on small projects, informal projects, or projects that need a light-\\nweight way to record a design:\\nThe bad news is that, in our \\nopinion, we will never find the \\nphilosopher’s stone. We will \\nnever find a process that allows \\nus to design software in a per-\\nfectly rational way. The good \\nnews is that we can fake it. \\n—David Parnas and Paul \\nClements\\nInsert design documentation into the code itself Document key design decisions in \\ncode comments, typically in the file or class header. When you couple this approach \\nwith a documentation extractor like JavaDoc, this assures that design documentation \\nwill be readily available to a programmer working on a section of code, and it \\nimproves the chance that programmers will keep the design documentation reason-\\nably up to date. \\nCapture design discussions and decisions on a Wiki Have your design discussions \\nin writing, on a project Wiki (that is, a collection of Web pages that can be edited eas-\\nily by anyone on your project using a Web browser). This will capture your design dis-\\ncussions and decision automatically, albeit with the extra overhead of typing rather \\nthan talking. You can also use the Wiki to capture digital pictures to supplement the \\ntext discussion, links to websites that support the design decision, white papers, and \\nother materials. This technique is especially useful if your development team is geo-\\ngraphically distributed. \\nWrite e-mail summaries After a design discussion, adopt the practice of designating \\nsomeone to write a summary of the discussion—especially what was decided—and send \\nit to the project team. Archive a copy of the e-mail in the project’s public e-mail folder.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 154}, page_content='118 Chapter 5: Design in Construction\\nUse a digital camera One common barrier to documenting designs is the tedium of \\ncreating design drawings in some popular drawing tools. But the documentation \\nchoices are not limited to the two options of “capturing the design in a nicely format-\\nted, formal notation” vs. “no design documentation at all.” \\nTaking pictures of whiteboard drawings with a digital camera and then embedding \\nthose pictures into traditional documents can be a low-effort way to get 80 percent of \\nthe benefit of saving design drawings by doing about 1 percent of the work required \\nif you use a drawing tool. \\nSave design flip charts There’s no law that says your design documentation has to \\nfit on standard letter-size paper. If you make your design drawings on large flip chart \\npaper, you can simply archive the flip charts in a convenient location—or, better yet, \\npost them on the walls around the project area so that people can easily refer to them \\nand update them when needed. \\ncc2e.com/0513 Use CRC (Class, Responsibility, Collaborator) cards Another low-tech alternative \\nfor documenting designs is to use index cards. On each card, designers write a class \\nname, responsibilities of the class, and collaborators (other classes that cooperate \\nwith the class). A design group then works with the cards until they’re satisfied that \\nthey’ve created a good design. At that point, you can simply save the cards for future \\nreference. Index cards are cheap, unintimidating, and portable, and they encourage \\ngroup interaction (Beck 1991). \\nCreate UML diagrams at appropriate levels of detail One popular technique for \\ndiagramming designs is called Unified Modeling Language (UML), which is defined \\nby the Object Management Group (Fowler 2004). Figure 5-6 earlier in this chapter \\nwas one example of a UML class diagram. UML provides a rich set of formalized rep-\\nresentations for design entities and relationships. You can use informal versions of \\nUML to explore and discuss design approaches. Start with minimal sketches and add \\ndetail only after you’ve zeroed in on a final design solution. Because UML is standard-\\nized, it supports common understanding in communicating design ideas and it can \\naccelerate the process of considering design alternatives when working in a group. \\nThese techniques can work in various combinations, so feel free to mix and match these \\napproaches on a project-by-project basis or even within different areas of a single project. \\n5.5 Comments on Popular Methodologies\\nThe history of design in software has been marked by fanatic advocates of wildly con-\\nflicting design approaches. When I published the first edition of Code Complete in the \\nearly 1990s, design zealots were advocating dotting every design i and crossing every \\ndesign t before beginning coding. That recommendation didn’t make any sense.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 155}, page_content='Additional Resources 119\\nPeople who preach software \\ndesign as a disciplined activ-\\nity spend considerable \\nenergy making us all feel \\nguilty. We can never be \\nstructured enough or object-\\noriented enough to achieve \\nnirvana in this lifetime. We \\nall truck around a kind of \\noriginal sin from having \\nlearned Basic at an impres-\\nsionable age. But my bet is \\nthat most of us are better \\ndesigners than the purists \\nwill ever acknowledge.\\n—P.  J .  P l a u g e r\\nAs I write this edition in the mid-2000s, some software swamis are arguing for not \\ndoing any design at all. “Big Design Up Front is BDUF,” they say. “BDUF is bad. You’re \\nbetter off not doing any design before you begin coding!” \\nIn ten years the pendulum has swung from “design everything” to “design nothing.” \\nBut the alternative to BDUF isn’t no design up front, it’s a Little Design Up Front \\n(LDUF) or Enough Design Up Front—ENUF. \\nHow do you tell how much is enough? That’s a judgment call, and no one can make \\nthat call perfectly. But while you can’t know the exact right amount of design with any \\nconfidence, two amounts of design are guaranteed to be wrong every time: designing \\nevery last detail and not designing anything at all. The two positions advocated by \\nextremists on both ends of the scale turn out to be the only two positions that are \\nalways wrong!\\nAs P.J. Plauger says, “The more dogmatic you are about applying a design method, the \\nfewer real-life problems you are going to solve” (Plauger 1993). Treat design as a \\nwicked, sloppy, heuristic process. Don’t settle for the first design that occurs to you. \\nCollaborate. Strive for simplicity. Prototype when you need to. Iterate, iterate, and iter-\\nate again. You’ll be happy with your designs. \\nAdditional Resources\\ncc2e.com/0520 Software design is a rich field with abundant resources. The challenge is identifying \\nwhich resources will be most useful. Here are some suggestions.\\nSoftware Design, General\\nWeisfeld, Matt. The Object-Oriented Thought Process, 2d ed. SAMS, 2004. This is an \\naccessible book that introduces object-oriented programming. If you’re already famil-\\niar with object-oriented programming, you’ll probably want a more advanced book, \\nbut if you’re just getting your feet wet in object orientation, this book introduces fun-\\ndamental object-oriented concepts, including objects, classes, interfaces, inheritance, \\npolymorphism, overloading, abstract classes, aggregation and association, construc-\\ntors/destructors, exceptions, and others.\\nRiel, Arthur J. Object-Oriented Design Heuristics. Reading, MA: Addison-Wesley, 1996. \\nThis book is easy to read and focuses on design at the class level. \\nPlauger, P. J. Programming on Purpose: Essays on Software Design. Englewood Cliffs, NJ: \\nPTR Prentice Hall, 1993. I picked up as many tips about good software design from \\nreading this book as from any other book I’ve read. Plauger is well-versed in a wide-\\nvariety of design approaches, he’s pragmatic, and he’s a great writer.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 156}, page_content='120 Chapter 5: Design in Construction\\nMeyer, Bertrand. Object-Oriented Software Construction , 2d ed. New York, NY: Pren-\\ntice Hall PTR, 1997. Meyer presents a forceful advocacy of hard-core object-oriented \\nprogramming.\\nRaymond, Eric S. The Art of UNIX Programming. Boston, MA: Addison-Wesley, 2004. \\nThis is a well-researched look at software design through UNIX-colored glasses. Section \\n1.6 is an especially concise 12-page explanation of 17 key UNIX design principles.\\nLarman, Craig. Applying UML and Patterns: An Introduction to Object-Oriented Analysis \\nand Design and the Unified Process, 2d ed. Englewood Cliffs, NJ: Prentice Hall, 2001. \\nThis book is a popular introduction to object-oriented design in the context of the \\nUnified Process. It also discusses object-oriented analysis.\\nSoftware Design Theory\\nParnas, David L., and Paul C. Clements. “A Rational Design Process: How and Why to \\nFake It.” IEEE Transactions on Software Engineering SE-12, no. 2 (February 1986): 251–57. \\nThis classic article describes the gap between how programs are really designed and \\nhow you sometimes wish they were designed. The main point is that no one ever \\nreally goes through a rational, orderly design process but that aiming for it makes for \\nbetter designs in the end.\\nI’m not aware of any comprehensive treatment of information hiding. Most software-\\nengineering textbooks discuss it briefly, frequently in the context of object-oriented \\ntechniques. The three Parnas papers listed below are the seminal presentations of the \\nidea and are probably still the best resources on information hiding.\\nParnas, David L. “On the Criteria to Be Used in Decomposing Systems into Modules.” \\nCommunications of the ACM 5, no. 12 (December 1972): 1053-58.\\nParnas, David L. “Designing Software for Ease of Extension and Contraction.” IEEE \\nTransactions on Software Engineering SE-5, no. 2 (March 1979): 128-38.\\nParnas, David L., Paul C. Clements, and D. M. Weiss. “The Modular Structure of Com-\\nplex Systems.” IEEE Transactions on Software Engineering SE-11, no. 3 (March 1985): \\n259-66.\\nDesign Patterns\\nGamma, Erich, et al. Design Patterns. Reading, MA: Addison-Wesley, 1995. This book \\nby the “Gang of Four” is the seminal book on design patterns. \\nShalloway, Alan, and James R. Trott. Design Patterns Explained. Boston, MA: Addison-\\nWesley, 2002.  This book contains an easy-to-read introduction to design patterns.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 157}, page_content='Additional Resources 121\\nDesign in General\\nAdams, James L. Conceptual Blockbusting: A Guide to Better Ideas, 4th ed. Cambridge, \\nMA: Perseus Publishing, 2001. Although not specifically about software design, this \\nbook was written to teach design to engineering students at Stanford. Even if you \\nnever design anything, the book is a fascinating discussion of creative thought pro-\\ncesses. It includes many exercises in the kinds of thinking required for effective \\ndesign. It also contains a well-annotated bibliography on design and creative thinking. \\nIf you like problem solving, you’ll like this book.\\nPolya, G. How to Solve It: A New Aspect of Mathematical Method, 2d ed. Princeton, NJ: \\nPrinceton University Press, 1957. This discussion of heuristics and problem solving \\nfocuses on mathematics but is applicable to software development. Polya’s book was \\nthe first written about the use of heuristics in mathematical problem solving. It draws \\na clear distinction between the messy heuristics used to discover solutions and the \\ntidier techniques used to present them once they’ve been discovered. It’s not easy \\nreading, but if you’re interested in heuristics, you’ll eventually read it whether you \\nwant to or not. Polya’s book makes it clear that problem solving isn’t a deterministic \\nactivity and that adherence to any single methodology is like walking with your feet in \\nchains. At one time, Microsoft gave this book to all its new programmers.\\nMichalewicz, Zbigniew, and David B. Fogel. How to Solve It: Modern Heuristics. Berlin: \\nSpringer-Verlag, 2000. This is an updated treatment of Polya’s book that’s quite a bit \\neasier to read and that also contains some nonmathematical examples. \\nSimon, Herbert. The Sciences of the Artificial, 3d ed. Cambridge, MA: MIT Press, 1996. \\nThis fascinating book draws a distinction between sciences that deal with the natural \\nworld (biology, geology, and so on) and sciences that deal with the artificial world cre-\\nated by humans (business, architecture, and computer science). It then discusses the \\ncharacteristics of the sciences of the artificial, emphasizing the science of design. It has \\nan academic tone and is well worth reading for anyone intent on a career in software \\ndevelopment or any other “artificial” field.\\nGlass, Robert L. Software Creativity. Englewood Cliffs, NJ: Prentice Hall PTR, 1995. Is \\nsoftware development controlled more by theory or by practice? Is it primarily cre-\\native or is it primarily deterministic? What intellectual qualities does a software devel-\\noper need? This book contains an interesting discussion of the nature of software \\ndevelopment with a special emphasis on design. \\nPetroski, Henry. Design Paradigms: Case Histories of Error and Judgment in Engineering. \\nCambridge: Cambridge University Press, 1994. This book draws heavily from the field of \\ncivil engineering (especially bridge design) to explain its main argument that successful \\ndesign depends at least as much upon learning from past failures as from past successes.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 158}, page_content='122 Chapter 5: Design in Construction\\nStandards\\nIEEE Std 1016-1998, Recommended Practice for Software Design Descriptions. This docu-\\nment contains the IEEE-ANSI standard for software-design descriptions. It describes \\nwhat should be included in a software-design document.\\nIEEE Std 1471-2000. Recommended Practice for Architectural Description of Software Inten-\\nsive Systems. Los Alamitos, CA: IEEE Computer Society Press. This document is the \\nIEEE-ANSI guide for creating software architecture specifications. \\ncc2e.com/0527 CHECKLIST: Design in Construction\\nDesign Practices\\n❑ Have you iterated, selecting the best of several attempts rather than the \\nfirst attempt?\\n❑ Have you tried decomposing the system in several different ways to see \\nwhich way will work best?\\n❑ Have you approached the design problem both from the top down and \\nfrom the bottom up? \\n❑ Have you prototyped risky or unfamiliar parts of the system, creating the \\nabsolute minimum amount of throwaway code needed to answer specific \\nquestions? \\n❑ Has your design been reviewed, formally or informally, by others? \\n❑ Have you driven the design to the point that its implementation seems \\nobvious?\\n❑ Have you captured your design work using an appropriate technique such \\nas a Wiki, e-mail, flip charts, digital photography, UML, CRC cards, or \\ncomments in the code itself? \\nDesign Goals\\n❑ Does the design adequately address issues that were identified and \\ndeferred at the architectural level?\\n❑ Is the design stratified into layers?\\n❑ Are you satisfied with the way the program has been decomposed into \\nsubsystems, packages, and classes?\\n❑ Are you satisfied with the way the classes have been decomposed into \\nroutines?\\n❑ Are classes designed for minimal interaction with each other?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 159}, page_content='Key Points 123\\n❑ Are classes and subsystems designed so that you can use them in other \\nsystems?\\n❑ Will the program be easy to maintain?\\n❑ Is the design lean? Are all of its parts strictly necessary?\\n❑ Does the design use standard techniques and avoid exotic, hard-to-under-\\nstand elements?\\n❑ Overall, does the design help mini mize both accidental and essential \\ncomplexity? \\nKey Points\\n■ Software’s Primary Technical Imperative is managing complexity. This is greatly \\naided by a design focus on simplicity. \\n■ Simplicity is achieved in two general ways: minimizing the amount of essential \\ncomplexity that anyone’s brain has to deal with at any one time, and keeping \\naccidental complexity from proliferating needlessly. \\n■ Design is heuristic. Dogmatic adherence to any single methodology hurts cre-\\nativity and hurts your programs. \\n■ Good design is iterative; the more design possibilities you try, the better your \\nfinal design will be.\\n■ Information hiding is a particularly valuable concept. Asking “What should I \\nhide?” settles many difficult design issues. \\n■ Lots of useful, interesting information on design is available outside this book. \\nThe perspectives presented here are just the tip of the iceberg.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 161}, page_content='125\\nChapter 6\\nWorking Classes\\ncc2e.com/0665 Contents\\n■ 6.1 Class Foundations: Abstract Data Types (ADTs): page 126\\n■ 6.2 Good Class Interfaces: page 133\\n■ 6.3 Design and Implementation Issues: page 143\\n■ 6.4 Reasons to Create a Class: page 152\\n■ 6.5 Language-Specific Issues: page 156\\n■ 6.6 Beyond Classes: Packages: page 156\\nRelated Topics\\n■ Design in construction: Chapter 5\\n■ Software architecture: Section 3.5\\n■ High-quality routines: Chapter 7\\n■ The Pseudocode Programming Process: Chapter 9\\n■ Refactoring: Chapter 24\\nIn the dawn of computing, programmers thought about programming in terms of \\nstatements. Throughout the 1970s and 1980s, programmers began thinking about \\nprograms in terms of routines. In the twenty-first century, programmers think about \\nprogramming in terms of classes. \\nA class is a collection of data and routines that share a cohesive, well-defined respon-\\nsibility. A class might also be a collection of routines that provides a cohesive set of ser-\\nvices even if no common data is involved. A key to being an effective programmer is \\nmaximizing the portion of a program that you can safely ignore while working on any \\none section of code. Classes are the primary tool for accomplishing that objective. \\nThis chapter contains a distillation of advice in creating high-quality classes. If you’re \\nstill warming up to object-oriented  concepts, this chapter might be too advanced. \\nMake sure you’ve read Chapter 5, “Design in Construction.” Then start with Section \\n6.1, “Class Foundations: Abstract Data Types (ADTs),” and ease your way into the \\nremaining sections. If you’re already familiar with class basics, you might skim Section \\n6.1 and then dive into the discussion of class interfaces in Section 6.2. The “Additional \\nResources” section at the end of this chapter contains pointers to introductory reading, \\nadvanced reading, and programming-language-specific resources.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 162}, page_content='126 Chapter 6: Working Classes\\n6.1 Class Foundations: Abstract Data Types (ADTs)\\nAn abstract data type is a collection of data and operations that work on that data. The \\noperations both describe the data to the rest of the program and allow the rest of the \\nprogram to change the data. The word “data” in “abstract data type” is used loosely. \\nAn ADT might be a graphics window with all the operations that affect it, a file and file \\noperations, an insurance-rates table and the operations on it, or something else. \\nCross-Reference Thinking \\nabout ADTs first and classes \\nsecond is an example of pro-\\ngramming into a language \\nvs. programming in one. See \\nSection 4.3, “Your Location \\non the Technology Wave,” \\nand Section 34.4, “Program \\ninto Your Language, Not in It.”\\nUnderstanding ADTs is essential to understanding object-oriented programming. \\nWithout understanding ADTs, programmers create classes that are “classes” in name \\nonly—in reality, they are little more than convenient carrying cases for loosely related \\ncollections of data and routines. With an understanding of ADTs, programmers can \\ncreate classes that are easier to implement initially and easier to modify over time. \\nTraditionally, programming books wax mathematical when they arrive at the topic of \\nabstract data types. They tend to make statements like “One can think of an abstract \\ndata type as a mathematical model with a collection of operations defined on it.” Such \\nbooks make it seem as if you’d never actually use an abstract data type except as a \\nsleep aid.\\nSuch dry explanations of abstract data types completely miss the point. Abstract data \\ntypes are exciting because you can use them to manipulate real-world entities rather \\nthan low-level, implementation entities. Instead of inserting a node into a linked list, \\nyou can add a cell to a spreadsheet, a new type of window to a list of window types, or \\nanother passenger car to a train simulation. Tap into the power of being able to work \\nin the problem domain rather than at the low-level implementation domain! \\nExample of the Need for an ADT\\nTo get things started, here’s an example of a case in which an ADT would be useful. \\nWe’ll get to the details after we have an example to talk about. \\nSuppose you’re writing a program to control text output to the screen using a variety \\nof typefaces, point sizes, and font attributes (such as bold and italic). Part of the pro-\\ngram manipulates the text’s fonts. If you use an ADT, you’ll have a group of font rou-\\ntines bundled with the data—the typeface names, point sizes, and font attributes—they \\noperate on. The collection of font routines and data is an ADT.\\nIf you’re not using ADTs, you’ll take an ad hoc approach to manipulating fonts. For \\nexample, if you need to change to a 12-point font size, which happens to be 16 pixels \\nhigh, you’ll have code like this:\\ncurrentFont.size = 16'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 163}, page_content='6.1 Class Foundations: Abstract Data Types (ADTs) 127\\nIf you’ve built up a collection of library routines, the code might be slightly more \\nreadable:\\ncurrentFont.size = PointsToPixels( 12 )\\nOr you could provide a more specific name for the attribute, something like\\ncurrentFont.sizeInPixels = PointsToPixels( 12 )\\nBut what you can’t do is have both currentFont.sizeInPixels and currentFont.sizeInPoints, \\nbecause, if both the data members are in play, currentFont won’t have any way to know \\nwhich of the two it should use. And if you change sizes in several places in the pro-\\ngram, you’ll have similar lines spread throughout your program.\\nIf you need to set a font to bold, you might have code like this that uses a logical or and \\na hexidecimal constant 0x02: \\ncurrentFont.attribute = currentFont.attribute or 0x02\\nIf you’re lucky, you’ll have something cleaner than that, but the best you’ll get with an \\nad hoc approach is something like this:\\ncurrentFont.attribute = currentFont.attribute or BOLD\\nOr maybe something like this:\\ncurrentFont.bold = True\\nAs with the font size, the limitation is that the client code is required to control the \\ndata members directly, which limits how currentFont can be used. \\nIf you program this way, you’re likely to have similar lines in many places in your \\nprogram.\\nBenefits of Using ADTs\\nThe problem isn’t that the ad hoc approach is bad programming practice. It’s that you \\ncan replace the approach with a better programming practice that produces these \\nbenefits:\\nYou can hide implementation details Hiding information about the font data type \\nmeans that if the data type changes, you can change it in one place without affecting \\nthe whole program. For example, unless you hid the implementation details in an \\nADT, changing the data type from the first representation of bold to the second would \\nentail changing your program in every place in which bold was set rather than in just \\none place. Hiding the information also protects the rest of the program if you decide \\nto store data in external storage rather than in memory or to rewrite all the font-\\nmanipulation routines in another language.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 164}, page_content='128 Chapter 6: Working Classes\\nChanges don’t affect the whole program If fonts need to become richer and support \\nmore operations (such as switching to small caps, superscripts, strikethrough, and so \\non), you can change the program in one place. The change won’t affect the rest of the \\nprogram.\\nYou can make the interface more informative Code like currentFont.size = 16 is \\nambiguous because 16 could be a size in either pixels or points. The context doesn’t \\ntell you which is which. Collecting all similar operations into an ADT allows you to \\ndefine the entire interface in terms of points, or in terms of pixels, or to clearly differ-\\nentiate between the two, which helps avoid confusing them. \\nIt’s easier to improve performance If you need to improve font performance, you can \\nrecode a few well-defined routines rather than wading through an entire program.\\nThe program is more obviously correctYou can replace the more tedious task of ver-\\nifying that statements like currentFont.attribute = currentFont.attribute or 0x02 are cor-\\nrect with the easier task of verifying that calls to currentFont.SetBoldOn() are correct. \\nWith the first statement, you can have the wrong structure name, the wrong field \\nname, the wrong operation (and instead of or), or the wrong value for the attribute \\n(0x20 instead of 0x02). In the second case, the only thing that could possibly be \\nwrong with the call to currentFont.SetBoldOn() is that it’s a call to the wrong routine \\nname, so it’s easier to see whether it’s correct.\\nThe program becomes more self-documenting You can improve statements like cur-\\nrentFont.attribute or 0x02 by replacing 0x02 with BOLD or whatever 0x02 represents, but \\nthat doesn’t compare to the readability of a routine call such as currentFont.SetBoldOn().\\nWoodfield, Dunsmore, and Shen conducted a study in which graduate and senior \\nundergraduate computer-science students answered questions about two programs: \\none that was divided into eight routines along functional lines, and one that was \\ndivided into eight abstract-data-type routines (1981). Students using the abstract-data-\\ntype program scored over 30 percent higher than students using the functional ver-\\nsion.\\nYou don’t have to pass data all over your program In the examples just presented, \\nyou have to change currentFont directly or pass it to every routine that works with fonts. \\nIf. you use an abstract data type, you don’t have to pass currentFont all over the program \\nand you don’t have to turn it into global data either. The ADT has a structure that con-\\ntains currentFont’s data. The data is directly accessed only by routines that are part of the \\nADT. Routines that aren’t part of the ADT don’t have to worry about the data.\\nYou’re able to work with real-world entities rather than with low-level implementation \\nstructures You can define operations dealing with fonts so that most of the program \\noperates solely in terms of fonts rather than in terms of array accesses, structure defi-\\nnitions, and True and False.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 165}, page_content='6.1 Class Foundations: Abstract Data Types (ADTs) 129\\nIn this case, to define an abstract data type, you’d define a few routines to control \\nfonts—perhaps like this:\\ncurrentFont.SetSizeInPoints( sizeInPoints )\\ncurrentFont.SetSizeInPixels( sizeInPixels )\\ncurrentFont.SetBoldOn()\\ncurrentFont.SetBoldOff()\\ncurrentFont.SetItalicOn()\\ncurrentFont.SetItalicOff()\\ncurrentFont.SetTypeFace( faceName )\\nThe code inside these routines would probably be short—it would probably be similar \\nto the code you saw in the ad hoc approach to the font problem earlier. The difference \\nis that you’ve isolated font operations in a set of routines. That provides a better level \\nof abstraction for the rest of your program to work with fonts, and it gives you a layer \\nof protection against changes in font operations. \\nMore Examples of ADTs\\nSuppose you’re writing software that controls the cooling system for a nuclear reactor. \\nYou can treat the cooling system as an abstract data type by defining the following \\noperations for it:\\ncoolingSystem.GetTemperature()\\ncoolingSystem.SetCirculationRate( rate )\\ncoolingSystem.OpenValve( valveNumber )\\ncoolingSystem.CloseValve( valveNumber )\\nThe specific environment would determine the code written to implement each of \\nthese operations. The rest of the program could deal with the cooling system through \\nthese functions and wouldn’t have to worry about internal details of data-structure \\nimplementations, data-structure limitations, changes, and so on.\\nHere are more examples of abstract data types and likely operations on them:\\nKEY POINT\\nCruise Control Blender Fuel Tank\\nSet speed Turn on Fill tank\\nGet current settings Turn off Drain tank\\nResume former speed Set speed Get tank capacity\\nDeactivate Start “Insta-Pulverize” Get tank status\\nStop “Insta-Pulverize”\\nList Stack\\nInitialize list Light Initialize stack \\nInsert item in list Turn on Push item onto stack\\nRemove item from list Turn off Pop item from stack\\nRead next item from list Read top of stack'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 166}, page_content='130 Chapter 6: Working Classes\\nYon can derive several guidelines from a study of these examples; those guidelines are \\ndescribed in the following subsections: \\nBuild or use typical low-level data types as ADTs, not as low-level data types Most \\ndiscussions of ADTs focus on representing typical low-level data types as ADTs. As you \\ncan see from the examples, you can represent a stack, a list, and a queue, as well as vir-\\ntually any other typical data type, as an ADT.\\nThe question you need to ask is, “What does this stack, list, or queue represent?” If a \\nstack represents a set of employees, treat the ADT as employees rather than as a stack. \\nIf a list represents a set of billing records, treat it as billing records rather than a list. If \\na queue represents cells in a spreadsheet, treat it as a collection of cells rather than a \\ngeneric item in a queue. Treat yourself to the highest possible level of abstraction.\\nTreat common objects such as files as ADTs Most languages include a few abstract \\ndata types that you’re probably familiar with but might not think of as ADTs. File oper-\\nations are a good example. While writing to disk, the operating system spares you the \\ngrief of positioning the read/write head at a specific physical address, allocating a new \\ndisk sector when you exhaust an old one, and interpreting cryptic error codes. The oper-\\nating system provides a first level of abstraction and the ADTs for that level. High-level \\nlanguages provide a second level of abstraction and ADTs for that higher level. A high-\\nlevel language protects you from the messy details of generating operating-system calls \\nand manipulating data buffers. It allows you to treat a chunk of disk space as a “file.”\\nYou can layer ADTs similarly. If you want to use an ADT at one level that offers data-\\nstructure level operations (like pushing and popping a stack), that’s fine. You can cre-\\nate another level on top of that one that works at the level of the real-world problem.\\nSet of Help Screens Menu File\\nAdd help topic Start new menu Open file\\nRemove help topic Delete menu Read file\\nSet current help topic Add menu item Write file\\nDisplay help screen Remove menu item Set current file location\\nRemove help display Activate menu item Close file\\nDisplay help index Deactivate menu item\\nBack up to previous screen Display menu Elevator\\nHide menu Move up one floor\\nPointer Get menu choice Move down one floor\\nGet pointer to new memory Move to specific floor\\nDispose of memory from \\nexisting pointer\\nReport current floor\\nReturn to home floor\\nChange amount of memory \\nallocated'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 167}, page_content='6.1 Class Foundations: Abstract Data Types (ADTs) 131\\nTreat even simple items as ADTs You don’t have to have a formidable data type to \\njustify using an abstract data type. One of the ADTs in the example list is a light that \\nsupports only two operations—turning it on and turning it off. You might think that it \\nwould be a waste to isolate simple “on” and “off” operations in routines of their own, \\nbut even simple operations can benefit from the use of ADTs. Putting the light and its \\noperations into an ADT makes the code more self-documenting and easier to change, \\nconfines the potential consequences of changes to the TurnLightOn() and TurnLight-\\nOff() routines, and reduces the number of data items you have to pass around.\\nRefer to an ADT independently of the medium it’s stored on Suppose you have an \\ninsurance-rates table that’s so big that it’s always stored on disk. You might be \\ntempted to refer to it as a “rate file” and create access routines such as RateFile.Read(). \\nWhen you refer to it as a file, however, you’re exposing more information about the \\ndata than you need to. If you ever change the program so that the table is in memory \\ninstead of on disk, the code that refers to it as a file will be incorrect, misleading, and \\nconfusing. Try to make the names of classes and access routines independent of how \\nthe data is stored, and refer to the abstract data type, like the insurance-rates table, \\ninstead. That would give your class and access routine names like rateTable.Read() or \\nsimply rates.Read(). \\nHandling Multiple Instances of Data with ADTs in Non-Object-\\nOriented Environments\\nObject-oriented languages provide automatic support for handling multiple instances \\nof an ADT. If you’ve worked exclusively in object-oriented environments and you’ve \\nnever had to handle the implementation details of multiple instances yourself, count \\nyour blessings! (You can also move on to the next section, “ADTs and Classes.”)\\nIf you’re working in a non-object-oriented environment such as C, you will have to \\nbuild support for multiple instances manually. In general, that means including ser-\\nvices for the ADT to create and delete instances and designing the ADT’s other ser-\\nvices so that they can work with multiple instances.\\nThe font ADT originally offered these services:\\ncurrentFont.SetSize( sizeInPoints )\\ncurrentFont.SetBoldOn()\\ncurrentFont.SetBoldOff()\\ncurrentFont.SetItalicOn()\\ncurrentFont.SetItalicOff()\\ncurrentFont.SetTypeFace( faceName )'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 168}, page_content='132 Chapter 6: Working Classes\\nIn a non-object-oriented environment, these functions would not be attached to a \\nclass and would look more like this:\\nSetCurrentFontSize( sizeInPoints )\\nSetCurrentFontBoldOn()\\nSetCurrentFontBoldOff()\\nSetCurrentFontItalicOn()\\nSetCurrentFontItalicOff()\\nSetCurrentFontTypeFace( faceName )\\nIf you want to work with more than one font at a time, you’ll need to add services to \\ncreate and delete font instances—maybe these:\\nCreateFont( fontId )\\nDeleteFont( fontId )\\nSetCurrentFont( fontId )\\nThe notion of a fontId has been added as a way to keep track of multiple fonts as \\nthey’re created and used. For other operations, you can choose from among three \\nways to handle the ADT interface:\\n■ Option 1: Explicitly identify instances each time you use ADT services. In this \\ncase, you don’t have the notion of a “current font.” You pass fontId to each rou-\\ntine that manipulates fonts. The Font functions keep track of any underlying \\ndata, and the client code needs to keep track only of the fontId. This requires \\nadding fontId as a parameter to each font routine.\\n■ Option 2: Explicitly provide the data used by the ADT services. In this approach, \\nyou declare the data that the ADT uses within each routine that uses an ADT ser-\\nvice. In other words, you create a Font data type that you pass to each of the ADT \\nservice routines. You must design the ADT service routines so that they use the \\nFont data that’s passed to them each time they’re called. The client code doesn’t \\nneed a font ID if you use this approach because it keeps track of the font data \\nitself. (Even though the data is available directly from the Font data type, you \\nshould access it only with the ADT service routines. This is called keeping the \\nstructure “closed.”) \\nThe advantage of this approach is that the ADT service routines don’t have to \\nlook up font information based on a font ID. The disadvantage is that it exposes \\nfont data to the rest of the program, which increases the likelihood that client \\ncode will make use of the ADT’s implementation details that should have \\nremained hidden within the ADT.\\n■ Option 3: Use implicit instances (with great care). Design a new service to call to \\nmake a specific font instance the current one—something like SetCurrentFont\\n( fontId ). Setting the current font makes all other services use the current font \\nwhen they’re called. If you use this approach, you don’t need fontId as a param-\\neter to the other services. For simple applications, this can streamline use of'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 169}, page_content='6.2 Good Class Interfaces 133\\nmultiple instances. For complex applications, this systemwide dependence on \\nstate means that you must keep track of the current font instance throughout \\ncode that uses the Font functions. Complexity tends to proliferate, and for appli-\\ncations of any size, better alternatives exist. \\nInside the abstract data type, you’ll have a wealth of options for handling multiple \\ninstances, but outside, this sums up the choices if you’re working in a non-object-ori-\\nented language. \\nADTs and Classes\\nAbstract data types form the foundation for the concept of classes. In languages that \\nsupport classes, you can implement each abstract data type as its own class. Classes \\nusually involve the additional concepts of inheritance and polymorphism. One way of \\nthinking of a class is as an abstract data type plus inheritance and polymorphism.\\n6.2 Good Class Interfaces\\nThe first and probably most important step in creating a high-quality class is creating \\na good interface. This consists of creating a good abstraction for the interface to repre-\\nsent and ensuring that the details remain hidden behind the abstraction. \\nGood Abstraction\\nAs “Form Consistent Abstractions” in Section 5.3 described, abstraction is the ability \\nto view a complex operation in a simplified form. A class interface provides an abstrac-\\ntion of the implementation that’s hidden behind the interface. The class’s interface \\nshould offer a group of routines that clearly belong together. \\nYou might have a class that implements an employee. It would contain data describing \\nthe employee’s name, address, phone number, and so on. It would offer services to ini-\\ntialize and use an employee. Here’s how that might look. \\nC+ + Example of a Class Interface That Presents a Good Abstraction\\nCross-Reference Code sam-\\nples in this book are format-\\nted using a coding \\nconvention that emphasizes \\nsimilarity of styles across \\nmultiple languages. For \\ndetails on the convention \\n(and discussions about mul-\\ntiple coding styles), see \\n“Mixed-Language Program-\\nming Considerations” in \\nSection 11.4.\\nclass Employee {\\npublic:\\n   // public constructors and destructors\\n   Employee();\\n   Employee( \\n      FullName name, \\n      String address, \\n      String workPhone, \\n      String homePhone,\\n      TaxId taxIdNumber, \\n      JobClassification jobClass \\n   );\\n   virtual ~Employee();'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 170}, page_content='134 Chapter 6: Working Classes\\n   // public routines\\n   FullName GetName() const; \\n   String GetAddress() const; \\n   String GetWorkPhone() const; \\n   String GetHomePhone() const; \\n   TaxId GetTaxIdNumber() const; \\n   JobClassification GetJobClassification() const; \\n   ...\\nprivate:\\n   ...\\n};\\nInternally, this class might have additional routines and data to support these ser-\\nvices, but users of the class don’t need to know anything about them. The class inter-\\nface abstraction is great because every routine in the interface is working toward a \\nconsistent end. \\nA class that presents a poor abstraction would be one that contained a collection of \\nmiscellaneous functions. Here’s an example:\\nC+ + Example of a Class Interface That Presents a Poor Abstraction\\nclass Program {\\npublic:\\n   ...\\n   // public routines\\n   void InitializeCommandStack();\\n   void PushCommand( Command command );\\n   Command PopCommand(); \\n   void ShutdownCommandStack();\\n   void InitializeReportFormatting(); \\n   void FormatReport( Report report );\\n   void PrintReport( Report report );\\n   void InitializeGlobalData(); \\n   void ShutdownGlobalData(); \\n   ...\\nprivate:\\n   ...\\n};\\nSuppose that a class contains routines to work with a command stack, to format \\nreports, to print reports, and to initialize global data. It’s hard to see any connection \\namong the command stack and report routines or the global data. The class interface \\ndoesn’t present a consistent abstraction, so the class has poor cohesion. The routines \\nshould be reorganized into more-focused classes, each of which provides a better \\nabstraction in its interface. \\nIf these routines were part of a Program class, they could be revised to present a con-\\nsistent abstraction, like so: \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 171}, page_content='6.2 Good Class Interfaces 135\\nC+ + Example of a Class Interface That Presents a Better Abstraction\\nclass Program {\\npublic:\\n   ...\\n   // public routines\\n   void InitializeUserInterface(); \\n   void ShutDownUserInterface(); \\n   void InitializeReports(); \\n   void ShutDownReports(); \\n   ...\\nprivate:\\n   ...\\n};\\nThe cleanup of this interface assumes that some of the original routines were moved \\nto other, more appropriate classes and some were converted to private routines used \\nby InitializeUserInterface() and the other routines. \\nThis evaluation of class abstraction is based on the class’s collection of public rou-\\ntines—that is, on the class’s interface. The routines inside the class don’t necessarily \\npresent good individual abstractions just because the overall class does, but they need \\nto be designed to present good abstractions too. For guidelines on that, see Section \\n7.2, “Design at the Routine Level.”\\nThe pursuit of good, abstract interfaces gives rise to several guidelines for creating \\nclass interfaces. \\nPresent a consistent level of abstraction in the class interface A good way to think \\nabout a class is as the mechanism for implementing the abstract data types described \\nin Section 6.1. Each class should implement one and only one ADT. If you find a class \\nimplementing more than one ADT, or if you can’t determine what ADT the class \\nimplements, it’s time to reorganize the class into one or more well-defined ADTs. \\nHere’s an example of a class that presents an interface that’s inconsistent because its \\nlevel of abstraction is not uniform: \\nC+ + Example of a Class Interface with Mixed Levels of Abstraction\\nclass EmployeeCensus: public ListContainer {\\npublic:\\n   ...\\n   // public routines\\nThe abstraction of these \\nroutines is at the “employee” \\nlevel.\\n   void AddEmployee( Employee employee ); \\n   void RemoveEmployee( Employee employee ); \\nThe abstraction of these \\nroutines is at the “list” level.\\n   Employee NextItemInList();\\n   Employee FirstItem();\\n   Employee LastItem();\\n   ...\\nprivate:\\n   ...\\n};\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 172}, page_content='136 Chapter 6: Working Classes\\nThis class is presenting two ADTs: an Employee and a ListContainer. This sort of mixed \\nabstraction commonly arises when a programmer uses a container class or other \\nlibrary classes for implementation and doesn’t hide the fact that a library class is used. \\nAsk yourself whether the fact that a container class is used should be part of the \\nabstraction. Usually that’s an implementation detail that should be hidden from the \\nrest of the program, like this:\\nC+ + Example of a Class Interface with Consistent Levels of Abstraction\\nclass EmployeeCensus {\\npublic:\\n   ...\\n   // public routines\\nThe abstraction of all these \\nroutines is now at the \\n“employee” level. \\n   void AddEmployee( Employee employee ); \\n   void RemoveEmployee( Employee employee ); \\n   Employee NextEmployee();\\n   Employee FirstEmployee();\\n   Employee LastEmployee();\\n   ...\\nprivate:\\nThat the class uses the \\nListContainer library is now \\nhidden.\\n   ListContainer m_EmployeeList; \\n   ...\\n};\\nProgrammers might argue that inheriting from ListContainer is convenient because it \\nsupports polymorphism, allowing an external search or sort function that takes a List-\\nContainer object. That argument fails the main test for inheritance, which is, “Is inher-\\nitance used only for “is a” relationships?” To inherit from ListContainer would mean \\nthat EmployeeCensus “is a” ListContainer, which obviously isn’t true. If the abstraction \\nof the EmployeeCensus object is that it can be searched or sorted, that should be incor-\\nporated as an explicit, consistent part of the class interface. \\nIf you think of the class’s public routines as an air lock that keeps water from getting \\ninto a submarine, inconsistent public routines are leaky panels in the class. The leaky \\npanels might not let water in as quickly as an open air lock, but if you give them \\nenough time, they’ll still sink the boat. In practice, this is what happens when you mix \\nlevels of abstraction. As the program is modified, the mixed levels of abstraction make \\nthe program harder and harder to understand, and it gradually degrades until it \\nbecomes unmaintainable.\\nBe sure you understand what abstraction the class is implementing Some classes are \\nsimilar enough that you must be careful to understand which abstraction the class \\ninterface should capture. I once worked on a program that needed to allow informa-\\ntion to be edited in a table format. We wanted to use a simple grid control, but the grid \\ncontrols that were available didn’t allow us to color the data-entry cells, so we decided \\nto use a spreadsheet control that did provide that capability. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 173}, page_content='6.2 Good Class Interfaces 137\\nThe spreadsheet control was far more complicated than the grid control, providing \\nabout 150 routines to the grid control’s 15. Since our goal was to use a grid control, \\nnot a spreadsheet control, we assigned a programmer to write a wrapper class to hide \\nthe fact that we were using a spreadsheet control as a grid control. The programmer \\ngrumbled quite a bit about unnecessary overhead and bureaucracy, went away, and \\ncame back a couple days later with a wrapper class that faithfully exposed all 150 rou-\\ntines of the spreadsheet control. \\nThis was not what was needed. We wanted a grid-control interface that encapsulated \\nthe fact that, behind the scenes, we were using a much more complicated spreadsheet \\ncontrol. The programmer should have exposed just the 15 grid-control routines plus \\na 16th routine that supported cell coloring. By exposing all 150 routines, the program-\\nmer created the possibility that, if we ever wanted to change the underlying imple-\\nmentation, we could find ourselves supporting 150 public routines. The programmer \\nfailed to achieve the encapsulation we were looking for, as well as creating a lot more \\nwork for himself than necessary. \\nDepending on specific circumstances, the right abstraction might be either a spread-\\nsheet control or a grid control. When you have to choose between two similar abstrac-\\ntions, make sure you choose the right one. \\nProvide services in pairs with their opposites Most operations have corresponding, \\nequal, and opposite operations. If you have an operation that turns a light on, you’ll \\nprobably need one to turn it off. If you have an operation to add an item to a list, you’ll \\nprobably need one to delete an item from the list. If you have an operation to activate \\na menu item, you’ll probably need one to deactivate an item. When you design a class, \\ncheck each public routine to determine whether you need its complement. Don’t cre-\\nate an opposite gratuitously, but do check to see whether you need one.\\nMove unrelated information to another class In some cases, you’ll find that half a \\nclass’s routines work with half the class’s data and half the routines work with the \\nother half of the data. In such a case, you really have two classes masquerading as one. \\nBreak them up!\\nMake interfaces programmatic rather than semantic when possibleEach interface \\nconsists of a programmatic part and a semantic part. The programmatic part consists of \\nthe data types and other attributes of the interface that can be enforced by the compiler. \\nThe semantic part of the interface consists of the assumptions about how the interface \\nwill be used, which cannot be enforced by the compiler. The semantic interface includes \\nconsiderations such as “RoutineA must be called before RoutineB” or “RoutineA will crash \\nif dataMember1 isn’t initialized before it’s passed to RoutineA.” The semantic interface \\nshould be documented in comments, but try to keep interfaces minimally dependent \\non documentation. Any aspect of an interface that can’t be enforced by the compiler is \\nan aspect that’s likely to be misused. Look for ways to convert semantic interface ele-\\nments to programmatic interface elements by using Asserts or other techniques.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 174}, page_content='138 Chapter 6: Working Classes\\nCross-Reference For more \\nsuggestions about how to \\npreserve code quality as \\ncode is modified, see Chap-\\nter 24, “Refactoring.” \\nBeware of erosion of the interface’s abstraction under modification As a class is \\nmodified and extended, you often discover additional functionality that’s needed, that \\ndoesn’t quite fit with the original class interface, but that seems too hard to implement \\nany other way. For example, in the Employee class, you might find that the class \\nevolves to look like this:\\nC+ + Example of a Class Interface That’s Eroding Under Maintenance\\nclass Employee {\\npublic:\\n   ...\\n   // public routines\\n   FullName GetName() const; \\n   Address GetAddress() const; \\n   PhoneNumber GetWorkPhone() const; \\n   ...\\n   bool IsJobClassificationValid( JobClassification jobClass ); \\n   bool IsZipCodeValid( Address address ); \\n   bool IsPhoneNumberValid( PhoneNumber phoneNumber ); \\n   SqlQuery GetQueryToCreateNewEmployee() const; \\n   SqlQuery GetQueryToModifyEmployee() const; \\n   SqlQuery GetQueryToRetrieveEmployee() const; \\n   ...\\nprivate:\\n   ...\\n};\\nWhat started out as a clean abstraction in an earlier code sample has evolved into a \\nhodgepodge of functions that are only loosely related. There’s no logical connection \\nbetween employees and routines that check ZIP Codes, phone numbers, or job classi-\\nfications. The routines that expose SQL query details are at a much lower level of \\nabstraction than the Employee class, and they break the Employee abstraction.\\nDon’t add public members that are inconsistent with the interface abstraction Each \\ntime you add a routine to a class interface, ask “Is this routine consistent with the \\nabstraction provided by the existing interface?” If not, find a different way to make the \\nmodification and preserve the integrity of the abstraction. \\nConsider abstraction and cohesion together The ideas of abstraction and cohesion \\nare closely related—a class interface that presents a good abstraction usually has \\nstrong cohesion. Classes with strong cohesion tend to present good abstractions, \\nalthough that relationship is not as strong. \\nI have found that focusing on the abstraction presented by the class interface tends to \\nprovide more insight into class design than focusing on class cohesion. If you see that \\na class has weak cohesion and aren’t sure how to correct it, ask yourself whether the \\nclass presents a consistent abstraction instead. \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 175}, page_content='6.2 Good Class Interfaces 139\\nGood Encapsulation\\nCross-Reference For more \\non encapsulation, see \\n“Encapsulate Implementa-\\ntion Details” in Section 5.3. \\nAs Section 5.3 discussed, encapsulation is a stronger concept than abstraction. \\nAbstraction helps to manage complexity by providing models that allow you to ignore \\nimplementation details. Encapsulation is the enforcer that prevents you from looking \\nat the details even if you want to. \\nThe two concepts are related because, without encapsulation, abstraction tends to \\nbreak down. In my experience, either you have both abstraction and encapsulation or \\nyou have neither. There is no middle ground. \\nThe single most important \\nfactor that distinguishes a \\nwell-designed module from \\na poorly designed one is the \\ndegree to which the module \\nhides its internal data and \\nother implementation details \\nfrom other modules.\\n—Joshua Bloch\\nMinimize accessibility of classes and members Minimizing accessibility is one of \\nseveral rules that are designed to encourage encapsulation. If you’re wondering \\nwhether a specific routine should be public, private, or protected, one school of \\nthought is that you should favor the strictest level of privacy that’s workable (Meyers \\n1998, Bloch 2001). I think that’s a fine guideline, but I think the more important \\nguideline is, “What best preserves the integrity of the interface abstraction?” If expos-\\ning the routine is consistent with the abstraction, it’s probably fine to expose it. If \\nyou’re not sure, hiding more is generally better than hiding less. \\nDon’t expose member data in public Exposing member data is a violation of encap-\\nsulation and limits your control over the abstraction. As Arthur Riel points out, a Point \\nclass that exposes \\nfloat x;\\nfloat y;\\nfloat z;\\nis violating encapsulation because client code is free to monkey around with Point’s \\ndata and Point won’t necessarily even know when its values have been changed (Riel \\n1996). However, a Point class that exposes \\nfloat GetX();\\nfloat GetY();\\nfloat GetZ();\\nvoid SetX( float x );\\nvoid SetY( float y );\\nvoid SetZ( float z );\\nis maintaining perfect encapsulation. You have no idea whether the underlying imple-\\nmentation is in terms of floats x, y, and z, whether Point is storing those items as dou-\\nbles and converting them to floats, or whether Point is storing them on the moon and \\nretrieving them from a satellite in outer space. \\nAvoid putting private implementation details into a class’s interface With true \\nencapsulation, programmers would not be able to see implementation details at all. \\nThey would be hidden both figuratively and literally. In popular languages, including'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 176}, page_content='140 Chapter 6: Working Classes\\nC++, however, the structure of the language requires programmers to disclose imple-\\nmentation details in the class interface. Here’s an example:\\nC+ + Example of Exposing a Class’s Implementation Details\\nclass Employee {\\npublic:\\n   ...\\n   Employee( \\n      FullName name,\\n      String address,\\n      String workPhone,\\n      String homePhone,\\n      TaxId taxIdNumber,\\n      JobClassification jobClass \\n   );\\n   ...\\n   FullName GetName() const; \\n   String GetAddress() const; \\n   ...\\nprivate:\\nHere are the exposed \\nimplementation details. \\n   String m_Name;\\n   String m_Address;\\n   int m_jobClass;\\n   ...\\n};\\nIncluding private declarations in the class header file might seem like a small trans-\\ngression, but it encourages other programmers to examine the implementation \\ndetails. In this case, the client code is intended to use the Address type for addresses \\nbut the header file exposes the implementation detail that addresses are stored as \\nStrings. \\nScott Meyers describes a common way to address this issue in Item 34 of Effective C++, \\n2d ed. (Meyers 1998). You separate the class interface from the class implementation. \\nWithin the class declaration, include a pointer to the class’s implementation but don’t \\ninclude any other implementation details. \\nC+ + Example of Hiding a Class’s Implementation Details\\nclass Employee {\\npublic:\\n   ...\\n   Employee( ... );\\n   ...\\n   FullName GetName() const; \\n   String GetAddress() const; \\n   ...\\nprivate:\\nHere the implementation \\ndetails are hidden behind \\nthe pointer. \\n   EmployeeImplementation *m_implementation;\\n};'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 177}, page_content=\"6.2 Good Class Interfaces 141\\nNow you can put implementation details inside the EmployeeImplementation class, \\nwhich should be visible only to the Employee class and not to the code that uses the \\nEmployee class. \\nIf you’ve already written lots of code that doesn’t use this approach for your project, \\nyou might decide it isn’t worth the effort to convert a mountain of existing code to use \\nthis approach. But when you read code that exposes its implementation details, you \\ncan resist the urge to comb through the private section of the class interface looking \\nfor implementation clues. \\nDon’t make assumptions about the class’s users A class should be designed and \\nimplemented to adhere to the contract implied by the class interface. It shouldn’t \\nmake any assumptions about how that interface will or won’t be used, other than \\nwhat’s documented in the interface. Comments like the following one are an indica-\\ntion that a class is more aware of its users than it should be:\\n-- initialize x, y, and z to 1.0 because DerivedClass blows \\n-- up if they're initialized to 0.0\\nAvoid friend classes In a few circumstances such as the State pattern, friend classes \\ncan be used in a disciplined way that contributes to managing complexity (Gamma et al. \\n1995). But, in general, friend classes violate encapsulation. They expand the amount of \\ncode you have to think about at any one time, thereby increasing complexity.\\nDon’t put a routine into the public interface just because it uses only public routines\\nThe fact that a routine uses only public routines is not a significant consideration. \\nInstead, ask whether exposing the routine would be consistent with the abstraction \\npresented by the interface.\\nFavor read-time convenience to write-time convenience Code is read far more times \\nthan it’s written, even during initial development. Favoring a technique that speeds \\nwrite-time convenience at the expense of read-time convenience is a false economy. \\nThis is especially applicable to creation of class interfaces. Even if a routine doesn’t \\nquite fit the interface’s abstraction, sometimes it’s tempting to add a routine to an \\ninterface that would be convenient for the particular client of a class that you’re work-\\ning on at the time. But adding that routine is the first step down a slippery slope, and \\nit’s better not to take even the first step. \\nIt ain’t abstract if you have to \\nlook at the underlying imple-\\nmentation to understand \\nwhat’s going on.\\n—P.  J .  P l a u g e r\\nBe very, very wary of semantic violations of encapsulation At one time I thought \\nthat when I learned how to avoid syntax errors I would be home free. I soon discov-\\nered that learning how to avoid syntax errors had merely bought me a ticket to a \\nwhole new theater of coding errors, most of which were more difficult to diagnose and \\ncorrect than the syntax errors. \\nThe difficulty of semantic encapsulation compared to syntactic encapsulation is similar. \\nSyntactically, it’s relatively easy to avoid poking your nose into the internal workings of \\nanother class just by declaring the class’s internal routines and data private. Achieving\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 178}, page_content='142 Chapter 6: Working Classes\\nsemantic encapsulation is another matter entirely. Here are some examples of the ways \\nthat a user of a class can break encapsulation semantically:\\n■ Not calling Class A’s InitializeOperations() routine because you know that Class \\nA’s PerformFirstOperation() routine calls it automatically.\\n■ Not calling the database.Connect() routine before you call employee.Retrieve( \\ndatabase ) because you know that the employee.Retrieve() function will connect \\nto the database if there isn’t already a connection. \\n■ Not calling Class A’s Terminate() routine because you know that Class A’s Per-\\nformFinalOperation() routine has already called it. \\n■ Using a pointer or reference to ObjectB created by ObjectA even after ObjectA has \\ngone out of scope, because you know that ObjectA keeps ObjectB in static storage \\nand ObjectB will still be valid. \\n■ Using Class B’s MAXIMUM_ELEMENTS constant instead of using \\nClassA.MAXIMUM_ELEMENTS, because you know that they’re both equal to \\nthe same value. \\nThe problem with each of these examples is that they make the client code dependent \\nnot on the class’s public interface, but on its private implementation. Anytime you \\nfind yourself looking at a class’s implementation to figure out how to use the class, \\nyou’re not programming to the interface; you’re programming through the interface to \\nthe implementation. If you’re programming through the interface, encapsulation is \\nbroken, and once encapsulation starts to break down, abstraction won’t be far behind. \\nIf you can’t figure out how to use a class based solely on its interface documentation, \\nthe right response is not to pull up the source code and look at the implementation. \\nThat’s good initiative but bad judgment. The right response is to contact the author of \\nthe class and say “I can’t figure out how to use this class.” The right response on the \\nclass-author’s part is not to answer your question face to face. The right response for \\nthe class author is to check out the class-interface file, modify the class-interface doc-\\numentation, check the file back in, and then say “See if you can understand how it \\nworks now.” You want this dialog to occur in the interface code itself so that it will be \\npreserved for future programmers. You don’t want the dialog to occur solely in your \\nown mind, which will bake subtle semantic dependencies into the client code that \\nuses the class. And you don’t want the dialog to occur interpersonally so that it bene-\\nfits only your code but no one else’s. \\nWatch for coupling that’s too tight “Coupling” refers to how tight the connection is \\nbetween two classes. In general, the looser the connection, the better. Several general \\nguidelines flow from this concept: \\n■ Minimize accessibility of classes and members.\\n■ Avoid friend classes, because they’re tightly coupled.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 179}, page_content='6.3 Design and Implementation Issues 143\\n■ Make data private rather than protected in a base class to make derived classes \\nless tightly coupled to the base class.\\n■ Avoid exposing member data in a class’s public interface.\\n■ Be wary of semantic violations of encapsulation.\\n■ Observe the “Law of Demeter” (discussed in Section 6.3 of this chapter).\\nCoupling goes hand in glove with abstraction and encapsulation. Tight coupling \\noccurs when an abstraction is leaky, or when encapsulation is broken. If a class offers \\nan incomplete set of services, other routines might find they need to read or write its \\ninternal data directly. That opens up the class, making it a glass box instead of a black \\nbox, and it virtually eliminates the class’s encapsulation. \\n6.3 Design and Implementation Issues\\nDefining good class interfaces goes a long way toward creating a high-quality pro-\\ngram. The internal class design and implementation are also important. This section \\ndiscusses issues related to containment, inheritance, member functions and data, \\nclass coupling, constructors, and value-vs.-reference objects. \\nContainment (“has a” Relationships)\\nContainment is the simple idea that a class contains a primitive data element or \\nobject. A lot more is written about inheritance than about containment, but that’s \\nbecause inheritance is more tricky and error-prone, not because it’s better. Contain-\\nment is the work-horse technique in object-oriented programming. \\nImplement “has a” through containment One way of thinking of containment is as a \\n“has a” relationship. For example, an employee “has a” name, “has a” phone number, \\n“has a” tax ID, and so on. You can usually accomplish this by making the name, phone \\nnumber, and tax ID member data of the Employee class. \\nImplement “has a” through private inheritance as a last resort In some instances \\nyou might find that you can’t achieve containment through making one object a mem-\\nber of another. In that case, some experts suggest privately inheriting from the con-\\ntained object (Meyers 1998, Sutter 2000). The main reason you would do that is to set \\nup the containing class to access protected member functions or protected member \\ndata of the class that’s contained. In practice, this approach creates an overly cozy rela-\\ntionship with the ancestor class and violates encapsulation. It tends to point to design \\nerrors that should be resolved some way other than through private inheritance. \\nBe critical of classes that contain more than about seven data members The number \\n“7±2” has been found to be a number of discrete items a person can remember while \\nperforming other tasks (Miller 1956). If a class contains more than about seven data \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 180}, page_content='144 Chapter 6: Working Classes\\nmembers, consider whether the class should be decomposed into multiple smaller \\nclasses (Riel 1996). You might err more toward the high end of 7±2 if the data mem-\\nbers are primitive data types like integers and strings, more toward the lower end of \\n7±2 if the data members are complex objects. \\nInheritance (“is a” Relationships) \\nInheritance is the idea that one class is a specialization of another class. The purpose of \\ninheritance is to create simpler code by defining a base class that specifies common ele-\\nments of two or more derived classes. The common elements can be routine interfaces, \\nimplementations, data members, or data types. Inheritance helps avoid the need to \\nrepeat code and data in multiple locations by centralizing it within a base class.\\nWhen you decide to use inheritance, you have to make several decisions:\\n■ For each member routine, will the routine be visible to derived classes? Will it \\nhave a default implementation? Will the default implementation be overridable? \\n■ For each data member (including variables, named constants, enumerations, \\nand so on), will the data member be visible to derived classes? \\nThe following subsections explain the ins and outs of making these decisions:\\nThe single most important \\nrule in object-oriented pro-\\ngramming with C++ is this: \\npublic inheritance means \\n“is a.” Commit this rule to \\nmemory. \\n—Scott Meyers\\nImplement “is a” through public inheritance When a programmer decides to create \\na new class by inheriting from an existing class, that programmer is saying that the \\nnew class “is a” more specialized version of the older class. The base class sets expec-\\ntations about how the derived class will operate and imposes constraints on how the \\nderived class can operate (Meyers 1998). \\nIf the derived class isn’t going to adhere completely to the same interface contract \\ndefined by the base class, inheritance is not the right implementation technique. Con-\\nsider containment or making a change further up the inheritance hierarchy. \\nDesign and document for inheritance or prohibit it Inheritance adds complexity to a \\nprogram, and, as such, it’s a dangerous technique. As Java guru Joshua Bloch says, \\n“Design and document for inheritance, or prohibit it.” If a class isn’t designed to be \\ninherited from, make its members non-virtual in C++, final in Java, or non-overridable \\nin Microsoft Visual Basic so that you can’t inherit from it. \\nAdhere to the Liskov Substitution Principle (LSP) In one of object-oriented pro-\\ngramming’s seminal papers, Barbara Liskov argued that you shouldn’t inherit from a \\nbase class unless the derived class truly “is a” more specific version of the base class \\n(Liskov 1988). Andy Hunt and Dave Thomas summarize LSP like this: “Subclasses \\nmust be usable through the base class interface without the need for the user to know \\nthe difference” (Hunt and Thomas 2000).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 181}, page_content='6.3 Design and Implementation Issues 145\\nIn other words, all the routines defined in the base class should mean the same thing \\nwhen they’re used in each of the derived classes. \\nIf you have a base class of Account and derived classes of CheckingAccount, SavingsAc-\\ncount, and AutoLoanAccount, a programmer should be able to invoke any of the rou-\\ntines derived from Account on any of Account’s subtypes without caring about which \\nsubtype a specific account object is. \\nIf a program has been written so that the Liskov Substitution Principle is true, inher-\\nitance is a powerful tool for reducing complexity because a programmer can focus on \\nthe generic attributes of an object without worrying about the details. If a programmer \\nmust be constantly thinking about semantic differences in subclass implementations, \\nthen inheritance is increasing complexity rather than reducing it. Suppose a program-\\nmer has to think this: “If I call the InterestRate() routine on CheckingAccount or Sav-\\ningsAccount, it returns the interest the bank pays, but if I call InterestRate() on \\nAutoLoanAccount I have to change the sign because it returns the interest the con-\\nsumer pays to the bank.” According to LSP, AutoLoanAccount should not inherit from \\nthe Account base class in this example because the semantics of the InterestRate() rou-\\ntine are not the same as the semantics of the base class’s InterestRate() routine.\\nBe sure to inherit only what you want to inherit A derived class can inherit member \\nroutine interfaces, implementations, or both. Table 6-1 shows the variations of how \\nroutines can be implemented and overridden. \\nAs the table suggests, inherited routines come in three basic flavors:\\n■ An abstract overridable routine means that the derived class inherits the routine’s \\ninterface but not its implementation. \\n■ An overridable routine  means that the derived class inherits the routine’s inter-\\nface and a default implementation and it is allowed to override the default \\nimplementation.\\n■ A non-overridable routine means that the derived class inherits the routine’s inter-\\nface and its default implementation and it is not allowed to override the rou-\\ntine’s implementation.\\nTable 6-1 Variations on Inherited Routines \\nOverridable Not Overridable\\nImplementation: Default \\nProvided\\nOverridable Routine Non-Overridable Routine\\nImplementation: No Default \\nProvided\\nAbstract Overridable \\nRoutine\\nNot used (doesn’t make sense to \\nleave a routine undefined and \\nnot allow it to be overridden)'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 182}, page_content='146 Chapter 6: Working Classes\\nWhen you choose to implement a new class through inheritance, think through the \\nkind of inheritance you want for each member routine. Beware of inheriting imple-\\nmentation just because you’re inheriting an interface, and beware of inheriting an \\ninterface just because you want to inherit an implementation. If you want to use a \\nclass’s implementation but not its interface, use containment rather than inheritance. \\nDon’t “override” a non-overridable member function Both C++ and Java allow a pro-\\ngrammer to override a non-overridable member routine—kind of. If a function is pri-\\nvate in the base class, a derived class can create a function with the same name. To the \\nprogrammer reading the code in the derived class, such a function can create confu-\\nsion because it looks like it should be polymorphic, but it isn’t; it just has the same \\nname. Another way to state this guideline is, “Don’t reuse names of non-overridable \\nbase-class routines in derived classes.”\\nMove common interfaces, data, and behavior as high as possible in the inheritance \\ntree The higher you move interfaces, data, and behavior, the more easily derived \\nclasses can use them. How high is too high? Let abstraction be your guide. If you find \\nthat moving a routine higher would break the higher object’s abstraction, don’t do it. \\nBe suspicious of classes of which there is only one instanceA single instance might \\nindicate that the design confuses objects with classes. Consider whether you could \\njust create an object instead of a new class. Can the variation of the derived class be \\nrepresented in data rather than as a distinct class? The Singleton pattern is one nota-\\nble exception to this guideline. \\nBe suspicious of base classes of which there is only one derived class When I see a \\nbase class that has only one derived class, I suspect that some programmer has been \\n“designing ahead”—trying to anticipate future needs, usually without fully under-\\nstanding what those future needs are. The best way to prepare for future work is not to \\ndesign extra layers of base classes that “might be needed someday”; it’s to make cur-\\nrent work as clear, straightforward, and simple as possible. That means not creating \\nany more inheritance structure than is absolutely necessary. \\nBe suspicious of classes that override a routine and do nothing inside the derived \\nroutine This typically indicates an error in the design of the base class. For instance, \\nsuppose you have a class Cat and a routine Scratch() and suppose that you eventually \\nfind out that some cats are declawed and can’t scratch. You might be tempted to create \\na class derived from Cat named ScratchlessCat and override the Scratch() routine to do \\nnothing. This approach presents several problems:\\n■ It violates the abstraction (interface contract) presented in the Cat class by \\nchanging the semantics of its interface. \\n■ This approach quickly gets out of control when you extend it to other derived \\nclasses. What happens when you find a cat without a tail? Or a cat that doesn’t \\ncatch mice? Or a cat that doesn’t drink milk? Eventually you’ll end up with \\nderived classes like ScratchlessTaillessMicelessMilklessCat.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 183}, page_content='6.3 Design and Implementation Issues 147\\n■ Over time, this approach gives rise to code that’s confusing to maintain because \\nthe interfaces and behavior of the ancestor classes imply little or nothing about \\nthe behavior of their descendants. \\nThe place to fix this problem is not in the base class, but in the original Cat class. Cre-\\nate a Claws class and contain that within the Cats class. The root problem was the \\nassumption that all cats scratch, so fix that problem at the source, rather than just \\nbandaging it at the destination. \\nAvoid deep inheritance trees Object-oriented programming provides a large number \\nof techniques for managing complexity. But every powerful tool has its hazards, and \\nsome object-oriented techniques have a tendency to increase complexity rather than \\nreduce it. \\nIn his excellent book Object-Oriented Design Heuristics (1996), Arthur Riel suggests \\nlimiting inheritance hierarchies to a maximum of six levels. Riel bases his recommen-\\ndation on the “magic number 7±2,” but I think that’s grossly optimistic. In my experi-\\nence most people have trouble juggling more than two or three levels of inheritance in \\ntheir brains at once. The “magic number 7±2” is probably better applied as a limit to \\nthe total number of subclasses of a base class rather than the number of levels in an \\ninheritance tree.\\nDeep inheritance trees have been found to be significantly associated with increased \\nfault rates (Basili, Briand, and Melo 1996). Anyone who has ever tried to debug a com-\\nplex inheritance hierarchy knows why. Deep inheritance trees increase complexity, \\nwhich is exactly the opposite of what inheritance should be used to accomplish. Keep \\nthe primary technical mission in mind. Make sure you’re using inheritance to avoid \\nduplicating code and to minimize complexity. \\nPrefer polymorphism to extensive type checking Frequently repeated case statements \\nsometimes suggest that inheritance might be a better design choice, although this is \\nnot always true. Here is a classic example of code that cries out for a more object-ori-\\nented approach: \\nC+ + Example of a Case Statement That Probably Should Be Replaced \\nby Polymorphism\\nswitch ( shape.type ) {\\n   case Shape_Circle:\\n      shape.DrawCircle();\\n      break;\\n   case Shape_Square:\\n      shape.DrawSquare();\\n      break;\\n   ...\\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 184}, page_content='148 Chapter 6: Working Classes\\nIn this example, the calls to shape.DrawCircle() and shape.DrawSquare() should be \\nreplaced by a single routine named shape.Draw(), which can be called regardless of \\nwhether the shape is a circle or a square. \\nOn the other hand, sometimes case statements are used to separate truly different \\nkinds of objects or behavior. Here is an example of a case statement that is appropriate \\nin an object-oriented program:\\nC+ + Example of a Case Statement That Probably Should Not Be Replaced \\nby Polymorphism\\nswitch ( ui.Command() ) {\\n   case Command_OpenFile:\\n      OpenFile();\\n      break;\\n   case Command_Print:\\n      Print(); \\n      break;\\n   case Command_Save:\\n      Save(); \\n      break;\\n   case Command_Exit:\\n      ShutDown();\\n      break;\\n   ...\\n}\\nIn this case, it would be possible to create a base class with derived classes and a poly-\\nmorphic DoCommand() routine for each command (as in the Command pattern). But \\nin a simple case like this one, the meaning of DoCommand() would be so diluted as to \\nbe meaningless, and the case statement is the more understandable solution. \\nMake all data private, not protected As Joshua Bloch says, “Inheritance breaks \\nencapsulation” (2001). When you inherit from an object, you obtain privileged access \\nto that object’s protected routines and data. If the derived class really needs access to \\nthe base class’s attributes, provide protected accessor functions instead. \\nMultiple Inheritance\\nThe one indisputable fact \\nabout multiple inheritance in \\nC++ is that it opens up a \\nPandora’s box of complexi-\\nties that simply do not exist \\nunder single inheritance.\\n—Scott Meyers\\nInheritance is a power tool. It’s like using a chain saw to cut down a tree instead of a \\nmanual crosscut saw. It can be incredibly useful when used with care, but it’s danger-\\nous in the hands of someone who doesn’t observe proper precautions.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 185}, page_content='6.3 Design and Implementation Issues 149\\nIf inheritance is a chain saw, multiple inheritance is a 1950s-era chain saw with no \\nblade guard, no automatic shutoff, and a finicky engine. There are times when such a \\ntool is valuable; mostly, however, you’re better off leaving the tool in the garage where \\nit can’t do any damage. \\nAlthough some experts recommend broad use of multiple inheritance (Meyer 1997), \\nin my experience multiple inheritance is useful primarily for defining “mixins,” simple \\nclasses that are used to add a set of properties to an object. Mixins are called mixins \\nbecause they allow properties to be “mixed in” to derived classes. Mixins might be \\nclasses like Displayable, Persistant, Serializable, or Sortable. Mixins are nearly always \\nabstract and aren’t meant to be instantiated independently of other objects. \\nMixins require the use of multiple inheritance, but they aren’t subject to the classic \\ndiamond-inheritance problem associated with multiple inheritance as long as all mix-\\nins are truly independent of each other. They also make the design more comprehen-\\nsible by “chunking” attributes together. A programmer will have an easier time \\nunderstanding that an object uses the mixins Displayable and Persistent than under-\\nstanding that an object uses the 11 more-specific routines that would otherwise be \\nneeded to implement those two properties. \\nJava and Visual Basic recognize the value of mixins by allowing multiple inheritance \\nof interfaces but only single-class inheritance. C++ supports multiple inheritance of \\nboth interface and implementation. Programmers should use multiple inheritance \\nonly after carefully considering the alternatives and weighing the impact on system \\ncomplexity and comprehensibility. \\nWhy Are There So Many Rules for Inheritance?\\nThis section has presented numerous rules for staying out of trouble with inheritance. \\nThe underlying message of all these rules is that inheritance tends to work against the pri-\\nmary technical imperative you have as a programmer, which is to manage complexity. For the \\nsake of controlling complexity, you should maintain a heavy bias against inheritance. \\nHere’s a summary of when to use inheritance and when to use containment: \\nCross-Reference For more \\non complexity, see “Soft-\\nware’s Primary Technical \\nImperative: Managing Com-\\nplexity” in Section 5.2.\\n■ If multiple classes share common data but not behavior, create a common object \\nthat those classes can contain. \\n■ If multiple classes share common behavior but not data, derive them from a \\ncommon base class that defines the common routines. \\n■ If multiple classes share common data and behavior, inherit from a common \\nbase class that defines the common data and routines. \\n■ Inherit when you want the base class to control your interface; contain when \\nyou want to control your interface.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 186}, page_content='150 Chapter 6: Working Classes\\nMember Functions and Data\\nCross-Reference For more \\ndiscussion of routines in \\ngeneral, see Chapter 7, \\n“High-Quality Routines.”\\nHere are a few guidelines for implementing member functions and member data \\neffectively.\\nKeep the number of routines in a class as small as possible A study of C++ programs \\nfound that higher numbers of routines per class were associated with higher fault \\nrates (Basili, Briand, and Melo 1996). However, other competing factors were found to \\nbe more significant, including deep inheritance trees, large number of routines called \\nwithin a class, and strong coupling between classes. Evaluate the tradeoff between \\nminimizing the number of routines and these other factors. \\nDisallow implicitly generated member functions and operators you don’t want\\nSometimes you’ll find that you want to disallow certain functions—perhaps you want \\nto disallow assignment, or you don’t want to allow an object to be constructed. You \\nmight think that, since the compiler generates operators automatically, you’re stuck \\nallowing access. But in such cases you can disallow those uses by declaring the con-\\nstructor, assignment operator, or other function or operator private, which will pre-\\nvent clients from accessing it. (Making the constructor private is a standard technique \\nfor defining a singleton class, which is discussed later in this chapter.)\\nMinimize the number of different routines called by a class One study found that \\nthe number of faults in a class was statistically correlated with the total number of rou-\\ntines that were called from within a class (Basili, Briand, and Melo 1996). The same \\nstudy found that the more classes a class used, the higher its fault rate tended to be. \\nThese concepts are sometimes called “fan out.”\\nFurther Reading Good \\naccounts of the Law of \\nDemeter can be found in \\nPragmatic Programmer \\n(Hunt and Thomas 2000), \\nApplying UML and Patterns \\n(Larman 2001), and Funda-\\nmentals of Object-Oriented \\nDesign in UML (Page-Jones \\n2000).\\nMinimize indirect routine calls to other classes Direct connections are hazardous \\nenough. Indirect connections—such as account.ContactPerson().DaytimeContact-\\nInfo().PhoneNumber()—tend to be even more hazardous. Researchers have formulated \\na rule called the “Law of Demeter” (Lieberherr and Holland 1989), which essentially \\nstates that Object A can call any of its own routines. If Object A instantiates an Object \\nB, it can call any of Object B’s routines. But it should avoid calling routines on objects \\nprovided by Object B. In the account example above, that means account.ContactPer-\\nson() is OK but account.ContactPerson().DaytimeContactInfo() is not. \\nThis is a simplified explanation. See the additional resources at the end of this chapter \\nfor more details. \\nIn general, minimize the extent to which a class collaborates with other classes Try \\nto minimize all of the following:\\n■ Number of kinds of objects instantiated\\n■ Number of different direct routine calls on instantiated objects \\n■ Number of routine calls on objects returned by other instantiated objects'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 187}, page_content='6.3 Design and Implementation Issues 151\\nConstructors\\nFollowing are some guidelines that apply specifically to constructors. Guidelines for \\nconstructors are pretty similar across languages (C++, Java, and Visual Basic, anyway). \\nDestructors vary more, so you should check out the materials listed in this chapter’s \\n“Additional Resources” section for information on destructors.\\nInitialize all member data in all constructors, if possible Initializing all data mem-\\nbers in all constructors is an inexpensive defensive programming practice. \\nFurther Reading The code \\nto do this in C++ would be \\nsimilar. For details, see More \\nEffective C++, Item 26 (Mey-\\ners 1998).\\nEnforce the singleton property by using a private constructor If you want to define a \\nclass that allows only one object to be instantiated, you can enforce this by hiding all \\nthe constructors of the class and then providing a static GetInstance() routine to access \\nthe class’s single instance. Here’s an example of how that would work: \\nJava Example of Enforcing a Singleton with a Private Constructor\\npublic class MaxId {\\n   // constructors and destructors\\nHere is the private \\nconstructor.\\n   private MaxId() {\\n      ...\\n   }\\n   ...\\n   // public routines\\nHere is the public routine \\nthat provides access to the \\nsingle instance. \\n   public static MaxId GetInstance() {\\n      return m_instance;\\n   }\\n   ...\\n   // private members\\nHere is the single instance.    private static final MaxId m_instance = new MaxId();\\n   ...\\n}\\nThe private constructor is called only when the static object m_instance is initialized. \\nIn this approach, if you want to reference the MaxId singleton, you would simply refer \\nto MaxId.GetInstance(). \\nPrefer deep copies to shallow copies until proven otherwise One of the major deci-\\nsions you’ll make about complex objects is whether to implement deep copies or shal-\\nlow copies of the object. A deep copy of an object is a member-wise copy of the \\nobject’s member data; a shallow copy typically just points to or refers to a single refer-\\nence copy, although the specific meanings of “deep” and “shallow” vary. \\nThe motivation for creating shallow copies is typically to improve performance. \\nAlthough creating multiple copies of large objects might be aesthetically offensive, it \\nrarely causes any measurable performance impact. A small number of objects might \\ncause performance issues, but programmers are notoriously poor at guessing which \\ncode really causes problems. (For details, see Chapter 25, “Code-Tuning Strategies.”)'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 188}, page_content='152 Chapter 6: Working Classes\\nBecause it’s a poor tradeoff to add complexity for dubious performance gains, a good \\napproach to deep vs. shallow copies is to prefer deep copies until proven otherwise. \\nDeep copies are simpler to code and maintain than shallow copies. In addition to the \\ncode either kind of object would contain, shallow copies add code to count references, \\nensure safe object copies, safe comparisons, safe deletes, and so on. This code can be \\nerror-prone, and you should avoid it unless there’s a compelling reason to create it. \\nIf you find that you do need to use a shallow-copy approach, Scott Meyers’s More \\nEffective C++, Item 29 (1996) contains an excellent discussion of the issues in C++. \\nMartin Fowler’s Refactoring (1999) describes the specific steps needed to convert \\nfrom shallow copies to deep copies and from deep copies to shallow copies. (Fowler \\ncalls them reference obje cts and value objects.)\\n6.4 Reasons to Create a Class\\nCross-Reference Reasons \\nfor creating classes and \\nroutines overlap. See \\nSection 7.1.\\nIf you believe everything you read, you might get the idea that the only reason to cre-\\nate a class is to model real-world objects. In practice, classes get created for many more \\nreasons than that. Here’s a list of good reasons to create a class. \\nCross-Reference For more \\non identifying real-world \\nobjects, see “Find Real-\\nWorld Objects” in Section \\n5.3.\\nModel real-world objects Modeling real-world objects might not be the only reason \\nto create a class, but it’s still a good reason! Create a class for each real-world object \\ntype that your program models. Put the data needed for the object into the class, and \\nthen build service routines that model the behavior of the object. See the discussion of \\nADTs in Section 6.1 for examples. \\nModel abstract objects Another good reason to create a class is to model an abstract \\nobject—an object that isn’t a concrete, real-world object but that provides an abstrac-\\ntion of other concrete objects. A good example is the classic Shape object. Circle and \\nSquare really exist, but Shape is an abstraction of other specific shapes. \\nOn programming projects, the abstractions are not ready-made the way Shape is, so \\nwe have to work harder to come up with clean abstractions. The process of distilling \\nabstract concepts from real-world entities is non-deterministic, and different designers \\nwill abstract out different generalities. If we didn’t know about geometric shapes like \\ncircles, squares and triangles, for example, we might come up with more unusual \\nshapes like squash shape, rutabaga shape, and Pontiac Aztek shape. Coming up with \\nappropriate abstract objects is one of the major challenges in object-oriented design.\\nReduce complexity The single most important reason to create a class is to reduce a \\nprogram’s complexity. Create a class to hide information so that you won’t need to \\nthink about it. Sure, you’ll need to think about it when you write the class. But after it’s \\nwritten, you should be able to forget the details and use the class without any knowl-\\nedge of its internal workings. Other reasons to create classes—minimizing code size, \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 189}, page_content='6.4 Reasons to Create a Class 153\\nimproving maintainability, and improving correctness—are also good reasons, but \\nwithout the abstractive power of classes, complex programs would be impossible to \\nmanage intellectually.\\nIsolate complexity Complexity in all forms—complicated algorithms, large data sets, \\nintricate communications protocols, and so on—is prone to errors. If an error does \\noccur, it will be easier to find if it isn’t spread through the code but is localized within \\na class. Changes arising from fixing the error won’t affect other code because only one \\nclass will have to be fixed—other code won’t be touched. If you find a better, simpler, \\nor more reliable algorithm, it will be easier to replace the old algorithm if it has been \\nisolated into a class. During development, it will be easier to try several designs and \\nkeep the one that works best.\\nHide implementation details The desire to hide implementation details is a wonder-\\nful reason to create a class whether the details are as complicated as a convoluted data-\\nbase access or as mundane as whether a specific data member is stored as a number \\nor a string. \\nLimit effects of changes Isolate areas that are likely to change so that the effects of \\nchanges are limited to the scope of a single class or a few classes. Design so that areas \\nthat are most likely to change are the easiest to change. Areas likely to change include \\nhardware dependencies, input/output, complex data types, and business rules. The \\nsubsection titled “Hide Secrets (Information Hiding)” in Section 5.3 described several \\ncommon sources of change. \\nCross-Reference For a dis-\\ncussion of problems associ-\\nated with using global data, \\nsee Section 13.3, “Global \\nData.” \\nHide global data If you need to use global data, you can hide its implementation \\ndetails behind a class interface. Working with global data through access routines pro-\\nvides several benefits compared to working with global data directly. You can change \\nthe structure of the data without changing your program. You can monitor accesses to \\nthe data. The discipline of using access routines also encourages you to think about \\nwhether the data is really global; it often becomes apparent that the “global data” is \\nreally just object data.\\nStreamline parameter passing If you’re passing a parameter among several routines, \\nthat might indicate a need to factor those routines into a class that share the parameter \\nas object data. Streamlining parameter passing isn’t a goal, per se, but passing lots of \\ndata around suggests that a different class organization might work better. \\nCross-Reference For details \\non information hiding, see \\n“Hide Secrets (Information \\nHiding)” in Section 5.3. \\nMake central points of control It’s a good idea to control each task in one place. \\nControl assumes many forms. Knowledge of the number of entries in a table is one \\nform. Control of devices—files, database connections, printers, and so on—is another. \\nUsing one class to read from and write to a database is a form of centralized control. \\nIf the database needs to be converted to a flat file or to in-memory data, the changes \\nwill affect only one class.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 190}, page_content='154 Chapter 6: Working Classes\\nThe idea of centralized control is similar to information hiding, but it has unique heu-\\nristic power that makes it worth adding to your programming toolbox.\\nFacilitate reusable code Code put into well-factored classes can be reused in other \\nprograms more easily than the same code embedded in one larger class. Even if a sec-\\ntion of code is called from only one place in the program and is understandable as \\npart of a larger class, it makes sense to put it into its own class if that piece of code \\nmight be used in another program.\\nNASA’s Software Engineering Laboratory studied ten projects that pursued reuse \\naggressively (McGarry, Waligora, and McDermott 1989). In both the object-oriented \\nand the functionally oriented approaches, the initial projects weren’t able to take \\nmuch of their code from previous projects because previous projects hadn’t estab-\\nlished a sufficient code base. Subsequently, the projects that used functional design \\nwere able to take about 35 percent of their code from previous projects. Projects that \\nused an object-oriented approach were able to take more than 70 percent of their code \\nfrom previous projects. If you can avoid writing 70 percent of your code by planning \\nahead, do it!\\nCross-Reference For more \\non implementing the mini-\\nmum amount of functional-\\nity required, see “A program \\ncontains code that seems \\nlike it might be needed \\nsomeday” in Section 24.2.\\nNotably, the core of NASA’s approach to creating reusable classes does not involve \\n“designing for reuse.” NASA identifies reuse candidates at the ends of their projects. \\nThey then perform the work needed to make the classes reusable as a special project \\nat the end of the main project or as the first step in a new project. This approach helps \\nprevent “gold-plating”—creation of functionality that isn’t required and that unneces-\\nsarily adds complexity. \\nPlan for a family of programs If you expect a program to be modified, it’s a good \\nidea to isolate the parts that you expect to change by putting them into their own \\nclasses. You can then modify the classes without affecting the rest of the program, or \\nyou can put in completely new classes instead. Thinking through not just what one \\nprogram will look like but what the whole family of programs might look like is a \\npowerful heuristic for anticipating entire categories of changes (Parnas 1976). \\nSeveral years ago I managed a team that wrote a series of programs used by our clients \\nto sell insurance. We had to tailor each program to the specific client’s insurance rates, \\nquote-report format, and so on. But many parts of the programs were similar: the \\nclasses that input information about potential customers, that stored information in a \\ncustomer database, that looked up rates, that computed total rates for a group, and so \\non. The team factored the program so that each part that varied from client to client \\nwas in its own class. The initial programming might have taken three months or so, \\nbut when we got a new client, we merely wrote a handful of new classes for the new \\nclient and dropped them into the rest of the code. A few days’ work and—voila!—cus-\\ntom software! \\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 191}, page_content='6.4 Reasons to Create a Class 155\\nPackage related operations In cases in which you can’t hide information, share data, \\nor plan for flexibility, you can still package sets of operations into sensible groups, \\nsuch as trig functions, statistical functions, string-manipulation routines, bit-manipu-\\nlation routines, graphics routines, and so on. Classes are one means of combining \\nrelated operations. You could also use packages, namespaces, or header files, depend-\\ning on the language you’re working in. \\nAccomplish a specific refactoring Many of the specific refactorings described in \\nChapter 24, “Refactoring,” result in new classes—including converting one class to \\ntwo, hiding a delegate, removing a middle man, and introducing an extension class. \\nThese new classes could be motivated by a desire to better accomplish any of the \\nobjectives described throughout this section.\\nClasses to Avoid\\nWhile classes in general are good, you can run into a few gotchas. Here are some \\nclasses to avoid. \\nAvoid creating god classesAvoid creating omniscient classes that are all-knowing \\nand all-powerful. If a class spends its time retrieving data from other classes using \\nGet() and Set() routines (that is, digging into their business and telling them what to \\ndo), ask whether that functionality might better be organized into those other classes \\nrather than into the god class (Riel 1996). \\nCross-Reference This kind of \\nclass is usually called a struc-\\nture. For more on structures, \\nsee Section 13.1, “Struc-\\ntures.”\\nEliminate irrelevant classes If a class consists only of data but no behavior, ask your-\\nself whether it’s really a class and consider demoting it so that its member data just \\nbecomes attributes of one or more other classes. \\nAvoid classes named after verbs A class that has only behavior but no data is gener-\\nally not really a class. Consider turning a class like DatabaseInitialization() or String-\\nBuilder() into a routine on some other class. \\nSummary of Reasons to Create a Class\\nHere’s a summary list of the valid reasons to create a class: \\n■ Model real-world objects\\n■ Model abstract objects\\n■ Reduce complexity \\n■ Isolate complexity\\n■ Hide implementation details\\n■ Limit effects of changes\\n■ Hide global data'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 192}, page_content='156 Chapter 6: Working Classes\\n■ Streamline parameter passing\\n■ Make central points of control\\n■ Facilitate reusable code\\n■ Plan for a family of programs\\n■ Package related operations\\n■ Accomplish a specific refactoring \\n6.5 Language-Specific Issues\\nApproaches to classes in different programming languages vary in interesting ways. \\nConsider how you override a member routine to achieve polymorphism in a derived \\nclass. In Java, all routines are overridable by default and a routine must be declared \\nfinal to prevent a derived class from overriding it. In C++, routines are not overridable \\nby default. A routine must be declared virtual in the base class to be overridable. In \\nVisual Basic, a routine must be declared overridable in the base class and the derived \\nclass should use the overrides keyword. \\nHere are some of the class-related areas that vary significantly depending on the \\nlanguage:\\n■ Behavior of overridden constructors and destructors in an inheritance tree\\n■ Behavior of constructors and destructors under exception-handling conditions\\n■ Importance of default constructors (constructors with no arguments) \\n■ Time at which a destructor or finalizer is called\\n■ Wisdom of overriding the language’s built-in operators, including assignment \\nand equality \\n■ How memory is handled as objects are created and destroyed or as they are \\ndeclared and go out of scope\\nDetailed discussions of these issues are beyond the scope of this book, but the “Addi-\\ntional Resources” section points to good language-specific resources. \\n6.6 Beyond Classes: Packages\\nCross-Reference For more \\non the distinction between \\nclasses and packages, see \\n“Levels of Design” in \\nSection 5.2.\\nClasses are currently the best way for programmers to achieve modularity. But modular-\\nity is a big topic, and it extends beyond classes. Over the past several decades, software \\ndevelopment has advanced in large part by increasing the granularity of the aggrega-\\ntions that we have to work with. The first aggregation we had was the statement, which'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 193}, page_content='6.6 Beyond Classes: Packages 157\\nat the time seemed like a big step up from machine instructions. Then came subrou-\\ntines, and later came classes.\\nIt’s evident that we could better support the goals of abstraction and encapsulation if \\nwe had good tools for aggregating groups of objects. Ada supported the notion of \\npackages more than a decade ago, and Java supports packages today. If you’re pro-\\ngramming in a language that doesn’t support packages directly, you can create your \\nown poor-programmer’s version of a package and enforce it through programming \\nstandards that include the following:\\n■ Naming conventions that differentiate which classes are public and which are \\nfor the package’s private use\\n■ Naming conventions, code-organization conventions (project structure), or \\nboth that identify which package each class belongs to\\n■ Rules that define which packages are allowed to use which other packages, \\nincluding whether the usage can be inheritance, containment, or both\\nThese workarounds are good examples of the distinction between programming in a \\nlanguage vs. programming into a language. For more on this distinction, see Section \\n34.4, “Program into Your Language, Not in It.”\\ncc2e.com/0672\\nCross-Reference This is a \\nchecklist of considerations \\nabout the quality of the \\nclass. For a list of the steps \\nused to build a class, see the \\nchecklist “The Pseudocode \\nProgramming Process” in \\nChapter 9, page 233.\\nCHECKLIST: Class Quality\\nAbstract Data Types\\n❑ Have you thought of the classes in your program as abstract data types \\nand evaluated their interfaces from that point of view? \\nAbstraction\\n❑ Does the class have a central purpose?\\n❑ Is the class well named, and does its name describe its central purpose? \\n❑ Does the class’s interface present a consistent abstraction? \\n❑ Does the class’s interface make obvious how you should use the class? \\n❑ Is the class’s interface abstract enough that you don’t have to think about \\nhow its services are implemented? Can you treat the class as a black box?\\n❑ Are the class’s services complete enough that other classes don’t have to \\nmeddle with its internal data?\\n❑ Has unrelated information been moved out of the class? \\n❑ Have you thought about subdividing the class into component classes, \\nand have you subdivided it as much as you can?\\n❑ Are you preserving the integrity of the class’s interface as you modify the \\nclass?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 194}, page_content='158 Chapter 6: Working Classes\\nEncapsulation\\n❑ Does the class minimize accessibility to its members?\\n❑ Does the class avoid exposing member data?\\n❑ Does the class hide its implementation details from other classes as much \\nas the programming language permits?\\n❑ Does the class avoid making assumptions about its users, including its \\nderived classes? \\n❑ Is the class independent of other classes? Is it loosely coupled?\\nInheritance\\n❑ Is inheritance used only to model “is a” relationships—that is, do derived \\nclasses adhere to the Liskov Substitution Principle?\\n❑ Does the class documentation describe the inheritance strategy?\\n❑ Do derived classes avoid “overriding” non-overridable routines? \\n❑ Are common interfaces, data, and behavior as high as possible in the \\ninheritance tree? \\n❑ Are inheritance trees fairly shallow? \\n❑ Are all data members in the base class private rather than protected? \\nOther Implementation Issues\\n❑ Does the class contain about seven data members or fewer?\\n❑ Does the class minimize direct and indirect routine calls to other classes? \\n❑ Does the class collaborate with other classes only to the extent absolutely \\nnecessary? \\n❑ Is all member data initialized in the constructor? \\n❑ Is the class designed to be used as deep copies rather than shallow copies \\nunless there’s a measured reason to create shallow copies? \\nLanguage-Specific Issues\\n❑ Have you investigated the language-specific issues for classes in your spe-\\ncific programming language?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 195}, page_content='Additional Resources 159\\nAdditional Resources\\nClasses in General\\ncc2e.com/0679 Meyer, Bertrand. Object-Oriented Software Construction, 2d ed. New York, NY: Prentice \\nHall PTR, 1997. This book contains an in-depth discussion of abstract data types and \\nexplains how they form the basis for classes. Chapters 14–16 discuss inheritance in \\ndepth. Meyer provides an argument in favor of multiple inheritance in Chapter 15. \\nRiel, Arthur J. Object-Oriented Design Heuristics. Reading, MA: Addison-Wesley, 1996. \\nThis book contains numerous suggestions for improving program design, mostly at the \\nclass level. I avoided the book for several years because it appeared to be too big—talk \\nabout people in glass houses! However, the body of the book is only about 200 pages \\nlong. Riel’s writing is accessible and enjoyable. The content is focused and practical. \\nC++\\ncc2e.com/0686 Meyers, Scott. Effective C++: 50 Specific Ways to Improve Your Programs and Designs, 2d \\ned. Reading, MA: Addison-Wesley, 1998. \\nMeyers, Scott, 1996, More Effective C++: 35 New Ways to Improve Your Programs and \\nDesigns. Reading, MA: Addison-Wesley, 1996. Both of Meyers’ books are canonical ref-\\nerences for C++ programmers. The books are entertaining and help to instill a lan-\\nguage-lawyer’s appreciation for the nuances of C++. \\nJava\\ncc2e.com/0693 Bloch, Joshua. Effective Java Programming Language Guide . Boston, MA: Addison-\\nWesley, 2001. Bloch’s book provides much good Java-specific advice as well as intro-\\nducing more general, good object-oriented practices. \\nVisual Basic\\ncc2e.com/0600 The following books are good references on classes in Visual Basic:\\nFoxall, James. Practical Standards for Microsoft Visual Basic .NET. Redmond, WA: \\nMicrosoft Press, 2003. \\nCornell, Gary, and Jonathan Morrison. Programming VB .NET: A Guide for Experienced \\nProgrammers. Berkeley, CA: Apress, 2002. \\nBarwell, Fred, et al. Professional VB.NET, 2d ed. Wrox, 2002.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 196}, page_content='160 Chapter 6: Working Classes\\nKey Points\\n■ Class interfaces should provide a consistent abstraction. Many problems arise \\nfrom violating this single principle. \\n■ A class interface should hide something—a system interface, a design decision, \\nor an implementation detail. \\n■ Containment is usually preferable to inheritance unless you’re modeling an “is \\na” relationship. \\n■ Inheritance is a useful tool, but it adds complexity, which is counter to Soft-\\nware’s Primary Technical Imperative of managing complexity. \\n■ Classes are your primary tool for managing complexity. Give their design as \\nmuch attention as needed to accomplish that objective.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 197}, page_content='161\\nChapter 7\\nHigh-Quality Routines\\ncc2e.com/0778 Contents\\n■ 7.1 Valid Reasons to Create a Routine: page 164\\n■ 7.2 Design at the Routine Level: page 168\\n■ 7.3 Good Routine Names: page 171\\n■ 7.4 How Long Can a Routine Be?: page 173\\n■ 7.5 How to Use Routine Parameters: page 174\\n■ 7.6 Special Considerations in the Use of Functions: page 181\\n■ 7.7 Macro Routines and Inline Routines: page 182\\nRelated Topics\\n■ Steps in routine construction: Section 9.3\\n■ Working classes: Chapter 6 \\n■ General design techniques: Chapter 5\\n■ Software architecture: Section 3.5\\nChapter 6 described the details of creating classes. This chapter zooms in on routines, \\non the characteristics that make the difference between a good routine and a bad one. \\nIf you’d rather read about issues that affect the design of routines before wading into \\nthe nitty-gritty details, be sure to read Chapter 5, “Design in Construction,” first and \\ncome back to this chapter later. Some important attributes of high-quality routines are \\nalso discussed in Chapter 8, “Defensive Programming.” If you’re more interested in \\nreading about steps to create routines and classes, Chapter 9, “The Pseudocode Pro-\\ngramming Process,” might be a better place to start. \\nBefore jumping into the details of high-quality routines, it will be useful to nail down \\ntwo basic terms. What is a “routine”? A routine is an individual method or procedure \\ninvocable for a single purpose. Examples include a function in C++, a method in Java, \\na function or sub procedure in Microsoft Visual Basic. For some uses, macros in C and \\nC++ can also be thought of as routines. You can apply many of the techniques for cre-\\nating a high-quality routine to these variants.\\nWhat is a high-quality routine? That’s a harder question. Perhaps the easiest answer is \\nto show what a high-quality routine is not. Here’s an example of a low-quality routine:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 198}, page_content='162 Chapter 7: High-Quality Routines\\nC+ + Example of a Low-Quality Routine\\nvoid HandleStuff( CORP_DATA & inputRec, int crntQtr, EMP_DATA empRec, \\n   double & estimRevenue, double ytdRevenue, int screenX, int screenY,\\n   COLOR_TYPE & newColor, COLOR_TYPE & prevColor, StatusType & status, \\n   int expenseType )\\n{\\nint i;\\nfor ( i = 0; i < 100; i++ ) {\\n   inputRec.revenue[i] = 0;\\n   inputRec.expense[i] = corpExpense[ crntQtr ][ i ];\\n   }\\nUpdateCorpDatabase( empRec );\\nestimRevenue = ytdRevenue * 4.0 / (double) crntQtr;\\nnewColor = prevColor;\\nstatus = SUCCESS;\\nif ( expenseType == 1 ) {\\n     for ( i = 0; i < 12; i++ )\\n           profit[i] = revenue[i] - expense.type1[i];\\n     }\\nelse if ( expenseType == 2 )  {\\n          profit[i] = revenue[i] - expense.type2[i];\\n          }\\nelse if ( expenseType == 3 )\\n          profit[i] = revenue[i] - expense.type3[i];\\n          }\\nWhat’s wrong with this routine? Here’s a hint : you should be able to find at least 10 \\ndifferent problems with it. Once you’ve come  up with your own list, look at the fol-\\nlowing list:\\n■ The routine has a bad name. HandleStuff() tells you nothing about what the rou-\\ntine does.\\n■ The routine isn’t documented. (The subject of documentation extends beyond \\nthe boundaries of individual routines and is discussed in Chapter 32, “Self-Doc-\\numenting Code.”)\\n■ The routine has a bad layout. The physical organization of the code on the page \\ngives few hints about its logical organization. Layout strategies are used haphaz-\\nardly, with different styles in different parts of the routine. Compare the styles \\nwhere expenseType == 2 and expenseType == 3. (Layout is discussed in Chapter 31, \\n“Layout and Style.”)\\n■ The routine’s input variable, inputRec, is changed. If it’s an input variable, its \\nvalue should not be modified (and in C++ it should be declared const). If the \\nvalue of the variable is supposed to be modified, the variable should not be \\ncalled inputRec.\\n■ The routine reads and writes global variables—it reads from corpExpense and \\nwrites to profit. It should communicate with other routines more directly than \\nby reading and writing global variables.\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 199}, page_content='163A Low-Quality Routine\\n■ The routine doesn’t have a single purpose. It initializes some variables, writes to \\na database, does some calculations—none of which seem to be related to each \\nother in any way. A routine should have a single, clearly defined purpose.\\n■ The routine doesn’t defend itself against bad data. If crntQtr equals 0, the expres-\\nsion ytdRevenue * 4.0 / (double) crntQtr causes a divide-by-zero error.\\n■ The routine uses several magic numbers: 100, 4.0, 12, 2, and 3. Magic numbers \\nare discussed in Section 12.1, “Numbers in General.”\\n■ Some of the routine’s parameters are unused: screenX and screenY are not refer-\\nenced within the routine.\\n■ One of the routine’s parameters is passed incorrectly: prevColor is labeled as a \\nreference parameter (&) even though it isn’t assigned a value within the routine. \\n■ The routine has too many parameters. The upper limit for an understandable \\nnumber of parameters is about 7; this routine has 11. The parameters are laid \\nout in such an unreadable way that most people wouldn’t try to examine them \\nclosely or even count them.\\n■ The routine’s parameters are poorly ordered and are not documented. (Parameter \\nordering is discussed in this chapter. Documentation is discussed in Chapter 32.)\\ncc2e.com/0799\\nCross-Reference The class is \\nalso a good contender for \\nthe single greatest invention \\nin computer science. For \\ndetails on how to use classes \\neffectively, see Chapter 6, \\n“Working Classes.”\\nAside from the computer itself, the routine is the single greatest invention in computer \\nscience. The routine makes programs easier to read and easier to understand than any \\nother feature of any programming language, and it’s a crime to abuse this senior \\nstatesman of computer science with code like that in the example just shown.\\nThe routine is also the greatest technique ever invented for saving space and improv-\\ning performance. Imagine how much larger your code would be if you had to repeat \\nthe code for every call to a routine instead of branching to the routine. Imagine how \\nhard it would be to make performance improvements in the same code used in a \\ndozen places instead of making them all in one routine. The routine makes modern \\nprogramming possible.\\n“OK,” you say, “I already know that routines are great, and I program with them all the \\ntime. This discussion seems kind of remedial, so what do you want me to do about it?”\\nI want you to understand that many valid reasons to create a routine exist and that \\nthere are right ways and wrong ways to go about it. As an undergraduate computer-sci-\\nence student, I thought that the main reason to create a routine was to avoid duplicate \\ncode. The introductory textbook I used said that routines were good because the \\navoidance of duplication made a program easier to develop, debug, document, and \\nmaintain. Period. Aside from syntactic details about how to use parameters and local \\nvariables, that was the extent of the textbook’s coverage. It was not a good or complete \\nexplanation of the theory and practice of routines. The following sections contain a \\nmuch better explanation.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 200}, page_content='164 Chapter 7: High-Quality Routines\\n7.1 Valid Reasons to Create a Routine\\nHere’s a list of valid reasons to create a routine. The reasons overlap somewhat, and \\nthey’re not intended to make an orthogonal set.\\nReduce complexity The single most important reason to create a routine is to reduce \\na program’s complexity. Create a routine to hide information so that you won’t need \\nto think about it. Sure, you’ll need to think about it when you write the routine. But \\nafter it’s written, you should be able to forget the details and use the routine without \\nany knowledge of its internal workings. Other reasons to create routines—minimizing \\ncode size, improving maintainability, and improving correctness—are also good rea-\\nsons, but without the abstractive power of routines, complex programs would be \\nimpossible to manage intellectually.\\nOne indication that a routine needs to be broken out of another routine is deep nest-\\ning of an inner loop or a conditional. Reduce the containing routine’s complexity by \\npulling the nested part out and putting it into its own routine.\\nIntroduce an intermediate, understandable abstraction Putting a section of code \\ninto a well-named routine is one of the best ways to document its purpose. Instead of \\nreading a series of statements like\\nif ( node <> NULL ) then\\nwhile ( node.next <> NULL ) do\\nnode = node.next\\nleafName = node.name\\nend while\\nelse\\nleafName = \"\"\\nend if\\nyou can read a statement like this: \\nleafName = GetLeafName( node )\\nThe new routine is so short that nearly all it needs for documentation is a good name. \\nThe name introduces a higher level of abstraction than the original eight lines of code, \\nwhich makes the code more readable and easier to understand, and it reduces com-\\nplexity within the routine that originally contained the code.\\nAvoid duplicate code Undoubtedly the most popular reason for creating a routine is \\nto avoid duplicate code. Indeed, creation of similar code in two routines implies an \\nerror in decomposition. Pull the duplicate code from both routines, put a generic ver-\\nsion of the common code into a base class, and then move the two specialized rou-\\ntines into subclasses. Alternatively, you could migrate the common code into its own \\nroutine, and then let both call the part that was put into the new routine. With code in \\none place, you save the space that would have been used by duplicated code. Modifi-\\ncations will be easier because you’ll need to modify the code in only one location. The \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 201}, page_content='7.1 Valid Reasons to Create a Routine 165\\ncode will be more reliable because you’ll have to check only one place to ensure that \\nthe code is right. Modifications will be more reliable because you’ll avoid making suc-\\ncessive and slightly different modifications under the mistaken assumption that \\nyou’ve made identical ones.\\nSupport subclassing You need less new code to override a short, well-factored rou-\\ntine than a long, poorly factored routine. You’ll also reduce the chance of error in sub-\\nclass implementations if you keep overrideable routines simple. \\nHide sequences It’s a good idea to hide the order in which events happen to be pro-\\ncessed. For example, if the program typically gets data from the user and then gets \\nauxiliary data from a file, neither the routine that gets the user data nor the routine \\nthat gets the file data should depend on the other routine’s being performed first. \\nAnother example of a sequence might be found when you have two lines of code that \\nread the top of a stack and decrement a stackTop variable. Put those two lines of code \\ninto a PopStack() routine to hide the assumption about the order in which the two \\noperations must be performed. Hiding that assumption will be better than baking it \\ninto code from one end of the system to the other. \\nHide pointer operations Pointer operations tend to be hard to read and error prone. \\nBy isolating them in routines, you can concentrate on the intent of the operation \\nrather than on the mechanics of pointer manipulation. Also, if the operations are done \\nin only one place, you can be more certain that the code is correct. If you find a better \\ndata type than pointers, you can change the program without traumatizing the code \\nthat would have used the pointers.\\nImprove portability Use of routines isolates nonportable capabilities, explicitly identi-\\nfying and isolating future portability work. Nonportable capabilities include nonstandard \\nlanguage features, hardware dependencies, operating-system dependencies, and so on.\\nSimplify complicated boolean tests Understanding complicated boolean tests in \\ndetail is rarely necessary for understanding program flow. Putting such a test into a \\nfunction makes the code more readable because (1) the details of the test are out of \\nthe way and (2) a descriptive function name summarizes the purpose of the test. \\nGiving the test a function of its own emphasizes its significance. It encourages extra \\neffort to make the details of the test readable inside its function. The result is that both \\nthe main flow of the code and the test itself become clearer. Simplifying a boolean test \\nis an example of reducing complexity, which was discussed earlier. \\nImprove performance You can optimize the code in one place instead of in several \\nplaces. Having code in one place will make it easier to profile to find inefficiencies. \\nCentralizing code into a routine means that a single optimization benefits all the code \\nthat uses that routine, whether it uses it directly or indirectly. Having code in one \\nplace makes it practical to recode the routine with a more efficient algorithm or in a \\nfaster, more efficient language.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 202}, page_content='166 Chapter 7: High-Quality Routines\\nCross-Reference For details \\non information hiding, see \\n“Hide Secrets (Information \\nHiding)” in Section 5.3.\\nTo ensure all routines are small? No. With so many good reasons for putting code \\ninto a routine, this one is unnecessary. In fact, some jobs are performed better in a sin-\\ngle large routine. (The best length for a routine is discussed in Section 7.4, “How Long \\nCan a Routine Be?”)\\nOperations That Seem Too Simple to Put Into Routines \\nOne of the strongest mental blocks to creating effective routines is a reluctance to cre-\\nate a simple routine for a simple purpose. Constructing a whole routine to contain two \\nor three lines of code might seem like overkill, but experience shows how helpful a \\ngood small routine can be.\\nSmall routines offer several advantages. One is that they improve readability. I once \\nhad the following single line of code in about a dozen places in a program:\\nPseudocode Example of a Calculation\\npoints = deviceUnits * ( POINTS_PER_INCH / DeviceUnitsPerInch() )\\nThis is not the most complicated line of code you’ll ever read. Most people would \\neventually figure out that it converts a measurement in device units to a measurement \\nin points. They would see that each of the dozen lines did the same thing. It could \\nhave been clearer, however, so I created a well-named routine to do the conversion in \\none place:\\nPseudocode Example of a Calculation Converted to a Function\\nFunction DeviceUnitsToPoints ( deviceUnits Integer ): Integer\\nDeviceUnitsToPoints = deviceUnits *\\n( POINTS_PER_INCH / DeviceUnitsPerInch() )\\nEnd Function\\nWhen the routine was substituted for the inline code, the dozen lines of code all \\nlooked more or less like this one:\\nPseudocode Example of a Function Call to a Calculation Function\\npoints = DeviceUnitsToPoints( deviceUnits )\\nThis line is more readable—even approaching self-documenting.\\nThis example hints at another reason to put small operations into functions: small \\noperations tend to turn into larger operations. I didn’t know it when I wrote the rou-\\ntine, but under certain conditions and when certain devices were active, Device-\\nUnitsPerlnch() returned 0. That meant I had to account for division by zero, which \\ntook three more lines of code:\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 203}, page_content='7.1 Valid Reasons to Create a Routine 167\\nPseudocode Example of a Calculation That Expands Under Maintenance\\nFunction DeviceUnitsToPoints( deviceUnits: Integer ) Integer;\\nif ( DeviceUnitsPerInch() <> 0 )\\nDeviceUnitsToPoints = deviceUnits *\\n( POINTS_PER_INCH / DeviceUnitsPerInch() )\\nelse\\nDeviceUnitsToPoints = 0\\nend if\\nEnd Function\\nIf that original line of code had still been in a dozen places, the test would have been \\nrepeated a dozen times, for a total of 36 new lines of code. A simple routine reduced \\nthe 36 new lines to 3.\\nSummary of Reasons to Create a Routine\\nHere’s a summary list of the valid reasons for creating a routine: \\n■ Reduce complexity\\n■ Introduce an intermediate, understandable abstraction\\n■ Avoid duplicate code\\n■ Support subclassing\\n■ Hide sequences\\n■ Hide pointer operations\\n■ Improve portability\\n■ Simplify complicated boolean tests\\n■ Improve performance\\nIn addition, many of the reasons to create a class are also good reasons to create a rou-\\ntine: \\n■ Isolate complexity\\n■ Hide implementation details\\n■ Limit effects of changes\\n■ Hide global data\\n■ Make central points of control\\n■ Facilitate reusable code\\n■ Accomplish a specific refactoring'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 204}, page_content='168 Chapter 7: High-Quality Routines\\n7.2 Design at the Routine Level\\nThe idea of cohesion was introduced in a paper by Wayne Stevens, Glenford Myers, \\nand Larry Constantine (1974). Other more modern concepts, including abstraction \\nand encapsulation, tend to yield more insight at the class level (and have, in fact, \\nlargely superceded cohesion at the class level), but cohesion is still alive and well as \\nthe workhorse design heuristic at the individual-routine level. \\nCross-Reference For a dis-\\ncussion of cohesion in gen-\\neral, see “Aim for Strong \\nCohesion” in Section 5.3. \\nFor routines, cohesion refers to how closely the operations in a routine are related. \\nSome programmers prefer the term “strength”: how strongly related are the opera-\\ntions in a routine? A function like Cosine() is perfectly cohesive because the whole rou-\\ntine is dedicated to performing one function. A function like CosineAndTan() has lower \\ncohesion because it tries to do more than one thing. The goal is to have each routine \\ndo one thing well and not do anything else.\\nThe payoff is higher reliability. One study of 450 routines found that 50 percent of the \\nhighly cohesive routines were fault free, whereas only 18 percent of routines with low \\ncohesion were fault free (Card, Church, and Agresti 1986). Another study of a differ-\\nent 450 routines (which is just an unusual coincidence) found that routines with the \\nhighest coupling-to-cohesion ratios had 7 times as many errors as those with the low-\\nest coupling-to-cohesion ratios and were 20 times as costly to fix (Selby and Basili \\n1991).\\nDiscussions about cohesion typically refer to several levels of cohesion. Understand-\\ning the concepts is more important than remembering specific terms. Use the con-\\ncepts as aids in thinking about how to make routines as cohesive as possible.\\nFunctional cohesion is the strongest and best kind of cohesion, occurring when a rou-\\ntine performs one and only one operation. Examples of highly cohesive routines \\ninclude sin(), GetCustomerName(), EraseFile(), CalculateLoanPayment(), and AgeFrom-\\nBirthdate(). Of course, this evaluation of their cohesion assumes that the routines do \\nwhat their names say they do—if they do anything else, they are less cohesive and \\npoorly named.\\nSeveral other kinds of cohesion are normally considered to be less than ideal:\\n■ Sequential cohesion exists when a routine contains operations that must be per-\\nformed in a specific order, that share data from step to step, and that don’t make \\nup a complete function when done together. \\nAn example of sequential cohesion is a routine that, given a birth date, calculates \\nan employee’s age and time to retirement. If the routine calculates the age and \\nthen uses that result to calculate the employee’s time to retirement, it has \\nsequential cohesion. If the routine calculates the age and then calculates the \\ntime to retirement in a completely separate computation that happens to use the \\nsame birth-date data, it has only communicational cohesion.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 205}, page_content='7.2 Design at the Routine Level 169\\nHow would you make the routine functionally cohesive? You’d create separate \\nroutines to compute an employee’s age given a birth date and compute time to \\nretirement given a birth date. The time-to-retirement routine could call the age \\nroutine. They’d both have functional cohesion. Other routines could call either \\nroutine or both routines.\\n■ Communicational cohesion occurs when operations in a routine make use of the \\nsame data and aren’t related in any other way. If a routine prints a summary \\nreport and then reinitializes the summary data passed into it, the routine has \\ncommunicational cohesion: the two operations are related only by the fact that \\nthey use the same data.\\nTo give this routine better cohesion, the summary data should be reinitialized \\nclose to where it’s created, which shouldn’t be in the report-printing routine. \\nSplit the operations into individual routines. The first prints the report. The sec-\\nond reinitializes the data, close to the code that creates or modifies the data. Call \\nboth routines from the higher-level routine that originally called the communi-\\ncationally cohesive routine.\\n■ Temporal cohesion occurs when operations are combined into a routine because \\nthey are all done at the same time. Typical examples would be Startup(), Com-\\npleteNewEmployee(), and Shutdown(). Some programmers consider temporal \\ncohesion to be unacceptable because it’s sometimes associated with bad pro-\\ngramming practices such as having a hodgepodge of code in a Startup() routine.\\nTo avoid this problem, think of temporal routines as organizers of other events. \\nThe Startup() routine, for example, might read a configuration file, initialize a \\nscratch file, set up a memory manager, and show an initial screen. To make it \\nmost effective, have the temporally cohesive routine call other routines to per-\\nform specific activities rather than performing the operations directly itself. That \\nway, it will be clear that the point of the routine is to orchestrate activities rather \\nthan to do them directly.\\nThis example raises the issue of choosing a name that describes the routine at \\nthe right level of abstraction. You could decide to name the routine ReadConfig-\\nFileInitScratchFileEtc(), which would imply that the routine had only coinciden-\\ntal cohesion. If you name it Startup(), however, it would be clear that it had a \\nsingle purpose and clear that it had functional cohesion.\\nThe remaining kinds of cohesion are generally unacceptable. They result in code \\nthat’s poorly organized, hard to debug, and hard to modify. If a routine has bad cohe-\\nsion, it’s better to put effort into a rewrite to have better cohesion than investing in a \\npinpoint diagnosis of the problem. Knowing what to avoid can be useful, however, so \\nhere are the unacceptable kinds of cohesion:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 206}, page_content='170 Chapter 7: High-Quality Routines\\n■ Procedural cohesion occurs when operations in a routine are done in a specified \\norder. An example is a routine that gets an employee name, then an address, and \\nthen a phone number. The order of these operations is important only because \\nit matches the order in which the user is asked for the data on the input screen. \\nAnother routine gets the rest of the employee data. The routine has procedural \\ncohesion because it puts a set of operations in a specified order and the opera-\\ntions don’t need to be combined for any other reason.\\nTo achieve better cohesion, put the separate operations into their own routines. \\nMake sure that the calling routine has a single, complete job: GetEmployee() \\nrather than GetFirstPartOfEmployeeData(). You’ll probably need to modify the \\nroutines that get the rest of the data too. It’s common to modify two or more \\noriginal routines before you achieve functional cohesion in any of them. \\n■ Logical cohesion occurs when several operations are stuffed into the same routine \\nand one of the operations is selected by a control flag that’s passed in. It’s called \\nlogical cohesion because the control flow or “logic” of the routine is the only \\nthing that ties the operations together—they’re all in a big if statement or case \\nstatement together. It isn’t because the operations are logically related in any \\nother sense. Considering that the defining attribute of logical cohesion is that \\nthe operations are unrelated, a better name might “illogical cohesion.” \\nOne example would be an InputAll() routine that inputs customer names, \\nemployee timecard information, or inventory data depending on a flag passed to \\nthe routine. Other examples would be ComputeAll(), EditAll(), PrintAll(), and \\nSaveAll(). The main problem with such routines is that you shouldn’t need to \\npass in a flag to control another routine’s processing. Instead of having a routine \\nthat does one of three distinct operations, depending on a flag passed to it, it’s \\ncleaner to have three routines, each of which does one distinct operation. If the \\noperations use some of the same code or share data, the code should be moved \\ninto a lower-level routine and the routines should be packaged into a class.\\nCross-Reference Although \\nthe routine might have bet-\\nter cohesion, a higher-level \\ndesign issue is whether the \\nsystem should be using a \\ncase statement instead of \\npolymorphism. For more on \\nthis issue, see “Replace con-\\nditionals with polymorphism \\n(especially repeated case \\nstatements)” in Section 24.3\\nIt’s usually all right, however, to create a logically cohesive routine if its code con-\\nsists solely of a series of if or case statements and calls to other routines. In such \\na case, if the routine’s only function is to dispatch commands and it doesn’t do \\nany of the processing itself, that’s usually a good design. The technical term for \\nthis kind of routine is “event handler.” An event handler is often used in interac-\\ntive environments such as the Apple Macintosh, Microsoft Windows, and other \\nGUI environments.\\n■ Coincidental cohesion occurs when the operations in a routine have no discernible \\nrelationship to each other. Other good names are “no cohesion” or “chaotic cohe-\\nsion.” The low-quality C++ routine at the beginning of this chapter had coinciden-\\ntal cohesion. It’s hard to convert coincidental cohesion to any better kind of \\ncohesion—you usually need to do a deeper redesign and reimplementation.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 207}, page_content='7.3 Good Routine Names 171\\nNone of these terms are magical or sacred. Learn the ideas rather than the terminol-\\nogy. It’s nearly always possible to write routines with functional cohesion, so focus \\nyour attention on functional cohesion for maximum benefit. \\n7.3 Good Routine Names\\nCross-Reference For details \\non naming variables, see \\nChapter 11, “The Power of \\nVariable Names.”\\nA good name for a routine clearly describes everything the routine does. Here are \\nguidelines for creating effective routine names:\\nDescribe everything the routine does In the routine’s name, describe all the outputs \\nand side effects. If a routine computes report totals and opens an output file, Compute-\\nReportTotals() is not an adequate name for the routine. ComputeReportTotalsAndOpen-\\nOutputFile() is an adequate name but is too long and silly. If you have routines with \\nside effects, you’ll have many long, silly names. The cure is not to use less-descriptive \\nroutine names; the cure is to program so that you cause things to happen directly \\nrather than with side effects.\\nAvoid meaningless, vague, or wishy-washy verbs Some verbs are elastic, stretched to \\ncover just about any meaning. Routine names like HandleCalculation(), PerformSer-\\nvices(), OutputUser(), ProcessInput(), and DealWithOutput() don’t tell you what the rou-\\ntines do. At the most, these names tell you that the routines have something to do \\nwith calculations, services, users, input, and output. The exception would be when \\nthe verb “handle” was used in the specific technical sense of handling an event.\\nSometimes the only problem with a routine is that its name is wishy-washy; the rou-\\ntine itself might actually be well designed. If HandleOutput() is replaced with For-\\nmatAndPrintOutput(), you have a pretty good idea of what the routine does.\\nIn other cases, the verb is vague because the operations performed by the routine are \\nvague. The routine suffers from a weakness of purpose, and the weak name is a symp-\\ntom. If that’s the case, the best solution is to restructure the routine and any related \\nroutines so that they all have stronger purposes and stronger names that accurately \\ndescribe them.\\nDon’t differentiate routine names solely by number One developer wrote all his \\ncode in one big function. Then he took every 15 lines and created functions named \\nPart1, Part2, and so on. After that, he created one high-level function that called each \\npart. This method of creating and naming routines is especially egregious (and rare, I \\nhope). But programmers sometimes use numbers to differentiate routines with names \\nlike OutputUser, OutputUser1, and OutputUser2. The numerals at the ends of these \\nnames provide no indication of the different abstractions the routines represent, and \\nthe routines are thus poorly named. \\nMake names of routines as long as necessary Research shows that the optimum \\naverage length for a variable name is 9 to 15 characters. Routines tend to be more com-\\nKEY POINT\\nKEY POINT\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 208}, page_content='172 Chapter 7: High-Quality Routines\\nplicated than variables, and good names for them tend to be longer. On the other \\nhand, routine names are often attached to object names, which essentially provides \\npart of the name for free. Overall, the emphasis when creating a routine name should \\nbe to make the name as clear as possible, which means you should make its name as \\nlong or short as needed to make it understandable.\\nCross-Reference For the \\ndistinction between proce-\\ndures and functions, see \\nSection 7.6, “Special Consid-\\nerations in the Use of Func-\\ntions,” later in this chapter.\\nTo name a function, use a description of the return value A function returns a value, \\nand the function should be named for the value it returns. For example, cos(), \\ncustomerId.Next(), printer.IsReady(), and pen.CurrentColor() are all good function \\nnames that indicate precisely what the functions return.\\nTo name a procedure, use a strong verb followed by an object A procedure with \\nfunctional cohesion usually performs an operation on an object. The name should \\nreflect what the procedure does, and an operation on an object implies a verb-plus-\\nobject name. PrintDocument(), CalcMonthlyRevenues(), CheckOrderlnfo(), and Repagi-\\nnateDocument() are samples of good procedure names.\\nIn object-oriented languages, you don’t need to include the name of the object in the \\nprocedure name because the object itself is included in the call. You invoke routines \\nwith statements like document.Print(), orderInfo.Check(), and monthlyRevenues.Calc(). \\nNames like document.PrintDocument() are redundant and can become inaccurate \\nwhen they’re carried through to derived classes. If Check is a class derived from Docu-\\nment, check.Print() seems clearly to be printing a check, whereas check.PrintDocument() \\nsounds like it might be printing a checkbook register or monthly statement, but it \\ndoesn’t sound like it’s printing a check. \\nCross-Reference For a simi-\\nlar list of opposites in vari-\\nable names, see “Common \\nOpposites in Variable \\nNames” in Section 11.1.\\nUse opposites precisely Using naming conventions for opposites helps consistency, \\nwhich helps readability. Opposite-pairs like first/last are commonly understood. \\nOpposite-pairs like FileOpen() and _lclose() are not symmetrical and are confusing. \\nHere are some common opposites:\\nEstablish conventions for common operations In some systems, it’s important to dis-\\ntinguish among different kinds of operations. A naming convention is often the easiest \\nand most reliable way of indicating these distinctions. \\nThe code on one of my projects assigned each object a unique identifier. We neglected \\nto establish a convention for naming the routines that would return the object identi-\\nfier, so we had routine names like these:\\nadd/remove increment/decrement open/close\\nbegin/end insert/delete show/hide\\ncreate/destroy lock/unlock source/target\\nfirst/last min/max start/stop\\nget/put next/previous up/down\\nget/set old/new'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 209}, page_content='7.4 How Long Can a Routine Be? 173\\nemployee.id.Get()\\ndependent.GetId()\\nsupervisor()\\ncandidate.id()\\nThe Employee class exposed its id object, which in turn exposed its Get() routine. The \\nDependent class exposed a GetId() routine. The Supervisor class made the id its default \\nreturn value. The Candidate class made use of the fact that the id object’s default \\nreturn value was the id, and exposed the id object. By the middle of the project, no one \\ncould remember which of these routines was supposed to be used on which object, \\nbut by that time too much code had been written to go back and make everything con-\\nsistent. Consequently, every person on the team had to devote an unnecessary \\namount of gray matter to remembering the inconsequential detail of which syntax \\nwas used on which class to retrieve the id. A naming convention for retrieving ids \\nwould have eliminated this annoyance. \\n7.4 How Long Can a Routine Be?\\nOn their way to America, the Pilgrims argued about the best maximum length for a \\nroutine. After arguing about it for the entire trip, they arrived at Plymouth Rock and \\nstarted to draft the Mayflower Compact. They still hadn’t settled the maximum-length \\nquestion, and since they couldn’t disembark until they’d signed the compact, they \\ngave up and didn’t include it. The result has been an interminable debate ever since \\nabout how long a routine can be.\\nThe theoretical best maximum length is often described as one screen or one or two \\npages of program listing, approximately 50 to 150 lines. In this spirit, IBM once lim-\\nited routines to 50 lines, and TRW limited them to two pages (McCabe 1976). Modern \\nprograms tend to have volumes of extremely short routines mixed in with a few longer \\nroutines. Long routines are far from extinct, however. Shortly before finishing this \\nbook, I visited two client sites within a month. Programmers at one site were wrestling \\nwith a routine that was about 4,000 lines of code long, and programmers at the other \\nsite were trying to tame a routine that was more than 12,000 lines long!\\nA mountain of research on routine length has accumulated over the years, some of \\nwhich is applicable to modern programs, and some of which isn’t: \\n■ A study by Basili and Perricone found that routine size was inversely correlated \\nwith errors: as the size of routines increased (up to 200 lines of code), the num-\\nber of errors per line of code decreased (Basili and Perricone 1984).\\n■ Another study found that routine size was not correlated with errors, even \\nthough structural complexity and amount of data were correlated with errors \\n(Shen et al. 1985).\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 210}, page_content='174 Chapter 7: High-Quality Routines\\n■ A 1986 study found that small routines (32 lines of code or fewer) were not cor-\\nrelated with lower cost or fault rate (Card, Church, and Agresti 1986; Card and \\nGlass 1990). The evidence suggested that larger routines (65 lines of code or \\nmore) were cheaper to develop per line of code.\\n■ An empirical study of 450 routines found that small routines (those with fewer \\nthan 143 source statements, including comments) had 23 percent more errors \\nper line of code than larger routines but were 2.4 times less expensive to fix than \\nlarger routines (Selby and Basili 1991).\\n■ Another study found that code needed to be changed least when routines aver-\\naged 100 to 150 lines of code (Lind and Vairavan 1989).\\n■ A study at IBM found that the most error-prone routines were those that were \\nlarger than 500 lines of code. Beyond 500 lines, the error rate tended to be pro-\\nportional to the size of the routine (Jones 1986a).\\nWhere does all this leave the question of routine length in object-oriented programs? \\nA large percentage of routines in object-oriented programs will be  accessor routines, \\nwhich will be very short. From time to time, a complex algorithm will lead to a longer \\nroutine, and in those circumstances, the routine should be allowed to grow organi-\\ncally up to 100–200 lines. (A line is a noncomment, nonblank line of source code.) \\nDecades of evidence say that routines of such length are no more error prone than \\nshorter routines. Let issues such as the routine’s cohesion, depth of nesting, number \\nof variables, number of decision points, number of comments needed to explain the \\nroutine, and other complexity-related considerations dictate the length of the routine \\nrather than imposing a length restriction per se. \\nThat said, if you want to write routines longer than about 200 lines, be careful. None \\nof the studies that reported decreased cost, decreased error rates, or both with larger \\nroutines distinguished among sizes larger than 200 lines, and you’re bound to run \\ninto an upper limit of understandability as you pass 200 lines of code.\\n7.5 How to Use Routine Parameters\\nInterfaces between routines are some of the most error-prone areas of a program. One \\noften-cited study by Basili and Perricone (1984) found that 39 percent of all errors \\nwere internal interface errors—errors in communication between routines. Here are a \\nfew guidelines for minimizing interface problems:\\nCross-Reference For details \\non documenting routine \\nparameters, see “Comment-\\ning Routines” in Section 32.5. \\nFor details on formatting \\nparameters, see Section \\n31.7, “Laying Out Routines.”\\nPut parameters in input-modify-output order Instead of ordering parameters ran-\\ndomly or alphabetically, list the parameters that are input-only first, input-and-output \\nsecond, and output-only third. This ordering implies the sequence of operations hap-\\npening within the routine-inputting data, changing it, and sending back a result. Here \\nare examples of parameter lists in Ada:\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 211}, page_content='7.5 How to Use Routine Parameters 175\\nAda Example of Parameters in Input-Modify-Output Order\\nprocedure InvertMatrix(\\nAda uses in and out key-\\nwords to make input and \\noutput parameters clear.\\noriginalMatrix: in Matrix;\\nresultMatrix: out Matrix\\n);\\n...\\nprocedure ChangeSentenceCase(\\ndesiredCase: in StringCase;\\nsentence: in out Sentence\\n);\\n...\\nprocedure PrintPageNumber(\\npageNumber: in Integer;\\nstatus: out StatusType\\n);\\nThis ordering convention conflicts with the C-library convention of putting the mod-\\nified parameter first. The input-modify-output convention makes more sense to me, \\nbut if you consistently order parameters in some way, you will still do the readers of \\nyour code a service.\\nConsider creating your own in and out keywords Other modern languages don’t \\nsupport the in and out keywords like Ada does. In those languages, you might still be \\nable to use the preprocessor to create your own in and out keywords:\\nC+ + Example of Defining Your Own In and Out Keywords\\n#define IN\\n#define OUT\\nvoid InvertMatrix(\\nIN Matrix originalMatrix,\\nOUT Matrix *resultMatrix\\n);\\n...\\nvoid ChangeSentenceCase(\\nIN StringCase desiredCase,\\nIN OUT Sentence *sentenceToEdit\\n);\\n...\\nvoid PrintPageNumber(\\nIN int pageNumber,\\nOUT StatusType &status\\n);\\nIn this case, the IN and OUT macro-keywords are used for documentation purposes. \\nTo make the value of a parameter changeable by the called routine, the parameter still \\nneeds to be passed as a pointer or as a reference parameter.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 212}, page_content='176 Chapter 7: High-Quality Routines\\nBefore adopting this technique, be sure to consider a pair of significant drawbacks. Defin-\\ning your own IN and OUT keywords extends the C++ language in a way that will be unfa-\\nmiliar to most people reading your code. If you extend the language this way, be sure to \\ndo it consistently, preferably projectwide. A second limitation is that the IN and OUT key-\\nwords won’t be enforceable by the compiler, which means that you could potentially \\nlabel a parameter as IN and then modify it inside the routine anyway. That could lull a \\nreader of your code into assuming code is correct when it isn’t. Using C++’s const key-\\nword will normally be the preferable means of identifying input-only parameters. \\nIf several routines use similar parameters, put the similar parameters in a consistent \\norder The order of routine parameters can be a mnemonic, and inconsistent order \\ncan make parameters hard to remember. For example, in C, the fprintf() routine is the \\nsame as the printf() routine except that it adds a file as the first argument. A similar \\nroutine, fputs(), is the same as puts() except that it adds a file as the last argument. This \\nis an aggravating, pointless difference that makes the parameters of these routines \\nharder to remember than they need to be.\\nOn the other hand, the routine strncpy() in C takes the arguments target string, source \\nstring, and maximum number of bytes, in that order, and the routine memcpy() takes \\nthe same arguments in the same order. The similarity between the two routines helps \\nin remembering the parameters in either routine.\\nUse all the parameters If you pass a parameter to a routine, use it. If you aren’t using \\nit, remove the parameter from the routine interface. Unused parameters are correlated \\nwith an increased error rate. In one study, 46 percent of routines with no unused vari-\\nables had no errors, and only 17 to 29 percent of routines with more than one unref-\\nerenced variable had no errors (Card, Church, and Agresti 1986).\\nThis rule to remove unused parameters has one exception. If you’re compiling part of \\nyour program conditionally, you might compile out parts of a routine that use a cer-\\ntain parameter. Be nervous about this practice, but if you’re convinced it works, that’s \\nOK too. In general, if you have a good reason not to use a parameter, go ahead and \\nleave it in place. If you don’t have a good reason, make the effort to clean up the code.\\nPut status or error variables last By convention, status variables and variables that \\nindicate an error has occurred go last in the parameter list. They are incidental to the \\nmain purpose of the routine, and they are output-only parameters, so it’s a sensible \\nconvention.\\nDon’t use routine parameters as working variables It’s dangerous to use the param-\\neters passed to a routine as working variables. Use local variables instead. For exam-\\nple, in the following Java fragment, the variable inputVal is improperly used to store \\nintermediate results of a computation:\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 213}, page_content='7.5 How to Use Routine Parameters 177\\nJava Example of Improper Use of Input Parameters\\nint Sample( int inputVal ) {\\ninputVal = inputVal * CurrentMultiplier( inputVal );\\ninputVal = inputVal + CurrentAdder( inputVal );\\n...\\nAt this point, inputVal no \\nlonger contains the value \\nthat was input.\\nreturn inputVal;\\n}\\nIn this code fragment, inputVal is misleading because by the time execution reaches the \\nlast line, inputVal no longer contains the input value; it contains a computed value based \\nin part on the input value, and it is therefore misnamed. If you later need to modify the \\nroutine to use the original input value in some other place, you’ll probably use inputVal \\nand assume that it contains the original input value when it actually doesn’t.\\nHow do you solve the problem? Can you solve it by renaming inputVal? Probably not. \\nYou could name it something like workingVal, but that’s an incomplete solution because \\nthe name fails to indicate that the variable’s original value comes from outside the rou-\\ntine. You could name it something ridiculous like inputValThatBecomesWorkingVal or \\ngive up completely and name it x or val, but all these approaches are weak.\\nA better approach is to avoid current and future problems by using working variables \\nexplicitly. The following code fragment demonstrates the technique: \\nJava Example of Good Use of Input Parameters\\nint Sample( int inputVal ) {\\nint workingVal = inputVal;\\nworkingVal = workingVal * CurrentMultiplier( workingVal );\\nworkingVal = workingVal + CurrentAdder( workingVal );\\n...\\nIf you need to use the origi-\\nnal value of inputVal  here \\nor somewhere else, it’s still \\navailable.\\n...\\nreturn workingVal;\\n}\\nIntroducing the new variable workingVal clarifies the role of inputVal and eliminates \\nthe chance of erroneously using inputVal at the wrong time. (Don’t take this reasoning \\nas a justification for literally naming a variable inputVal or workingVal. In general, \\ninputVal and workingVal are terrible names for variables, and these names are used in \\nthis example only to make the variables’ roles clear.)\\nAssigning the input value to a working variable emphasizes where the value comes \\nfrom. It eliminates the possibility that a variable from the parameter list will be modi-\\nfied accidentally. In C++, this practice can be enforced by the compiler using the key-\\nword const. If you designate a parameter as const, you’re not allowed to modify its value \\nwithin a routine.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 214}, page_content='178 Chapter 7: High-Quality Routines\\nCross-Reference For details \\non interface assumptions, \\nsee the introduction to \\nChapter 8, “Defensive Pro-\\ngramming.” For details on \\ndocumentation, see Chapter \\n32, “Self-Documenting \\nCode.”\\nDocument interface assumptions about parameters If you assume the data being \\npassed to your routine has certain characteristics, document the assumptions as you \\nmake them. It’s not a waste of effort to document your assumptions both in the rou-\\ntine itself and in the place where the routine is called. Don’t wait until you’ve written \\nthe routine to go back and write the comments—you won’t remember all your assump-\\ntions. Even better than commenting your assumptions, use assertions to put them \\ninto code.\\nWhat kinds of interface assumptions about parameters should you document? \\n■ Whether parameters are input-only, modified, or output-only\\n■ Units of numeric parameters (inches, feet, meters, and so on)\\n■ Meanings of status codes and error values if enumerated types aren’t used \\n■ Ranges of expected values\\n■ Specific values that should never appear\\nLimit the number of a routine’s parameters to about seven Seven is a magic number \\nfor people’s comprehension. Psychological research has found that people generally \\ncannot keep track of more than about seven chunks of information at once (Miller \\n1956). This discovery has been applied to an enormous number of disciplines, and it \\nseems safe to conjecture that most people can’t keep track of more than about seven \\nroutine parameters at once.\\nIn practice, how much you can limit the number of parameters depends on how your \\nlanguage handles complex data types. If you program in a modern language that sup-\\nports structured data, you can pass a composite data type containing 13 fields and \\nthink of it as one mental “chunk” of data. If you program in a more primitive language, \\nyou might need to pass all 13 fields individually.\\nCross-Reference For details \\non how to think about inter-\\nfaces, see “Good Abstrac-\\ntion” in Section 6.2.\\nIf you find yourself consistently passing more than a few arguments, the coupling \\namong your routines is too tight. Design the routine or group of routines to reduce the \\ncoupling. If you are passing the same data to many different routines, group the rou-\\ntines into a class and treat the frequently used data as class data.\\nConsider an input, modify, and output naming convention for parameters If you \\nfind that it’s important to distinguish among input, modify, and output parameters, \\nestablish a naming convention that identifies them. You could prefix them with i_, \\nm_, and o_. If you’re feeling verbose, you could prefix them with Input_, Modify_, and \\nOutput_.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 215}, page_content='7.5 How to Use Routine Parameters 179\\nPass the variables or objects that the routine needs to maintain its interface \\nabstraction There are two competing schools of thought about how to pass members \\nof an object to a routine. Suppose you have an object that exposes data through 10 \\naccess routines and the called routine needs three of those data elements to do its job. \\nProponents of the first school of thought argue that only the three specific elements \\nneeded by the routine should be passed. They argue that doing this will keep the con-\\nnections between routines to a minimum; reduce coupling; and make them easier to \\nunderstand, reuse, and so on. They say that passing the whole object to a routine vio-\\nlates the principle of encapsulation by potentially exposing all 10 access routines to \\nthe routine that’s called. \\nProponents of the second school argue that the whole object should be passed. They \\nargue that the interface can remain more stable if the called routine has the flexibility \\nto use additional members of the object without changing the routine’s interface. \\nThey argue that passing three specific elements violates encapsulation by exposing \\nwhich specific data elements the routine is using. \\nI think both these rules are simplistic and miss the most important consideration: \\nwhat abstraction is presented by the routine’s interface? If the abstraction is that the rou-\\ntine expects you to have three specific data elements, and it is only a coincidence that \\nthose three elements happen to be provided by the same object, then you should pass \\nthe three specific data elements individually. However, if the abstraction is that you \\nwill always have that particular object in hand and the routine will do something or \\nother with that object, then you truly do break the abstraction when you expose the \\nthree specific data elements.\\nIf you’re passing the whole object and you find yourself creating the object, populat-\\ning it with the three elements needed by the called routine, and then pulling those ele-\\nments out of the object after the routine is called, that’s an indication that you should \\nbe passing the three specific elements rather than the whole object. (In general, code \\nthat “sets up” for a call to a routine or “takes down” after a call to a routine is an indi-\\ncation that the routine is not well designed.)\\nIf you find yourself frequently changing the parameter list to the routine, with the \\nparameters coming from the same object each time, that’s an indication that you \\nshould be passing the whole object rather than specific elements.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 216}, page_content='180 Chapter 7: High-Quality Routines\\nUse named parameters In some languages, you can explicitly associate formal param-\\neters with actual parameters. This makes parameter usage more self-documenting and \\nhelps avoid errors from mismatching parameters. Here’s an example in Visual Basic:\\nVisual Basic Example of Explicitly Identifying Parameters\\nPrivate Function Distance3d( _\\nHere’s where the formal \\nparameters are declared. \\nByVal xDistance As Coordinate, _\\nByVal yDistance As Coordinate, _\\nByVal zDistance As Coordinate _\\n)\\n...\\nEnd Function\\n...\\nPrivate Function Velocity( _\\nByVal latitude as Coordinate, _\\nByVal longitude as Coordinate, _\\nByVal elevation as Coordinate _\\n)\\n...\\nHere’s where the actual \\nparameters are mapped to \\nthe formal parameters. \\nDistance = Distance3d( xDistance := latitude, yDistance := longitude, _\\nzDistance := elevation )\\n...\\nEnd Function\\nThis technique is especially useful when you have longer-than-average lists of identi-\\ncally typed arguments, which increases the chances that you can insert a parameter \\nmismatch without the compiler detecting it. Explicitly associating parameters may be \\noverkill in many environments, but in safety-critical or other high-reliability environ-\\nments the extra assurance that parameters match up the way you expect can be \\nworthwhile. \\nMake sure actual parameters match formal parameters Formal parameters, also \\nknown as “dummy parameters,” are the variables declared in a routine definition. \\nActual parameters are the variables, constants, or expressions used in the actual rou-\\ntine calls.\\nA common mistake is to put the wrong type of variable in a routine call—for example, \\nusing an integer when a floating point is needed. (This is a problem only in weakly \\ntyped languages like C when you’re not using full compiler warnings. Strongly typed \\nlanguages such as C++ and Java don’t have this problem.) When arguments are input \\nonly, this is seldom a problem; usually the compiler converts the actual type to the for-\\nmal type before passing it to the routine. If it is a problem, usually your compiler gives \\nyou a warning. But in some cases, particularly when the argument is used for both \\ninput and output, you can get stung by passing the wrong type of argument.\\nDevelop the habit of checking types of arguments in parameter lists and heeding com-\\npiler warnings about mismatched parameter types.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 217}, page_content='7.6 Special Considerations in the Use of Functions 181\\n7.6 Special Considerations in the Use of Functions\\nModern languages such as C++, Java, and Visual Basic support both functions and proce-\\ndures. A function is a routine that returns a value; a procedure is a routine that does not. \\nIn C++, all routines are typically called “functions”; however, a function with a void return \\ntype is semantically a procedure. The distinction between functions and procedures is as \\nmuch a semantic distinction as a syntactic one, and semantics should be your guide. \\nWhen to Use a Function and When to Use a Procedure \\nPurists argue that a function should return only one value, just as a mathematical func-\\ntion does. This means that a function would take only input parameters and return its \\nonly value through the function itself. The function would always be named for the value \\nit returned, as sin(), CustomerID(), and ScreenHeight() are. A procedure, on the other \\nhand, could take input, modify, and output parameters—as many of each as it wanted to.\\nA common programming practice is to have a function that operates as a procedure and \\nreturns a status value. Logically, it works as a procedure, but because it returns a value, \\nit’s officially a function. For example, you might have a routine called FormatOutput() \\nused with a report object in statements like this one:\\nif ( report.FormatOutput( formattedReport ) = Success ) then ...\\nIn this example, report.FormatOutput() operates as a procedure in that it has an output \\nparameter, formattedReport, but it is technically a function because the routine itself \\nreturns a value. Is this a valid way to use a function? In defense of this approach, you \\ncould maintain that the function return value has nothing to do with the main purpose \\nof the routine, formatting output, or with the routine name, report.FormatOutput(). In \\nthat sense it operates more as a procedure does even if it is technically a function. The \\nuse of the return value to indicate the success or failure of the procedure is not con-\\nfusing if the technique is used consistently.\\nThe alternative is to create a procedure that has a status variable as an explicit param-\\neter, which promotes code like this fragment:\\nreport.FormatOutput( formattedReport, outputStatus )\\nif ( outputStatus = Success ) then ...\\nI prefer the second style of coding, not because I’m hard-nosed about the difference \\nbetween functions and procedures but because it makes a clear separation between \\nthe routine call and the test of the status value. To combine the call and the test into \\none line of code increases the density of the statement and, correspondingly, its com-\\nplexity. The following use of a function is fine too:\\noutputStatus = report.FormatOutput( formattedReport )\\nif ( outputStatus = Success ) then ...'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 218}, page_content='182 Chapter 7: High-Quality Routines\\nIn short, use a function if the primary purpose of the routine is to return the value \\nindicated by the function name. Otherwise, use a procedure. \\nSetting the Function’s Return Value\\nUsing a function creates the risk that the function will return an incorrect return \\nvalue. This usually happens when the function has several possible paths and one of \\nthe paths doesn’t set a return value. To reduce this risk, do the following: \\nCheck all possible return paths When creating a function, mentally execute each \\npath to be sure that the function returns a value under all possible circumstances. It’s \\ngood practice to initialize the return value at the beginning of the function to a default \\nvalue—this provides a safety net in the event that the correct return value is not set. \\nDon’t return references or pointers to local data As soon as the routine ends and the \\nlocal data goes out of scope, the reference or pointer to the local data will be invalid. If \\nan object needs to return information about its internal data, it should save the informa-\\ntion as class member data. It should then provide accessor functions that return the val-\\nues of the member data items rather than references or pointers to local data.\\n7.7 Macro Routines and Inline Routines\\nCross-Reference Even if \\nyour language doesn’t have \\na macro preprocessor, you \\ncan build your own. For \\ndetails, see Section 30.5, \\n“Building Your Own Pro-\\ngramming Tools.”\\nRoutines created with preprocessor macros call for a few unique considerations. The \\nfollowing rules and examples pertain to using the preprocessor in C++. If you’re using \\na different language or preprocessor, adapt the rules to your situation.\\nFully parenthesize macro expressions Because macros and their arguments are \\nexpanded into code, be careful that they expand the way you want them to. One com-\\nmon problem lies in creating a macro like this one:\\nC+ + Example of a Macro That Doesn’t Expand Properly\\n#define Cube( a ) a*a*a\\nIf you pass this macro nonatomic values for a, it won’t do the multiplication properly. \\nIf you use the expression Cube( x+1 ), it expands to x+1 * x + 1 * x + 1, which, because \\nof the precedence of the multiplication and addition operators, is not what you want. \\nA better, but still not perfect, version of the macro looks like this:\\nC+ + Example of a Macro That Still Doesn’t Expand Properly \\n#define Cube( a ) (a)*(a)*(a)\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 219}, page_content='7.7 Macro Routines and Inline Routines 183\\nThis is close, but still no cigar. If you use Cube() in an expression that has operators \\nwith higher precedence than multiplication, the (a)*(a)*(a) will be torn apart. To pre-\\nvent that, enclose the whole expression in parentheses:\\nC+ + Example of a Macro That Works \\n#define Cube( a ) ((a)*(a)*(a))\\nSurround multiple-statement macros with curly braces A macro can have multiple \\nstatements, which is a problem if you treat it as if it were a single statement. Here’s an \\nexample of a macro that’s headed for trouble:\\nC+ + Example of a Nonworking Macro with Multiple Statements\\n#define LookupEntry( key, index ) \\\\\\nindex = (key - 10) / 5; \\\\\\nindex = min( index, MAX_INDEX ); \\\\\\nindex = max( index, MIN_INDEX );\\n...\\nfor ( entryCount = 0; entryCount < numEntries; entryCount++ )\\nLookupEntry( entryCount, tableIndex[ entryCount ] );\\nThis macro is headed for trouble because it doesn’t work as a regular function would. \\nAs it’s shown, the only part of the macro that’s executed in the for loop is the first line \\nof the macro:\\nindex = (key - 10) / 5;\\nTo avoid this problem, surround the macro with curly braces: \\nC+ + Example of a Macro with Multiple Statements That Works\\n#define LookupEntry( key, index ) { \\\\\\nindex = (key - 10) / 5; \\\\\\nindex = min( index, MAX_INDEX ); \\\\\\nindex = max( index, MIN_INDEX ); \\\\\\n}\\nThe practice of using macros as substitutes for function calls is generally considered \\nrisky and hard to understand—bad programming practice—so use this technique only \\nif your specific circumstances require it. \\nName macros that expand to code like routines so that they can be replaced by routines \\nif necessary The convention in C++ for naming macros is to use all capital letters. If \\nthe macro can be replaced by a routine, however, name it using the naming conven-\\ntion for routines instead. That way you can replace macros with routines and vice \\nversa without changing anything but the routine involved.\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 220}, page_content='184 Chapter 7: High-Quality Routines\\nFollowing this recommendation entails some risk. If you commonly use ++ and -- as \\nside effects (as part of other statements), you’ll get burned when you use macros that \\nyou think are routines. Considering the other problems with side effects, this is yet \\nanother reason to avoid using side effects.\\nLimitations on the Use of Macro Routines\\nModern languages like C++ provide numerous alternatives to the use of macros:\\n■ const for declaring constant values\\n■ inline for defining functions that will be compiled as inline code\\n■ template for defining standard operations like min, max, and so on in a type-safe \\nway\\n■ enum for defining enumerated types\\n■ typedef for defining simple type substitutions\\nAs Bjarne Stroustrup, designer of C++ points out, “Almost every macro demonstrates \\na flaw in the programming language, in the program, or in the programmer.... When \\nyou use macros, you should expect inferior service from tools such as debuggers, \\ncross-reference tools, and profilers” (Stroustrup 1997). Macros are useful for support-\\ning conditional compilation—see Section 8.6, “Debugging Aids”—but careful program-\\nmers generally use a macro as an alternative to a routine only as a last resort. \\nInline Routines\\nC++ supports an inline keyword. An inline routine allows the programmer to treat the \\ncode as a routine at code-writing time, but the compiler will generally convert each \\ninstance of the routine into inline code at compile time. The theory is that inline can \\nhelp produce highly efficient code that avoids routine-call overhead.\\nUse inline routines sparingly Inline routines violate encapsulation because C++ \\nrequires the programmer to put the code for the implementation of the inline routine \\nin the header file, which exposes it to every programmer who uses the header file.\\nInline routines require a routine’s full code to be generated every time the routine is \\ninvoked, which for an inline routine of any size will increase code size. That can create \\nproblems of its own. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 221}, page_content='7.7 Macro Routines and Inline Routines 185\\nThe bottom line on inlining for performance reasons is the same as the bottom line on \\nany other coding technique that’s motivated by performance: profile the code and \\nmeasure the improvement. If the anticipated performance gain doesn’t justify the \\nbother of profiling the code to verify the improvement, it doesn’t justify the erosion in \\ncode quality either.  \\ncc2e.com/0792\\nCross-Reference This is a \\nchecklist of considerations \\nabout the quality of the rou-\\ntine. For a list of the steps \\nused to build a routine, see \\nthe checklist “The Pseudo-\\ncode Programming Process” \\nin Chapter 9, page 215.\\nCHECKLIST: High-Quality Routines\\nBig-Picture Issues\\n❑ Is the reason for creating the routine sufficient?\\n❑ Have all parts of the routine that would benefit from being put into rou-\\ntines of their own been put into routines of their own?\\n❑ Is the routine’s name a strong, clear verb-plus-object name for a procedure \\nor a description of the return value for a function?\\n❑ Does the routine’s name describe everything the routine does?\\n❑ Have you established naming conventions for common operations? \\n❑ Does the routine have strong, functional cohesion—doing one and only \\none thing and doing it well?\\n❑ Do the routines have loose coupling—are the routine’s connections to \\nother routines small, intimate, visible, and flexible?\\n❑ Is the length of the routine determined naturally by its function and logic, \\nrather than by an artificial coding standard?\\nParameter-Passing Issues\\n❑ Does the routine’s parameter list, taken as a whole, present a consistent \\ninterface abstraction? \\n❑ Are the routine’s parameters in a sensible order, including matching the \\norder of parameters in similar routines?\\n❑ Are interface assumptions documented?\\n❑ Does the routine have seven or fewer parameters?\\n❑ Is each input parameter used? \\n❑ Is each output parameter used? \\n❑ Does the routine avoid using input parameters as working variables? \\n❑ If the routine is a function, does it return a valid value under all possible \\ncircumstances?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 222}, page_content='186 Chapter 7: High-Quality Routines\\nKey Points\\n■ The most important reason for creating a routine is to improve the intellectual \\nmanageability of a program, and you can create a routine for many other good \\nreasons. Saving space is a minor reason; improved readability, reliability, and \\nmodifiability are better reasons.\\n■ Sometimes the operation that most benefits from being put into a routine of its \\nown is a simple one.\\n■ You can classify routines into various kinds of cohesion, but you can make most \\nroutines functionally cohesive, which is best. \\n■ The name of a routine is an indication of its quality. If the name is bad and it’s \\naccurate, the routine might be poorly designed. If the name is bad and it’s inac-\\ncurate, it’s not telling you what the program does. Either way, a bad name means \\nthat the program needs to be changed.\\n■ Functions should be used only when the primary purpose of the function is to \\nreturn the specific value described by the function’s name. \\n■ Careful programmers use macro routines with care and only as a last resort.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 223}, page_content='187\\nChapter 8\\nDefensive Programming\\ncc2e.com/0861 Contents\\n■ 8.1 Protecting Your Program from Invalid Inputs: page 188\\n■ 8.2 Assertions: page 189\\n■ 8.3 Error-Handling Techniques: page 194\\n■ 8.4 Exceptions: page 198\\n■ 8.5 Barricade Your Program to Contain the Damage Caused by Errors: page 203\\n■ 8.6 Debugging Aids: page 205\\n■ 8.7 Determining How Much Defensive Programming to Leave in Production \\nCode: page 209\\n■ 8.8 Being Defensive About Defensive Programming: page 210\\nRelated Topics\\n■ Information hiding: \"Hide Secrets (Information Hiding)\" in Section 5.3\\n■ Design for change: \"Identify Areas Likely to Change\" in Section 5.3\\n■ Software architecture: Section 3.5\\n■ Design in Construction: Chapter 5\\n■ Debugging: Chapter 23\\nDefensive programming doesn’t mean being defensive about your programming—“It \\ndoes so work!” The idea is based on defensive driving. In defensive driving, you adopt \\nthe mind-set that you’re never sure what the other drivers are going to do. That way, \\nyou make sure that if they do something dangerous you won’t be hurt. You take \\nresponsibility for protecting yourself even when it might be the other driver’s fault. In \\ndefensive programming, the main idea is that if a routine is passed bad data, it won’t \\nbe hurt, even if the bad data is another routine’s fault. More generally, it’s the recogni-\\ntion that programs will have problems and modifications, and that a smart program-\\nmer will develop code accordingly.\\nThis chapter describes how to protect yourself from the cold, cruel world of invalid \\ndata, events that can “never” happen, and other programmers’ mistakes. If you’re an \\nexperienced programmer, you might skip the next section on handling input data and \\nbegin with Section 8.2, which reviews the use of assertions. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 224}, page_content='188 Chapter 8: Defensive Programming\\n8.1 Protecting Your Program from Invalid Inputs\\nIn school you might have heard the expression, “Garbage in, garbage out.” That expres-\\nsion is essentially software development’s version of caveat emptor: let the user beware.\\nFor production software, garbage in, garbage out isn’t good enough. A good program \\nnever puts out garbage, regardless of what it takes in. A good program uses “garbage in, \\nnothing out,” “garbage in, error message out,” or “no garbage allowed in” instead. By \\ntoday’s standards, “garbage in, garbage out” is the mark of a sloppy, nonsecure program.\\nThere are three general ways to handle garbage in: \\nCheck the values of all data from external sources When getting data from a file, a \\nuser, the network, or some other external interface, check to be sure that the data falls \\nwithin the allowable range. Make sure that numeric values are within tolerances and \\nthat strings are short enough to handle. If a string is intended to represent a restricted \\nrange of values (such as a financial transaction ID or something similar), be sure that \\nthe string is valid for its intended purpose; otherwise reject it. If you’re working on a \\nsecure application, be especially leery of data that might attack your system: \\nattempted buffer overflows, injected SQL commands, injected HTML or XML code, \\ninteger overflows, data passed to system calls, and so on. \\nCheck the values of all routine input parameters Checking the values of routine \\ninput parameters is essentially the same as checking data that comes from an external \\nsource, except that the data comes from another routine instead of from an external \\ninterface. The discussion in Section 8.5, “Barricade Your Program to Contain the Dam-\\nage Caused by Errors,” provides a practical way to determine which routines need to \\ncheck their inputs. \\nDecide how to handle bad inputs Once you’ve detected an invalid parameter, what \\ndo you do with it? Depending on the situation, you might choose any of a dozen dif-\\nferent approaches, which are described in detail in Section 8.3, “Error-Handling Tech-\\nniques,” later in this chapter. \\nDefensive programming is useful as an adjunct to the other quality-improvement tech-\\nniques described in this book. The best form of defensive coding is not inserting \\nerrors in the first place. Using iterative design, writing pseudocode before code, writ-\\ning test cases before writing the code, and having low-level design inspections are all \\nactivities that help to prevent inserting defects. They should thus be given a higher pri-\\nority than defensive programming. Fortunately, you can use defensive programming \\nin combination with the other techniques.\\nAs Figure 8-1 suggests, protecting yourself from seemingly small problems can make \\nmore of a difference than you might think. The rest of this chapter describes specific \\noptions for checking data from external sources, checking input parameters, and han-\\ndling bad inputs.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 225}, page_content='8.2 Assertions 189\\nFigure 8-1 Part of the Interstate-90 floating bridge in Seattle sank during a storm because \\nthe flotation tanks were left uncovered, they filled with water, and the bridge became too \\nheavy to float. During construction, protecting yourself against the small stuff matters more \\nthan you might think.\\n8.2 Assertions\\nAn assertion is code that’s used during development—usually a routine or macro—that \\nallows a program to check itself as it runs. When an assertion is true, that means \\neverything is operating as expected. When it’s false, that means it has detected an \\nunexpected error in the code. For example, if the system assumes that a customer-\\ninformation file will never have more than 50,000 records, the program might contain \\nan assertion that the number of records is less than or equal to 50,000. As long as the \\nnumber of records is less than or equal to 50,000, the assertion will be silent. If it \\nencounters more than 50,000 records, however, it will loudly “assert” that an error is \\nin the program.\\nAssertions are especially useful in large, complicated programs and in high-reliability \\nprograms. They enable programmers to more quickly flush out mismatched interface \\nassumptions, errors that creep in when code is modified, and so on. \\nAn assertion usually takes two arguments: a boolean expression that describes the \\nassumption that’s supposed to be true, and a message to display if it isn’t. Here’s what a \\nJava assertion would look like if the variable denominator were expected to be nonzero:\\nMike Siegel/The Seattle Times\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 226}, page_content='190 Chapter 8: Defensive Programming\\nJava Example of an Assertion\\nassert denominator != 0 : \"denominator is unexpectedly equal to 0.\";\\nThis assertion asserts that denominator is not equal to 0. The first argument, denomi-\\nnator != 0, is a boolean expression that evaluates to true or false. The second argument \\nis a message to print if the first argument is false—that is, if the assertion is false.\\nUse assertions to document assumptions made in the code and to flush out unex-\\npected conditions. Assertions can be used to check assumptions like these:\\n■ That an input parameter’s value falls within its expected range (or an output \\nparameter’s value does)\\n■ That a file or stream is open (or closed) when a routine begins executing (or \\nwhen it ends executing)\\n■ That a file or stream is at the beginning (or end) when a routine begins execut-\\ning (or when it ends executing)\\n■ That a file or stream is open for read-only, write-only, or both read and write\\n■ That the value of an input-only variable is not changed by a routine \\n■ That a pointer is non-null \\n■ That an array or other container passed into a routine can contain at least X \\nnumber of data elements\\n■ That a table has been initialized to contain real values\\n■ That a container is empty (or full) when a routine begins executing (or when it \\nfinishes)\\n■ That the results from a highly optimized, complicated routine match the results \\nfrom a slower but clearly written routine\\nOf course, these are just the basics, and your own routines will contain many more \\nspecific assumptions that you can document using assertions. \\nNormally, you don’t want users to see assertion messages in production code; assertions \\nare primarily for use during development and maintenance. Assertions are normally \\ncompiled into the code at development time and compiled out of the code for produc-\\ntion. During development, assertions flush out contradictory assumptions, unexpected \\nconditions, bad values passed to routines, and so on. During production, they can be \\ncompiled out of the code so that the assertions don’t degrade system performance.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 227}, page_content='8.2 Assertions 191\\nBuilding Your Own Assertion Mechanism\\nCross-Reference Building \\nyour own assertion routine is \\na good example of program-\\nming “into” a language \\nrather than just program-\\nming “in” a language. For \\nmore details on this distinc-\\ntion, see Section 34.4, \"Pro-\\ngram into Your Language, \\nNot in It.\"\\nMany languages have built-in support for assertions, including C++, Java, and \\nMicrosoft Visual Basic. If your language doesn’t directly support assertion routines, \\nthey are easy to write. The standard C++ assert macro doesn’t provide for text mes-\\nsages. Here’s an example of an improved ASSERT implemented as a C++ macro:\\nC+ + Example of an Assertion Macro\\n#define ASSERT( condition, message ) { \\\\\\nif ( !(condition) ) { \\\\\\nLogError( \"Assertion failed: \", \\\\\\n#condition, message ); \\\\\\nexit( EXIT_FAILURE ); \\\\\\n}\\\\\\n}\\nGuidelines for Using Assertions\\nHere are some guidelines for using assertions:\\nUse error-handling code for conditions you expect to occur; use assertions for \\nconditions that should never occur Assertions check for conditions that should \\nnever occur. Error-handling code checks for off-nominal circumstances that might not \\noccur very often, but that have been anticipated by the programmer who wrote the \\ncode and that need to be handled by the production code. Error handling typically \\nchecks for bad input data; assertions check for bugs in the code. \\nIf error-handling code is used to address an anomalous condition, the error handling \\nwill enable the program to respond to the error gracefully. If an assertion is fired for an \\nanomalous condition, the corrective action is not merely to handle an error grace-\\nfully—the corrective action is to change the program’s source code, recompile, and \\nrelease a new version of the software. \\nA good way to think of assertions is as executable documentation—you can’t rely on \\nthem to make the code work, but they can document assumptions more actively than \\nprogram-language comments can.\\nAvoid putting executable code into assertions Putting code into an assertion raises \\nthe possibility that the compiler will eliminate the code when you turn off the asser-\\ntions. Suppose you have an assertion like this:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 228}, page_content='192 Chapter 8: Defensive Programming\\nCross-Reference You could \\nview this as one of many \\nproblems associated with \\nputting multiple statements \\non one line. For more exam-\\nples, see \"Using Only One \\nStatement per Line\" in \\nSection 31.5.\\nVisual Basic Example of a Dangerous Use of an Assertion\\nDebug.Assert( PerformAction() ) \\' Couldn\\'t perform action\\nThe problem with this code is that, if you don’t compile the assertions, you don’t com-\\npile the code that performs the action. Put executable statements on their own lines, \\nassign the results to status variables, and test the status variables instead. Here’s an \\nexample of a safe use of an assertion:\\nVisual Basic Example of a Safe Use of an Assertion\\nactionPerformed = PerformAction()\\nDebug.Assert( actionPerformed ) \\' Couldn\\'t perform action\\nFurther Reading For much \\nmore on preconditions and \\npostconditions, see Object-\\nOriented Software Construc-\\ntion (Meyer 1997).  \\nUse assertions to document and verify preconditions and postconditions Precondi-\\ntions and postconditions are part of an approach to program design and development \\nknown as “design by contract” (Meyer 1997). When preconditions and postcondi-\\ntions are used, each routine or class forms a contract with the rest of the program. \\nPreconditions are the properties that the client code of a routine or class promises will \\nbe true before it calls the routine or instantiates the object. Preconditions are the client \\ncode’s obligations to the code it calls.\\nPostconditions are the properties that the routine or class promises will be true when it \\nconcludes executing. Postconditions are the routine’s or class’s obligations to the \\ncode that uses it.\\nAssertions are a useful tool for documenting preconditions and postconditions. Com-\\nments could be used to document preconditions and postconditions, but, unlike com-\\nments, assertions can check dynamically whether the preconditions and \\npostconditions are true.\\nIn the following example, assertions are used to document the preconditions and \\npostcondition of the Velocity routine.\\nVisual Basic Example of Using Assertions to Document Preconditions and \\nPostconditions\\nPrivate Function Velocity ( _\\nByVal latitude As Single, _\\nByVal longitude As Single, _\\nByVal elevation As Single _\\n) As Single\\n\\' Preconditions\\nDebug.Assert ( -90 <= latitude And latitude <= 90 )\\nDebug.Assert ( 0 <= longitude And longitude < 360 )\\nDebug.Assert ( -500 <= elevation And elevation <= 75000 )'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 229}, page_content='8.2 Assertions 193\\n...\\n\\' Postconditions\\nDebug.Assert ( 0 <= returnVelocity And returnVelocity <= 600 )\\n\\' return value\\nVelocity = returnVelocity\\nEnd Function\\nIf the variables latitude, longitude, and elevation were coming from an external source, \\ninvalid values should be checked and handled by error-handling code rather than by \\nassertions. If the variables are coming from a trusted, internal source, however, and \\nthe routine’s design is based on the assumption that these values will be within their \\nvalid ranges, then assertions are appropriate. \\nCross-Reference For more \\non robustness, see \"Robust-\\nness vs. Correctness\" in Sec-\\ntion 8.3, later in this chapter. \\nFor highly robust code, assert and then handle the error anyway For any given \\nerror condition, a routine will generally use either an assertion or error-handling code, \\nbut not both. Some experts argue that only one kind is needed (Meyer 1997). \\nBut real-world programs and projects tend to be too messy to rely solely on assertions. \\nOn a large, long-lasting system, different parts might be designed by different design-\\ners over a period of 5–10 years or more. The designers will be separated in time, across \\nnumerous versions. Their designs will focus on different technologies at different \\npoints in the system’s development. The designers will be separated geographically, \\nespecially if parts of the system are acquired from external sources. Programmers will \\nhave worked to different coding standards at different points in the system’s lifetime. \\nOn a large development team, some programmers will inevitably be more conscien-\\ntious than others and some parts of the code will be reviewed more rigorously than \\nother parts of the code. Some programmers will unit test their code more thoroughly \\nthan others. With test teams working across different geographic regions and subject \\nto business pressures that result in test coverage that varies with each release, you \\ncan’t count on comprehensive, system-level regression testing, either. \\nIn such circumstances, both assertions and error-handling code might be used to \\naddress the same error. In the source code for Microsoft Word, for example, condi-\\ntions that should always be true are asserted, but such errors are also handled by \\nerror-handling code in case the assertion fails. For extremely large, complex, long-\\nlived applications like Word, assertions are valuable because they help to flush out as \\nmany development-time errors as possible. But the application is so complex (mil-\\nlions of lines of code) and has gone through so many generations of modification that \\nit isn’t realistic to assume that every conceivable error will be detected and corrected \\nbefore the software ships, and so errors must be handled in the production version of \\nthe system as well.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 230}, page_content=\"194 Chapter 8: Defensive Programming\\nHere’s an example of how that might work in the Velocity example: \\nVisual Basic Example of Using Assertions to Document Preconditions and \\nPostconditions\\nPrivate Function Velocity ( _\\nByRef latitude As Single, _\\nByRef longitude As Single, _\\nByRef elevation As Single _\\n) As Single\\n' Preconditions\\nHere is the assertion code. Debug.Assert ( -90 <= latitude And latitude <= 90 )\\nDebug.Assert ( 0 <= longitude And longitude < 360 )\\nDebug.Assert ( -500 <= elevation And elevation <= 75000 )\\n...\\n' Sanitize input data. Values should be within the ranges asserted above,\\n' but if a value is not within its valid range, it will be changed to the\\n' closest legal value\\nHere is the code that handles \\nbad input data at run time. \\nIf ( latitude < -90 ) Then\\nlatitude = -90\\nElseIf ( latitude > 90 ) Then\\nlatitude = 90\\nEnd If\\nIf ( longitude < 0 ) Then\\nlongitude = 0\\nElseIf ( longitude > 360 ) Then\\n...\\n8.3 Error-Handling Techniques\\nAssertions are used to handle errors that  should never occur in the code. How do \\nyou handle errors that you do expect to occur? Depending on the specific circum-\\nstances, you might want to return a neutra l value, substitute the next piece of valid \\ndata, return the same answer as the previous time, substitute the closest legal value, \\nlog a warning message to a file, return an error code, call an error-processing routine \\nor object, display an error message, or shut down—or you might want to use a com-\\nbination of these responses.\\nHere are some more details on these options:\\nReturn a neutral valueSometimes the best response to bad data is to continue oper-\\nating and simply return a value that’s known to be harmless. A numeric computation \\nmight return 0. A string operation might return an empty string, or a pointer opera-\\ntion might return an empty pointer. A drawing routine that gets a bad input value for \\ncolor in a video game might use the default background or foreground color. A draw-\\ning routine that displays x-ray data for cancer patients, however, would not want to \\ndisplay a “neutral value.” In that case, you’d be better off shutting down the program \\nthan displaying incorrect patient data.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 231}, page_content='8.3 Error-Handling Techniques 195\\nSubstitute the next piece of valid data When processing a stream of data, some cir-\\ncumstances call for simply returning the next valid data. If you’re reading records \\nfrom a database and encounter a corrupted record, you might simply continue read-\\ning until you find a valid record. If you’re taking readings from a thermometer 100 \\ntimes per second and you don’t get a valid reading one time, you might simply wait \\nanother 1/100th of a second and take the next reading. \\nReturn the same answer as the previous time If the thermometer-reading software \\ndoesn’t get a reading one time, it might simply return the same value as last time. \\nDepending on the application, temperatures might not be very likely to change much in \\n1/100th of a second. In a video game, if you detect a request to paint part of the screen \\nan invalid color, you might simply return the same color used previously. But if you’re \\nauthorizing transactions at a cash machine, you probably wouldn’t want to use the \\n“same answer as last time”—that would be the previous user’s bank account number!\\nSubstitute the closest legal value In some cases, you might choose to return the clos-\\nest legal value, as in the Velocity example earlier. This is often a reasonable approach \\nwhen taking readings from a calibrated instrument. The thermometer might be cali-\\nbrated between 0 and 100 degrees Celsius, for example. If you detect a reading less \\nthan 0, you can substitute 0, which is the closest legal value. If you detect a value \\ngreater than 100, you can substitute 100. For a string operation, if a string length is \\nreported to be less than 0, you could substitute 0. My car uses this approach to error \\nhandling whenever I back up. Since my speedometer doesn’t show negative speeds, \\nwhen I back up it simply shows a speed of 0—the closest legal value. \\nLog a warning message to a file When bad data is detected, you might choose to log \\na warning message to a file and then continue on. This approach can be used in con-\\njunction with other techniques like substituting the closest legal value or substituting \\nthe next piece of valid data. If you use a log, consider whether you can safely make it \\npublicly available or whether you need to encrypt it or protect it some other way. \\nReturn an error code You could decide that only certain parts of a system will han-\\ndle errors. Other parts will not handle errors locally; they will simply report that an \\nerror has been detected and trust that some other routine higher up in the calling hier-\\narchy will handle the error. The specific mechanism for notifying the rest of the sys-\\ntem that an error has occurred could be any of the following:\\n■ Set the value of a status variable \\n■ Return status as the function’s return value\\n■ Throw an exception by using the language’s built-in exception mechanism\\nIn this case, the specific error-reporting mechanism is less important than the deci-\\nsion about which parts of the system will handle errors directly and which will just \\nreport that they’ve occurred. If security is an issue, be sure that calling routines always \\ncheck return codes.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 232}, page_content='196 Chapter 8: Defensive Programming\\nCall an error-processing routine/object Another approach is to centralize error han-\\ndling in a global error-handling routine or error-handling object. The advantage of this \\napproach is that error-processing responsibility can be centralized, which can make \\ndebugging easier. The tradeoff is that the whole program will know about this central \\ncapability and will be coupled to it. If you ever want to reuse any of the code from the \\nsystem in another system, you’ll have to drag the error-handling machinery along \\nwith the code you reuse. \\nThis approach has an important security implication. If your code has encountered a \\nbuffer overrun, it’s possible that an attacker has compromised the address of the han-\\ndler routine or object. Thus, once a buffer overrun has occurred while an application \\nis running, it is no longer safe to use this approach. \\nDisplay an error message wherever the error is encounteredThis approach mini-\\nmizes error-handling overhead; however, it does have the potential to spread user \\ninterface messages through the entire application, which can create challenges when \\nyou need to create a consistent user interface, when you try to clearly separate the UI \\nfrom the rest of the system, or when you try to localize the software into a different \\nlanguage. Also, beware of telling a potential attacker of the system too much. Attackers \\nsometimes use error messages to discover how to attack a system. \\nHandle the error in whatever way works best locally Some designs call for handling \\nall errors locally—the decision of which specific error-handling method to use is left \\nup to the programmer designing and implementing the part of the system that \\nencounters the error. \\nThis approach provides individual developers with great flexibility, but it creates a sig-\\nnificant risk that the overall performance of the system will not satisfy its require-\\nments for correctness or robustness (more on this in a moment). Depending on how \\ndevelopers end up handling specific errors, this approach also has the potential to \\nspread user interface code throughout the system, which exposes the program to all \\nthe problems associated with displaying error messages.\\nShut down Some systems shut down whenever they detect an error. This approach \\nis useful in safety-critical applications. For example, if the software that controls radi-\\nation equipment for treating cancer patients receives bad input data for the radiation \\ndosage, what is its best error-handling response? Should it use the same value as last \\ntime? Should it use the closest legal value? Should it use a neutral value? In this case, \\nshutting down is the best option. We’d much prefer to reboot the machine than to run \\nthe risk of delivering the wrong dosage. \\nA similar approach can be used to improve the security of Microsoft Windows. By \\ndefault, Windows continues to operate even when its security log is full. But you can \\nconfigure Windows to halt the server if the security log becomes full, which can be \\nappropriate in a security-critical environment.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 233}, page_content='8.3 Error-Handling Techniques 197\\nRobustness vs. Correctness\\nAs the video game and x-ray examples show us, the style of error processing that is \\nmost appropriate depends on the kind of software the error occurs in. These exam-\\nples also illustrate that error processing generally favors more correctness or more \\nrobustness. Developers tend to use these terms informally, but, strictly speaking, \\nthese terms are at opposite ends of the scale from each other. Correctness means never \\nreturning an inaccurate result; returning no result is better than returning an inaccu-\\nrate result. Robustness means always trying to do something that will allow the soft-\\nware to keep operating, even if that leads to results that are inaccurate sometimes. \\nSafety-critical applications tend to favor correctness to robustness. It is better to return \\nno result than to return a wrong result. The radiation machine is a good example of \\nthis principle. \\nConsumer applications tend to favor robustness to correctness. Any result whatsoever is \\nusually better than the software shutting down. The word processor I’m using occasion-\\nally displays a fraction of a line of text at the bottom of the screen. If it detects that con-\\ndition, do I want the word processor to shut down? No. I know that the next time I hit \\nPage Up or Page Down, the screen will refresh and the display will be back to normal.\\nHigh-Level Design Implications of Error Processing \\nWith so many options, you need to be careful to handle invalid parameters in consistent \\nways throughout the program. The way in which errors are handled affects the software’s \\nability to meet requirements related to correctness, robustness, and other nonfunctional \\nattributes. Deciding on a general approach to bad parameters is an architectural or high-\\nlevel design decision and should be addressed at one of those levels.\\nOnce you decide on the approach, make sure you follow it consistently. If you decide \\nto have high-level code handle errors and low-level code merely report errors, make \\nsure the high-level code actually handles the errors! Some languages give you the \\noption of ignoring the fact that a function is returning an error code—in C++, you’re \\nnot required to do anything with a function’s return value—but don’t ignore error \\ninformation! Test the function return value. If you don’t expect the function ever to \\nproduce an error, check it anyway. The whole point of defensive programming is \\nguarding against errors you don’t expect.\\nThis guideline holds true for system functions as well as for your own functions. \\nUnless you’ve set an architectural guideline of not checking system calls for errors, \\ncheck for error codes after each call. If you detect an error, include the error number \\nand the description of the error.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 234}, page_content='198 Chapter 8: Defensive Programming\\n8.4 Exceptions\\nExceptions are a specific means by which code can pass along errors or exceptional \\nevents to the code that called it. If code in one routine encounters an unexpected con-\\ndition that it doesn’t know how to handle, it throws an exception, essentially throwing \\nup its hands and yelling, “I don’t know what to do about this—I sure hope somebody \\nelse knows how to handle it!” Code that has no sense of the context of an error can \\nreturn control to other parts of the system that might have a better ability to interpret \\nthe error and do something useful about it. \\nExceptions can also be used to straighten out tangled logic within a single stretch of \\ncode, such as the “Rewrite with try-finally” example in Section 17.3. The basic structure \\nof an exception is that a routine uses throw to throw an exception object. Code in some \\nother routine up the calling hierarchy will catch the exception within a try-catch block. \\nPopular languages vary in how they implement exceptions. Table 8-1 summarizes the \\nmajor differences in three of them:\\nTable 8-1 Popular-Language Support for Exceptions \\nException \\nAttribute C++ Java Visual Basic\\nTry-catch support yes yes yes\\nTry-catch-finally \\nsupport\\nno yes yes\\nWhat can be \\nthrown\\nException object or \\nobject derived from \\nException class; object \\npointer; object refer-\\nence; data type like \\nstring or int\\nException object or \\nobject derived from \\nException class\\nException object or \\nobject derived from \\nException class\\nEffect of uncaught \\nexception\\nInvokes std::unex-\\npected(), which by \\ndefault invokes \\nstd::terminate(), \\nwhich by default \\ninvokes abort()\\nTerminates thread \\nof execution if \\nexception is a \\n“checked excep-\\ntion”; no effect if \\nexception is a \\n“runtime \\nexception”\\nTerminates \\nprogram\\nExceptions thrown \\nmust be defined \\nin class interface\\nNo Yes No\\nExceptions caught \\nmust be defined \\nin class interface\\nNo Yes No'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 235}, page_content='8.4 Exceptions 199\\nPrograms that use excep-\\ntions as part of their normal \\nprocessing suffer from all \\nthe readability and maintain-\\nability problems of classic \\nspaghetti code.\\n—Andy Hunt and Dave \\nThomas\\nExceptions have an attribute in common with inheritance: used judiciously, they can \\nreduce complexity. Used imprudently, they can make code almost impossible to fol-\\nlow. This section contains suggestions for realizing the benefits of exceptions and \\navoiding the difficulties often associated with them. \\nUse exceptions to notify other parts of the program about errors that should not be \\nignored The overriding benefit of exceptions is their ability to signal error condi-\\ntions in such a way that they cannot be ignored (Meyers 1996). Other approaches to \\nhandling errors create the possibility that an error condition can propagate through a \\ncode base undetected. Exceptions eliminate that possibility. \\nThrow an exception only for conditions that are truly exceptional Exceptions \\nshould be reserved for conditions that are truly exceptional—in other words, for con-\\nditions that cannot be addressed by other coding practices. Exceptions are used in \\nsimilar circumstances to assertions—for events that are not just infrequent but for \\nevents that should never occur.\\nExceptions represent a tradeoff between a powerful way to handle unexpected condi-\\ntions on the one hand and increased complexity on the other. Exceptions weaken \\nencapsulation by requiring the code that calls a routine to know which exceptions \\nmight be thrown inside the code that’s called. That increases code complexity, which \\nworks against what Chapter 5, “Design in Construction,” refers to as Software’s Pri-\\nmary Technical Imperative: Managing Complexity. \\nDon’t use an exception to pass the buck If an error condition can be handled locally, \\nhandle it locally. Don’t throw an uncaught exception in a section of code if you can \\nhandle the error locally. \\nAvoid throwing exceptions in constructors and destructors unless you catch them in the \\nsame place The rules for how exceptions are processed become very complicated \\nvery quickly when exceptions are thrown in constructors and destructors. In C++, for \\nexample, destructors aren’t called unless an object is fully constructed, which means \\nif code within a constructor throws an exception, the destructor won’t be called, \\nthereby setting up a possible resource leak (Meyers 1996, Stroustrup 1997). Similarly \\ncomplicated rules apply to exceptions within destructors.  \\nLanguage lawyers might say that remembering rules like these is “trivial,” but pro-\\ngrammers who are mere mortals will have trouble remembering them. It’s better pro-\\ngramming practice simply to avoid the extra complexity such code creates by not \\nwriting that kind of code in the first place. \\nCross-Reference For more \\non maintaining consistent \\ninterface abstractions, see \\n\"Good Abstraction\" in \\nSection 6.2.\\nThrow exceptions at the right level of abstraction A routine should present a consis-\\ntent abstraction in its interface, and so should a class. The exceptions thrown are part \\nof the routine interface, just like specific data types are.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 236}, page_content='200 Chapter 8: Defensive Programming\\nWhen you choose to pass an exception to the caller, make sure the exception’s level of \\nabstraction is consistent with the routine interface’s abstraction. Here’s an example of \\nwhat not to do:\\nBad Java Example of a Class that Throws an Exception at an Inconsistent Level \\nof Abstraction\\nclass Employee {\\n...\\nHere is the declaration of the \\nexception that’s at an incon-\\nsistent level of abstraction. \\npublic TaxId GetTaxId() throws EOFException {\\n...\\n}\\n...\\n}\\nThe GetTaxId() code passes the lower-level EOFException exception back to its caller. It \\ndoesn’t take ownership of the exception itself; it exposes some details about how it’s \\nimplemented by passing the lower-level exception to its caller. This effectively couples \\nthe routine’s client’s code not to the Employee class’s code but to the code below the \\nEmployee class that throws the EOFException exception. Encapsulation is broken, and \\nintellectual manageability starts to decline. \\nInstead, the GetTaxId() code should pass back an exception that’s consistent with the \\nclass interface of which it’s a part, like this:\\nGood Java Example of a Class that Throws an Exception at a Consistent Level \\nof Abstraction\\nclass Employee {\\n...\\nHere is the declaration of \\nthe exception that contrib-\\nutes to a consistent level \\nof abstraction.\\npublic TaxId GetTaxId() throws EmployeeDataNotAvailable {\\n...\\n}\\n...\\n}\\nThe exception-handling code inside GetTaxId() will probably just map the \\nio_disk_not_ready exception onto the EmployeeDataNotAvailable exception, which is \\nfine because that’s sufficient to preserve the interface abstraction. \\nInclude in the exception message all information that led to the exception Every \\nexception occurs in specific circumstances that are detected at the time the code \\nthrows the exception. This information is invaluable to the person who reads the \\nexception message. Be sure the message contains the information needed to under-\\nstand why the exception was thrown. If the exception was thrown because of an array \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 237}, page_content='8.4 Exceptions 201\\nindex error, be sure the exception message includes the upper and lower array limits \\nand the value of the illegal index. \\nAvoid empty catch blocks Sometimes it’s tempting to pass off an exception that you \\ndon’t know what to do with, like this:\\nBad Java Example of Ignoring an Exception\\ntry {\\n...\\n// lots of code\\n...\\n} catch ( AnException exception ) {\\n}\\nSuch an approach says that either the code within the try block is wrong because it \\nraises an exception for no reason, or the code within the catch block is wrong because \\nit doesn’t handle a valid exception. Determine which is the root cause of the problem, \\nand then fix either the try block or the catch block. \\nYou might occasionally find rare circumstances in which an exception at a lower level \\nreally doesn’t represent an exception at the level of abstraction of the calling routine. If \\nthat’s the case, at least document why an empty catch block is appropriate. You could \\n“document” that case with comments or by logging a message to a file, as follows:\\nGood Java Example of Ignoring an Exception\\ntry {\\n...\\n// lots of code\\n...\\n} catch ( AnException exception ) {\\nLogError( \"Unexpected exception\" );\\n}\\nKnow the exceptions your library code throws If you’re working in a language that \\ndoesn’t require a routine or class to define the exceptions it throws, be sure you know \\nwhat exceptions are thrown by any library code you use. Failing to catch an exception \\ngenerated by library code will crash your program just as fast as failing to catch an \\nexception you generated yourself. If the library code doesn’t document the exceptions it \\nthrows, create prototyping code to exercise the libraries and flush out the exceptions. \\nConsider building a centralized exception reporter One approach to ensuring con-\\nsistency in exception handling is to use a centralized exception reporter. The central-\\nized exception reporter provides a central repository for knowledge about what kinds \\nof exceptions there are, how each exception should be handled, formatting of excep-\\ntion messages, and so on. \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 238}, page_content='202 Chapter 8: Defensive Programming\\nHere is an example of a simple exception handler that simply prints a diagnostic \\nmessage: \\nVisual Basic Example of a Centralized Exception Reporter, Part 1\\nFurther Reading For a more \\ndetailed explanation of this \\ntechnique, see Practical \\nStandards for Microsoft \\nVisual Basic .NET (Foxall \\n2003). \\nSub ReportException( _\\nByVal className, _\\nByVal thisException As Exception _\\n)\\nDim message As String\\nDim caption As String\\nmessage = \"Exception: \" & thisException.Message & \".\" & ControlChars.CrLf & _\\n\"Class: \" & className & ControlChars.CrLf & _\\n\"Routine: \" & thisException.TargetSite.Name & ControlChars.CrLf\\ncaption = \"Exception\"\\nMessageBox.Show( message, caption, MessageBoxButtons.OK, _\\nMessageBoxIcon.Exclamation )\\nEnd Sub\\nYou would use this generic exception handler with code like this: \\nVisual Basic Example of a Centralized Exception Reporter, Part 2\\nTry\\n...\\nCatch exceptionObject As Exception\\nReportException( CLASS_NAME, exceptionObject )\\nEnd Try\\nThe code in this version of ReportException() is simple. In a real application, you \\ncould make the code as simple or as elab orate as needed to meet your exception-\\nhandling needs. \\nIf you do decide to build a centralized exception reporter, be sure to consider the gen-\\neral issues involved in centralized error handling, which are discussed in \"Call an \\nerror-processing routine/object\" in Section 8.3.\\nStandardize your project’s use of exceptions To keep exception handling as intel-\\nlectually manageable as possible, you can standardize your use of exceptions in sev-\\neral ways:\\n■ If you’re working in a language like C++ that allows you to throw a variety of \\nkinds of objects, data, and pointers, standardize on what specifically you will \\nthrow. For compatibility with other languages, consider throwing only objects \\nderived from the Exception base class.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 239}, page_content='8.5 Barricade Your Program to Contain the Damage Caused by Errors 203\\n■ Consider creating your own project-specific exception class, which can serve as \\nthe base class for all exceptions thrown on your project. This supports centraliz-\\ning and standardizing logging, error reporting, and so on. \\n■ Define the specific circumstances under which code is allowed to use throw-\\ncatch syntax to perform error processing locally. \\n■ Define the specific circumstances under which code is allowed to throw an \\nexception that won’t be handled locally. \\n■ Determine whether a centralized exception reporter will be used. \\n■ Define whether exceptions are allowed in constructors and destructors. \\nCross-Reference For numer-\\nous alternative error-han-\\ndling approaches, see \\nSection 8.3, \"Error-Handling \\nTechniques,” earlier in this \\nchapter. \\nConsider alternatives to exceptions Several programming languages have sup-\\nported exceptions for 5–10 years or more, but little conventional wisdom has emerged \\nabout how to use them safely. \\nSome programmers use exceptions to handle errors just because their language pro-\\nvides that particular error-handling mechanism. You should always consider the full \\nset of error-handling alternatives: handling the error locally, propagating the error by \\nusing an error code, logging debug information to a file, shutting down the system, or \\nusing some other approach. Handling errors with exceptions just because your lan-\\nguage provides exception handling is a classic example of programming in a language \\nrather than programming into a language. (For details on that distinction, see Section \\n4.3, “Your Location on the Technology Wave,” and Section 34.4, \"Program into Your \\nLanguage, Not in It.\"\\nFinally, consider whether your program really needs to handle exceptions, period. As \\nBjarne Stroustrup points out, sometimes the best response to a serious run-time error \\nis to release all acquired resources and abort. Let the user rerun the program with \\nproper input (Stroustrup 1997).  \\n8.5 Barricade Your Program to Contain the Damage Caused \\nby Errors \\nBarricades are a damage-containment strategy. The reason is similar to that for having \\nisolated compartments in the hull of a ship. If the ship runs into an iceberg and pops \\nopen the hull, that compartment is shut off and the rest of the ship isn’t affected. They \\nare also similar to firewalls in a building. A building’s firewalls prevent fire from spread-\\ning from one part of a building to another part. (Barricades used to be called “firewalls,” \\nbut the term “firewall” now commonly refers to blocking hostile network traffic.)\\nOne way to barricade for defensive programming purposes is to designate certain \\ninterfaces as boundaries to “safe” areas. Check data crossing the boundaries of a safe'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 240}, page_content='204 Chapter 8: Defensive Programming\\narea for validity, and respond sensibly if the data isn’t valid. Figure 8-2 illustrates \\nthis concept.\\nFigure 8-2 Defining some parts of the software that work with dirty data and some that \\nwork with clean data can be an effective way to relieve the majority of the code of the \\nresponsibility for checking for bad data. \\nThis same approach can be used at the class level. The class’s public methods assume \\nthe data is unsafe, and they are responsible for checking the data and sanitizing it. \\nOnce the data has been accepted by the class’s public methods, the class’s private \\nmethods can assume the data is safe. \\nAnother way of thinking about this approach is as an operating-room technique. Data \\nis sterilized before it’s allowed to enter the operating room. Anything that’s in the \\noperating room is assumed to be safe. The key design decision is deciding what to put \\nin the operating room, what to keep out, and where to put the doors—which routines \\nare considered to be inside the safety zone, which are outside, and which sanitize the \\ndata. The easiest way to do this is usually by sanitizing external data as it arrives, but \\ndata often needs to be sanitized at more than one level, so multiple levels of steriliza-\\ntion are sometimes required.\\nConvert input data to the proper type at input time Input typically arrives in the \\nform of a string or number. Sometimes the value will map onto a boolean type like \\n“yes” or “no.” Sometimes the value will map onto an enumerated type like Color_Red, \\nColor_Green, and Color_Blue. Carrying data of questionable type for any length of time \\nin a program increases complexity and increases the chance that someone can crash \\nyour program by inputting a color like “Yes.” Convert input data to the proper form as \\nsoon as possible after it’s input. \\nInternal \\nClass 11\\nInternal \\nClass 9\\nInternal \\nClass 7\\nInternal \\nClass 5\\nInternal \\nClass 3\\nInternal \\nClass 1\\nInternal \\nClass n\\nInternal \\nClass 10\\nInternal \\nClass 8\\nInternal \\nClass 6\\nInternal \\nClass 4\\nInternal \\nClass 2\\nValidation \\nClass 1\\nValidation \\nClass 2\\nValidation \\nClass n\\nGraphical \\nUser Interface\\nCommand \\nLine Interface\\nReal-time \\nData Feed\\nExternal \\nFiles\\nOther external \\nobjects\\nData here is \\nassumed to be dirty \\nand untrusted.\\nThese classes are responsible \\nfor cleaning the data. They \\nmake up the barricade.\\nThese classses can \\nassume data is clean \\nand trusted.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 241}, page_content='8.6 Debugging Aids 205\\nRelationship Between Barricades and Assertions\\nThe use of barricades makes the distinction between assertions and error handling \\nclean-cut. Routines that are outside the barricade should use error handling because it \\nisn’t safe to make any assumptions about the data. Routines inside the barricade \\nshould use assertions, because the data passed to them is supposed to be sanitized \\nbefore it’s passed across the barricade. If one of the routines inside the barricade \\ndetects bad data, that’s an error in the program rather than an error in the data. \\nThe use of barricades also illustrates the value of deciding at the architectural level \\nhow to handle errors. Deciding which code is inside and which is outside the barri-\\ncade is an architecture-level decision. \\n8.6 Debugging Aids\\nAnother key aspect of defensive programming is the use of debugging aids, which can \\nbe a powerful ally in quickly detecting errors. \\nDon’t Automatically Apply Production Constraints to the \\nDevelopment Version\\nFurther Reading For more \\non using debug code to sup-\\nport defensive program-\\nming, see Writing Solid Code \\n(Maguire 1993). \\nA common programmer blind spot is the assumption that limitations of the produc-\\ntion software apply to the development version. The production version has to run \\nfast. The development version might be able to run slow. The production version has \\nto be stingy with resources. The development version might be allowed to use \\nresources extravagantly. The production version shouldn’t expose dangerous opera-\\ntions to the user. The development version can have extra operations that you can use \\nwithout a safety net. \\nOne program I worked on made extensive use of a quadruply linked list. The linked-\\nlist code was error prone, and the linked list tended to get corrupted. I added a menu \\noption to check the integrity of the linked list. \\nIn debug mode, Microsoft Word contains code in the idle loop that checks the integ-\\nrity of the Document object every few seconds. This helps to detect data corruption \\nquickly, and it makes for easier error diagnosis. \\nBe willing to trade speed and resource usage during development in exchange for \\nbuilt-in tools that can make development go more smoothly. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 242}, page_content='206 Chapter 8: Defensive Programming\\nIntroduce Debugging Aids Early\\nThe earlier you introduce debugging aids, the more they’ll help. Typically, you won’t \\ngo to the effort of writing a debugging aid until after you’ve been bitten by a problem \\nseveral times. If you write the aid after the first time, however, or use one from a previ-\\nous project, it will help throughout the project.\\nUse Offensive Programming\\nCross-Reference For more \\ndetails on handling unantici-\\npated cases, see \"Tips for \\nUsing case Statements\" in \\nSection 15.2.\\nExceptional cases should be handled in a way that makes them obvious during \\ndevelopment and recoverable when production code is running. Michael Howard \\nand David LeBlanc refer to this approach as “offensive programming” (Howard and \\nLeBlanc 2003).\\nSuppose you have a case statement that you expect to handle only five kinds of \\nevents. During development, the default case should be used to generate a warning \\nthat says “Hey! There’s another case he re! Fix the program!” During production, \\nhowever, the default case should do so mething more graceful , like writing a mes-\\nsage to an error-log file.\\nA dead program normally \\ndoes a lot less damage than \\na crippled one.\\n—Andy Hunt and \\nDave Thomas\\nHere are some ways you can program offensively:\\n■ Make sure asserts abort the program. Don’t allow programmers to get into the \\nhabit of just hitting the Enter key to bypass a known problem. Make the prob-\\nlem painful enough that it will be fixed. \\n■ Completely fill any memory allocated so that you can detect memory allocation \\nerrors. \\n■ Completely fill any files or streams allocated to flush out any file-format errors. \\n■ Be sure the code in each case statement’s default or else clause fails hard (aborts \\nthe program) or is otherwise impossible to overlook. \\n■ Fill an object with junk data just before it’s deleted.\\n■ Set up the program to e-mail error log files to yourself so that you can see the \\nkinds of errors that are occurring in the released software, if that’s appropriate \\nfor the kind of software you’re developing. \\nSometimes the best defense is a good offense. Fail hard during development so that \\nyou can fail softer during production.\\nPlan to Remove Debugging Aids\\nIf you’re writing code for your own use, it might be fine to leave all the debugging code \\nin the program. If you’re writing code for commercial use, the performance penalty in \\nsize and speed can be prohibitive. Plan to avoid shuffling debugging code in and out \\nof a program. Here are several ways to do that:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 243}, page_content='8.6 Debugging Aids 207\\nCross-Reference For details \\non version control, see Sec-\\ntion 28.2, \"Configuration \\nManagement.\"\\nUse version-control tools and build tools like ant and make Version-control tools \\ncan build different versions of a program from the same source files. In development \\nmode, you can set the build tool to include all the debug code. In production mode, \\nyou can set it to exclude any debug code you don’t want in the commercial version. \\nUse a built-in preprocessor If your programming environment has a preprocessor—\\nas C++ does, for example—you can include or exclude debug code at the flick of a com-\\npiler switch. You can use the preprocessor directly or by writing a macro that works \\nwith preprocessor definitions. Here’s an example of writing code using the preproces-\\nsor directly:\\nC+ + Example of Using the Preprocessor Directly to Control Debug Code\\nTo include the debugging \\ncode, use #define to define \\nthe symbol DEBUG. To \\nexclude the debugging code, \\ndon’t define DEBUG.\\n#define DEBUG\\n...\\n#if defined( DEBUG )\\n// debugging code\\n...\\n#endif\\nThis theme has several variations. Rather than just defining DEBUG, you can assign it \\na value and then test for the value rather than testing whether it’s defined. That way \\nyou can differentiate between different levels of debug code. You might have some \\ndebug code that you want in your program all the time, so you surround that by a \\nstatement like #if DEBUG > 0. Other debug code might be for specific purposes only, \\nso you can surround it by a statement like #if DEBUG == POINTER_ERROR. In other \\nplaces, you might want to set debug levels, so you could have statements like #if \\nDEBUG > LEVEL_A. \\nIf you don’t like having #if defined()s spread throughout your code, you can write a \\npreprocessor macro to accomplish the same task. Here’s an example:\\nC+ + Example of Using a Preprocessor Macro to Control Debug Code \\n#define DEBUG\\n#if defined( DEBUG )\\n#define DebugCode( code_fragment ) { code_fragment }\\n#else\\n#define DebugCode( code_fragment )\\n#endif\\n...\\nDebugCode(\\nThis code is included or \\nexcluded, depending on \\nwhether DEBUG has been \\ndefined.\\nstatement 1;\\nstatement 2;\\n...\\nstatement n;\\n);\\n...'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 244}, page_content=\"208 Chapter 8: Defensive Programming\\nAs in the first example of using the preprocessor, this technique can be altered in a \\nvariety of ways that make it more sophisticated than completely including all debug \\ncode or completely excluding all of it.\\nCross-Reference For more \\ninformation on preproces-\\nsors and for direction to \\nsources of information on \\nwriting one of your own, see \\n“Macro Preprocessors”  in \\nSection 30.3.\\nWrite your own preprocessor If a language doesn’t include a preprocessor, it’s fairly \\neasy to write one for including and excluding debug code. Establish a convention for \\ndesignating debug code, and write your precompiler to follow that convention. For \\nexample, in Java you could write a precompiler to respond to the keywords //#BEGIN \\nDEBUG and //#END DEBUG. Write a script to call the preprocessor, and then com-\\npile the processed code. You’ll save time in the long run, and you won’t mistakenly \\ncompile the unpreprocessed code.\\nCross-Reference For details \\non stubs, see “Building Scaf-\\nfolding to Test Individual \\nRoutines” in Section 22.5.\\nUse debugging stubs In many instances, you can call a routine to do debugging \\nchecks. During development, the routine might perform several operations before con-\\ntrol returns to the caller. For production code, you can replace the complicated routine \\nwith a stub routine that merely returns control immediately to the caller or that per-\\nforms a couple of quick operations before returning control. This approach incurs only \\na small performance penalty, and it’s a quicker solution than writing your own prepro-\\ncessor. Keep both the development and production versions of the routines so that you \\ncan switch back and forth during future development and production.\\nYou might start with a routine designed to check pointers that are passed to it: \\nC+ + Example of a Routine That Uses a Debugging Stub\\nvoid DoSomething(\\nSOME_TYPE *pointer;\\n...\\n){\\n// check parameters passed in\\nThis line calls the routine to \\ncheck the pointer.\\nCheckPointer( pointer );\\n...\\n}\\nDuring development, the CheckPointer() routine would perform full checking on the \\npointer. It would be slow but effective, and it could look like this: \\nC+ + Example of a Routine for Checking Pointers During Development\\nThis routine checks any \\npointer that’s passed to it. It \\ncan be used during develop-\\nment to perform as many \\nchecks as you can bear. \\nvoid CheckPointer( void *pointer ) {\\n// perform check 1--maybe check that it's not NULL\\n// perform check 2--maybe check that its dogtag is legitimate\\n// perform check 3--maybe check that what it points to isn't corrupted\\n...\\n// perform check n--...\\n}\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 245}, page_content='8.7 Determining How Much Defensive Programming to Leave in Production Code 209\\nWhen the code is ready for production, you might not want all the overhead associ-\\nated with this pointer checking. You could swap out the preceding routine and swap \\nin this routine:\\nC+ + Example of a Routine for Checking Pointers During Production\\nThis routine just returns \\nimmediately to the caller.\\nvoid CheckPointer( void *pointer ) {\\n// no code; just return to caller\\n}\\nThis is not an exhaustive survey of all the ways you can plan to remove debugging \\naids, but it should be enough to give you an idea for some things that will work in your \\nenvironment.\\n8.7 Determining How Much Defensive Programming to \\nLeave in Production Code \\nOne of the paradoxes of defensive programming is that during development, you’d like \\nan error to be noticeable—you’d rather have it be obnoxious than risk overlooking it. But \\nduring production, you’d rather have the error be as unobtrusive as possible, to have the \\nprogram recover or fail gracefully. Here are some guidelines for deciding which defen-\\nsive programming tools to leave in your production code and which to leave out:\\nLeave in code that checks for important errors Decide which areas of the program \\ncan afford to have undetected errors and which areas cannot. For example, if you were \\nwriting a spreadsheet program, you could afford to have undetected errors in the \\nscreen-update area of the program because the main penalty for an error is only a \\nmessy screen. You could not afford to have undetected errors in the calculation engine \\nbecause such errors might result in subtly incorrect results in someone’s spreadsheet. \\nMost users would rather suffer a messy screen than incorrect tax calculations and an \\naudit by the IRS. \\nRemove code that checks for trivial errors If an error has truly trivial consequences, \\nremove code that checks for it. In the previous example, you might remove the code \\nthat checks the spreadsheet screen update. “Remove” doesn’t mean physically remove \\nthe code. It means use version control, precompiler switches, or some other technique \\nto compile the program without that particular code. If space isn’t a problem, you \\ncould leave in the error-checking code but have it log messages to an error-log file \\nunobtrusively.\\nRemove code that results in hard crashes As I mentioned, during development, \\nwhen your program detects an error, you’d like the error to be as noticeable as possi-\\nble so that you can fix it. Often, the best way to accomplish that goal is to have the pro-\\ngram print a debugging message and crash when it detects an error. This is useful \\neven for minor errors.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 246}, page_content='210 Chapter 8: Defensive Programming\\nDuring production, your users need a chance to save their work before the program \\ncrashes and they are probably willing to tolerate a few anomalies in exchange for keep-\\ning the program going long enough for them to do that. Users don’t appreciate any-\\nthing that results in the loss of their work, regardless of how much it helps debugging \\nand ultimately improves the quality of the program. If your program contains debug-\\nging code that could cause a loss of data, take it out of the production version.\\nLeave in code that helps the program crash gracefully If your program contains \\ndebugging code that detects potentially fatal errors, leave the code in that allows the \\nprogram to crash gracefully. In the Mars Pathfinder, for example, engineers left some \\nof the debug code in by design. An error occurred after the Pathfinder had landed. By \\nusing the debug aids that had been left in, engineers at JPL were able to diagnose the \\nproblem and upload revised code to the Pathfinder, and the Pathfinder completed its \\nmission perfectly (March 1999).\\nLog errors for your technical support personnel Consider leaving debugging aids in \\nthe production code but changing their behavior so that it’s appropriate for the pro-\\nduction version. If you’ve loaded your code with assertions that halt the program dur-\\ning development, you might consider changing the assertion routine to log messages \\nto a file during production rather than eliminating them altogether. \\nMake sure that the error messages you leave in are friendly If you leave internal \\nerror messages in the program, verify that they’re in language that’s friendly to the \\nuser. In one of my early programs, I got a call from a user who reported that she’d got-\\nten a message that read “You’ve got a bad pointer allocation, Dog Breath!” Fortunately \\nfor me, she had a sense of humor. A common and effective approach is to notify the \\nuser of an “internal error” and list an e-mail address or phone number the user can \\nuse to report it.\\n8.8 Being Defensive About Defensive Programming\\nToo much of anything is bad, \\nbut too much whiskey is just \\nenough. \\n—Mark Twain\\nToo much defensive programming creates problems of its own. If you check data \\npassed as parameters in every conceivable way in every conceivable place, your pro-\\ngram will be fat and slow. What’s worse, the additional code needed for defensive pro-\\ngramming adds complexity to the software. Code installed for defensive \\nprogramming is not immune to defects, and you’re just as likely to find a defect in \\ndefensive-programming code as in any other code—more likely, if you write the code \\ncasually. Think about where you need to be defensive, and set your defensive-pro-\\ngramming priorities accordingly.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 247}, page_content='8.8 Being Defensive About Defensive Programming 211\\ncc2e.com/0868 CHECKLIST: Defensive Programming\\nGeneral\\n❑ Does the routine protect itself from bad input data? \\n❑ Have you used assertions to document assumptions, including precondi-\\ntions and postconditions?\\n❑ Have assertions been used only to document conditions that should never \\noccur? \\n❑ Does the architecture or high-level design specify a specific set of error-\\nhandling techniques? \\n❑ Does the architecture or high-level design specify whether error handling \\nshould favor robustness or correctness? \\n❑ Have barricades been created to contain the damaging effect of errors and \\nreduce the amount of code that has to be concerned about error process-\\ning?\\n❑ Have debugging aids been used in the code?\\n❑ Have debugging aids been installed in such a way that they can be acti-\\nvated or deactivated without a great deal of fuss?\\n❑ Is the amount of defensive programming code appropriate—neither too \\nmuch nor too little? \\n❑ Have you used offensive-programming techniques to make errors difficult \\nto overlook during development? \\nExceptions\\n❑ Has your project defined a standardized approach to exception handling?\\n❑ Have you considered alternatives to using an exception?\\n❑ Is the error handled locally rather than throwing a nonlocal exception, if \\npossible? \\n❑ Does the code avoid throwing exceptions in constructors and destructors?\\n❑ Are all exceptions at the appropriate levels of abstraction for the routines \\nthat throw them? \\n❑ Does each exception include all relevant exception background informa-\\ntion?\\n❑ Is the code free of empty catch blocks? (Or if an empty catch block truly is \\nappropriate, is it documented?)'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 248}, page_content='212 Chapter 8: Defensive Programming\\nSecurity Issues\\n❑ Does the code that checks for bad input data check for attempted buffer \\noverflows, SQL injection, HTML injection, integer overflows, and other \\nmalicious inputs? \\n❑ Are all error-return codes checked? \\n❑ Are all exceptions caught? \\n❑ Do error messages avoid providing information that would help an \\nattacker break into the system? \\nAdditional Resources\\ncc2e.com/0875 Take a look at the following defensive-programming resources:\\nSecurity\\nHoward, Michael, and David LeBlanc. Writing Secure Code, 2d ed. Redmond, WA: \\nMicrosoft Press, 2003. Howard and LeBlanc cover the security implications of trusting \\ninput. The book is eye-opening in that it illustrates just how many ways a program can \\nbe breached—some of which have to do with construction practices and many of which \\ndon’t. The book spans a full range of requirements, design, code, and test issues.\\nAssertions\\nMaguire, Steve. Writing Solid Code. Redmond, WA: Microsoft Press, 1993. Chapter 2 \\ncontains an excellent discussion on the use of assertions, including several interesting \\nexamples of assertions in well-known Microsoft products.\\nStroustrup, Bjarne. The C++ Programming Language, 3d ed. Reading, MA: Addison-\\nWesley, 1997. Section 24.3.7.2 describes several variations on the theme of imple-\\nmenting assertions in C++, including the relationship between assertions and precon-\\nditions and postconditions. \\nMeyer, Bertrand. Object-Oriented Software Construction, 2d ed. New York, NY: Prentice \\nHall PTR, 1997. This book contains the definitive discussion of preconditions and \\npostconditions. \\nExceptions\\nMeyer, Bertrand. Object-Oriented Software Construction, 2d ed. New York, NY: Prentice \\nHall PTR, 1997. Chapter 12 contains a detailed discussion of exception handling.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 249}, page_content='Key Points 213\\nStroustrup, Bjarne. The C++ Programming Language, 3d ed. Reading, MA: Addison-\\nWesley, 1997. Chapter 14 contains a detailed discussion of exception handling in C++. \\nSection 14.11 contains an excellent summary of 21 tips for handling C++ exceptions. \\nMeyers, Scott. More Effective C++: 35 New Ways to Improve Your Programs and Designs. \\nReading, MA: Addison-Wesley, 1996. Items 9–15 describe numerous nuances of \\nexception handling in C++. \\nArnold, Ken, James Gosling, and David Holmes. The Java Programming Language, 3d \\ned. Boston, MA: Addison-Wesley, 2000. Chapter 8 contains a discussion of exception \\nhandling in Java. \\nBloch, Joshua. Effective Java Programming Language Guide. Boston, MA: Addison-Wes-\\nley, 2001. Items 39–47 describe nuances of exception handling in Java. \\nFoxall, James. Practical Standards for Microsoft Visual Basic .NET. Redmond, WA: \\nMicrosoft Press, 2003. Chapter 10 describes exception handling in Visual Basic. \\nKey Points\\n■ Production code should handle errors in a more sophisticated way than “gar-\\nbage in, garbage out.”\\n■ Defensive-programming techniques make errors easier to find, easier to fix, and \\nless damaging to production code.\\n■ Assertions can help detect errors early, especially in large systems, high-reliabil-\\nity systems, and fast-changing code bases. \\n■ The decision about how to handle bad inputs is a key error-handling decision \\nand a key high-level design decision.\\n■ Exceptions provide a means of handling errors that operates in a different \\ndimension from the normal flow of the code. They are a valuable addition to the \\nprogrammer’s intellectual toolbox when used with care, and they should be \\nweighed against other error-processing techniques. \\n■ Constraints that apply to the production system do not necessarily apply to the \\ndevelopment version. You can use that to your advantage, adding code to the \\ndevelopment version that helps to flush out errors quickly.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 251}, page_content='215\\nChapter 9\\nThe Pseudocode \\nProgramming Process\\ncc2e.com/0936 Contents\\n■ 9.1 Summary of Steps in Building Classes and Routines: page 216\\n■ 9.2 Pseudocode for Pros: page 218\\n■ 9.3 Constructing Routines by Using the PPP: page 220\\n■ 9.4 Alternatives to the PPP: page 232\\nRelated Topics\\n■ Creating high-quality classes: Chapter 6\\n■ Characteristics of high-quality routines: Chapter 7\\n■ Design in Construction: Chapter 5\\n■ Commenting style: Chapter 32\\nAlthough you could view this whole book as an extended description of the program-\\nming process for creating classes and routines, this chapter puts the steps in context. \\nThis chapter focuses on programming in the small—on the specific steps for building \\nan individual class and its routines, the steps that are critical on projects of all sizes. \\nThe chapter also describes the Pseudocode Programming Process (PPP), which \\nreduces the work required during design and documentation and improves the qual-\\nity of both.\\nIf you’re an expert programmer, you might just skim this chapter, but look at the sum-\\nmary of steps and review the tips for constructing routines using the Pseudocode Pro-\\ngramming Process in Section 9.3. Few programmers exploit the full power of the \\nprocess, and it offers many benefits.\\nThe PPP is not the only procedure for creating classes and routines. Section 9.4, at the \\nend of this chapter, describes the most popular alternatives, including test-first devel-\\nopment and design by contract.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 252}, page_content='216 Chapter 9: The Pseudocode Programming Process\\n9.1 Summary of Steps in Building Classes and Routines\\nClass construction can be approached from numerous directions, but usually it’s an \\niterative process of creating a general design for the class, enumerating specific rou-\\ntines within the class, constructing specific routines, and checking class construction \\nas a whole. As Figure 9-1 suggests, class creation can be a messy process for all the rea-\\nsons that design is a messy process (reasons that are described in Section 5.1, “Design \\nChallenges”).\\nFigure 9-1 Details of class construction vary, but the activities generally occur in the order \\nshown here. \\nSteps in Creating a Class\\nThe key steps in constructing a class are:\\nCreate a general design for the class Class design includes numerous specific issues. \\nDefine the class’s specific responsibilities, define what “secrets” the class will hide, and \\ndefine exactly what abstraction the class interface will capture. Determine whether the \\nclass will be derived from another class and whether other classes will be allowed to \\nderive from it. Identify the class’s key public methods, and identify and design any non-\\ntrivial data members used by the class. Iterate through these topics as many times as \\nneeded to create a straightforward design for the routine. These considerations and \\nmany others are discussed in more detail in Chapter 6, “Working Classes.” \\nBegin\\nDone\\nCreate a \\ngeneral design \\nfor the class\\nReview and \\ntest the class as \\na whole\\nConstruct the \\nroutines within \\nthe class'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 253}, page_content='9.1 Summary of Steps in Building Classes and Routines 217\\nConstruct each routine within the class Once you’ve identified the class’s major rou-\\ntines in the first step, you must construct each specific routine. Construction of each \\nroutine typically unearths the need for additional routines, both minor and major, and \\nissues arising from creating those additional routines often ripple back to the overall \\nclass design. \\nReview and test the class as a whole Normally, each routine is tested as it’s created. \\nAfter the class as a whole becomes operational, the class as a whole should be \\nreviewed and tested for any issues that can’t be tested at the individual-routine level.\\nSteps in Building a Routine\\nMany of a class’s routines will be simple and straightforward to implement: accessor \\nroutines, pass-throughs to other objects’ routines, and the like. Implementation of \\nother routines will be more complicated, and creation of those routines benefits from \\na systematic approach. The major activities involved in creating a routine—designing \\nthe routine, checking the design, coding the routine, and checking the code—are typi-\\ncally performed in the order shown in Figure 9-2.\\nFigure 9-2 These are the major activities that go into constructing a routine. They’re usu-\\nally performed in the order shown.\\nExperts have developed numerous approaches to creating routines, and my favorite \\napproach is the Pseudocode Programming Process, described in the next section. \\nBegin\\nRepeat if \\nnecessary\\nDone\\nDesign the \\nroutine\\nCheck the \\ndesign\\nReview and \\ntest the code\\nCode the \\nroutine'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 254}, page_content='218 Chapter 9: The Pseudocode Programming Process\\n9.2 Pseudocode for Pros\\nThe term “pseudocode” refers to an informal, English-like notation for describing how \\nan algorithm, a routine, a class, or a program will work. The Pseudocode Program-\\nming Process defines a specific approach to using pseudocode to streamline the cre-\\nation of code within routines. \\nBecause pseudocode resembles English, it’s natural to assume that any English-like \\ndescription that collects your thoughts will have roughly the same effect as any other. \\nIn practice, you’ll find that some styles of pseudocode are more useful than others. \\nHere are guidelines for using pseudocode effectively:\\n■ Use English-like statements that precisely describe specific operations. \\n■ Avoid syntactic elements from the target programming language. Pseudocode \\nallows you to design at a slightly higher level than the code itself. When you use \\nprogramming-language constructs, you sink to a lower level, eliminating the \\nmain benefit of design at a higher level, and you saddle yourself with unneces-\\nsary syntactic restrictions.\\nCross-Reference For details \\non commenting at the level \\nof intent, see “Kinds of Com-\\nments” in Section 32.4.\\n■ Write pseudocode at the level of intent. Describe the meaning of the approach \\nrather than how the approach will be implemented in the target language.\\n■ Write pseudocode at a low enough level that generating code from it will be \\nnearly automatic. If the pseudocode is at too high a level, it can gloss over prob-\\nlematic details in the code. Refine the pseudocode in more and more detail until \\nit seems as if it would be easier to simply write the code.\\nOnce the pseudocode is written, you build the code around it and the pseudocode \\nturns into programming-language comments. This eliminates most commenting \\neffort. If the pseudocode follows the guidelines, the comments will be complete and \\nmeaningful.\\nHere’s an example of a design in pseudocode that violates virtually all the principles \\njust described:\\nExample of Bad Pseudocode \\nincrement resource number by 1\\nallocate a dlg struct using malloc\\nif malloc() returns NULL then return 1\\ninvoke OSrsrc_init to initialize a resource for the operating system\\n*hRsrcPtr = resource number\\nreturn 0\\nWhat is the intent of this block of pseudocode? Because it’s poorly written, it’s hard to \\ntell. This so-called pseudocode is bad because it includes target language coding \\ndetails, such as *hRsrcPtr (in specific C-language pointer notation) and malloc() (a spe-\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 255}, page_content='9.2 Pseudocode for Pros 219\\ncific C-language function). This pseudocode block focuses on how the code will be \\nwritten rather than on the meaning of the design. It gets into coding details—whether \\nthe routine returns a 1 or a 0. If you think about this pseudocode from the standpoint \\nof whether it will turn into good comments, you’ll begin to understand that it isn’t \\nmuch help.\\nHere’s a design for the same operation in a much-improved pseudocode: \\nExample of Good Pseudocode\\nKeep track of current number of resources in use\\nIf another resource is available\\n   Allocate a dialog box structure\\n   If a dialog box structure could be allocated\\n      Note that one more resource is in use\\n      Initialize the resource\\n      Store the resource number at the location provided by the caller\\n   Endif\\nEndif\\nReturn true if a new resource was created; else return false\\nThis pseudocode is better than the first because it’s written entirely in English; it \\ndoesn’t use any syntactic elements of the target language. In the first example, the \\npseudocode could have been implemented only in C. In the second example, the \\npseudocode doesn’t restrict the choice of languages. The second block of pseudocode \\nis also written at the level of intent. What does the second block of pseudocode mean? \\nIt is probably easier for you to understand than the first block.\\nEven though it’s written in clear English, the second block of pseudocode is precise \\nand detailed enough that it can easily be used as a basis for programming-language \\ncode. When the pseudocode statements are converted to comments, they’ll be a good \\nexplanation of the code’s intent.\\nHere are the benefits you can expect from using this style of pseudocode:\\n■ Pseudocode makes reviews easier. You can review detailed designs without \\nexamining source code. Pseudocode makes low-level design reviews easier and \\nreduces the need to review the code itself.\\n■ Pseudocode supports the idea of iterative refinement. You start with a high-level \\ndesign, refine the design to pseudocode, and then refine the pseudocode to \\nsource code. This successive refinement in small steps allows you to check your \\ndesign as you drive it to lower levels of detail. The result is that you catch high-\\nlevel errors at the highest level, mid-level errors at the middle level, and low-level \\nerrors at the lowest level—before any of them becomes a problem or contami-\\nnates work at more detailed levels.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 256}, page_content='220 Chapter 9: The Pseudocode Programming Process\\nFurther Reading For more \\ninformation on the advan-\\ntages of making changes at \\nthe least-value stage, see \\nAndy Grove’s High Output \\nManagement (Grove 1983).\\n■ Pseudocode makes changes easier. A few lines of pseudocode are easier to change \\nthan a page of code. Would you rather change a line on a blueprint or rip out a \\nwall and nail in the two-by-fours somewhere else? The effects aren’t as physically \\ndramatic in software, but the principle of changing the product when it’s most \\nmalleable is the same. One of the keys to the success of a project is to catch errors \\nat the “least-value stage,” the stage at which the least effort has been invested. \\nMuch less has been invested at the pseudocode stage than after full coding, test-\\ning, and debugging, so it makes economic sense to catch the errors early.\\n■ Pseudocode minimizes commenting effort. In the typical coding scenario, you \\nwrite the code and add comments afterward. In the PPP, the pseudocode state-\\nments become the comments, so it actually takes more work to remove the com-\\nments than to leave them in.\\n■ Pseudocode is easier to maintain than other forms of design documentation. \\nWith other approaches, design is separated from the code, and when one \\nchanges, the two fall out of agreement. With the PPP, the pseudocode state-\\nments become comments in the code. As long as the inline comments are main-\\ntained, the pseudocode’s documentation of the design will be accurate.\\nAs a tool for detailed design, pseudocode is hard to beat. One survey found that pro-\\ngrammers prefer pseudocode for the way it eases construction in a programming lan-\\nguage, for its ability to help them detect insufficiently detailed designs, and for the \\nease of documentation and ease of modification it provides (Ramsey, Atwood, and \\nVan Doren 1983). Pseudocode isn’t the only tool for detailed design, but pseudocode \\nand the PPP are useful tools to have in your programmer’s toolbox. Try them. The \\nnext section shows you how.\\n9.3 Constructing Routines by Using the PPP\\nThis section describes the activities involved in constructing a routine, namely these:\\n■ Design the routine.\\n■ Code the routine.\\n■ Check the code.\\n■ Clean up loose ends.\\n■ Repeat as needed.\\nDesign the Routine\\nCross-Reference For details \\non other aspects of design, \\nsee Chapters 5 through 8.\\nOnce you’ve identified a class’s routines, the first step in constructing any of the class’s \\nmore complicated routines is to design it. Suppose that you want to write a routine to \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 257}, page_content='9.3 Constructing Routines by Using the PPP 221\\noutput an error message depending on an error code, and suppose that you call the rou-\\ntine ReportErrorMessage(). Here’s an informal spec for ReportErrorMessage():\\nReportErrorMessage()  takes an error code as an input argument and outputs \\nan error message corresponding to the code. It’s responsible for handling \\ninvalid codes. If the program is operating interactively, ReportErrorMessage()  \\ndisplays the message to the user. If it’s operating in command-line mode, \\nReportErrorMessage()  logs the message to a message file. After outputting the \\nmessage, ReportErrorMessage()  returns a status value, indicating whether it \\nsucceeded or failed.\\nThe rest of the chapter uses this routine as a running example. The rest of this section \\ndescribes how to design the routine. \\nCross-Reference For details \\non checking prerequisites, \\nsee Chapter 3, “Measure \\nTwice, Cut Once: Upstream \\nPrerequisites,” and Chapter 4, \\n“Key Construction Decisions.”\\nCheck the prerequisites Before doing any work on the routine itself, check to see that \\nthe job of the routine is well defined and fits cleanly into the overall design. Check to \\nbe sure that the routine is actually called for, at the very least indirectly, by the \\nproject’s requirements.\\nDefine the problem the routine will solve State the problem the routine will solve in \\nenough detail to allow creation of the routine. If the high-level design is sufficiently \\ndetailed, the job might already be done. The high-level design should at least indicate \\nthe following:\\n■ The information the routine will hide \\n■ Inputs to the routine\\n■ Outputs from the routine\\nCross-Reference For details \\non preconditions and post-\\nconditions, see “Use asser-\\ntions to document and verify \\npreconditions and postcon-\\nditions” in Section 8.2. \\n■ Preconditions that are guaranteed to be true before the routine is called (input \\nvalues within certain ranges, streams initialized, files opened or closed, buffers \\nfilled or flushed, etc.)\\n■ Postconditions that the routine guarantees will be true before it passes control \\nback to the caller (output values within specified ranges, streams initialized, files \\nopened or closed, buffers filled or flushed, etc.)\\nHere’s how these concerns are addressed in the ReportErrorMessage() example:\\n■ The routine hides two facts: the error message text and the current processing \\nmethod (interactive or command line). \\n■ There are no preconditions guaranteed to the routine. \\n■ The input to the routine is an error code. \\n■ Two kinds of output are called for: the first is the error message, and the second \\nis the status that ReportErrorMessage() returns to the calling routine. \\n■ The routine guarantees that the status value will have a value of either Success or \\nFailure.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 258}, page_content='222 Chapter 9: The Pseudocode Programming Process\\nCross-Reference For details \\non naming routines, see Sec-\\ntion 7.3, “Good Routine \\nNames.”\\nName the routine Naming the routine might seem trivial, but good routine names \\nare one sign of a superior program and they’re not easy to come up with. In general, a \\nroutine should have a clear, unambiguous name. If you have trouble creating a good \\nname, that usually indicates that the purpose of the routine isn’t clear. A vague, wishy-\\nwashy name is like a politician on the campaign trail. It sounds as if it’s saying some-\\nthing, but when you take a hard look, you can’t figure out what it means. If you can \\nmake the name clearer, do so. If the wishy-washy name results from a wishy-washy \\ndesign, pay attention to the warning sign. Back up and improve the design.\\nIn the example, ReportErrorMessage() is unambiguous. It is a good name.\\nFurther Reading For a dif-\\nferent approach to construc-\\ntion that focuses on writing \\ntest cases first, see Test-\\nDriven Development: By \\nExample (Beck 2003).\\nDecide how to test the routine As you’re writing the routine, think about how you \\ncan test it. This is useful for you when you do unit testing and for the tester who tests \\nyour routine independently.\\nIn the example, the input is simple, so you might plan to test ReportErrorMessage() \\nwith all valid error codes and a variety of invalid codes.\\nResearch functionality available in the standard libraries The single biggest way to \\nimprove both the quality of your code and your productivity is to reuse good code. If \\nyou find yourself grappling to design a routine that seems overly complicated, ask \\nwhether some or all of the routine’s functionality might already be available in the \\nlibrary code of the language, platform, or tools you’re using. Ask whether the code \\nmight be available in library code maintained by your company. Many algorithms \\nhave already been invented, tested, discussed in the trade literature, reviewed, and \\nimproved. Rather than spending your time inventing something when someone has \\nalready written a Ph.D. dissertation on it, take a few minutes to look through the code \\nthat’s already been written and make sure you’re not doing more work than necessary. \\nThink about error handling Think about all the things that could possibly go wrong \\nin the routine. Think about bad input values, invalid values returned from other rou-\\ntines, and so on. \\nRoutines can handle errors numerous ways, and you should choose consciously how \\nto handle errors. If the program’s architecture defines the program’s error-handling \\nstrategy, you can simply plan to follow that strategy. In other cases, you have to decide \\nwhat approach will work best for the specific routine. \\nThink about efficiency Depending on your situation, you can address efficiency in \\none of two ways. In the first situation, in the vast majority of systems, efficiency isn’t \\ncritical. In such a case, see that the routine’s interface is well abstracted and its code is \\nreadable so that you can improve it later if you need to. If you have good encapsula-\\ntion, you can replace a slow, resource-hogging, high-level language implementation \\nwith a better algorithm or a fast, lean, low-level language implementation, and you \\nwon’t affect any other routines.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 259}, page_content='9.3 Constructing Routines by Using the PPP 223\\nCross-Reference For details \\non efficiency, see Chapter 25, \\n“Code-Tuning Strategies,” \\nand Chapter 26, “Code-\\nTuning Techniques.”\\nIn the second situation—in the minority of systems—performance is critical. The per-\\nformance issue might be related to scarce database connections, limited memory, few \\navailable handles, ambitious timing constraints, or some other scarce resource. The \\narchitecture should indicate how many resources each routine (or class) is allowed to \\nuse and how fast it should perform its operations.\\nDesign your routine so that it will meet its resource and speed goals. If either \\nresources or speed seems more critical, design so that you trade resources for speed or \\nvice versa. It’s acceptable during initial construction of the routine to tune it enough to \\nmeet its resource and speed budgets.\\nAside from taking the approaches suggested for these two general situations, it’s usu-\\nally a waste of effort to work on efficiency at the level of individual routines. The big \\noptimizations come from refining the high-level design, not the individual routines. \\nYou generally use micro-optimizations only when the high-level design turns out not \\nto support the system’s performance goals, and you won’t know that until the whole \\nprogram is done. Don’t waste time scraping for incremental improvements until you \\nknow they’re needed.\\nResearch the algorithms and data types If functionality isn’t available in the avail-\\nable libraries, it might still be described in an algorithms book. Before you launch into \\nwriting complicated code from scratch, check an algorithms book to see what’s \\nalready available. If you use a predefined algorithm, be sure to adapt it correctly to \\nyour programming language.\\nWrite the pseudocode You might not have much in writing after you finish the pre-\\nceding steps. The main purpose of the steps is to establish a mental orientation that’s \\nuseful when you actually write the routine.\\nCross-Reference This discus-\\nsion assumes that good \\ndesign techniques are used to \\ncreate the pseudocode ver-\\nsion of the routine. For details \\non design, see Chapter 5, \\n“Design in Construction.”\\nWith the preliminary steps completed, you can begin to write the routine as high-level \\npseudocode. Go ahead and use your programming editor or your integrated environ-\\nment to write the pseudocode—the pseudocode will be used shortly as the basis for \\nprogramming-language code.\\nStart with the general and work toward something more specific. The most general \\npart of a routine is a header comment describing what the routine is supposed to do, \\nso first write a concise statement of the purpose of the routine. Writing the statement \\nwill help you clarify your understanding of the routine. Trouble in writing the general \\ncomment is a warning that you need to understand the routine’s role in the program \\nbetter. In general, if it’s hard to summarize the routine’s role, you should probably \\nassume that something is wrong. Here’s an example of a concise header comment \\ndescribing a routine:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 260}, page_content='224 Chapter 9: The Pseudocode Programming Process\\nExample of a Header Comment for a Routine\\nThis routine outputs an error message based on an error code\\nsupplied by the calling routine. The way it outputs the message\\ndepends on the current processing state, which it retrieves\\non its own. It returns a value indicating success or failure.\\nAfter you’ve written the general comment, fill in high-level pseudocode for the routine. \\nHere’s the pseudocode for this example:\\nExample of Pseudocode for a Routine\\nThis routine outputs an error message based on an error code\\nsupplied by the calling routine. The way it outputs the message\\ndepends on the current processing state, which it retrieves\\non its own. It returns a value indicating success or failure.\\nset the default status to \"fail\"\\nlook up the message based on the error code \\nif the error code is valid\\n   if doing interactive processing, display the error message \\n   interactively and declare success\\n   if doing command line processing, log the error message to the \\n   command line and declare success\\nif the error code isn\\'t valid, notify the user that an internal error \\nhas been detected\\nreturn status information\\nAgain, note that the pseudocode is written at a fairly high level. It certainly isn’t writ-\\nten in a programming language . Instead, it expresses in  precise English what the \\nroutine needs to do.\\nCross-Reference For details \\non effective use of variables, \\nsee Chapters 10 through 13.\\nThink about the data You can design the routine’s data at several different points in \\nthe process. In this example, the data is simple and data manipulation isn’t a prominent \\npart of the routine. If data manipulation is a prominent part of the routine, it’s worth-\\nwhile to think about the major pieces of data before you think about the routine’s logic. \\nDefinitions of key data types are useful to have when you design the logic of a routine.\\nCross-Reference For details \\non review techniques, see \\nChapter 21, “Collaborative \\nConstruction.”\\nCheck the pseudocode Once you’ve written the pseudocode and designed the data, \\ntake a minute to review the pseudocode you’ve written. Back away from it, and think \\nabout how you would explain it to someone else.\\nAsk someone else to look at it or listen to you explain it. You might think that it’s silly \\nto have someone look at 11 lines of pseudocode, but you’ll be surprised. Pseudocode \\ncan make your assumptions and high-level mistakes more obvious than program-\\nming-language code does. People are also more willing to review a few lines of \\npseudocode than they are to review 35 lines of C++ or Java.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 261}, page_content='9.3 Constructing Routines by Using the PPP 225\\nMake sure you have an easy and comfortable understanding of what the routine does \\nand how it does it. If you don’t understand it conceptually, at the pseudocode level, \\nwhat chance do you have of understanding it at the programming-language level? And \\nif you don’t understand it, who else will?\\nCross-Reference For more \\non iteration, see Section \\n34.8, “Iterate, Repeatedly, \\nAgain and Again.”\\nTry a few ideas in pseudocode, and keep the best (iterate) Try as many ideas as you \\ncan in pseudocode before you start coding. Once you start coding, you get emotionally \\ninvolved with your code and it becomes harder to throw away a bad design and start over.\\nThe general idea is to iterate the routine in pseudocode until the pseudocode state-\\nments become simple enough that you can fill in code below each statement and leave \\nthe original pseudocode as documentation. Some of the pseudocode from your first \\nattempt might be high-level enough that you need to decompose it further. Be sure \\nyou do decompose it further. If you’re not sure how to code something, keep working \\nwith the pseudocode until you are sure. Keep refining and decomposing the \\npseudocode until it seems like a waste of time to write it instead of the actual code.\\nCode the Routine\\nOnce you’ve designed the routine, construct it. You can perform construction steps in \\na nearly standard order, but feel free to vary them as you need to. Figure 9-3 shows the \\nsteps in constructing a routine.\\nFigure 9-3 You’ll perform all of these steps as you design a routine but not necessarily in \\nany particular order.\\nStart with pseudocode\\nWrite the routine declaration\\nWrite the first and last statements, and turn \\nthe pseudocode into high-level comments\\nFill in the code below each comment\\nRepeat as needed\\nClean up leftovers\\nDone\\nCheck the code'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 262}, page_content='226 Chapter 9: The Pseudocode Programming Process\\nWrite the routine declaration Write the routine interface statement—the function \\ndeclaration in C++, method declaration in Java, function or sub procedure declaration \\nin Microsoft Visual Basic, or whatever your language calls for. Turn the original header \\ncomment into a programming-language comment. Leave it in position above the \\npseudocode you’ve already written. Here are the example routine’s interface state-\\nment and header in C++:\\nC+ + Example of a Routine Interface and Header Added to Pseudocode\\nHere’s the header comment \\nthat’s been turned into a \\nC++-style comment.\\n/* This routine outputs an error message based on an error code\\nsupplied by the calling routine. The way it outputs the message\\ndepends on the current processing state, which it retrieves \\non its own. It returns a value indicating success or failure. \\n*/\\nHere’s the interface \\nstatement.\\nStatus ReportErrorMessage(\\n   ErrorCode errorToReport\\n   )\\nset the default status to \"fail\"\\nlook up the message based on the error code \\nif the error code is valid\\n   if doing interactive processing, display the error message \\n   interactively and declare success\\n   if doing command line processing, log the error message to the \\n   command line and declare success\\nif the error code isn\\'t valid, notify the user that an \\ninternal error has been detected\\nreturn status information\\nThis is a good time to make notes about any interface assumptions. In this case, the \\ninterface variable errorToReport is straightforward and typed for its specific purpose, \\nso it doesn’t need to be documented.\\nTurn the pseudocode into high-level comments Keep the ball rolling by writing the \\nfirst and last statements: { and } in C++. Then turn the pseudocode into comments. \\nHere’s how it would look in the example:\\nC+ + Example of Writing the First and Last Statements Around Pseudocode \\n/* This routine outputs an error message based on an error code\\nsupplied by the calling routine. The way it outputs the message\\ndepends on the current processing state, which it retrieves\\non its own. It returns a value indicating success or failure.\\n*/\\nStatus ReportErrorMessage(\\n   ErrorCode errorToReport\\n   ) {\\nC09619670.fm  Page 226  Tuesday, April 12, 2011  2:33 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 263}, page_content='9.3 Constructing Routines by Using the PPP 227\\nThe pseudocode statements \\nfrom here down have been \\nturned into C++ comments.\\n   // set the default status to \"fail\"\\n   // look up the message based on the error code\\n   // if the error code is valid\\n      // if doing interactive processing, display the error message \\n      // interactively and declare success\\n      // if doing command line processing, log the error message to the \\n      // command line and declare success\\n   // if the error code isn\\'t valid, notify the user that an \\n   // internal error has been detected\\n   // return status information\\n}\\nAt this point, the character of the routine is evident. The design work is complete, and \\nyou can sense how the routine works even without seeing any code. You should feel that \\nconverting the pseudocode to programming-language code will be mechanical, natural, \\nand easy. If you don’t, continue designing in pseudocode until the design feels solid.\\nCross-Reference This is a \\ncase where the writing meta-\\nphor works well—in the \\nsmall. For criticism of apply-\\ning the writing metaphor in \\nthe large, see “Software Pen-\\nmanship: Writing Code” in \\nSection 2.3.\\nFill in the code below each comment Fill in the code below each line of pseudocode \\ncomment. The process is a lot like writing a term paper. First you write an outline, and \\nthen you write a paragraph for each point in the outline. Each pseudocode comment \\ndescribes a block or paragraph of code. Like the lengths of literary paragraphs, the \\nlengths of code paragraphs vary according to the thought being expressed, and the \\nquality of the paragraphs depends on the vividness and focus of the thoughts in them.\\nIn this example, the first two pseudocode comments give rise to two lines of code: \\nC+ + Example of Expressing Pseudocode Comments as Code\\n/* This routine outputs an error message based on an error code\\nsupplied by the calling routine. The way it outputs the message\\ndepends on the current processing state, which it retrieves\\non its own. It returns a value indicating success or failure.\\n*/\\nStatus ReportErrorMessage(\\n   ErrorCode errorToReport\\n   ) {\\n   // set the default status to \"fail\"\\nHere’s the code that’s been \\nfilled in.\\nStatus errorMessageStatus = Status_Failure;\\n   \\n   // look up the message based on the error code\\nHere’s the new variable \\nerrorMessage.\\n   Message errorMessage = LookupErrorMessage( errorToReport );\\n   // if the error code is valid\\n      // if doing interactive processing, display the error message \\n      // interactively and declare success\\n      // if doing command line processing, log the error message to the \\n      // command line and declare success'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 264}, page_content='228 Chapter 9: The Pseudocode Programming Process\\n   // if the error code isn\\'t valid, notify the user that an \\n   // internal error has been detected\\n   // return status information\\n}\\nThis is a start on the code. The variable errorMessage is used, so it needs to be declared. \\nIf you were commenting after the fact, two lines of comments for two lines of code \\nwould nearly always be overkill. In this approach, however, it’s the semantic content \\nof the comments that’s important, not how many lines of code they comment. The \\ncomments are already there, and they explain the intent of the code, so leave them in.\\nThe code below each of the remaining comments needs to be filled in:\\nC+ + Example of a Complete Routine Created with the Pseudocode \\nProgramming Process\\n/* This routine outputs an error message based on an error code\\nsupplied by the calling routine. The way it outputs the message\\ndepends on the current processing state, which it retrieves\\non its own. It returns a value indicating success or failure. \\n*/\\nStatus ReportErrorMessage(\\n   ErrorCode errorToReport\\n   ) {\\n   // set the default status to \"fail\"\\n   Status errorMessageStatus = Status_Failure;\\n   // look up the message based on the error code\\n   Message errorMessage = LookupErrorMessage( errorToReport );\\n   // if the error code is valid\\nThe code for each comment \\nhas been filled in from here \\ndown.\\nif ( errorMessage.ValidCode() ) {\\n      // determine the processing method\\n      ProcessingMethod errorProcessingMethod = CurrentProcessingMethod();\\n      // if doing interactive processing, display the error message \\n      // interactively and declare success\\n      if ( errorProcessingMethod == ProcessingMethod_Interactive ) {\\n         DisplayInteractiveMessage( errorMessage.Text() );\\n         errorMessageStatus = Status_Success;\\n      }\\n      // if doing command line processing, log the error message to the \\n      // command line and declare success\\nThis code is a good candidate \\nfor being further decom-\\nposed into a new routine: \\nDisplayCommandLine-\\nMessage(). \\n      else if ( errorProcessingMethod == ProcessingMethod_CommandLine ) {\\n         CommandLine messageLog;\\n         if ( messageLog.Status() == CommandLineStatus_Ok ) { \\n            messageLog.AddToMessageQueue( errorMessage.Text() );\\n            messageLog.FlushMessageQueue();\\n            errorMessageStatus = Status_Success;\\n          }'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 265}, page_content='9.3 Constructing Routines by Using the PPP 229\\nThis code and comment are \\nnew and are the result of \\nfleshing out the if test. \\n         else {\\n            // can\\'t do anything because the routine is already error processing\\n         }\\nThis code and comment are \\nalso new. \\n      else {\\n         // can\\'t do anything because the routine is already error processing\\n      }\\n   }\\n   // if the error code isn\\'t valid, notify the user that an \\n   // internal error has been detected\\n   else {\\n      DisplayInteractiveMessage( \\n         \"Internal Error: Invalid error code in ReportErrorMessage()\" \\n      );\\n   }\\n   // return status information\\n   return errorMessageStatus;\\n}\\nEach comment has given rise to one or more lines of code. Each block of code forms a \\ncomplete thought based on the comment. The comments have been retained to provide \\na higher-level explanation of the code. All variables have been declared and defined \\nclose to the point they’re first used. Each comment should normally expand to about 2 \\nto 10 lines of code. (Because this example is just for purposes of illustration, the code \\nexpansion is on the low side of what you should usually experience in practice.)\\nNow look again at the spec on page 221 and the initial pseudocode on page 224. The \\noriginal five-sentence spec expanded to 15 lines of pseudocode (depending on how \\nyou count the lines), which in turn expanded into a page-long routine. Even though \\nthe spec was detailed, creation of the routine required substantial design work in \\npseudocode and code. That low-level design is one reason why “coding” is a nontrivial \\ntask and why the subject of this book is important.\\nCheck whether code should be further factored In some cases, you’ll see an explo-\\nsion of code below one of the initial lines of pseudocode. In this case, you should con-\\nsider taking one of two courses of action:\\nCross-Reference For more \\non refactoring, see Chapter \\n24, “Refactoring.”\\nI Factor the code below the comment into a new routine. If you find one line of \\npseudocode expanding into more code that than you expected, factor the code \\ninto its own routine. Write the code to call the routine, including the routine name. \\nIf you’ve used the PPP well, the name of the new routine should drop out easily \\nfrom the pseudocode. Once you’ve completed the routine you were originally cre-\\nating, you can dive into the new routine and apply the PPP again to that routine. \\nI Apply the PPP recursively. Rather than writing a couple dozen lines of code \\nbelow one line of pseudocode, take the time to decompose the original line of \\npseudocode into several more lines of pseudocode. Then continue filling in the \\ncode below each of the new lines of pseudocode. \\nC09619670.fm  Page 229  Tuesday, April 12, 2011  2:34 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 266}, page_content='230 Chapter 9: The Pseudocode Programming Process\\nCheck the Code \\nAfter designing and implementing the routine, the third big step in constructing it is \\nchecking to be sure that what you’ve constructed is correct. Any errors you miss at this \\nstage won’t be found until later testing. They’re more expensive to find and correct \\nthen, so you should find all that you can at this stage.\\nCross-Reference For details \\non checking for errors in \\narchitecture and require-\\nments, see Chapter 3, \\n“Measure Twice, Cut Once: \\nUpstream Prerequisites.”\\nA problem might not appear until the routine is fully coded for several reasons. An \\nerror in the pseudocode might become more apparent in the detailed implementation \\nlogic. A design that looks elegant in pseudocode might become clumsy in the imple-\\nmentation language. Working with the detailed implementation might disclose an \\nerror in the architecture, high-level design, or requirements. Finally, the code might \\nhave an old-fashioned, mongrel coding error—nobody’s perfect! For all these reasons, \\nreview the code before you move on.\\nMentally check the routine for errors The first formal check of a routine is mental. \\nThe cleanup and informal checking steps mentioned earlier are two kinds of mental \\nchecks. Another is executing each path mentally. Mentally executing a routine is diffi-\\ncult, and that difficulty is one reason to keep your routines small. Make sure that you \\ncheck nominal paths and endpoints and all exception conditions. Do this both by \\nyourself, which is called “desk checking,” and with one or more peers, which is called \\na “peer review,” a “walk-through,” or an “inspection,” depending on how you do it.\\nOne of the biggest differences between hobbyists and professional programmers is \\nthe difference that grows out of moving from superstition into understanding. The \\nword “superstition” in this context doesn’t refer to a program that gives you the creeps \\nor generates extra errors when the moon is full. It means substituting feelings about \\nthe code for understanding. If you often find yourself suspecting that the compiler or \\nthe hardware made an error, you’re still in the realm of superstition. A study con-\\nducted many years ago found that only about five percent of all errors are hardware, \\ncompiler, or operating-system errors (Ostrand and Weyuker 1984). Today, that per-\\ncentage would probably be even lower. Programmers who have moved into the realm \\nof understanding always suspect their own work first because they know that they \\ncause 95 percent of errors. Understand the role of each line of code and why it’s \\nneeded. Nothing is ever right just because it seems to work. If you don’t know why it \\nworks, it probably doesn’t—you just don’t know it yet.\\nBottom line: A working routine isn’t enough. If you don’t know why it works, study it, \\ndiscuss it, and experiment with alternative designs until you do. \\nCompile the routine After reviewing the routine, compile it. It might seem inefficient \\nto wait this long to compile since the code was completed several pages ago. Admit-\\ntedly, you might have saved some work by compiling the routine earlier and letting \\nthe computer check for undeclared variables, naming conflicts, and so on.\\n1\\n2\\n3\\nHARD DATA\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 267}, page_content='9.3 Constructing Routines by Using the PPP 231\\nYou’ll benefit in several ways, however, by not compiling until late in the process. The \\nmain reason is that when you compile new code, an internal stopwatch starts ticking. \\nAfter the first compile, you step up the pressure: “I’ll get it right with just one more \\ncompile.” The “Just One More Compile” syndrome leads to hasty, error-prone changes \\nthat take more time in the long run. Avoid the rush to completion by not compiling \\nuntil you’ve convinced yourself that the routine is right.\\nThe point of this book is to show how to rise above the cycle of hacking something \\ntogether and running it to see if it work s. Compiling before you’re sure your pro-\\ngram works is often a symptom of the hacker mindset. If you’re not caught in the \\nhacking-and-compiling cycle, compile when you feel it’s appropriate. But be con-\\nscious of the tug most people feel toward “hacking, compiling, and fixing” their way \\nto a working program.\\nHere are some guidelines for getting the most out of compiling your routine:\\n■ Set the compiler’s warning level to the pickiest level possible. You can catch an \\namazing number of subtle errors simply by allowing the compiler to detect them.\\n■ Use validators. The compiler checking performed by languages like C can be \\nsupplemented by use of tools like lint. Even code that isn’t compiled, such as \\nHTML and JavaScript, can be checked by validation tools. \\n■ Eliminate the causes of all error messages and warnings. Pay attention to what \\nthe messages tell you about your code. A large number of warnings often indi-\\ncates low-quality code, and you should try to understand each warning you get. \\nIn practice, warnings you’ve seen again and again have one of two possible \\neffects: you ignore them and they camouflage other, more important, warnings, \\nor they simply become annoying. It’s usually safer and less painful to rewrite the \\ncode to solve the underlying problem and eliminate the warnings.\\nStep through the code in the debugger Once the routine compiles, put it into the \\ndebugger and step through each line of code. Make sure each line executes as you \\nexpect it to. You can find many errors by following this simple practice.\\nCross-Reference For details, \\nsee Chapter 22, “Developer \\nTesting.” Also see “Building \\nScaffolding to Test Individual \\nClasses” in Section 22.5.\\nTest the code Test the code using the test cases you planned or created while you \\nwere developing the routine. You might have to develop scaffolding to support your \\ntest cases—that is, code that’s used to support routines while they’re tested and that \\nisn’t included in the final product. Scaffolding can be a test-harness routine that calls \\nyour routine with test data, or it can be stubs called by your routine.\\nCross-Reference For details, \\nsee Chapter 23, “Debugging.”\\nRemove errors from the routine Once an error has been detected, it has to be \\nremoved. If the routine you’re developing is buggy at this point, chances are good that \\nit will stay buggy. If you find that a routine is unusually buggy, start over. Don’t hack \\naround it—rewrite it. Hacks usually indicate incomplete understanding and guarantee \\nerrors both now and later. Creating an entirely new design for a buggy routine pays \\noff. Few things are more satisfying than rewriting a problematic routine and never \\nfinding another error in it.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 268}, page_content='232 Chapter 9: The Pseudocode Programming Process\\nClean Up Leftovers\\nWhen you’ve finished checking your code for problems, check it for the general char-\\nacteristics described throughout this book. You can take several cleanup steps to \\nmake sure that the routine’s quality is up to your standards:\\n■ Check the routine’s interface. Make sure that all input and output data is \\naccounted for and that all parameters are used. For more details, see Section 7.5, \\n“How to Use Routine Parameters.”\\n■ Check for general design quality. Make sure the routine does one thing and does \\nit well, that it’s loosely coupled to other routines, and that it’s designed defen-\\nsively. For details, see Chapter 7, “High-Quality Routines.”\\n■ Check the routine’s variables. Check for inaccurate variable names, unused \\nobjects, undeclared variables, improperly initialized objects, and so on. For \\ndetails, see the chapters on using variables, Chapters 10 through 13.\\n■ Check the routine’s statements and logic. Check for off-by-one errors, infinite \\nloops, improper nesting, and resource leaks. For details, see the chapters on \\nstatements, Chapters 14 through 19.\\n■ Check the routine’s layout. Make sure you’ve used white space to clarify the log-\\nical structure of the routine, expressions, and parameter lists. For details, see \\nChapter 31, “Layout and Style.”\\n■ Check the routine’s documentation. Make sure the pseudocode that was trans-\\nlated into comments is still accurate. Check for algorithm descriptions, for doc-\\numentation on interface assumptions and nonobvious dependencies, for \\njustification of unclear coding practices, and so on. For details, see Chapter 32, \\n“Self-Documenting Code.”\\n■ Remove redundant comments. Sometimes a pseudocode comment turns out to be \\nredundant with the code the comment describes, especially when the PPP has been \\napplied recursively and the comment just precedes a call to a well-named routine. \\nRepeat Steps as Needed\\nIf the quality of the routine is poor, back  up to the pseudocode. High-quality pro-\\ngramming is an iterative proc ess, so don’t hesitate to loop through the construction \\nactivities again.\\n9.4 Alternatives to the PPP\\nFor my money, the PPP is the best method for creating classes and routines. Here are \\nsome different approaches recommended by other experts. You can use these \\napproaches as alternatives or as supplements to the PPP.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 269}, page_content='9.4 Alternatives to the PPP 233\\nTest-first development Test-first is a popular development style in which test cases \\nare written prior to writing any code. This approach is described in more detail in \\n“Test First or Test Last?” in Section 22.2. A good book on test-first programming is \\nKent Beck’s Test-Driven Development: By Example (Beck 2003). \\nRefactoring Refactoring is a development approach in which you improve code \\nthrough a series of semantic preserving transformations. Programmers use patterns of \\nbad code or “smells” to identify sections of code that need to be improved. Chapter \\n24, “Refactoring,” describes this approach in detail, and a good book on the topic is \\nMartin Fowler’s Refactoring: Improving the Design of Existing Code (Fowler 1999).\\nDesign by contract Design by contract is a development approach in which each \\nroutine is considered to have preconditions and postconditions. This approach is \\ndescribed in “Use assertions to document and verify preconditions and postcondi-\\ntions” in Section 8.2. The best source of information on design by contract is Bertrand \\nMeyers’s Object-Oriented Software Construction (Meyer 1997). \\nHacking? Some programmers try to hack their way toward working code rather \\nthan using a systematic approach like the PPP. If you’ve ever found that you’ve coded \\nyourself into a corner in a routine and have to start over, that’s an indication that the \\nPPP might work better. If you find yourself losing your train of thought in the middle \\nof coding a routine, that’s another indication that the PPP would be beneficial. Have \\nyou ever simply forgotten to write part of a class or part of routine? That hardly ever \\nhappens if you’re using the PPP. If you find yourself staring at the computer screen not \\nknowing where to start, that’s a surefire sign that the PPP would make your program-\\nming life easier. \\ncc2e.com/0943 CHECKLIST: The Pseudocode Programming Process\\nCross-Reference The point \\nof this list is to check \\nwhether you followed a \\ngood set of steps to create a \\nroutine. For a checklist that \\nfocuses on the quality of the \\nroutine itself, see the “High-\\nQuality Routines” checklist in \\nChapter 7, page 185.\\n❑ Have you checked that the prerequisites have been satisfied?\\n❑ Have you defined the problem that the class will solve?\\n❑ Is the high-level design clear enough to give the class and each of its rou-\\ntines a good name?\\n❑ Have you thought about how to test the class and each of its routines?\\n❑ Have you thought about efficiency mainly in terms of stable interfaces and \\nreadable implementations or mainly in terms of meeting resource and \\nspeed budgets?\\n❑ Have you checked the standard libraries and other code libraries for appli-\\ncable routines or components? \\n❑ Have you checked reference books for helpful algorithms?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 270}, page_content='234 Chapter 9: The Pseudocode Programming Process\\n❑ Have you designed each routine by using detailed pseudocode?\\n❑ Have you mentally checked the pseudocode? Is it easy to understand? \\n❑ Have you paid attention to warnings that would send you back to design \\n(use of global data, operations that seem better suited to another class or \\nanother routine, and so on)?\\n❑ Did you translate the pseudocode to code accurately?\\n❑ Did you apply the PPP recursively, breaking routines into smaller routines \\nwhen needed? \\n❑ Did you document assumptions as you made them?\\n❑ Did you remove comments that turned out to be redundant? \\n❑ Have you chosen the best of several iterations, rather than merely stop-\\nping after your first iteration?\\n❑ Do you thoroughly understand your code? Is it easy to understand? \\nKey Points\\n■ Constructing classes and constructing routines tends to be an iterative process. \\nInsights gained while constructing specific routines tend to ripple back through \\nthe class’s design. \\n■ Writing good pseudocode calls for using understandable English, avoiding fea-\\ntures specific to a single programming language, and writing at the level of \\nintent (describing what the design does rather than how it will do it).\\n■ The Pseudocode Programming Process is a useful tool for detailed design and \\nmakes coding easy. Pseudocode translates directly into comments, ensuring \\nthat the comments are accurate and useful.\\n■ Don’t settle for the first design you think of. Iterate through multiple approaches \\nin pseudocode and pick the best approach before you begin writing code. \\n■ Check your work at each step, and encourage others to check it too. That way, \\nyou’ll catch mistakes at the least expensive level, when you’ve invested the least \\namount of effort.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 271}, page_content='Part III\\nVariables\\nIn this part:\\nChapter 10: General Issues in Us ing Variables . . . . . . . . . . . . . . . . . . . . . .237\\nChapter 11: The Power of Variable Names . . . . . . . . . . . . . . . . . . . . . . . . .259\\nChapter 12: Fundamental Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . .291\\nChapter 13: Unusual Data Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .319'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 273}, page_content='237\\nChapter 10\\nGeneral Issues in Using \\nVariables\\ncc2e.com/1085 Contents\\n■ 10.1 Data Literacy: page 238\\n■ 10.2 Making Variable Declarations Easy: page 239\\n■ 10.3 Guidelines for Initializing Variables: page 240\\n■ 10.4 Scope: page 244\\n■ 10.5 Persistence: page 251\\n■ 10.6 Binding Time: page 252\\n■ 10.7 Relationship Between Data Types and Control Structures: page 254\\n■ 10.8 Using Each Variable for Exactly One Purpose: page 255\\nRelated Topics\\n■ Naming variables: Chapter 11\\n■ Fundamental data types: Chapter 12 \\n■ Unusual data types: Chapter 13\\n■ Formatting data declarations: “Laying Out Data Declarations” in Section 31.5\\n■ Documenting variables: “Commenting Data Declarations” in Section 32.5\\nIt’s normal and desirable for construction to fill in small gaps in the requirements and \\narchitecture. It would be inefficient to draw blueprints to such a microscopic level that \\nevery detail was completely specified. This chapter describes a nuts-and-bolts con-\\nstruction issue: the ins and outs of using variables.\\nThe information in this chapter should be particularly valuable to you if you’re an expe-\\nrienced programmer. It’s easy to start using hazardous practices before you’re fully aware \\nof your alternatives and then to continue to use them out of habit even after you’ve \\nlearned ways to avoid them. An experienced programmer might find the discussions on \\nbinding time in Section 10.6 and on using each variable for one purpose in Section 10.8 \\nparticularly interesting. If you’re not sure whether you qualify as an “experienced pro-\\ngrammer,” take the “Data Literacy Test” in the next section and find out.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 274}, page_content='238 Chapter 10: General Issues in Using Variables\\nThroughout this chapter I use the word “variable” to refer to objects as well as to built-\\nin data types like integers and arrays. The phrase “data type” generally refers to built-\\nin data types, while the word “data” refers to either objects or built-in types. \\n10.1 Data Literacy\\nThe first step in creating effective data is knowing which kind of data to create. A good \\nrepertoire of data types is a key part of a programmer’s toolbox. A tutorial in data \\ntypes is beyond the scope of this book, but the “Data Literacy Test” will help you \\ndetermine how much more you might need to learn about them.\\nThe Data Literacy Test\\nPut a 1 next to each term that looks familiar. If you think you know what a term means \\nbut aren’t sure, give yourself a 0.5. Add the points when you’re done, and interpret \\nyour score according to the scoring table below.\\nKEY POINT\\n______ abstract data type ______ literal\\n______ array ______ local variable\\n______ bitmap ______ lookup table\\n______ boolean variable ______ member data\\n______ B-tree ______ pointer\\n______ character variable ______ private\\n______ container class ______ retroactive synapse\\n______ double precision ______ referential integrity\\n______ elongated stream ______ stack\\n______ enumerated type ______ string\\n______ floating point ______ structured variable\\n______ heap ______ tree\\n______ index ______ typedef\\n______ integer ______ union\\n______ linked list ______ value chain\\n______ named constant ______ variant\\n______ Total Score'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 275}, page_content='10.2 Making Variable Declarations Easy 239\\nHere is how you can interpret the scores (loosely):\\nAdditional Resources on Data Types\\nThese books are good sources of information about data types:\\nCormen, H. Thomas, Charles E. Leiserson, Ronald L. Rivest. Introduction to Algorithms. \\nNew York, NY: McGraw Hill. 1990. \\nSedgewick, Robert. Algorithms in C++, Parts 1-4, 3d ed. Boston, MA: Addison-Wesley, \\n1998. \\nSedgewick, Robert. Algorithms in C++, Part 5, 3d ed. Boston, MA: Addison-Wesley, \\n2002. \\n10.2 Making Variable Declarations Easy\\nCross-Reference For details \\non layout of variable decla-\\nrations, see “Laying Out Data \\nDeclarations” in Section \\n31.5. For details on docu-\\nmenting them, see “Com-\\nmenting Data Declarations” \\nin Section 32.5.\\nThis section describes what you can do to streamline the task of declaring variables. \\nTo be sure, this is a small task, and you might think it’s too small to deserve its own \\nsection in this book. Nevertheless, you spend a lot of time creating variables, and \\ndeveloping the right habits can save time and frustration over the life of a project.\\nImplicit Declarations\\nSome languages have implicit variable declarations. For example, if you use a variable \\nin Microsoft Visual Basic without declaring it, the compiler declares it for you automat-\\nically (depending on your compiler settings).\\n0–14 You are a beginning programmer, probably in your first year of computer sci-\\nence in school or teaching yourself your first programming language. You can \\nlearn a lot by reading one of the books listed in the next subsection. Many of \\nthe descriptions of techniques in this part of the book are addressed to \\nadvanced programmers, and you’ll get more out of them after you’ve read \\none of these books.\\n15–19 You are an intermedia te programmer or an experienced programmer who has \\nforgotten a lot. Although many of the concepts will be familiar to you, you \\ntoo can benefit from reading one of the books listed below.\\n20–24 You are an expert programmer. You probably already have the books listed \\nbelow on your shelf.\\n25–29 You know more about data types than I do. Consider writing your own com-\\nputer book. (Send me a copy!)\\n30–32 You are a pompous fraud. The terms “elongated stream,” “retroactive syn-\\napse,” and “value chain” don’t refer to data types—I made them up. Please \\nread the “Intellectual Honesty” section in Chapter 33, “Personal Character”!'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 276}, page_content='240 Chapter 10: General Issues in Using Variables\\nImplicit declaration is one of the most hazardous features available in any language. If \\nyou program in Visual Basic, you know how frustrating it is to try to figure out why \\nacctNo doesn’t have the right value and then notice that acctNum is the variable that’s \\nreinitialized to 0. This kind of mistake is an easy one to make if your language doesn’t \\nrequire you to declare variables.\\nIf you’re programming in a language that requires you to declare variables, you have to \\nmake two mistakes before your program will bite you. First you have to put both acct-\\nNum and acctNo into the body of the routine. Then you have to declare both variables \\nin the routine. This is a harder mistake to make, and it virtually eliminates the synon-\\nymous-variables problem. Languages that require you to declare data explicitly are, in \\nessence, requiring you to use data more carefully, which is one of their primary advan-\\ntages. What do you do if you program in a language with implicit declarations? Here \\nare some suggestions:\\nTurn off implicit declarations Some compilers allow you to disable implicit declara-\\ntions. For example, in Visual Basic you would use an Option Explicit statement, which \\nforces you to declare all variables before you use them.\\nDeclare all variables As you type in a new variable, declare it, even though the com-\\npiler doesn’t require you to. This won’t catch all the errors, but it will catch some of them.\\nCross-Reference For details \\non the standardization of \\nabbreviations, see “General \\nAbbreviation Guidelines” in \\nSection 11.6.\\nUse naming conventions Establish a naming convention for common suffixes such as \\nNum and No so that you don’t use two variables when you mean to use one.\\nCheck variable names Use the cross-reference list generated by your compiler or \\nanother utility program. Many compilers list all the variables in a routine, allowing \\nyou to spot both acctNum and acctNo. They also point out variables that you’ve \\ndeclared and not used.\\n10.3 Guidelines for Initializing Variables\\nImproper data initialization is one of the most fertile sources of error in computer pro-\\ngramming. Developing effective techniques for avoiding initialization problems can \\nsave a lot of debugging time.\\nThe problems with improper initialization stem from a variable’s containing an initial \\nvalue that you do not expect it to contain. This can happen for any of several reasons:\\nCross-Reference For a test-\\ning approach based on data \\ninitialization and use pat-\\nterns, see “Data-Flow Test-\\ning” in Section 22.3.\\nI The variable has never been assigned a value. Its value is whatever bits hap-\\npened to be in its area of memory when the program started.\\nI The value in the variable is outdated. The variable was assigned a value at some \\npoint, but the value is no longer valid.\\nI Part of the variable has been assigned a value and part has not. \\nKEY POINT\\nKEY POINT\\nC10619670.fm  Page 240  Tuesday, April 12, 2011  2:37 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 277}, page_content=\"10.3 Guidelines for Initializing Variables 241\\nThis last theme has several variations. You can initialize some of the members of an \\nobject but not all of them. You can forget to allocate memory and then initialize the \\n“variable” the uninitialized pointer points to. This means that you are really selecting \\na random portion of computer memory and assigning it some value. It might be mem-\\nory that contains data. It might be memory that contains code. It might be the operat-\\ning system. The symptom of the pointer problem can manifest itself in completely \\nsurprising ways that are different each time—that’s what makes debugging pointer \\nerrors harder than debugging other errors.\\nFollowing are guidelines for avoiding initialization problems:\\nInitialize each variable as it’s declaredInitializing variables as they’re declared is an \\ninexpensive form of defensive programming. It’s a good insurance policy against ini-\\ntialization errors. The example below ensures that studentGrades will be reinitialized \\neach time you call the routine that contains it.\\nC+ + Example of Initialization at Declaration Time\\nfloat studentGrades[ MAX_STUDENTS ] = { 0.0 };   \\nCross-Reference Checking \\ninput parameters is a form of \\ndefensive programming. For \\ndetails on defensive pro-\\ngramming, see Chapter 8, \\n“Defensive Programming.”\\nInitialize each variable close to where it’s first used Some languages, including \\nVisual Basic, don’t support initializing variables as they’re declared. That can lead to \\ncoding styles like the following one, in which declarations are grouped together and \\nthen initializations are grouped together—all far from the first actual use of the variables. \\nVisual Basic Example of Bad Initialization\\n' declare all variables\\nDim accountIndex As Integer\\nDim total As Double\\nDim done As Boolean\\n' initialize all variables\\naccountIndex = 0\\ntotal = 0.0\\ndone = False\\n...\\n' code using accountIndex\\n...\\n' code using total\\n...\\n' code using done\\nWhile Not done\\n   ...\\nCODING \\nHORROR\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 278}, page_content=\"242 Chapter 10: General Issues in Using Variables\\nA better practice is to initialize variables as close as possible to where they’re first used:\\nVisual Basic Example of Good Initialization\\nDim accountIndex As Integer\\naccountIndex = 0\\n' code using accountIndex\\n...\\nDim total As Double\\ntotal is declared and initial-\\nized close to where it’s used.\\ntotal = 0.0\\n' code using total\\n...\\nDim done As Boolean\\ndone is also declared and \\ninitialized close to where it’s \\nused.\\ndone = False\\n' code using done\\nWhile Not done\\n   ...\\nThe second example is superior to the first for several reasons. By the time execution \\nof the first example gets to the code that uses done, done could have been modified. If \\nthat’s not the case when you first write the program, later modifications might make \\nit so. Another problem with the first approach is that throwing all the initializations \\ntogether creates the impression that all the variables are used throughout the whole \\nroutine—when in fact done is used only at the end. Finally, as the program is modified \\n(as it will be, if only by debugging), loops might be built around the code that uses \\ndone, and done will need to be reinitialized. The code in the second example will \\nrequire little modification in such a case. The code in the first example is more prone \\nto producing an annoying initialization error.\\nCross-Reference For more \\ndetails on keeping related \\nactions together, see Section \\n10.4, “Scope.”\\nThis is an example of the Principle of Proximity: keep related actions together. The \\nsame principle applies to keeping comments close to the code they describe, keeping \\nloop setup code close to the loop, grouping statements in straight-line code, and to \\nmany other areas.\\nIdeally, declare and define each variable close to where it’s first used A declaration \\nestablishes a variable’s type. A definition assigns the variable a specific value. In lan-\\nguages that support it, such as C++ and Java, variables should be declared and defined \\nclose to where they are first used.  Ideally, each variable should be defined at the same \\ntime it’s declared, as shown next: \\nJava Example of Good Initialization\\nint accountIndex = 0;\\n// code using accountIndex\\n...\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 279}, page_content='10.3 Guidelines for Initializing Variables 243\\ntotal is initialized close to \\nwhere it’s used.\\ndouble total = 0.0;\\n// code using total\\n...\\ndone is also initialized close \\nto where it’s used.\\nboolean done = false;\\n// code using done\\nwhile ( ! done ) {\\n   ...\\nCross-Reference For more \\ndetails on keeping related \\nactions together, see Section \\n14.2, “Statements Whose \\nOrder Doesn’t Matter.”\\nUse final or const when possible By declaring a variable to be final in Java or const \\nin C++, you can prevent the variable from being assigned a value after it’s initialized. \\nThe final and const keywords are useful for defining class constants, input-only \\nparameters, and any local variables whose va lues are intended to remain unchanged \\nafter initialization. \\nPay special attention to counters and accumulators The variables i, j, k, sum, and \\ntotal are often counters or accumulators. A common error is forgetting to reset a \\ncounter or an accumulator before the next time it’s used.\\nInitialize a class’s member data in its constructorJust as a routine’s variables should \\nbe initialized within each routine, a class’s data should be initialized within its construc-\\ntor. If memory is allocated in the constructor, it should be freed in the destructor. \\nCheck the need for reinitialization Ask yourself whether the variable will ever need \\nto be reinitialized, either because a loop in the routine uses the variable many times or \\nbecause the variable retains its value between calls to the routine and needs to be reset \\nbetween calls. If it needs to be reinitialized, make sure that the initialization statement \\nis inside the part of the code that’s repeated.\\nInitialize named constants once; initialize variables with executable code If you’re \\nusing variables to emulate named constants, it’s OK to write code that initializes them \\nonce, at the beginning of the program. To do this, initialize them in a Startup() routine. \\nInitialize true variables in executable code close to where they’re used. One of the \\nmost common program modifications is to change a routine that was originally called \\nonce so that you call it multiple times. Variables that are initialized in a program-level \\nStartup() routine aren’t reinitialized the second time through the routine.\\nUse the compiler setting that automatically initializes all variables If your compiler \\nsupports such an option, having the compiler set to automatically initialize all variables \\nis an easy variation on the theme of relying on your compiler. Relying on specific com-\\npiler settings, however, can cause problems when you move the code to another \\nmachine and another compiler. Make sure you document your use of the compiler set-\\nting; assumptions that rely on specific compiler settings are hard to uncover otherwise.\\nTake advantage of your compiler’s warning messages Many compilers warn you that \\nyou’re using an uninitialized variable.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 280}, page_content='244 Chapter 10: General Issues in Using Variables\\nCross-Reference For more \\non checking input parame-\\nters, see Section 8.1, “Pro-\\ntecting Your Program from \\nInvalid Inputs,” and the rest \\nof Chapter 8, “Defensive Pro-\\ngramming.” \\nCheck input parameters for validity Another valuable form of initialization is check-\\ning input parameters for validity. Before you assign input values to anything, make \\nsure the values are reasonable.\\nUse a memory-access checker to check for bad pointers In some operating systems, \\nthe operating-system code checks for invalid pointer references. In others, you’re on \\nyour own. You don’t have to stay on your own, however, because you can buy mem-\\nory-access checkers that check your program’s pointer operations.\\nInitialize working memory at the beginning of your program Initializing working \\nmemory to a known value helps to expose initialization problems. You can take any of \\nseveral approaches:\\n■ You can use a preprogram memory filler to fill the memory with a predictable \\nvalue. The value 0 is good for some purposes because it ensures that uninitial-\\nized pointers point to low memory, making it relatively easy to detect them \\nwhen they’re used. On the Intel processors, 0xCC is a good value to use because \\nit’s the machine code for a breakpoint interrupt; if you are running code in a \\ndebugger and try to execute your data rather than your code, you’ll be awash in \\nbreakpoints. Another virtue of the value 0xCC is that it’s easy to recognize in \\nmemory dumps—and it’s rarely used for legitimate reasons. Alternatively, Brian \\nKernighan and Rob Pike suggest using the constant 0xDEADBEEF as memory \\nfiller that’s easy to recognize in a debugger (1999). \\n■ If you’re using a memory filler, you can change the value you use to fill the mem-\\nory once in awhile. Shaking up the program sometimes uncovers problems that \\nstay hidden if the environmental background never changes.\\n■ You can have your program initialize its working memory at startup time. \\nWhereas the purpose of using a preprogram memory filler is to expose defects, \\nthe purpose of this technique is to hide them. By filling working memory with \\nthe same value every time, you guarantee that your program won’t be affected by \\nrandom variations in the startup memory.\\n10.4 Scope\\n“Scope” is a way of thinking about a variable’s celebrity status: how famous is it? \\nScope, or visibility, refers to the extent to which your variables are known and can be \\nreferenced throughout a program. A variable with limited or small scope is known in \\nonly a small area of a program—a loop index used in only one small loop, for instance. \\nA variable with large scope is known in many places in a program—a table of employee \\ninformation that’s used throughout a program, for instance.\\nDifferent languages handle scope in different ways. In some primitive languages, all \\nvariables are global. You therefore don’t have any control over the scope of a variable,'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 281}, page_content='10.4 Scope 245\\nand that can create a lot of problems. In C++ and similar languages, a variable can be \\nvisible to a block (a section of code enclosed in curly brackets), a routine, a class (and \\npossibly its derived classes), or the whole program. In Java and C#, a variable can also \\nbe visible to a package or namespace (a collection of classes). \\nThe following sections provide guidelines that apply to scope. \\nLocalize References to Variables\\nThe code between references to a variable is a “window of vulnerability.” In the win-\\ndow, new code might be added, inadvertently altering the variable, or someone read-\\ning the code might forget the value the variable is supposed to contain. It’s always a \\ngood idea to localize references to variables by keeping them close together.\\nThe idea of localizing references to a variable is pretty self-evident, but it’s an idea that \\nlends itself to formal measurement. One method of measuring how close together the \\nreferences to a variable are is to compute the “span” of a variable. Here’s an example:\\nJava Example of Variable Span\\na = 0;\\nb = 0;\\nc = 0;\\na = b + c;\\nIn this case, two lines come between the first reference to a and the second, so a has a \\nspan of two. One line comes between the two references to b, so b has a span of one, \\nand c has a span of zero. Here’s another example:\\nJava Example of Spans of One and Zero\\na = 0;\\nb = 0;\\nc = 0;\\nb = a + 1;\\nb = b / c;\\nFurther Reading For more \\ninformation on variable \\nspan, see Software Engineer-\\ning Metrics and Models \\n(Conte, Dunsmore, and Shen \\n1986).\\nIn this case, there is one line between the first reference to b and the second, for a span \\nof one. There are no lines between the second reference to b and the third, for a span \\nof zero.\\nThe average span is computed by averaging the individual spans. In the second exam-\\nple, for b, (1+0)/2 equals an average span of 0.5. When you keep references to vari-\\nables close together, you enable the person reading your code to focus on one section \\nat a time. If the references are far apart, you force the reader to jump around in the pro-\\ngram. Thus the main advantage of keeping references to variables together is that it \\nimproves program readability.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 282}, page_content='246 Chapter 10: General Issues in Using Variables\\nKeep Variables “Live” for as Short a Time as Possible\\nA concept that’s related to variable span is variable “live time,” the total number of \\nstatements over which a variable is live. A variable’s life begins at the first statement in \\nwhich it’s referenced; its life ends at the last statement in which it’s referenced.\\nUnlike span, live time isn’t affected by how many times the variable is used between \\nthe first and last times it’s referenced. If the variable is first referenced on line 1 and \\nlast referenced on line 25, it has a live time of 25 statements. If those are the only two \\nlines in which it’s used, it has an average span of 23 statements. If the variable were \\nused on every line from line 1 through line 25, it would have an average span of 0 \\nstatements, but it would still have a live time of 25 statements. Figure 10-1 illustrates \\nboth span and live time.\\nFigure 10-1 “Long live time” means that a variable is live over the course of many state-\\nments. “Short live time” means it’s live for only a few statements. “Span” refers to how close \\ntogether the references to a variable are.\\nAs with span, the goal with respect to live time is to keep the number low, to keep a \\nvariable live for as short a time as possible. And as with span, the basic advantage of \\nmaintaining a low number is that it reduces the window of vulnerability. You reduce \\nL ong live \\ntime\\nShort \\nspans\\nL ong live\\ntime\\nLo n g \\nspans\\nShort live \\ntime\\nShort spans'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 283}, page_content='10.4 Scope 247\\nthe chance of incorrectly or inadvertently altering a variable between the places in \\nwhich you intend to alter it.\\nA second advantage of keeping the live time short is that it gives you an accurate pic-\\nture of your code. If a variable is assigned a value in line 10 and not used again until \\nline 45, the very space between the two references implies that the variable is used \\nbetween lines 10 and 45. If the variable is assigned a value in line 44 and used in line \\n45, no other uses of the variable are implied, and you can concentrate on a smaller sec-\\ntion of code when you’re thinking about that variable.\\nA short live time also reduces the chance of initialization errors. As you modify a pro-\\ngram, straight-line code tends to turn into loops and you tend to forget initializations \\nthat were made far away from the loop. By keeping the initialization code and the loop \\ncode closer together, you reduce the chance that modifications will introduce initial-\\nization errors.\\nA short live time makes your code more readable. The fewer lines of code a reader has \\nto keep in mind at once, the easier your code is to understand. Likewise, the shorter \\nthe live time, the less code you have to keep on your screen when you want to see all \\nthe references to a variable during editing and debugging.\\nFinally, short live times are useful when splitting a large routine into smaller routines. \\nIf references to variables are kept close together, it’s easier to refactor related sections \\nof code into routines of their own. \\nMeasuring the Live Time of a Variable\\nYou can formalize the concept of live time by counting the number of lines between \\nthe first and last references to a variable (including both the first and last lines). Here’s \\nan example with live times that are too long:\\nJava Example of Variables with Excessively Long Live Times\\n1   // initialize all variables\\n2   recordIndex = 0;\\n3   total = 0;\\n4   done = false;\\n    ...\\n26  while ( recordIndex < recordCount ) {\\n27  ...\\nLast reference to recordIndex. 28     recordIndex = recordIndex + 1;\\n       ...\\n64  while ( !done ) {\\n       ...\\nLast reference to total.\\nLast reference to done.\\n69     if ( total > projectedTotal ) {\\n70        done = true;'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 284}, page_content='248 Chapter 10: General Issues in Using Variables\\nHere are the live times for the variables in this example:\\nThe example has been rewritten below so that the variable references are closer \\ntogether:\\nJava Example of Variables with Good, Short Live Times\\n    ...\\nInitialization of recordIndex \\nis moved down from line 3.\\n25  recordIndex = 0;\\n26  while ( recordIndex < recordCount ) {\\n27  ...\\n28     recordIndex = recordIndex + 1;\\n       ...\\nInitialization of total and \\ndone are moved down from \\nlines 4 and 5.\\n62  total = 0;\\n63  done = false;\\n64  while ( !done ) {\\n       ...\\n69     if ( total > projectedTotal ) {\\n70        done = true;\\nHere are the live times for the variables in this example:\\nFurther Reading For more \\ninformation on “live” vari-\\nables, see Software Engi-\\nneering Metrics and Models \\n(Conte, Dunsmore, and Shen \\n1986).\\nIntuitively, the second example seems better than the first because the initializations \\nfor the variables are performed closer to where the variables are used. The measured \\ndifference in average live time between the two examples is significant: An average of \\n54 vs. an average of 7 provides good quantitative support for the intuitive preference \\nfor the second piece of code.\\nDoes a hard number separate a good live time from a bad one? A good span from a \\nbad one? Researchers haven’t yet produced that quantitative data, but it’s safe to \\nassume that minimizing both span and live time is a good idea. \\nIf you try to apply the ideas of span and live time to global variables, you’ll find that \\nglobal variables have enormous spans and live times—one of many good reasons to \\navoid global variables.\\nrecordIndex ( line 28 - line 2 + 1 ) = 27\\ntotal ( line 69 - line 3 + 1 ) = 67\\ndone ( line 70 - line 4 + 1 ) = 67\\nAverage Live Time ( 27 + 67 + 67 ) / 3 ≈54\\nrecordIndex ( line 28 - line 25 + 1 ) = 4\\ntotal ( line 69 - line 62 + 1 ) = 8\\ndone ( line 70 - line 63 + 1 ) = 8\\nAverage Live Time ( 4 + 8 + 8 ) / 3 ≈7'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 285}, page_content='10.4 Scope 249\\nGeneral Guidelines for Minimizing Scope\\nHere are some specific guidelines you can use to minimize scope: \\nCross-Reference For details \\non initializing variables close \\nto where they’re used, see \\nSection 10.3, “Guidelines for \\nInitializing Variables,” earlier \\nin this chapter. \\nInitialize variables used in a loop immediately before the loop rather than back at the \\nbeginning of the routine containing the loop Doing this improves the chance that \\nwhen you modify the loop, you’ll remember to make corresponding modifications to \\nthe loop initialization. Later, when you modify the program and put another loop \\naround the initial loop, the initialization will work on each pass through the new loop \\nrather than on only the first pass.\\nCross-Reference For more \\non this style of variable dec-\\nlaration and definition, see \\n“Ideally, declare and define \\neach variable close to where \\nit’s first used” in Section 10.3. \\nDon’t assign a value to a variable until just before the value is used You might have \\nexperienced the frustration of trying to fi gure out where a variable was assigned its \\nvalue. The more you can do to clarify where a variable receives its value, the better. \\nLanguages like C++ and Java support variable initializations like these:\\nC+ + Example of Good Variable Declarations and Initializations\\nint receiptIndex = 0; \\nfloat dailyReceipts = TodaysReceipts();\\ndouble totalReceipts = TotalReceipts( dailyReceipts ); \\nCross-Reference For more \\ndetails on keeping related \\nstatements together, see Sec-\\ntion 14.2, “Statements Whose \\nOrder Doesn’t Matter.”\\nGroup related statements The following examples show a routine for summarizing \\ndaily receipts and illustrate how to put references to variables together so that they’re \\neasier to locate. The first example illustrates the violation of this principle:\\nC+ + Example of Using Two Sets of Variables in a Confusing Way \\nvoid SummarizeData(...) {\\n   ...\\nStatements using two sets \\nof variables.\\n   GetOldData( oldData, &numOldData );\\n   GetNewData( newData, &numNewData );\\n   totalOldData = Sum( oldData, numOldData );\\n   totalNewData = Sum( newData, numNewData );\\n   PrintOldDataSummary( oldData, totalOldData, numOldData );\\n   PrintNewDataSummary( newData, totalNewData, numNewData );\\n   SaveOldDataSummary( totalOldData, numOldData );\\n   SaveNewDataSummary( totalNewData, numNewData );\\n   ...\\n}\\nNote that, in this example, you have to keep track of oldData, newData, numOldData, \\nnumNewData, totalOldData, and totalNewData all at once—six variables for just this'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 286}, page_content='250 Chapter 10: General Issues in Using Variables\\nshort fragment. The next example shows how to reduce that number to only three ele-\\nments within each block of code:\\nC+ + Example of Using Two Sets of Variables More Understandably\\nvoid SummarizeData( ... ) {\\nStatements using oldData.    GetOldData( oldData, &numOldData );\\n   totalOldData = Sum( oldData, numOldData );\\n   PrintOldDataSummary( oldData, totalOldData, numOldData );\\n   SaveOldDataSummary( totalOldData, numOldData );\\n   ...\\nStatements using newData.    GetNewData( newData, &numNewData );\\n   totalNewData = Sum( newData, numNewData );\\n   PrintNewDataSummary( newData, totalNewData, numNewData );\\n   SaveNewDataSummary( totalNewData, numNewData );\\n   ...\\n}\\nWhen the code is broken up, the two blocks are each shorter than the original block \\nand individually contain fewer variables. They’re easier to understand, and if you need \\nto break this code out into separate routines, the shorter blocks with fewer variables \\nwill promote better-defined routines.\\nBreak groups of related statements into separate routines All other things being \\nequal, a variable in a shorter routine will tend to have smaller span and live time than \\na variable in a longer routine. By breaking related statements into separate, smaller \\nroutines, you reduce the scope that the variable can have. \\nCross-Reference For more \\non global variables, see \\nSection 13.3, “Global Data.”\\nBegin with most restricted visibility, and expand the variable’s scope only if \\nnecessary Part of minimizing the scope of a variable is keeping it as local as possi-\\nble. It is much more difficult to reduce the scope of a variable that has had a large \\nscope than to expand the scope of a variable that has had a small scope—in other \\nwords, it’s harder to turn a global variable into a class variable than it is to turn a class \\nvariable into a global variable. It’s harder to turn a protected data member into a pri-\\nvate data member than vice versa. For that reason, when in doubt, favor the smallest \\npossible scope for a variable: local to a specific loop, local to an individual routine, \\nthen private to a class, then protected, then package (if your programming language \\nsupports that), and global only as a last resort. \\nComments on Minimizing Scope\\nMany programmers’ approach to minimizing variables’ scope depends on their views \\nof the issues of “convenience” and “intellectual manageability.” Some programmers \\nmake many of their variables global because global scope makes variables convenient \\nto access and the programmers don’t have to fool around with parameter lists and \\nclass-scoping rules. In their minds, the convenience of being able to access variables at \\nany time outweighs the risks involved.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 287}, page_content='10.5 Persistence 251\\nCross-Reference The idea of \\nminimizing scope is related \\nto the idea of information \\nhiding. For details, see “Hide \\nSecrets (Information Hid-\\ning)” in Section 5.3.\\nOther programmers prefer to keep their variables as local as possible because local \\nscope helps intellectual manageability. The more information you can hide, the less \\nyou have to keep in mind at any one time. The less you have to keep in mind, the \\nsmaller the chance that you’ll make an error because you forgot one of the many \\ndetails you needed to remember.\\nThe difference between the “convenience” philosophy and the “intellectual manage-\\nability” philosophy boils down to a difference in emphasis between writing programs \\nand reading them. Maximizing scope might indeed make programs easy to write, but \\na program in which any routine can use any variable at any time is harder to under-\\nstand than a program that uses well-factored routines. In such a program, you can’t \\nunderstand only one routine; you have to understand all the other routines with \\nwhich that routine shares global data. Such programs are hard to read, hard to debug, \\nand hard to modify. \\nCross-Reference For details \\non using access routines, see \\n“Using Access Routines \\nInstead of Global Data” in \\nSection 13.3.\\nConsequently, you should declare each variable to be visible to the smallest segment \\nof code that needs to see it. If you can confine the variable’s scope to a single loop or \\nto a single routine, great. If you can’t confine the scope to one routine, restrict the vis-\\nibility to the routines in a single class. If you can’t restrict the variable’s scope to the \\nclass that’s most responsible for the variable, create access routines to share the vari-\\nable’s data with other classes. You’ll find that you rarely, if ever, need to use naked glo-\\nbal data.\\n10.5 Persistence\\n“Persistence” is another word for the life span of a piece of data. Persistence takes sev-\\neral forms. Some variables persist\\n■ for the life of a particular block of code or routine. Variables declared inside a for \\nloop in C++ or Java are examples of this kind of persistence.\\n■ as long as you allow them to. In Java, variables created with new persist until \\nthey are garbage collected. In C++, variables created with new persist until you \\ndelete them.\\n■ for the life of a program. Global variables in most languages fit this description, \\nas do static variables in C++ and Java. \\n■ forever. These variables might include values that you store in a database \\nbetween executions of a program. For example, if you have an interactive pro-\\ngram in which users can customize the color of the screen, you can store their \\ncolors in a file and then read them back each time the program is loaded. \\nThe main problem with persistence arises when you assume that a variable has a \\nlonger persistence than it really does. The variable is like that jug of milk in your refrig-\\nerator. It’s supposed to last a week. Sometimes it lasts a month, and sometimes it \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 288}, page_content='252 Chapter 10: General Issues in Using Variables\\nturns sour after five days. A variable can be just as unpredictable. If you try to use the \\nvalue of a variable after its normal life span is over, will it have retained its value? \\nSometimes the value in the variable is sour, and you know that you’ve got an error. \\nOther times, the computer leaves the old value in the variable, letting you imagine that \\nyou have used it correctly.\\nHere are a few steps you can take to avoid this kind of problem:\\nCross-Reference Debug \\ncode is easy to include in \\naccess routines and is dis-\\ncussed more in “Advantages \\nof Access Routines” in \\nSection 13.3.\\n■ Use debug code or assertions in your program to check critical variables for rea-\\nsonable values. If the values aren’t reasonable, display a warning that tells you to \\nlook for improper initialization.\\n■ Set variables to “unreasonable values” when you’re through with them. For \\nexample, you could set a pointer to null after you delete it. \\n■ Write code that assumes data isn’t persistent. For example, if a variable has a cer-\\ntain value when you exit a routine, don’t assume it has the same value the next \\ntime you enter the routine. This doesn’t apply if you’re using language-specific \\nfeatures that guarantee the value will remain the same, such as static in C++ and \\nJava.\\n■ Develop the habit of declaring and initializing all data right before it’s used. If \\nyou see data that’s used without a nearby initialization, be suspicious!\\n10.6 Binding Time\\nAn initialization topic with far-reaching implications for program maintenance and \\nmodifiability is “binding time”: the time at which the variable and its value are bound \\ntogether (Thimbleby 1988). Are they bound together when the code is written? When \\nit is compiled? When it is loaded? When the program is run? Some other time?\\nIt can be to your advantage to use the latest binding time possible. In general, the later \\nyou make the binding time, the more flexibility you build into your code. The next \\nexample shows binding at the earliest possible time, when the code is written:\\nJava Example of a Variable That’s Bound at Code-Writing Time \\ntitleBar.color = 0xFF; // 0xFF is hex value for color blue\\nThe value 0xFF is bound to the variable titleBar.color at the time the code is written \\nbecause 0xFF is a literal value hard-coded into the program. Hard-coding like this is \\nnearly always a bad idea because if this 0xFF changes, it can get out of synch with 0xFFs \\nused elsewhere in the code that must be the same value as this one.\\nHere’s an example of binding at a slightly later time, when the code is compiled:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 289}, page_content='10.6 Binding Time 253\\nJava Example of a Variable That’s Bound at Compile Time \\nprivate static final int COLOR_BLUE = 0xFF; \\nprivate static final int TITLE_BAR_COLOR = COLOR_BLUE; \\n...\\ntitleBar.color = TITLE_BAR_COLOR;\\nTITLE_BAR_COLOR is a named constant, an expression for which the compiler sub-\\nstitutes a value at compile time. This is nearly always better than hard-coding, if your \\nlanguage supports it. It increases readability because TITLE_BAR_COLOR tells you \\nmore about what is being represented than 0xFF  does. It makes changing the title bar \\ncolor easier because one change accounts for all occurrences. And it doesn’t incur a \\nrun-time performance penalty.\\nHere’s an example of binding later, at run time: \\nJava Example of a Variable That’s Bound at Run Time\\ntitleBar.color = ReadTitleBarColor();\\nReadTitleBarColor() is a routine that reads a value while a program is executing, per-\\nhaps from the Microsoft Windows registry file or a Java properties file. \\nThe code is more readable and flexible than it would be if a value were hard-coded. You \\ndon’t need to change the program to change titleBar.color; you simply change the con-\\ntents of the source that’s read by ReadTitleBarColor(). This approach is commonly used \\nfor interactive applications in which a user can customize the application environment. \\nThere is still another variation in binding time, which has to do with when the Read-\\nTitleBarColor() routine is called. That routine could be called once at program load \\ntime, each time the window is created, or each time the window is drawn—each alter-\\nnative represents successively later binding times. \\nTo summarize, following are the times a variable can be bound to a value in this exam-\\nple. (The details could vary somewhat in other cases.)\\n■ Coding time (use of magic numbers)\\n■ Compile time (use of a named constant)\\n■ Load time (reading a value from an external source such as the Windows regis-\\ntry file or a Java properties file)\\n■ Object instantiation time (such as reading the value each time a window is cre-\\nated)\\n■ Just in time (such as reading the value each time the window is drawn)'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 290}, page_content='254 Chapter 10: General Issues in Using Variables\\nIn general, the earlier the binding time, the lower the flexibility and the lower the com-\\nplexity. For the first two options, using named constants is preferable to using magic \\nnumbers for many reasons, so you can get the flexibility that named constants provide \\njust by using good programming practices. Beyond that, the greater the flexibility \\ndesired, the higher the complexity of the code needed to support that flexibility and \\nthe more error-prone the code will be. Because successful programming depends on \\nminimizing complexity, a skilled programmer will build in as much flexibility as \\nneeded to meet the software’s requirements but will not add flexibility—and related \\ncomplexity—beyond what’s required.  \\n10.7 Relationship Between Data Types and Control \\nStructures\\nData types and control structures relate to each other in well-defined ways that were \\noriginally described by the British computer scientist Michael Jackson (Jackson \\n1975). This section sketches the regular relationship between data and control flow. \\nJackson draws connections between three types of data and corresponding control \\nstructures:\\nCross-Reference For details \\non sequences, see Chapter \\n14, “Organizing Straight-\\nLine Code.”\\nSequential data translates to sequential statements in a program Sequences con-\\nsist of clusters of data used together in a certain order, as suggested by Figure 10-2. If \\nyou have five statements in a row that handle five different values, they are sequential \\nstatements. If you read an employee’s name, Social Security Number, address, phone \\nnumber, and age from a file, you’d have sequential statements in your program to read \\nsequential data from the file.\\nFigure 10-2 Sequential data is data that’s handled in a defined order.\\nCross-Reference For details \\non conditionals, see Chapter \\n15, “Using Conditionals.”\\nSelective data translates to if and case statements in a program In general, selective \\ndata is a collection in which one of several pieces of data is used at any particular time, but \\nonly one, as shown in Figure 10-3. The corresponding program statements must do the \\nactual selection, and they consist of if-then-else or case statements. If you had an employee \\npayroll program, you might process employees differently depending on whether they \\nwere paid hourly or salaried. Again, patterns in the code match patterns in the data.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 291}, page_content='10.8 Using Each Variable for Exactly One Purpose 255\\nFigure 10-3 Selective data allows you to use one piece or the other, but not both.\\nCross-Reference For details \\non loops, see Chapter 16, \\n“Controlling Loops.”\\nIterative data translates to for, repeat, and while looping structures in a program \\nIterative data is the same type of data repeated several times, as suggested by Fig-\\nure 10-4. Typically, iterative data is stored as elements in a container, records in a \\nfile, or elements in an array. You might have a list of Social Security Numbers that \\nyou read from a file. The iterative data would match the iterative code loop used to \\nread the data.\\nFigure 10-4 Iterative data is repeated.\\nYour real data can be combinations of the sequential, selective, and iterative types of \\ndata. You can combine the simple building blocks to describe more complicated data \\ntypes.\\n10.8 Using Each Variable for Exactly One Purpose\\nIt’s possible to use variables for more than one purpose in several subtle ways. You’re \\nbetter off without this kind of subtlety.\\nUse each variable for one purpose only It’s sometimes tempting to use one variable \\nin two different places for two different activities. Usually, the variable is named inap-\\npropriately for one of its uses or a “temporary” variable is used in both cases (with the \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 292}, page_content='256 Chapter 10: General Issues in Using Variables\\nusual unhelpful name x or temp). Here’s an example that shows a temporary variable \\nthat’s used for two purposes:\\nC+ + Example of Using One Variable for Two Purposes—Bad Practice\\n// Compute roots of a quadratic equation.\\n// This code assumes that (b*b-4*a*c) is positive.\\ntemp = Sqrt( b*b - 4*a*c );\\nroot[O] = ( -b + temp ) / ( 2 * a );\\nroot[1] = ( -b - temp ) / ( 2 * a );\\n...\\n// swap the roots\\ntemp = root[0];\\nroot[0] = root[1];\\nroot[1] = temp;\\nCross-Reference Routine \\nparameters should also be \\nused for one purpose only. \\nFor details on using routine \\nparameters, see Section 7.5, \\n“How to Use Routine \\nParameters.”\\nQuestion: What is the relationship between temp in the first few lines and temp in the \\nlast few? Answer: The two temps have no relationship. Using the same variable in both \\ninstances makes it seem as though they’re related when they’re not. Creating unique \\nvariables for each purpose makes your code more readable. Here’s an improvement:\\nC+ + Example of Using Two Variables for Two Purposes—Good Practice\\n// Compute roots of a quadratic equation.\\n// This code assumes that (b*b-4*a*c) is positive.\\ndiscriminant = Sqrt( b*b - 4*a*c );\\nroot[0] = ( -b + discriminant ) / ( 2 * a );\\nroot[1] = ( -b - discriminant ) / ( 2 * a );\\n...\\n// swap the roots\\noldRoot = root[0];\\nroot[0] = root[1];\\nroot[1] = oldRoot;\\nAvoid variables with hidden meanings Another way in which a variable can be used \\nfor more than one purpose is to have different values for the variable mean different \\nthings. For example:\\n■ The value in the variable pageCount might represent the number of pages \\nprinted, unless it equals -1, in which case it indicates that an error has occurred. \\n■ The variable customerId might represent a customer number, unless its value is \\ngreater than 500,000, in which case you subtract 500,000 to get the number of a \\ndelinquent account. \\n■ The variable bytesWritten might be the number of bytes written to an output file, \\nunless its value is negative, in which case it indicates the number of the disk \\ndrive used for the output.\\nCODING \\nHORROR\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 293}, page_content='10.8 Using Each Variable for Exactly One Purpose 257\\nAvoid variables with these kinds of hidden meanings. The technical name for this \\nkind of abuse is “hybrid coupling” (Page-Jones 1988). The variable is stretched over \\ntwo jobs, meaning that the variable is the wrong type for one of the jobs. In the page-\\nCount example, pageCount normally indicates the number of pages; it’s an integer. \\nWhen pageCount is -1, however, it indicates that an error has occurred; the integer is \\nmoonlighting as a boolean!\\nEven if the double use is clear to you, it won’t be to someone else. The extra clarity \\nyou’ll achieve by using two variables to hold two kinds of information will amaze you. \\nAnd no one will begrudge you the extra storage.\\nMake sure that all declared variables are used The opposite of using a variable for \\nmore than one purpose is not using it at all. A study by Card, Church, and Agresti \\nfound that unreferenced variables were correlated with higher fault rates (1986). Get \\nin the habit of checking to be sure that all variables that are declared are used. Some \\ncompilers and utilities (such as lint) report unused variables as a warning.\\ncc2e.com/1092 CHECKLIST: General Considerations In Using Data \\nCross-Reference For a \\nchecklist that applies to \\nspecific types of data rather \\nthan general issues, see the \\nchecklist in Chapter 12, \\n“Fundamental Data Types,” \\non page 316. For issues in \\nnaming variables, see the \\nchecklist in Chapter 11, “The \\nPower of Variable Names,” \\non page 288.\\nInitializing Variables\\n❑ Does each routine check input parameters for validity?\\n❑ Does the code declare variables close to where they’re first used?\\n❑ Does the code initialize variables as they’re declared, if possible?\\n❑ Does the code initialize variables close to where they’re first used, if it isn’t \\npossible to declare and initialize them at the same time?\\n❑ Are counters and accumulators initialized properly and, if necessary, rein-\\nitialized each time they are used?\\n❑ Are variables reinitialized properly in code that’s executed repeatedly?\\n❑ Does the code compile with no warnings from the compiler? (And have \\nyou turned on all the available warnings?)\\n❑ If your language uses implicit declarations, have you compensated for the \\nproblems they cause?\\nOther General Issues in Using Data\\n❑ Do all variables have the smallest scope possible?\\n❑ Are references to variables as close together as possible, both from each \\nreference to a variable to the next reference and in total live time?\\n❑ Do control structures correspond to the data types?\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 294}, page_content='258 Chapter 10: General Issues in Using Variables\\n❑ Are all the declared variables being used?\\n❑ Are all variables bound at appropriate times—that is, are you striking a con-\\nscious balance between the flexibility of late binding and the increased \\ncomplexity associated with late binding? \\n❑ Does each variable have one and only one purpose?\\n❑ Is each variable’s meaning explicit, with no hidden meanings?\\nKey Points\\n■ Data initialization is prone to errors, so use the initialization techniques described \\nin this chapter to avoid the problems caused by unexpected initial values.\\n■ Minimize the scope of each variable. Keep references to a variable close together. \\nKeep it local to a routine or class. Avoid global data.\\n■ Keep statements that work with the same variables as close together as possible.\\n■ Early binding tends to limit flexibility but minimize complexity. Late binding \\ntends to increase flexibility but at the price of increased complexity. \\n■ Use each variable for one and only one purpose.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 295}, page_content='259\\nChapter 11\\nThe Power of Variable Names\\ncc2e.com/1184 Contents\\n■ 11.1 Considerations in Choosing Good Names: page 259\\n■ 11.2 Naming Specific Types of Data: page 264\\n■ 11.3 The Power of Naming Conventions: page 270\\n■ 11.4 Informal Naming Conventions: page 272\\n■ 11.5 Standardized Prefixes: page 279\\n■ 11.6 Creating Short Names That Are Readable: page 282\\n■ 11.7 Kinds of Names to Avoid: page 285\\nRelated Topics\\n■ Routine names: Section 7.3\\n■ Class names: Section 6.2\\n■ General issues in using variables: Chapter 10\\n■ Formatting data declarations: “Laying Out Data Declarations” in Section 31.5\\n■ Documenting variables: “Commenting Data Declarations” in Section 32.5\\nAs important as the topic of good names is to effective programming, I have never read \\na discussion that covered more than a handful of the dozens of considerations that go \\ninto creating good names. Many programming texts devote a few paragraphs to \\nchoosing abbreviations, spout a few platitudes, and expect you to fend for yourself. I \\nintend to be guilty of the opposite: to inundate you with more information about good \\nnames than you will ever be able to use!\\nThis chapter’s guidelines apply primarily to naming variables—objects and primitive \\ndata. But they also apply to naming classes, packages, files, and other programming \\nentities. For details on naming routines, see Section 7.3, “Good Routine Names.”\\n11.1 Considerations in Choosing Good Names\\nYou can’t give a variable a name the way you give a dog a name—because it’s cute or it has \\na good sound. Unlike the dog and its name, which are different entities, a variable and a \\nvariable’s name are essentially the same thing. Consequently, the goodness or badness \\nof a variable is largely determined by its name. Choose variable names with care.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 296}, page_content='260 Chapter 11: The Power of Variable Names\\nHere’s an example of code that uses bad variable names:\\nJava Example of Poor Variable Names\\nx = x - xx;\\nxxx = fido + SalesTax( fido );\\nx = x + LateFee( x1, x ) + xxx;\\nx = x + Interest( x1, x );\\nWhat’s happening in this piece of code? What do x1, xx, and xxx mean? What does \\nfido mean? Suppose someone told you that the code computed a total customer bill \\nbased on an outstanding balance and a new set of purchases. Which variable would \\nyou use to print the customer’s bill for just the new set of purchases?\\nHere’s a version of the same code that makes these questions easier to answer:\\nJava Example of Good Variable Names\\nbalance = balance - lastPayment;\\nmonthlyTotal = newPurchases + SalesTax( newPurchases );\\nbalance = balance + LateFee( customerID, balance ) + monthlyTotal;\\nbalance = balance + Interest( customerID, balance );\\nIn view of the contrast between these two pieces of code, a good variable name is read-\\nable, memorable, and appropriate. You can use several general rules of thumb to \\nachieve these goals.\\nThe Most Important Naming Consideration\\nThe most important consideration in naming a variable is that the name fully and \\naccurately describe the entity the variable represents. An effective technique for com-\\ning up with a good name is to state in words what the variable represents. Often that \\nstatement itself is the best variable name. It’s easy to read because it doesn’t contain \\ncryptic abbreviations, and it’s unambiguous. Because it’s a full description of the \\nentity, it won’t be confused with something else. And it’s easy to remember because \\nthe name is similar to the concept.\\nFor a variable that represents the number of people on the U.S. Olympic team, you \\nwould create the name numberOfPeopleOnTheUsOlympicTeam. A variable that repre-\\nsents the number of seats in a stadium would be numberOfSeatsInTheStadium. A vari-\\nable that represents the maximum number of points scored by a country’s team in any \\nmodern Olympics would be maximumNumberOfPointsInModernOlympics. A variable \\nthat contains the current interest rate is better named rate or interestRate than r or x. \\nYou get the idea.\\nCODING \\nHORROR\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 297}, page_content='11.1 Considerations in Choosing Good Names 261\\nNote two characteristics of these names. First, they’re easy to decipher. In fact, they \\ndon’t need to be deciphered at all because you can simply read them. But second, \\nsome of the names are long—too long to be practical. I’ll get to the question of variable-\\nname length shortly.\\nTable 11-1 shows several examples of variable names, good and bad:\\nThe names currentDate and todaysDate are good names because they fully and accu-\\nrately describe the idea of “current date.” In fact, they use the obvious words. Program-\\nmers sometimes overlook using the ordinary words, which is often the easiest solution. \\nBecause they’re too short and not at all descriptive, cd and c are poor names. current is \\npoor because it doesn’t tell you what is current. date is almost a good name, but it’s a \\npoor name in the final analysis because the date involved isn’t just any date, but the cur-\\nrent date; date by itself gives no such indication. x, x1, and x2 are poor names because \\nthey’re always poor names—x traditionally represents an unknown quantity; if you don’t \\nwant your variables to be unknown quantities, think of better names.\\nNames should be as specific as possible. Names like x, temp, and i that are general \\nenough to be used for more than one purpose are not as informative as they could be \\nand are usually bad names.\\nProblem Orientation\\nA good mnemonic name generally speaks to the problem rather than the solution. A \\ngood name tends to express the what more than the how. In general, if a name refers \\nto some aspect of computing rather than to the problem, it’s a how rather than a what. \\nAvoid such a name in favor of a name that refers to the problem itself.\\nA record of employee data could be called inputRec or employeeData. inputRec is a com-\\nputer term that refers to computing ideas—input and record. employeeData refers to \\nthe problem domain rather than the computing universe. Similarly, for a bit field indi-\\ncating printer status, bitFlag is a more computerish name than printerReady. In an \\naccounting application, calcVal is more computerish than sum.\\nTable 11-1 Examples of Good and Bad Variable Names\\nPurpose of Variable\\nGood Names, \\nGood Descriptors\\nBad Names, \\nPoor Descriptors\\nRunning total of \\nchecks written to date\\nrunningTotal, checkTotal written, ct, checks, CHKTTL, x, \\nx1, x2\\nVelocity of a bullet \\ntrain\\nvelocity, trainVelocity, \\nvelocityInMph\\nvelt, v, tv, x, x1, x2, train\\nCurrent date currentDate, todaysDate cd , current, c, x, x1, x2, date\\nLines per page linesPerPage lpp, lines, l, x, x1, x2\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 298}, page_content='262 Chapter 11: The Power of Variable Names\\nOptimum Name Length\\nThe optimum length for a name seems to be somewhere between the lengths of x and \\nmaximumNumberOfPointsInModernOlympics. Names that are too short don’t convey \\nenough meaning. The problem with names like x1 and x2 is that even if you can discover \\nwhat x is, you won’t know anything about the relationship between x1 and x2. Names \\nthat are too long are hard to type and can obscure the visual structure of a program.\\nGorla, Benander, and Benander found that the effort required to debug a program was \\nminimized when variables had names that averaged 10 to 16 characters (1990). Pro-\\ngrams with names averaging 8 to 20 characters were almost as easy to debug. The \\nguideline doesn’t mean that you should try to make all of your variable names 9 to 15 \\nor 10 to 16 characters long. It does mean that if you look over your code and see many \\nnames that are shorter, you should check to be sure that the names are as clear as they \\nneed to be.\\nYou’ll probably come out ahead by taking the Goldilocks-and-the-Three-Bears \\napproach to naming variables, as Table 11-2 illustrates.\\nThe Effect of Scope on Variable Names\\nCross-Reference Scope is \\ndiscussed in more detail in \\nSection 10.4, “Scope.”\\nAre short variable names always bad? No, not always. When you give a variable a short \\nname like i, the length itself says something about the variable—namely, that the vari-\\nable is a scratch value with a limited scope of operation.\\nA programmer reading such a variable should be able to assume that its value isn’t \\nused outside a few lines of code. When you name a variable i, you’re saying, “This vari-\\nable is a run-of-the-mill loop counter or array index and doesn’t have any significance \\noutside these few lines of code.”\\nA study by W. J. Hansen found that longer names are better for rarely used variables or \\nglobal variables and shorter names are better for local variables or loop variables \\nTable 11-2 Variable Names That Are Too Long, Too Short, or Just Right\\nToo long: numberOfPeopleOnTheUsOlympicTeam\\nnumberOfSeatsInTheStadium\\nmaximumNumberOfPointsInModernOlympics\\nToo short: n, np, ntm\\nn, ns, nsisd\\nm, mp, max, points\\nJust right: numTeamMembers, teamMemberCount\\nnumSeatsInStadium, seatCount\\nteamPointsMax, pointsRecord\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 299}, page_content='11.1 Considerations in Choosing Good Names 263\\n(Shneiderman 1980). Short names are subject to many problems, however, and some \\ncareful programmers avoid them altogether as a matter of defensive-programming policy.\\nUse qualifiers on names that are in the global namespace If you have variables that \\nare in the global namespace (named constants, class names, and so on), consider \\nwhether you need to adopt a convention for partitioning the global namespace and \\navoiding naming conflicts. In C++ and C#, you can use the namespace keyword to par-\\ntition the global namespace. \\nC+ + Example of Using the namespace Keyword to Partition the Global Namespace\\nnamespace UserInterfaceSubsystem {\\n   ...\\n   // lots of declarations\\n   ...\\n}\\nnamespace DatabaseSubsystem { \\n   ...\\n   // lots of declarations\\n   ...\\n}\\nIf you declare an Employee class in both the UserInterfaceSubsystem and the Database-\\nSubsystem, you can identify which you wanted to refer to by writing UserInterfaceSub-\\nsystem::Employee or DatabaseSubsystem::Employee. In Java, you can accomplish the \\nsame thing by using packages. \\nIn languages that don’t support namespaces or packages, you can still use naming \\nconventions to partition the global namespace. One convention is to require that glo-\\nbally visible classes be prefixed with subsystem mnemonic. The user interface \\nemployee class might become uiEmployee, and the database employee class might \\nbecome dbEmployee. This minimizes the risk of global-namespace collisions. \\nComputed-Value Qualifiers in Variable Names\\nMany programs have variables that contain computed values: totals, averages, maxi-\\nmums, and so on. If you modify a name with a qualifier like Total, Sum, Average, Max, \\nMin, Record, String, or Pointer, put the modifier at the end of the name.\\nThis practice offers several advantages. First, the most significant part of the variable \\nname, the part that gives the variable most of its meaning, is at the front, so it’s most \\nprominent and gets read first. Second, by establishing this convention, you avoid the \\nconfusion you might create if you were to use both totalRevenue and revenueTotal in the \\nsame program. The names are semantically equivalent, and the convention would pre-\\nvent their being used as if they were different. Third, a set of names like revenueTotal, \\nexpenseTotal, revenueAverage, and expenseAverage has a pleasing symmetry. A set of names'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 300}, page_content='264 Chapter 11: The Power of Variable Names\\nlike totalRevenue, expenseTotal, revenueAverage, and averageExpense doesn’t appeal to a \\nsense of order. Finally, the consistency improves readability and eases maintenance.\\nAn exception to the rule that computed values go at the end of the name is the cus-\\ntomary position of the Num qualifier. Placed at the beginning of a variable name, Num \\nrefers to a total: numCustomers is the total number of customers. Placed at the end of \\nthe variable name, Num refers to an index: customerNum is the number of the current \\ncustomer. The s at the end of numCustomers is another tip-off about the difference in \\nmeaning. But, because using Num so often creates confusion, it’s probably best to side-\\nstep the whole issue by using Count or Total to refer to a total number of customers \\nand Index to refer to a specific customer. Thus, customerCount is the total number of \\ncustomers and customerIndex refers to a specific customer.\\nCommon Opposites in Variable Names\\nCross-Reference For a simi-\\nlar list of opposites in routine \\nnames, see “Use opposites \\nprecisely” in Section 7.3.\\nUse opposites precisely. Using naming conventions for opposites helps consistency, \\nwhich helps readability. Pairs like begin/end are easy to understand and remember. \\nPairs that depart from common-language opposites tend to be hard to remember and \\nare therefore confusing. Here are some common opposites:\\n■ begin/end\\n■ first/last\\n■ locked/unlocked\\n■ min/max\\n■ next/previous\\n■ old/new\\n■ opened/closed\\n■ visible/invisible\\n■ source/target\\n■ source/destination \\n■ up/down\\n11.2 Naming Specific Types of Data\\nIn addition to the general considerations in naming data, special considerations come \\nup in the naming of specific kinds of data. This section describes considerations spe-\\ncifically for loop variables, status variables, temporary variables, boolean variables, \\nenumerated types, and named constants.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 301}, page_content='11.2 Naming Specific Types of Data 265\\nNaming Loop Indexes\\nCross-Reference For details \\non loops, see Chapter 16, \\n“Controlling Loops.”\\nGuidelines for naming variables in loops have arisen because loops are such a com-\\nmon feature of computer programming. The names i, j, and k are customary:\\nJava Example of a Simple Loop Variable Name\\nfor ( i = firstItem; i < lastItem; i++ ) {\\n   data[ i ] = 0;\\n}\\nIf a variable is to be used outside the loop, it should be given a name more meaningful \\nthan i, j, or k. For example, if you are reading records from a file and need to remember \\nhow many records you’ve read, a name like recordCount would be appropriate:\\nJava Example of a Good Descriptive Loop Variable Name\\nrecordCount = 0;\\nwhile ( moreScores() ) {\\n   score[ recordCount ] = GetNextScore();\\n   recordCount++;\\n}\\n// lines using recordCount\\n...\\nIf the loop is longer than a few lines, it’s easy to forget what i is supposed to stand for \\nand you’re better off giving the loop index a more meaningful name. Because code is \\nso often changed, expanded, and copied into other programs, many experienced pro-\\ngrammers avoid names like i altogether.\\nOne common reason loops grow longer is that they’re nested. If you have several \\nnested loops, assign longer names to the loop variables to improve readability.\\nJava Example of Good Loop Names in a Nested Loop\\nfor ( teamIndex = 0; teamIndex < teamCount; teamIndex++ ) {\\n   for ( eventIndex = 0; eventIndex < eventCount[ teamIndex ]; eventIndex++ ) {\\n      score[ teamIndex ][ eventIndex ] = 0;\\n   }\\n}\\nCarefully chosen names for loop-index variables avoid the common problem of index \\ncross-talk: saying i when you mean j and j when you mean i. They also make array \\naccesses clearer: score[ teamIndex ][ eventIndex ] is more informative than score[ i ][ j ]. \\nIf you have to use i, j, and k, don’t use them for anything other than loop indexes for \\nsimple loops—the convention is too well established, and breaking it to use them in \\nother ways is confusing. The simplest way to avoid such problems is simply to think \\nof more descriptive names than i, j, and k.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 302}, page_content='266 Chapter 11: The Power of Variable Names\\nNaming Status Variables\\nStatus variables describe the state of your program. Here’s a naming guideline:\\nThink of a better name than flag for status variables It’s better to think of flags as \\nstatus variables. A flag should never have flag in its name because that doesn’t give you \\nany clue about what the flag does. For clarity, flags should be assigned values and \\ntheir values should be tested with enumerated types, named constants, or global vari-\\nables that act as named constants. Here are some examples of flags with bad names:\\nC+ + Examples of Cryptic Flags\\nif ( flag ) ...\\nif ( statusFlag & 0x0F ) ...\\nif ( printFlag == 16 ) ...\\nif ( computeFlag == 0 ) ...\\nflag = 0x1;\\nstatusFlag = 0x80;\\nprintFlag = 16;\\ncomputeFlag = 0;\\nStatements like statusFlag = 0x80 give you no clue about what the code does unless \\nyou wrote the code or have documentation that tells you both what statusFlag is and \\nwhat 0x80 represents. Here are equivalent code examples that are clearer:\\nC+ + Examples of Better Use of Status Variables\\nif ( dataReady ) ...\\nif ( characterType & PRINTABLE_CHAR ) ...\\nif ( reportType == ReportType_Annual ) ...\\nif ( recalcNeeded = false ) ...\\ndataReady = true;\\ncharacterType = CONTROL_CHARACTER;\\nreportType = ReportType_Annual;\\nrecalcNeeded = false;\\nClearly, characterType = CONTROL_CHARACTER is more meaningful than statusFlag = \\n0x80. Likewise, the conditional if ( reportType == ReportType_Annual ) is clearer than if \\n( printFlag == 16 ). The second example shows that you can use this approach with \\nenumerated types as well as predefined named constants. Here’s how you could use \\nnamed constants and enumerated types to set up the values used in the example:\\nDeclaring Status Variables in C++\\n// values for CharacterType\\nconst int LETTER = 0x01;\\nconst int DIGIT = 0x02;\\nconst int PUNCTUATION = 0x04;\\nconst int LINE_DRAW = 0x08;\\nCODING \\nHORROR\\nC11619670.fm  Page 266  Tuesday, April 12, 2011  2:40 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 303}, page_content='11.2 Naming Specific Types of Data 267\\nconst int PRINTABLE_CHAR = ( LETTER | DIGIT | PUNCTUATION | LINE_DRAW );\\nconst int CONTROL_CHARACTER = 0x80;\\n// values for ReportType\\nenum ReportType { \\n   ReportType_Daily, \\n   ReportType_Monthly, \\n   ReportType_Quarterly, \\n   ReportType_Annual,\\n   ReportType_All \\n};\\nWhen you find yourself “figuring out” a section of code, consider renaming the vari-\\nables. It’s OK to figure out murder mysteries, but you shouldn’t need to figure out \\ncode. You should be able to read it.\\nNaming T emporary Variables\\nTemporary variables are used to hold intermediate results of calculations, as tempo-\\nrary placeholders, and to hold housekeeping values. They’re usually called temp, x, or \\nsome other vague and nondescriptive name. In general, temporary variables are a sign \\nthat the programmer does not yet fully understand the problem. Moreover, because \\nthe variables are officially given a “temporary” status, programmers tend to treat them \\nmore casually than other variables, increasing the chance of errors.\\nBe leery of “temporary” variables It’s often necessary to preserve values tempo-\\nrarily. But in one way or another, most of the variables in your program are temporary. \\nCalling a few of them temporary may indicate that you aren’t sure of their real pur-\\nposes. Consider the following example:\\nC+ + Example of an Uninformative “T emporary” Variable Name\\n// Compute solutions of a quadratic equation. \\n// This assumes that (b^2-4*a*c) is positive.\\ntemp = sqrt( b^2 - 4*a*c );\\nsolution[0] = ( -b + temp ) / ( 2 * a );\\nsolution[1] = ( -b - temp ) / ( 2 * a );\\nIt’s fine to store the value of the expression sqrt( b^2 - 4 * a * c ) in a variable, especially \\nsince it’s used in two places later. But the name temp doesn’t tell you anything about \\nwhat the variable does. A better approach is shown in this example:\\nC+ + Example with a “T emporary” Variable Name Replaced with a Real Variable\\n// Compute solutions of a quadratic equation. \\n// This assumes that (b^2-4*a*c) is positive.\\ndiscriminant = sqrt( b^2 - 4*a*c );\\nsolution[0] = ( -b + discriminant ) / ( 2 * a );\\nsolution[1] = ( -b - discriminant ) / ( 2 * a );\\nC11619670.fm  Page 267  Tuesday, April 12, 2011  2:45 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 304}, page_content='268 Chapter 11: The Power of Variable Names\\nThis is essentially the same code, but it’s improved with the use of an accurate, \\ndescriptive variable name.\\nNaming Boolean Variables\\nFollowing are a few guidelines to use in naming boolean variables:\\nKeep typical boolean names in mind Here are some particularly useful boolean vari-\\nable names:\\n■ done Use done to indicate whether something is done. The variable can indi-\\ncate whether a loop is done or some other operation is done. Set done to false \\nbefore something is done, and set it to true when something is completed.\\n■ error Use error to indicate that an error has occurred. Set the variable to false \\nwhen no error has occurred and to true when an error has occurred.\\n■ found Use found to indicate whether a value has been found. Set found to false \\nwhen the value has not been found and to true once the value has been found. \\nUse found when searching an array for a value, a file for an employee ID, a list of \\npaychecks for a certain paycheck amount, and so on.\\n■ success  or ok Use success or ok to indicate whether an operation has been suc-\\ncessful. Set the variable to false when an operation has failed and to true when an \\noperation has succeeded. If you can, replace success with a more specific name \\nthat describes precisely what it means to be successful. If the program is success-\\nful when processing is complete, you might use processingComplete instead. If \\nthe program is successful when a value is found, you might use found instead.\\nGive boolean variables names that imply true or false Names like done and success \\nare good boolean names because the state is either true or false; something is done or \\nit isn’t; it’s a success or it isn’t. Names like status and sourceFile, on the other hand, are \\npoor boolean names because they’re not obviously true or false. What does it mean if \\nstatus is true? Does it mean that something has a status? Everything has a status. Does \\ntrue mean that the status of something is OK? Or does false mean that nothing has \\ngone wrong? With a name like status, you can’t tell.\\nFor better results, replace status with a name like error or statusOK, and replace source-\\nFile with sourceFileAvailable or sourceFileFound, or whatever the variable represents.\\nSome programmers like to put Is in front of their boolean names. Then the variable \\nname becomes a question: isdone? isError? isFound? isProcessingComplete? Answering \\nthe question with true or false provides the value of the variable. A benefit of this \\napproach is that it won’t work with vague names: isStatus? makes no sense at all. A \\ndrawback is that it makes simple logical expressions less readable: if ( isFound ) is \\nslightly less readable than if ( found ).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 305}, page_content='11.2 Naming Specific Types of Data 269\\nUse positive boolean variable names Negative names like notFound, notdone, and \\nnotSuccessful are difficult to read when they are negated—for example,\\nif not notFound\\nSuch a name should be replaced by found, done, or processingComplete and then \\nnegated with an operator as appropriate. If what you’re looking for is found, you have \\nfound instead of not notFound.\\nNaming Enumerated Types\\nCross-Reference For details \\non using enumerated types, \\nsee Section 12.6, “Enumer-\\nated Types.”\\nWhen you use an enumerated type, you can ensure that it’s clear that members of the type \\nall belong to the same group by using a group prefix, such as Color_, Planet_, or Month_. \\nHere are some examples of identifying elements of enumerated types using prefixes: \\nVisual Basic Example of Using a Prefix Naming Convention for Enumerated Types\\nPublic Enum Color\\n   Color_Red\\n   Color_Green\\n   Color_Blue\\nEnd Enum\\nPublic Enum Planet\\n   Planet_Earth\\n   Planet_Mars\\n   Planet_Venus\\nEnd Enum\\nPublic Enum Month\\n   Month_January\\n   Month_February\\n   ...\\n   Month_December\\nEnd Enum\\nIn addition, the enum type itself (Color, Planet, or Month) can be identified in various \\nways, including all caps or prefixes (e_Color, e_Planet, or e_Month). A person could \\nargue that an enum is essentially a user-defined type and so the name of the enum \\nshould be formatted the same as other user-defined types like classes. A different argu-\\nment would be that enums are types, but they are also constants, so the enum type \\nname should be formatted as constants. This book uses the convention of mixed case \\nfor enumerated type names. \\nIn some languages, enumerated types are treated more like classes, and the members \\nof the enumeration are always prefixed with the enum name, like Color.Color_Red or \\nPlanet.Planet_Earth. If you’re working in that kind of language, it makes little sense to \\nrepeat the prefix, so you can treat the name of the enum type itself as the prefix and \\nsimplify the names to Color.Red and Planet.Earth.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 306}, page_content='270 Chapter 11: The Power of Variable Names\\nNaming Constants\\nCross-Reference For details \\non using named constants, \\nsee Section 12.7, “Named \\nConstants.”\\nWhen naming constants, name the abstract  entity the constant represents rather \\nthan the number the constant refers to. FIVE is a bad name for a constant (regard-\\nless of whether the value it represents is 5.0). CYCLES_NEEDED  is a good name. \\nCYCLES_NEEDED  can equal 5.0 or 6.0. FIVE = 6.0 would be ridiculous. By the same \\ntoken, BAKERS_DOZEN is a poor constant name; DONUTS_MAX  is a good con-\\nstant name.\\n11.3 The Power of Naming Conventions\\nSome programmers resist standards and conventions—and with good reason. Some \\nstandards and conventions are rigid and ineffective—destructive to creativity and pro-\\ngram quality. This is unfortunate since effective standards are some of the most pow-\\nerful tools at your disposal. This section discusses why, when, and how you should \\ncreate your own standards for naming variables.\\nWhy Have Conventions?\\nConventions offer several specific benefits:\\n■ They let you take more for granted. By making one global decision rather than \\nmany local ones, you can concentrate on the more important characteristics of \\nthe code.\\n■ They help you transfer knowledge across projects. Similarities in names give you \\nan easier and more confident understanding of what unfamiliar variables are \\nsupposed to do.\\n■ They help you learn code more quickly on a new project. Rather than learning \\nthat Anita’s code looks like this, Julia’s like that, and Kristin’s like something \\nelse, you can work with a more consistent set of code.\\n■ They reduce name proliferation. Without naming conventions, you can easily \\ncall the same thing by two different names. For example, you might call total \\npoints both pointTotal and totalPoints. This might not be confusing to you when \\nyou write the code, but it can be enormously confusing to a new programmer \\nwho reads it later.\\n■ They compensate for language weaknesses. You can use conventions to emulate \\nnamed constants and enumerated types. The conventions can differentiate \\namong local, class, and global data and can incorporate type information for \\ntypes that aren’t supported by the compiler.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 307}, page_content='11.3 The Power of Naming Conventions 271\\n■ They emphasize relationships among related items. If you use object data, the \\ncompiler takes care of this automatically. If your language doesn’t support \\nobjects, you can supplement it with a naming convention. Names like address, \\nphone, and name don’t indicate that the variables are related. But suppose you \\ndecide that all employee-data variables should begin with an Employee prefix. \\nemployeeAddress, employeePhone, and employeeName leave no doubt that the vari-\\nables are related. Programming conventions can make up for the weakness of \\nthe language you’re using.\\nThe key is that any convention at all is often better than no convention. The conven-\\ntion may be arbitrary. The power of naming conventions doesn’t come from the spe-\\ncific convention chosen but from the fact that a convention exists, adding structure to \\nthe code and giving you fewer things to worry about.\\nWhen You Should Have a Naming Convention\\nThere are no hard-and-fast rules for when you should establish a naming convention, \\nbut here are a few cases in which conventions are worthwhile:\\n■ When multiple programmers are working on a project\\n■ When you plan to turn a program over to another programmer for modifica-\\ntions and maintenance (which is nearly always)\\n■ When your programs are reviewed by other programmers in your organization\\n■ When your program is so large that you can’t hold the whole thing in your brain \\nat once and must think about it in pieces\\n■ When the program will be long-lived enough that you might put it aside for a \\nfew weeks or months before working on it again\\n■ When you have a lot of unusual terms that are common on a project and want to \\nhave standard terms or abbreviations to use in coding\\nYou always benefit from having some kind of naming convention. The consider-\\nations above should help you determine the extent of the convention to use on a \\nparticular project.\\nDegrees of Formality\\nCross-Reference For details \\non the differences in for-\\nmality in small and large \\nprojects, see Chapter 27, \\n“How Program Size Affects \\nConstruction.”\\nDifferent conventions have different degrees of formality. An informal convention \\nmight be as simple as “Use meaningful names.” Other informal conventions are \\ndescribed in the next section. In general, the degree of formality you need is depen-\\ndent on the number of people working on a program, the size of the program, and the \\nprogram’s expected life span. On tiny, throwaway projects, a strict convention might \\nbe unnecessary overhead. On larger projects in which several people are involved, \\neither initially or over the program’s life span, formal conventions are an indispens-\\nable aid to readability.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 308}, page_content='272 Chapter 11: The Power of Variable Names\\n11.4 Informal Naming Conventions\\nMost projects use relatively informal naming conventions such as the ones laid out in \\nthis section.\\nGuidelines for a Language-Independent Convention\\nHere are some guidelines for creating a language-independent convention:\\nDifferentiate between variable names and routine names The convention this book \\nuses is to begin variable and object names with lower case and routine names with \\nupper case: variableName vs. RoutineName().\\nDifferentiate between classes and objects The correspondence between class names \\nand object names—or between types and variables of those types—can get tricky. Sev-\\neral standard options exist, as shown in the following examples:\\nOption 1: Differentiating Types and Variables via Initial Capitalization\\nWidget widget;\\nLongerWidget longerWidget;\\nOption 2: Differentiating Types and Variables via All Caps\\nWIDGET widget;\\nLONGERWIDGET longerWidget\\nOption 3: Differentiating Types and Variables via the “t_” Prefix for Types\\nt_Widget Widget;\\nt_LongerWidget LongerWidget;\\nOption 4: Differentiating Types and Variables via the “a” Prefix for Variables\\nWidget aWidget;\\nLongerWidget aLongerWidget;\\nOption 5: Differentiating Types and Variables via Using More Specific Names for the \\nVariables\\nWidget employeeWidget;\\nLongerWidget fullEmployeeWidget;\\nEach of these options has strengths and weaknesses. Option 1 is a common conven-\\ntion in case-sensitive languages including C++ and Java, but some programmers are \\nuncomfortable differentiating names solely on the basis of capitalization. Indeed, cre-\\nating names that differ only in the capitalization of the first letter in the name seems to \\nprovide too little “psychological distance” and too small a visual distinction between \\nthe two names.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 309}, page_content='11.4 Informal Naming Conventions 273\\nThe Option 1 approach can’t be applied consistently in mixed-language environments \\nif any of the languages are case-insensitive. In Microsoft Visual Basic, for example, Dim \\nwidget as Widget will generate a syntax error because widget and Widget are treated as \\nthe same token. \\nOption 2 creates a more obvious distinction between the type name and the variable \\nname. For historical reasons, all caps are used to indicate constants in C++ and Java, \\nhowever, and the approach is subject to the same problems in mixed-language envi-\\nronments that Option 1 is subject to.\\nOption 3 works adequately in all languages, but some programmers dislike the idea of \\nprefixes for aesthetic reasons. \\nOption 4 is sometimes used as an alternative to Option 3, but it has the drawback of \\naltering the name of every instance of a class instead of just the one class name.\\nOption 5 requires more thought on a variable-by-variable basis. In most instances, \\nbeing forced to think of a specific name for a variable results in more readable code. \\nBut sometimes a widget truly is just a generic widget, and in those instances you’ll find \\nyourself coming up with less-than-obvious names, like genericWidget, which are argu-\\nably less readable. \\nIn short, each of the available options involves tradeoffs. The code in this book uses \\nOption 5 because it’s the most understandable in situations in which the person read-\\ning the code isn’t necessarily familiar with a less intuitive naming convention. \\nIdentify global variables One common programming problem is misuse of global \\nvariables. If you give all global variable names a g_ prefix, for example, a programmer \\nseeing the variable g_RunningTotal will know it’s a global variable and treat it as such.\\nIdentify member variables Identify a class’s member data. Make it clear that the vari-\\nable isn’t a local variable and that it isn’t a global variable either. For example, you can \\nidentify class member variables with an m_ prefix to indicate that it is member data. \\nIdentify type definitions Naming conventions for types serve two purposes: they \\nexplicitly identify a name as a type name, and they avoid naming clashes with vari-\\nables. To meet those considerations, a prefix or suffix is a good approach. In C++, the \\ncustomary approach is to use all uppercase letters for a type name—for example, \\nCOLOR and MENU. (This convention applies to typedefs and structs, not class names.) \\nBut this creates the possibility of confusion with named preprocessor constants. To \\navoid confusion, you can prefix the type names with t_, such as t_Color and t_Menu.\\nIdentify named constants Named constants need to be identified so that you can tell \\nwhether you’re assigning a variable a value from another variable (whose value might \\nchange) or from a named constant. In Visual Basic, you have the additional possibility \\nthat the value might be from a function. Visual Basic doesn’t require function names to \\nuse parentheses, whereas in C++ even a function with no parameters uses parentheses.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 310}, page_content='274 Chapter 11: The Power of Variable Names\\nOne approach to naming constants is to use a prefix like c_ for constant names. That \\nwould give you names like c_RecsMax or c_LinesPerPageMax. In C++ and Java, the con-\\nvention is to use all uppercase letters, possibly with underscores to separate words, \\nRECSMAX or RECS_ MAX and LINESPERPAGEMAX or LINES_PER_PAGE_ MAX.\\nIdentify elements of enumerated types Elements of enumerated types need to be \\nidentified for the same reasons that named constants do—to make it easy to tell that \\nthe name is for an enumerated type as opposed to a variable, named constant, or func-\\ntion. The standard approach applies: you can use all caps or an e_ or E_ prefix for the \\nname of the type itself and use a prefix based on the specific type like Color_ or Planet_ \\nfor the members of the type. \\nIdentify input-only parameters in languages that don’t enforce them Sometimes \\ninput parameters are accidentally modified. In languages such as C++ and Visual \\nBasic, you must indicate explicitly whether you want a value that’s been modified to \\nbe returned to the calling routine. This is indicated with the *, &, and const qualifiers \\nin C++ or ByRef and ByVal in Visual Basic. \\nIn other languages, if you modify an input variable, it is returned whether you like it or \\nnot. This is especially true when passing objects. In Java, for example, all objects are \\npassed “by value,” so when you pass an object to a routine, the contents of the object \\ncan be changed within the called routine (Arnold, Gosling, Holmes 2000). \\nCross-Reference Augment-\\ning a language with a nam-\\ning convention to make up \\nfor limitations in the lan-\\nguage itself is an example of \\nprogramming into a lan-\\nguage instead of just pro-\\ngramming in it. For more \\ndetails on programming into \\na language, see Section 34.4, \\n“Program into Your Lan-\\nguage, Not in It.” \\nIn those languages, if you establish a naming convention in which input-only param-\\neters are given a const prefix (or final, nonmodifiable, or something comparable) , you’ll \\nknow that an error has occurred when you see anything with a const prefix on the left \\nside of an equal sign. If you see constMax.SetNewMax( ... ), you’ll know it’s a goof \\nbecause the const prefix indicates that the variable isn’t supposed to be modified.\\nFormat names to enhance readability Two common techniques for increasing read-\\nability are using capitalization and spacing characters to separate words. For example, \\nGYMNASTICSPOINTTOTAL is less readable than gymnasticsPointTotal or \\ngymnastics_point_total. C++, Java, Visual Basic, and other languages allow for mixed \\nuppercase and lowercase characters. C++, Java, Visual Basic, and other languages also \\nallow the use of the underscore (_) separator.\\nTry not to mix these techniques; that makes code hard to read. If you make an honest \\nattempt to use any of these readability techniques consistently, however, it will \\nimprove your code. People have managed to have zealous, blistering debates over fine \\npoints such as whether the first character in a name should be capitalized (TotalPoints \\nvs. totalPoints), but as long as you and your team are consistent, it won’t make much \\ndifference. This book uses initial lowercase because of the strength of the Java practice \\nand to facilitate similarity in style across several languages.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 311}, page_content='11.4 Informal Naming Conventions 275\\nGuidelines for Language-Specific Conventions\\nFollow the naming conventions of the language you’re using. You can find books for \\nmost languages that describe style guidelines. Guidelines for C, C++, Java, and Visual \\nBasic are provided in the following sections.\\nC Conventions\\nFurther Reading The classic \\nbook on C programming \\nstyle is C Programming \\nGuidelines (Plum 1984).\\nSeveral naming conventions apply specifically to the C programming language:\\n■ c and ch are character variables.\\n■ i and j are integer indexes.\\n■ n is a number of something.\\n■ p is a pointer.\\n■ s is a string.\\n■ Preprocessor macros are in ALL_CAPS. This is usually extended to include type-\\ndefs as well.\\n■ Variable and routine names are in all_lowercase.\\n■ The underscore (_) character is used as a separator: letters_in_lowercase is more \\nreadable than lettersinlowercase.\\nThese are the conventions for generic, UNIX-style and Linux-style C programming, \\nbut C conventions are different in different environments. In Microsoft Windows, C \\nprogrammers tend to use a form of the Hungarian naming convention and mixed \\nuppercase and lowercase letters for variable names. On the Macintosh, C program-\\nmers tend to use mixed-case names for routines because the Macintosh toolbox and \\noperating-system routines were originally designed for a Pascal interface.\\nC+ + Conventions\\nFurther Reading For more \\non C++ programming style, \\nsee The Elements of C++ \\nStyle (Misfeldt, Bumgardner, \\nand Gray 2004). \\nHere are the conventions that have grown up around C++ programming: \\n■ i and j are integer indexes.\\n■ p is a pointer.\\n■ Constants, typedefs, and preprocessor macros are in ALL_CAPS. \\n■ Class and other type names are in MixedUpperAndLowerCase(). \\n■ Variable and function names use lowercase for the first word, with the first letter \\nof each following word capitalized—for example, variableOrRoutineName.\\n■ The underscore is not used as a separator within names, except for names in all \\ncaps and certain kinds of prefixes (such as those used to identify global variables).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 312}, page_content='276 Chapter 11: The Power of Variable Names\\nAs with C programming, this convention is far from standard and different environ-\\nments have standardized on different convention details. \\nJava Conventions\\nFurther Reading For more \\non Java programming style, \\nsee The Elements of Java \\nStyle, 2d ed. (Vermeulen et \\nal. 2000).\\nIn contrast with C and C++, Java style conventions have been well established since \\nthe language’s beginning:\\n■ i and j are integer indexes.\\n■ Constants are in ALL_CAPS separated by underscores. \\n■ Class and interface names capitalize the fi rst letter of each word, including the \\nfirst word—for example, ClassOrInterfaceName.\\n■ Variable and method names use lowercase for the first word, with the first letter \\nof each following word capitalized—for example, variableOrRoutineName.\\n■ The underscore is not used as a separator within names except for names in all \\ncaps.\\n■ The get and set prefixes are used for accessor methods. \\nVisual Basic Conventions\\nVisual Basic has not really established firm conventions. The next section recom-\\nmends a convention for Visual Basic. \\nMixed-Language Programming Considerations\\nWhen programming in a mixed-language environment, the naming conventions (as \\nwell as formatting conventions, documentation conventions, and other conventions) \\ncan be optimized for overall consistency and readability—even if that means going \\nagainst convention for one of the languages that’s part of the mix. \\nIn this book, for example, variable names all begin with lowercase, which is consistent \\nwith conventional Java programming practice and some but not all C++ conventions. \\nThis book formats all routine names with an initial capital letter, which follows the \\nC++ convention. The Java convention would be to begin method names with lower-\\ncase, but this book uses routine names that begin in uppercase across all languages for \\nthe sake of overall readability. \\nSample Naming Conventions\\nThe standard conventions above tend to ignore several important aspects of naming \\nthat were discussed over the past few pages—including variable scoping (private, class, \\nor global), differentiating between class, object, routine, and variable names, and \\nother issues.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 313}, page_content='11.4 Informal Naming Conventions 277\\nThe naming-convention guidelines can look complicated when they’re strung across \\nseveral pages. They don’t need to be terribly complex, however, and you can adapt \\nthem to your needs. Variable names include three kinds of information:\\n■ The contents of the variable (what it represents)\\n■ The kind of data (named constant, primitive variable, user-defined type, or \\nclass)\\n■ The scope of the variable (private, class, package, or global)\\nTables 11-3, 11-4, and 11-5 provide naming conventions for C, C++, Java, and Visual \\nBasic that have been adapted from the guidelines presented earlier. These specific con-\\nventions aren’t necessarily recommended, but they give you an idea of what an infor-\\nmal naming convention includes.\\nTable 11-3 Sample Naming Conventions for C++ and Java\\nEntity Description\\nClassName Class names are in mixed uppercase and lowercase with \\nan initial capital letter. \\nTypeName Type definitions, including enumerated types and type-\\ndefs, use mixed uppercase and lowercase with an initial \\ncapital letter.\\nEnumeratedTypes In addition to the rule above, enumerated types are \\nalways stated in the plural form. \\nlocalVariable Local variables are in mixed uppercase and lowercase \\nwith an initial lowercase letter. The name should be inde-\\npendent of the underlying data type and should refer to \\nwhatever the variable represents.\\nroutineParameter Routine parameters are formatted the same as local vari-\\nables. \\nRoutineName() Routines are in mixed uppercase and lowercase. (Good \\nroutine names are discussed in Section 7.3.)\\nm_ClassVariable Member variables that are available to multiple routines \\nwithin a class, but only within a class, are prefixed with an \\nm_.\\ng_GlobalVariable Global variables are prefixed with a g_.\\nCONSTANT Named constants are in ALL_CAPS.\\nMACRO Macros are in ALL_CAPS.\\nBase_EnumeratedType Enumerated types are prefixed with a mnemonic for their \\nbase type stated in the singular—for example, Color_Red, \\nColor_Blue.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 314}, page_content='278 Chapter 11: The Power of Variable Names\\nBecause Visual Basic is not case-sensitive, special rules apply for differentiating \\nbetween type names and variable names. Take a look at Table 11-5. \\nTable 11-4 Sample Naming Conventions for C\\nEntity Description\\nTypeName Type definitions use mixed uppercase and lowercase with \\nan initial capital letter.\\nGlobalRoutineName() Public routines are in mixed uppercase and lowercase.\\nf_FileRoutineName() Routines that are private to a single module (file) are pre-\\nfixed with an f_.\\nLocalVariable Local variables are in mixed uppercase and lowercase. \\nThe name should be independent of the underlying data \\ntype and should refer to whatever the variable repre-\\nsents.\\nRoutineParameter Routine parameters are formatted the same as local vari-\\nables. \\nf_FileStaticVariable Module (file) variables are prefixed with an f_.\\nG_GLOBAL_GlobalVariable Global variables are prefixed with a G_ and a mnemonic \\nof the module (file) that defines the variable in all upper-\\ncase—for example, SCREEN_Dimensions.\\nLOCAL_CONSTANT Named constants that are private to a single routine or \\nmodule (file) are in all uppercase—for example, \\nROWS_MAX.\\nG_GLOBALCONSTANT Global named constants are in all uppercase and are pre-\\nfixed with G_ and a mnemonic of the module (file) that \\ndefines the named constant in all uppercase—for exam-\\nple, G_SCREEN_ROWS_MAX.\\nLOCALMACRO() Macro definitions that are private to a single routine or \\nmodule (file) are in all uppercase. \\nG_GLOBAL_MACRO() Global macro definitions are in all uppercase and are \\nprefixed with G_ and a mnemonic of the module (file) \\nthat defines the macro in all uppercase—for example, \\nG_SCREEN_LOCATION().\\nTable 11-5 Sample Naming Conventions for Visual Basic\\nEntity Description\\nC_ClassName Class names are in mixed uppercase and lowercase with \\nan initial capital letter and a C_ prefix. \\nT_TypeName Type definitions, including enumerated types and type-\\ndefs, use mixed uppercase and lowercase with an initial \\ncapital letter and a T_ prefix. \\nT_EnumeratedTypes In addition to the rule above, enumerated types are \\nalways stated in the plural form.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 315}, page_content='11.5 Standardized Prefixes 279\\n11.5 Standardized Prefixes\\nFurther Reading For further \\ndetails on the Hungarian \\nnaming convention, see \\n“The Hungarian Revolution” \\n(Simonyi and Heller 1991).\\nStandardizing prefixes for common meanings provides a terse but consistent and \\nreadable approach to naming data. The best known scheme for standardizing prefixes \\nis the Hungarian naming convention, which is a set of detailed guidelines for naming \\nvariables and routines (not Hungarians!) that was widely used at one time in \\nMicrosoft Windows programming. Although the Hungarian naming convention is no \\nlonger in widespread use, the basic idea of standardizing on terse, precise abbrevia-\\ntions continues to have value. \\nStandardized prefixes are composed of two parts: the user-defined type (UDT) abbre-\\nviation and the semantic prefix. \\nUser-Defined Type Abbreviations\\nThe UDT abbreviation identifies the data type of the object or variable being named. \\nUDT abbreviations might refer to entities such as windows, screen regions, and fonts. \\nA UDT abbreviation generally doesn’t refer to any of the predefined data types offered \\nby the programming language.\\nUDTs are described with short codes that you create for a specific program and then \\nstandardize on for use in that program. The codes are mnemonics such as wn for win-\\ndows and scr for screen regions. Table 11-6 offers a sample list of UDTs that you might \\nuse in a program for a word processor.\\nlocalVariable Local variables are in mixed uppercase and lowercase \\nwith an initial lowercase letter. The name should be inde-\\npendent of the underlying data type and should refer to \\nwhatever the variable represents.\\nroutineParameter Routine parameters are formatted the same as local vari-\\nables. \\nRoutineName() Routines are in mixed uppercase and lowercase. (Good \\nroutine names are discussed in Section 7.3.)\\nm_ClassVariable Member variables that are available to multiple routines \\nwithin a class, but only within a class, are prefixed with an \\nm_.\\ng_GlobalVariable Global variables are prefixed with a g_.\\nCONSTANT Named constants are in ALL_CAPS.\\nBase_EnumeratedType Enumerated types are prefixed with a mnemonic for their \\nbase type stated in the singular—for example, Color_Red, \\nColor_Blue.\\nTable 11-5 Sample Naming Conventions for Visual Basic\\nEntity Description'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 316}, page_content='280 Chapter 11: The Power of Variable Names\\nWhen you use UDTs, you also define programming-language data types that use the \\nsame abbreviations as the UDTs. Thus, if you had the UDTs in Table 11-6, you’d see \\ndata declarations like these:\\nCH    chCursorPosition;\\nSCR   scrUserWorkspace;\\nDOC   docActive\\nPA    firstPaActiveDocument;\\nPA    lastPaActiveDocument;\\nWN    wnMain;\\nAgain, these examples relate to a word processor. For use on your own projects, you’d \\ncreate UDT abbreviations for the UDTs that are used most commonly within your \\nenvironment. \\nSemantic Prefixes\\nSemantic prefixes go a step beyond the UDT and describe how the variable or object \\nis used. Unlike UDTs, which vary from project to project, semantic prefixes are some-\\nwhat standard across projects. Table 11-7 shows a list of standard semantic prefixes.\\nTable 11-6 Sample of UDTs for a Word Processor\\nUDT \\nAbbreviation Meaning\\nch Character (a character not in the C++ sense, but in the sense of the \\ndata type a word-processing program would use to represent a \\ncharacter in a document)\\ndoc Document\\npa Paragraph\\nscr Screen region\\nsel Selection\\nwn Window\\nTable 11-7 Semantic Prefixes \\nSemantic \\nPrefix Meaning\\nc Count (as in the number of records, characters, and so on)\\nfirst The first element that needs to be dealt with in an array. first is similar to \\nmin but relative to the current operation rather than to the array itself.\\ng Global variable\\ni Index into an array\\nlast The last element that needs to be dealt with in an array. last is the counter-\\npart of first.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 317}, page_content='11.5 Standardized Prefixes 281\\nSemantic prefixes are formatted in lowercase or mixed uppercase and lowercase and \\nare combined with the UDTs and with other semantic prefixes as needed. For exam-\\nple, the first paragraph in a document would be named pa to show that it’s a para-\\ngraph and first to show that it’s the first paragraph: firstPa. An index into the set of \\nparagraphs would be named iPa; cPa is the count, or the number of paragraphs; and \\nfirstPaActiveDocument and lastPaActiveDocument are the first and last paragraphs in the \\ncurrent active document.\\nAdvantages of Standardized Prefixes\\nStandardized prefixes give you all the general advantages of having a naming conven-\\ntion as well as several other advantages. Because so many names are standard, you \\nhave fewer names to remember in any single program or class. \\nStandardized prefixes add precision to several areas of naming that tend to be impre-\\ncise. The precise distinctions between min, first, last, and max are particularly helpful.\\nStandardized prefixes make names more compact. For example, you can use cpa for \\nthe count of paragraphs rather than totalParagraphs. You can use ipa to identify an \\nindex into an array of paragraphs rather than indexParagraphs or paragraphsIndex.\\nFinally, standardized prefixes allow you to check types accurately when you’re using \\nabstract data types that your compiler can’t necessarily check: paReformat = docRefor-\\nmat is probably wrong because pa and doc are different UDTs.\\nThe main pitfall with standardized prefixes is a programmer neglecting to give the \\nvariable a meaningful name in addition to its prefix. If ipa unambiguously designates \\nan index into an array of paragraphs, it’s tempting not to make the name more mean-\\ningful like ipaActiveDocument. For readability, close the loop and come up with a \\ndescriptive name. \\nlim The upper limit of elements that need to be dealt with in an array. lim is \\nnot a valid index. Like last, lim is used as a counterpart of first. Unlike last, \\nlim represents a noninclusive upper bound on the array; last represents a \\nfinal, legal element. Generally, lim equals last + 1.\\nm Class-level variable\\nmax The absolute last element in an array or other kind of list. max refers to the \\narray itself rather than to operations on the array.\\nmin The absolute first element in an array or other kind of list.\\np Pointer\\nTable 11-7 Semantic Prefixes \\nSemantic \\nPrefix Meaning\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 318}, page_content='282 Chapter 11: The Power of Variable Names\\n11.6 Creating Short Names That Are Readable\\nThe desire to use short variable names is in some ways a remnant of an earlier age of \\ncomputing. Older languages like assembler, generic Basic, and Fortran limited vari-\\nable names to 2–8 characters and forced programmers to create short names. Early \\ncomputing was more closely linked to mathematics and its use of terms like i, j, and k \\nas the variables in summations and other equations. In modern languages like C++, \\nJava, and Visual Basic, you can create names of virtually any length; you have almost \\nno reason to shorten meaningful names.\\nIf circumstances do require you to create short names, note that some methods of \\nshortening names are better than others. You can create good short variable names by \\neliminating needless words, using short synonyms, and using any of several abbrevia-\\ntion strategies. It’s a good idea to be familiar with multiple techniques for abbreviating \\nbecause no single technique works well in all cases.\\nGeneral Abbreviation Guidelines\\nHere are several guidelines for creating abbreviations. Some of them contradict others, \\nso don’t try to use them all at the same time.\\n■ Use standard abbreviations (the ones in common use, which are listed in a \\ndictionary).\\n■ Remove all nonleading vowels. (computer becomes cmptr, and screen becomes \\nscrn. apple becomes appl, and integer becomes intgr.)\\n■ Remove articles: and, or, the, and so on. \\n■ Use the first letter or first few letters of each word.\\n■ Truncate consistently after the first, second, or third (whichever is appropriate) \\nletter of each word.\\n■ Keep the first and last letters of each word.\\n■ Use every significant word in the name, up to a maximum of three words.\\n■ Remove useless suffixes—ing, ed, and so on.\\n■ Keep the most noticeable sound in each syllable.\\n■ Be sure not to change the meaning of the variable. \\n■ Iterate through these techniques until you abbreviate each variable name to \\nbetween 8 to 20 characters or the number of characters to which your language \\nlimits variable names.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 319}, page_content='11.6 Creating Short Names That Are Readable 283\\nPhonetic Abbreviations\\nSome people advocate creating abbreviations based on the sound of the words rather \\nthan their spelling. Thus skating becomes sk8ing, highlight becomes hilite, before \\nbecomes b4, execute becomes xqt, and so on. This seems too much like asking people \\nto figure out personalized license plates to me, and I don’t recommend it. As an exer-\\ncise, figure out what these names mean:\\nComments on Abbreviations\\nYou can fall into several traps when creating abbreviations. Here are some rules for \\navoiding pitfalls:\\nDon’t abbreviate by removing one character from a word Typing one character is lit-\\ntle extra work, and the one-character savings hardly justifies the loss in readability. It’s \\nlike the calendars that have “Jun” and “Jul.” You have to be in a big hurry to spell June \\nas “Jun.” With most one-letter deletions, it’s hard to remember whether you removed \\nthe character. Either remove more than one character or spell out the word.\\nAbbreviate consistently Always use the same abbreviation. For example, use Num \\neverywhere or No everywhere, but don’t use both. Similarly, don’t abbreviate a word \\nin some names and not in others. For instance, don’t use the full word Number in \\nsome places and the abbreviation Num in others.\\nCreate names that you can pronounce Use xPos rather than xPstn and needsComp \\nrather than ndsCmptg. Apply the telephone test—if you can’t read your code to some-\\none over the phone, rename your variables to be more distinctive (Kernighan and \\nPlauger 1978). \\nAvoid combinations that result in misreading or mispronunciation To refer to the \\nend of B, favor ENDB over BEND. If you use a good separation technique, you won’t \\nneed this guideline since B-END, BEnd, or b_end won’t be mispronounced.\\nUse a thesaurus to resolve naming collisions One problem in creating short names \\nis naming collisions—names that abbreviate to the same thing. For example, if you’re \\nlimited to three characters and you need to use fired and full revenue disbursal in the \\nsame area of a program, you might inadvertently abbreviate both to frd.\\nOne easy way to avoid naming collisions is to use a different word with the same \\nmeaning, so a thesaurus is handy. In this example, dismissed might be substituted for \\nfired and complete revenue disbursal might be substituted for full revenue disbursal. The \\nthree-letter abbreviations become dsm and crd, eliminating the naming collision.\\nILV2SK8 XMEQWK S2DTM8O NXTC TRMN8R'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 320}, page_content='284 Chapter 11: The Power of Variable Names\\nDocument extremely short names with translation tables in the code In languages \\nthat allow only very short names, include a translation table to provide a reminder of \\nthe mnemonic content of the variables. Include the table as comments at the begin-\\nning of a block of code. Here’s an example:\\nFortran Example of a Good Translation Table\\nC *******************************************************************\\nC    Translation Table\\nC\\nC    Variable    Meaning\\nC    --------    -------\\nC    XPOS        x-Coordinate Position (in meters)\\nC    YPOS        Y-Coordinate Position (in meters)\\nC    NDSCMP      Needs Computing (=0 if no computation is needed;\\nC                                 =1 if computation is needed)\\nC    PTGTTL      Point Grand Total\\nC    PTVLMX      Point Value Maximum\\nC    PSCRMX      Possible Score Maximum\\nC *****************************************************************\\nYou might think that this technique is outdated, but as recently as mid-2003 I \\nworked with a client that had hundreds of thousands of lines of code written in RPG \\nthat was subject to a 6-char acter–variable-name limitatio n. These issues still come \\nup from time to time. \\nDocument all abbreviations in a project-level “Standard Abbreviations” document\\nAbbreviations in code create two general risks:\\n■ A reader of the code might not understand the abbreviation.\\n■ Other programmers might use multiple abbreviations to refer to the same word, \\nwhich creates needless confusion.\\nTo address both these potential problems, you can create a “Standard Abbreviations” \\ndocument that captures all the coding abbreviations used on your project. The docu-\\nment can be a word processor document or a spreadsheet. On a very large project, it \\ncould be a database. The document is checked into version control and checked out \\nanytime anyone creates a new abbreviation in the code. Entries in the document \\nshould be sorted by the full word, not the abbreviation. \\nThis might seem like a lot of overhead, but aside from a small amount of startup over-\\nhead, it really just sets up a mechanism that helps the project use abbreviations effec-\\ntively. It addresses the first of the two general risks described above by documenting \\nall abbreviations in use. The fact that a programmer can’t create a new abbreviation \\nwithout the overhead of checking the Standard Abbreviations document out of ver-'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 321}, page_content='11.7 Kinds of Names to Avoid 285\\nsion control, entering the abbreviation, and checking it back in is a good thing. It \\nmeans that an abbreviation won’t be created unless it’s so common that it’s worth the \\nhassle of documenting it. \\nThis approach addresses the second risk by reducing the likelihood that a program-\\nmer will create a redundant abbreviation. A programmer who wants to abbreviate \\nsomething will check out the abbreviations document and enter the new abbrevia-\\ntion. If there is already an abbreviation for the word the programmer wants to abbre-\\nviate, the programmer will notice that and will then use the existing abbreviation \\ninstead of creating a new one. \\nThe general issue illustrated by this guideline is the difference between write-time con-\\nvenience and read-time convenience. This approach clearly creates a write-time incon-\\nvenience, but programmers over the lifetime of a system spend far more time reading \\ncode than writing code. This approach increases read-time convenience. By the time \\nall the dust settles on a project, it might well also have improved write-time conve-\\nnience. \\nRemember that names matter more to the reader of the code than to the writerRead \\ncode of your own that you haven’t seen for at least six months and notice where you \\nhave to work to understand what the names mean. Resolve to change the practices \\nthat cause such confusion.\\n11.7 Kinds of Names to Avoid\\nHere are some guidelines regarding variable names to avoid:\\nAvoid misleading names or abbreviations Make sure that a name is unambiguous. \\nFor example, FALSE is usually the opposite of TRUE and would be a bad abbreviation \\nfor “Fig and Almond Season.”\\nAvoid names with similar meanings If you can switch the names of two variables \\nwithout hurting the program, you need to rename both variables. For example, input \\nand inputValue, recordNum and numRecords, and fileNumber and fileIndex are so seman-\\ntically similar that if you use them in the same piece of code you’ll easily confuse them \\nand install some subtle, hard-to-find errors.\\nCross-Reference The techni-\\ncal term for differences like \\nthis between similar variable \\nnames is “psychological dis-\\ntance.” For details, see “How \\n‘Psychological Distance’ Can \\nHelp” in Section 23.4.\\nAvoid variables with different meanings but similar names If you have two variables \\nwith similar names and different meanings, try to rename one of them or change your \\nabbreviations. Avoid names like clientRecs and clientReps. They’re only one letter differ-\\nent from each other, and the letter is hard to notice. Have at least two-letter differences \\nbetween names, or put the differences at the beginning or at the end. clientRecords and \\nclientReports are better than the original names.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 322}, page_content='286 Chapter 11: The Power of Variable Names\\nAvoid names that sound similar, such as wrap and rap Homonyms get in the way \\nwhen you try to discuss your code with others. One of my pet peeves about Extreme \\nProgramming (Beck 2000) is its overly clever use of the terms Goal Donor and Gold \\nOwner, which are virtually indistinguishable when spoken. You end up having con-\\nversations like this:\\nI was just speaking with the Goal Donor—\\nDid you say “Gold Owner” or “Goal Donor”? \\nI said “Goal Donor.” \\nWhat?\\nGOAL - - - DONOR!\\nOK, Goal Donor. You don’t have to yell, Goll’ Darn it. \\nDid you say “Gold Donut?” \\nRemember that the telephone test applies to similar sounding names just as it does to \\noddly abbreviated names. \\nAvoid numerals in names If the numerals in a name are really significant, use an array \\ninstead of separate variables. If an array is inappropriate, numerals are even more inap-\\npropriate. For example, avoid file1 and file2, or total1 and total2. You can almost always \\nthink of a better way to differentiate between two variables than by tacking a 1 or a 2 \\nonto the end of the name. I can’t say never use numerals. Some real-world entities (such \\nas Route 66 or Interstate 405) have numerals embedded in them. But consider whether \\nthere are better alternatives before you create a name that includes numerals.\\nAvoid misspelled words in names It’s hard enough to remember how words are sup-\\nposed to be spelled. To require people to remember “correct” misspellings is simply \\ntoo much to ask. For example, misspelling highlight as hilite to save three characters \\nmakes it devilishly difficult for a reader to remember how highlight was misspelled. \\nWas it highlite? hilite? hilight? hilit? jai-a-lai-t? Who knows?\\nAvoid words that are commonly misspelled in English Absense, acummulate, acsend, \\ncalender, concieve, defferred, definate, independance, occassionally, prefered, reciept, super-\\nseed, and many others are common misspellings in English. Most English handbooks \\ncontain a list of commonly misspelled words. Avoid using such words in your variable \\nnames.\\nDon’t differentiate variable names solely by capitalization If you’re programming in \\na case-sensitive language such as C++, you may be tempted to use frd for fired, FRD for \\nfinal review duty, and Frd for full revenue disbursal. Avoid this practice. Although the \\nnames are unique, the association of each with a particular meaning is arbitrary and \\nconfusing. Frd could just as easily be associated with final review duty and FRD with \\nfull revenue disbursal, and no logical rule will help you or anyone else to remember \\nwhich is which.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 323}, page_content='11.7 Kinds of Names to Avoid 287\\nAvoid multiple natural languages In multinational projects, enforce use of a single \\nnatural language for all code, including class names, variable names, and so on. Read-\\ning another programmer’s code can be a challenge; reading another programmer’s \\ncode in Southeast Martian is impossible. \\nA more subtle problem occurs in variations of English. If a project is conducted in \\nmultiple English-speaking countries, standardize on one version of English so that \\nyou’re not constantly wondering whether the code should say “color” or “colour,” \\n“check” or “cheque,” and so on. \\nAvoid the names of standard types, variables, and routines All programming-\\nlanguage guides contain lists of the language’s reserved and predefined names. \\nRead the list occasionally to make sure you’re not stepping on the toes of the language \\nyou’re using. For example, the following code fragment is legal in PL/I, but you would \\nbe a certifiable idiot to use it:\\nif if = then then\\n   then = else;\\nelse else = if;\\nDon’t use names that are totally unrelated to what the variables represent Sprin-\\nkling names such as margaret and pookie throughout your program virtually guaran-\\ntees that no one else will be able to understand it. Avoid your boyfriend’s name, wife’s \\nname, favorite beer’s name, or other clever (aka silly) names for variables, unless the \\nprogram is really about your boyfriend, wife, or favorite beer. Even then, you would be \\nwise to recognize that each of these might change, and that therefore the generic \\nnames boyfriend, wife, and favoriteBeer are superior!\\nAvoid names containing hard-to-read characters Be aware that some characters look \\nso similar that it’s hard to tell them apart. If the only difference between two names is \\none of these characters, you might have a hard time telling the names apart. For exam-\\nple, try to circle the name that doesn’t belong in each of the following sets:\\neyeChartl     eyeChartI     eyeChartl\\nTTLCONFUSION  TTLCONFUSION  TTLC0NFUSION\\nhard2Read     hardZRead     hard2Read\\nGRANDTOTAL    GRANDTOTAL    6RANDTOTAL\\nttl5          ttlS          ttlS\\nPairs that are hard to distinguish include (1 and l), (1 and I), (. and ,), (0 and O), (2 \\nand Z), (; and :), (S and 5), and (G and 6).\\nCross-Reference For consid-\\nerations in using data, see \\nthe checklist on page 257 in \\nChapter 10, “General Issues \\nin Using Variables.”\\nDo details like these really matter? Indeed! Gerald Weinberg reports that in the 1970s, \\na comma was used in a Fortran FORMAT statement where a period should have been \\nused. The result was that scientists miscalculated a spacecraft’s trajectory and lost a \\nspace probe—to the tune of $1.6 billion (Weinberg 1983). \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 324}, page_content='288 Chapter 11: The Power of Variable Names\\ncc2e.com/1191 CHECKLIST: Naming Variables\\nGeneral Naming Considerations\\n❑ Does the name fully and accurately describe what the variable represents?\\n❑ Does the name refer to the real-world problem rather than to the program-\\nming-language solution?\\n❑ Is the name long enough that you don’t have to puzzle it out?\\n❑ Are computed-value qualifiers, if any, at the end of the name?\\n❑ Does the name use Count or Index instead of Num?\\nNaming Specific Kinds of Data\\n❑ Are loop index names meaningful (something other than i, j, or k if the \\nloop is more than one or two lines long or is nested)?\\n❑ Have all “temporary” variables been renamed to something more mean-\\ningful?\\n❑ Are boolean variables named so that their meanings when they’re true are \\nclear?\\n❑ Do enumerated-type names include a prefix or suffix that indicates the cat-\\negory—for example, Color_ for Color_Red, Color_Green, Color_Blue, and so \\non?\\n❑ Are named constants named for the abstract entities they represent rather \\nthan the numbers they refer to?\\nNaming Conventions\\n❑ Does the convention distinguish among local, class, and global data?\\n❑ Does the convention distinguish among type names, named constants, \\nenumerated types, and variables?\\n❑ Does the convention identify input-only parameters to routines in lan-\\nguages that don’t enforce them?\\n❑ Is the convention as compatible as possible with standard conventions for \\nthe language?\\n❑ Are names formatted for readability?\\nShort Names\\n❑ Does the code use long names (unless it’s necessary to use short ones)?\\n❑ Does the code avoid abbreviations that save only one character?\\n❑ Are all words abbreviated consistently?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 325}, page_content='Key Points 289\\n❑ Are the names pronounceable?\\n❑ Are names that could be misread or mispronounced avoided?\\n❑ Are short names documented in translation tables?\\nCommon Naming Problems: Have You Avoided...\\n❑ ...names that are misleading?\\n❑ ...names with similar meanings?\\n❑ ...names that are different by only one or two characters?\\n❑ ...names that sound similar?\\n❑ ...names that use numerals?\\n❑ ...names intentionally misspelled to make them shorter?\\n❑ ...names that are commonly misspelled in English?\\n❑ ...names that conflict with standard library routine names or with pre-\\ndefined variable names?\\n❑ ...totally arbitrary names?\\n❑ ...hard-to-read characters?\\nKey Points\\n■ Good variable names are a key element of program readability. Specific kinds of \\nvariables such as loop indexes and status variables require specific considerations.\\n■ Names should be as specific as possible. Names that are vague enough or gen-\\neral enough to be used for more than one purpose are usually bad names. \\n■ Naming conventions distinguish among local, class, and global data. They dis-\\ntinguish among type names, named constants, enumerated types, and variables.\\n■ Regardless of the kind of project you’re working on, you should adopt a variable \\nnaming convention. The kind of convention you adopt depends on the size of \\nyour program and the number of people working on it.\\n■ Abbreviations are rarely needed with modern programming languages. If you do \\nuse abbreviations, keep track of abbreviations in a project dictionary or use the \\nstandardized prefixes approach. \\n■ Code is read far more times than it is written. Be sure that the names you choose \\nfavor read-time convenience over write-time convenience.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 327}, page_content='291\\nChapter 12\\nFundamental Data Types \\ncc2e.com/1278 Contents\\n■ 12.1 Numbers in General: page 292\\n■ 12.2 Integers: page 293\\n■ 12.3 Floating-Point Numbers: page 295\\n■ 12.4 Characters and Strings: page 297\\n■ 12.5 Boolean Variables: page 301\\n■ 12.6 Enumerated Types: page 303\\n■ 12.7 Named Constants: page 307\\n■ 12.8 Arrays: page 310\\n■ 12.9 Creating Your Own Types (Type Aliasing): page 311\\nRelated Topics\\n■ Naming data: Chapter 11\\n■ Unusual data types: Chapter 13\\n■ General issues in using variables: Chapter 10\\n■ Formatting data declarations: “Laying Out Data Declarations” in Section 31.5\\n■ Documenting variables: “Commenting Data Declarations” in Section 32.5\\n■ Creating classes: Chapter 6\\nThe fundamental data types are the basic building blocks for all other data types. This \\nchapter contains tips for using numbers (in general), integers, floating-point numbers, \\ncharacters and strings, boolean variables, enumerated types, named constants, and \\narrays. The final section in this chapter describes how to create your own types. \\nThis chapter covers basic troubleshooting for the fundamental types of data. If you’ve \\ngot your fundamental-data bases covered, skip to the end of the chapter, review the \\nchecklist of problems to avoid, and move on to the discussion of unusual data types in \\nChapter 13.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 328}, page_content='292 Chapter 12: Fundamental Data Types\\n12.1 Numbers in General\\nHere are several guidelines for making your use of numbers less error-prone: \\nCross-Reference For more \\ndetails on using named con-\\nstants instead of magic num-\\nbers, see Section 12.7, \\n“Named Constants,” later in \\nthis chapter.\\nAvoid “magic numbers” Magic numbers are literal numbers, such as 100 or 47524, \\nthat appear in the middle of a program without explanation. If you program in a lan-\\nguage that supports named constants, use them instead. If you can’t use named con-\\nstants, use global variables when it’s feasible to do so. \\nAvoiding magic numbers yields three advantages:\\n■ Changes can be made more reliably. If you use named constants, you won’t over-\\nlook one of the 100s or change a 100 that refers to something else. \\n■ Changes can be made more easily. When the maximum number of entries \\nchanges from 100 to 200, if you’re using magic numbers you have to find all the \\n100s and change them to 200s. If you use 100+1 or 100-1, you’ll also have to find \\nall the 101s and 99s and change them to 201s and 199s. If you’re using a named \\nconstant, you simply change the definition of the constant from 100 to 200 in \\none place.\\n■ Your code is more readable. Sure, in the expression \\nfor i = 0 to 99 do ...\\nyou can guess that 99 refers to the maximum number of entries. But the expres-\\nsion\\nfor i = 0 to MAX_ENTRIES-1 do ...\\nleaves no doubt. Even if you’re certain that a number will never change, you get \\na readability benefit if you use a named constant.\\nUse hard-coded 0s and 1s if you need to The values 0 and 1 are used to increment, \\ndecrement, and start loops at the first element of an array. The 0 in \\nfor i = 0 to CONSTANT do ...\\nis OK, and the 1 in \\ntotal = total + 1\\nis OK. A good rule of thumb is that the only literals that should occur in the body of \\na program are 0 and 1. Any other literals should be replaced with something more \\ndescriptive.\\nAnticipate divide-by-zero errors Each time you use the division symbol (/ in most \\nlanguages), think about whether it’s possible for the denominator of the expression to \\nbe 0. If the possibility exists, write code to prevent a divide-by-zero error.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 329}, page_content='12.2 Integers 293\\nMake type conversions obvious Make sure that someone reading your code will be \\naware of it when a conversion between different data types occurs. In C++ you could say\\ny = x + (float) i\\nand in Microsoft Visual Basic you could say \\ny = x + CSng( i )\\nThis practice also helps to ensure that the conversion is the one you want to occur—\\ndifferent compilers do different conversions, so you’re taking your chances otherwise.\\nCross-Reference For a varia-\\ntion on this example, see \\n“Avoid equality compari-\\nsons” in Section 12.3.\\nAvoid mixed-type comparisons If x is a floating-point number and i is an integer, the \\ntest\\nif ( i = x ) then ...\\nis almost guaranteed not to work. By the time the compiler figures out which type it \\nwants to use for the comparison, converts one of the types to the other, does a bunch \\nof rounding, and determines the answer, you’ll be lucky if your program runs at all. \\nDo the conversion manually so that the compiler can compare two numbers of the \\nsame type and you know exactly what’s being compared.\\nHeed your compiler’s warnings Many modern compilers tell you when you have dif-\\nferent numeric types in the same expression. Pay attention! Every programmer has \\nbeen asked at one time or another to help someone track down a pesky error, only to \\nfind that the compiler had warned about the error all along. Top programmers fix \\ntheir code to eliminate all compiler warnings. It’s easier to let the compiler do the \\nwork than to do it yourself.\\n12.2 Integers\\nBear these considerations in mind when using integers:\\nCheck for integer division When you’re using integers, 7/10 does not equal 0.7. It \\nusually equals 0, or minus infinity, or the nearest integer, or—you get the picture. What \\nit equals varies from language to language. This applies equally to intermediate \\nresults. In the real world 10 * (7/10) = (10*7) / 10 = 7. Not so in the world of integer \\narithmetic. 10 * (7/10) equals 0 because the integer division (7/10) equals 0. The eas-\\niest way to remedy this problem is to reorder the expression so that the divisions are \\ndone last: (10*7) / 10.\\nCheck for integer overflow When doing integer multiplication or addition, you need \\nto be aware of the largest possible integer. The largest possible unsigned integer is \\noften 232-1 and is sometimes 216-1, or 65,535. The problem comes up when you mul-\\ntiply two numbers that produce a number bigger than the maximum integer. For \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 330}, page_content='294 Chapter 12: Fundamental Data Types\\nexample, if you multiply 250 * 300, the right answer is 75,000. But if the maximum \\ninteger is 65,535, the answer you’ll get is probably 9464 because of integer overflow \\n(75,000 - 65,536 = 9464). Table 12-1 shows the ranges of common integer types.\\nThe easiest way to prevent integer overflow is to think through each of the terms in \\nyour arithmetic expression and try to imagine the largest value each can assume. For \\nexample, if in the integer expression m = j * k, the largest expected value for j is 200 \\nand the largest expected value for k is 25, the largest value you can expect for m is 200 \\n* 25 = 5,000. This is OK on a 32-bit machine since the largest integer is 2,147,483,647. \\nOn the other hand, if the largest expected value for j is 200,000 and the largest \\nexpected value for k is 100,000, the largest value you can expect for m is 200,000 * \\n100,000 = 20,000,000,000. This is not OK since 20,000,000,000 is larger than \\n2,147,483,647. In this case, you would have to use 64-bit integers or floating-point \\nnumbers to accommodate the largest expected value of m.\\nAlso consider future extensions to the program. If m will never be bigger than 5,000, \\nthat’s great. But if you expect m to grow steadily for several years, take that into account.\\nCheck for overflow in intermediate results The number at the end of the equation \\nisn’t the only number you have to worry about. Suppose you have the following code:\\nJava Example of Overflow of Intermediate Results\\nint termA = 1000000;\\nint termB = 1000000;\\nint product = termA * termB / 1000000;\\nSystem.out.println( \"( \" + termA + \" * \" + termB + \" ) / 1000000 = \" + product );\\nIf you think the Product assignment is the same as (1,00,000*1,000,000) / 1,000,000, you \\nmight expect to get the answer 1,000,000. But the code has to compute the intermediate \\nresult of 1,000,000*1,000,000 before it can divide by the final 1,000,000, and that means \\nit needs a number as big as 1,000,000,000,000. Guess what? Here’s the result:\\n( 1000000 * 1000000 ) / 1000000 = -727\\nTa b l e  1 2 - 1Ranges for Different Types of Integers\\nInteger Type Range\\nSigned 8-bit -128 through 127\\nUnsigned 8-bit 0 through 255\\nSigned 16-bit -32,768 through 32,767\\nUnsigned 16-bit 0 through 65,535\\nSigned 32-bit -2,147,483,648 through 2,147,483,647\\nUnsigned 32-bit 0 through 4,294,967,295\\nSigned 64-bit -9,223,372,036,854,775,808 through \\n9,223,372,036,854,775,807\\nUnsigned 64-bit 0 through 18,446,744,073,709,551,615\\nC12619670.fm  Page 294  Tuesday, April 12, 2011  2:49 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 331}, page_content='12.3 Floating-Point Numbers 295\\nIf your integers go to only 2,147,483,647, the intermediate result is too large for the inte-\\nger data type. In this case, the intermediate result that should be 1,000,000,000,000 is  \\n-727,379,968, so when you divide by 1,000,000, you get -727, rather than 1,000,000.\\nYou can handle overflow in intermediate results the same way you handle integer \\noverflow, by switching to a long-integer or floating-point type.\\n12.3 Floating-Point Numbers\\nThe main consideration in using floating-point numbers is that many fractional deci-\\nmal numbers can’t be represented accurately using the 1s and 0s available on a digital \\ncomputer. Nonterminating decimals like 1/3 or 1/7 can usually be represented to \\nonly 7 or 15 digits of accuracy. In my version of Microsoft Visual Basic, a 32-bit float-\\ning-point representation of 1/3 equals 0.33333330. It’s accurate to 7 digits. This is \\naccurate enough for most purposes but inaccurate enough to trick you sometimes.\\nFollowing are a few specific guidelines for using floating-point numbers:\\nCross-Reference For algo-\\nrithms books that describe \\nways to solve these prob-\\nlems, see “Additional \\nResources on Data Types” in \\nSection 10.1.\\nAvoid additions and subtractions on numbers that have greatly different magnitudes\\nWith a 32-bit floating-point variable, 1,000,000.00 + 0.1 probably produces an answer of \\n1,000,000.00 because 32 bits don’t give you enough significant digits to encompass the \\nrange between 1,000,000 and 0.1. Likewise, 5,000,000.02 - 5,000,000.01 is probably 0.0.\\nSolutions? If you have to add a sequence of numbers that contains huge differences \\nlike this, sort the numbers first, and then add them starting with the smallest values. \\nLikewise, if you need to sum an infinite series, start with the smallest term—essentially, \\nsum the terms backwards. This doesn’t eliminate round-off problems, but it mini-\\nmizes them. Many algorithms books have suggestions for dealing with cases like this.\\n1 is equal to 2 for sufficiently \\nlarge values of 1. \\n— Anonymous \\nAvoid equality comparisons Floating-point numbers that should be equal are not \\nalways equal. The main problem is that two different paths to the same number don’t \\nalways lead to the same number. For example, 0.1 added 10 times rarely equals 1.0. The \\nfollowing example shows two variables, nominal and sum, that should be equal but aren’t.\\nJava Example of a Bad Comparison of Floating-Point Numbers \\nThe variable nominal is a\\n64-bit real.\\ndouble nominal = 1.0;\\ndouble sum = 0.0;\\nfor ( int i = 0; i < 10; i++ ) {\\nsum is 10*0.1. It should be \\n1.0.\\n   sum += 0.1;\\n}\\nHere’s the bad comparison. if ( nominal == sum ) {\\n   System.out.println( \"Numbers are the same.\" );\\n}\\nelse {\\n   System.out.println( \"Numbers are different.\" );\\n}\\nKEY POINT\\nC12619670.fm  Page 295  Tuesday, April 12, 2011  2:50 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 332}, page_content='296 Chapter 12: Fundamental Data Types\\nAs you can probably guess, the output from this program is\\nNumbers are different.\\nThe line-by-line values of sum in the for loop look like this:\\n0.1\\n0.2\\n0.30000000000000004\\n0.4\\n0.5\\n0.6\\n0.7\\n0.7999999999999999\\n0.8999999999999999\\n0.9999999999999999\\nThus, it’s a good idea to find an alternative to using an equality comparison for float-\\ning-point numbers. One effective approach is to determine a range of accuracy that is \\nacceptable and then use a boolean function to determine whether the values are close \\nenough. Typically, you’d write an Equals() function that returns true if the values are \\nclose enough and false otherwise. In Java, such a function would look like this:\\nCross-Reference This exam-\\nple is proof of the maxim \\nthat there’s an exception to \\nevery rule. Variables in this \\nrealistic example have digits \\nin their names. For the rule \\nagainst using digits in vari-\\nable names, see Section \\n11.7, “Kinds of Names to \\nAvoid.”\\nJava Example of a Routine to Compare Floating-Point Numbers  \\nfinal double ACCEPTABLE_DELTA = 0.00001;\\nboolean Equals( double Term1, double Term2 ) { \\n   if ( Math.abs( Term1 - Term2 ) < ACCEPTABLE_DELTA ) {\\n      return true;\\n   }\\n   else {\\n      return false;\\n   }\\n}\\nIf the code in the “bad comparison of floating-point numbers” example were con-\\nverted so that this routine could be used for comparisons, the new comparison would \\nlook like this:\\nif ( Equals( Nominal, Sum ) ) ...\\nThe output from the program when it uses this test is \\nNumbers are the same.\\nDepending on the demands of your application, it might be inappropriate to use a \\nhard-coded value for ACCEPTABLE_DELTA. You might need to compute \\nACCEPTABLE_DELTA based on the size of the two numbers being compared.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 333}, page_content='12.4 Characters and Strings 297\\nAnticipate rounding errors Rounding-error problems are no different from the prob-\\nlem of numbers with greatly different magnitudes. The same issue is involved, and \\nmany of the same techniques help to solve rounding problems. In addition, here are \\ncommon specific solutions to rounding problems: \\n■ Change to a variable type that has greater precision. If you’re using single-preci-\\nsion floating point, change to double-precision floating point, and so on. \\nCross-Reference Usually the \\nperformance impact of con-\\nverting to BCD will be mini-\\nmal. If you’re concerned \\nabout the performance \\nimpact, see Section 25.6, \\n“Summary of the Approach \\nto Code Tuning.”\\n■ Change to binary coded decimal (BCD) variables. The BCD scheme is typically \\nslower and takes up more storage space, but it prevents many rounding errors. \\nThis is particularly valuable if the variables you’re using represent dollars and \\ncents or other quantities that must balance precisely.\\n■ Change from floating-point to integer variables. This is a roll-your-own approach \\nto BCD variables. You will probably have to use 64-bit integers to get the preci-\\nsion you want. This technique requires you to keep track of the fractional part of \\nyour numbers yourself. Suppose you were originally keeping track of dollars \\nusing floating point with cents expressed as fractional parts of dollars. This is a \\nnormal way to handle dollars and cents. When you switch to integers, you have \\nto keep track of cents using integers and of dollars using multiples of 100 cents. \\nIn other words, you multiply dollars by 100 and keep the cents in the 0-to-99 \\nrange of the variable. This might seem absurd at first glance, but it’s an effective \\nsolution in terms of both speed and accuracy. You can make these manipula-\\ntions easier by creating a DollarsAndCents class that hides the integer representa-\\ntion and supports the necessary numeric operations. \\nCheck language and library support for specific data types Some languages, includ-\\ning Visual Basic, have data types such as Currency that specifically support data that is \\nsensitive to rounding errors. If your language has a built-in data type that provides \\nsuch functionality, use it!\\n12.4 Characters and Strings\\nThis section provides some tips for using st rings. The first applies to strings in all \\nlanguages.\\nCross-Reference Issues for \\nusing magic characters and \\nstrings are similar to those \\nfor magic numbers dis-\\ncussed in Section 12.1, \\n“Numbers in General.”\\nAvoid magic characters and strings Magic characters are literal characters (such as \\n\\'A\\') and magic strings are literal strings (such as \"Gigamatic Accounting Program\") that \\nappear throughout a program. If you program in a language that supports the use of \\nnamed constants, use them instead. Otherwise, use global variables. Several reasons \\nfor avoiding literal strings exist:\\n■ For commonly occurring strings like the name of your program, command \\nnames, report titles, and so on, you might at some point need to change the \\nstring’s contents. For example, \"Gigamatic Accounting Program\" might change to \\n\"New and Improved! Gigamatic Accounting Program\"  for a later version.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 334}, page_content='298 Chapter 12: Fundamental Data Types\\n■ International markets are becoming increasingly important, and it’s easier to \\ntranslate strings that are grouped in a string resource file than it is to translate to \\nthem in situ throughout a program.\\n■ String literals tend to take up a lot of space. They’re used for menus, messages, \\nhelp screens, entry forms, and so on. If you have too many, they grow beyond \\ncontrol and cause memory problems. String space isn’t a concern in many envi-\\nronments, but in embedded systems programming and other applications in \\nwhich storage space is at a premium, solutions to string-space problems are eas-\\nier to implement if the strings are relatively independent of the source code.\\n■ Character and string literals are cryptic. Comments or named constants clarify \\nyour intentions. In the next example, the meaning of 0x1B isn’t clear. The use of \\nthe ESCAPE constant makes the meaning more obvious.\\nC+ + Examples of Comparisons Using Strings \\nBad! if ( input_char == 0x1B ) ...\\nBetter!\\nif ( input_char == ESCAPE ) ...\\nWatch for off-by-one errors Because substrings can be indexed much as arrays are, \\nwatch for off-by-one errors that read or write past the end of a string. \\ncc2e.com/1285 Know how your language and environment support Unicode In some languages \\nsuch as Java, all strings are Unicode. In others such as C and C++, handling Unicode \\nstrings requires its own set of functions. Conversion between Unicode and other char-\\nacter sets is often required for communication with standard and third-party libraries. \\nIf some strings won’t be in Unicode (for example, in C or C++), decide early on \\nwhether to use the Unicode character set at all. If you decide to use Unicode strings, \\ndecide where and when to use them.\\nDecide on an internationalization/localization strategy early in the lifetime of a \\nprogram Issues related to internationalization and localization are major issues. Key \\nconsiderations are deciding whether to store all strings in an external resource and \\nwhether to create separate builds for each language or to determine the specific lan-\\nguage at run time. \\ncc2e.com/1292 If you know you only need to support a single alphabetic language, consider using an \\nISO 8859 character set For applications that need to support only a single alpha-\\nbetic language (such as English) and that don’t need to support multiple languages or \\nan ideographic language (such as written Chinese), the ISO 8859 extended-ASCII-\\ntype standard makes a good alternative to Unicode.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 335}, page_content='12.4 Characters and Strings 299\\nIf you need to support multiple languages, use Unicode Unicode provides more com-\\nprehensive support for international character sets than ISO 8859 or other standards. \\nDecide on a consistent conversion strategy among string types If you use multiple \\nstring types, one common approach that helps keep the string types distinct is to keep \\nall strings in a single format within the program and convert the strings to other for-\\nmats as close as possible to input and output operations. \\nStrings in C\\nC++’s standard template library string class has eliminated most of the traditional \\nproblems with strings in C. For those programmers working directly with C strings, \\nhere are some ways to avoid common pitfalls: \\nBe aware of the difference between string pointers and character arrays The prob-\\nlem with string pointers and character arrays arises because of the way C handles \\nstrings. Be alert to the difference between them in two ways: \\n■ Be suspicious of any expression containing a string that involves an equal sign. \\nString operations in C are nearly always done with strcmp(), strcpy(), strlen(), and \\nrelated routines. Equal signs often imply some kind of pointer error. In C, \\nassignments do not copy string literals to a string variable. Suppose you have a \\nstatement like\\nStringPtr = \"Some Text String\";\\nIn this case, \"Some Text String\" is a pointer to a literal text string and the assign-\\nment merely sets the pointer StringPtr to point to the text string. The assignment \\ndoes not copy the contents to StringPtr.\\n■ Use a naming convention to indicate whether the variables are arrays of charac-\\nters or pointers to strings. One common convention is to use ps as a prefix to \\nindicate a pointer to a string and ach as a prefix for an array of characters. \\nAlthough they’re not always wrong, you should regard expressions involving \\nboth ps and ach prefixes with suspicion.\\nDeclare C-style strings to have length CONSTANT+1 In C and C++, off-by-one \\nerrors with C-style strings are common because it’s easy to forget that a string of \\nlength n requires n + 1 bytes of storage and to forget to leave room for the null termi-\\nnator (the byte set to 0 at the end of the string). An effective way to avoid such prob-\\nlems is to use named constants to declare all strings. A key in this approach is that you \\nuse the named constant the same way every time. Declare the string to be length CON-\\nSTANT+1, and then use CONSTANT to refer to the length of a string in the rest of the \\ncode. Here’s an example:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 336}, page_content='300 Chapter 12: Fundamental Data Types\\nC Example of Good String Declarations\\n/* Declare the string to have length of \"constant+1\".\\n   Every other place in the program, \"constant\" rather \\n   than \"constant+1\" is used. */\\nThe string is declared to be of \\nlength NAME_LENGTH +1.\\nchar name[ NAME_LENGTH + 1 ] = { 0 }; /* string of length NAME_LENGTH */\\n...\\n/* Example 1: Set the string to all \\'A\\'s using the constant,\\n   NAME_LENGTH, as the number of \\'A\\'s that can be copied.\\n   Note that NAME_LENGTH rather than NAME_LENGTH + 1 is used. */\\nOperations on the string \\nusing NAME_LENGTH \\nhere…\\nfor ( i = 0; i < NAME_LENGTH; i++ )\\n   name[ i ] = \\'A\\';\\n...\\n/* Example 2: Copy another string into the first string using \\n   the constant as the maximum length that can be copied. */\\n…and here. strncpy( name, some_other_name, NAME_LENGTH );\\nIf you don’t have a convention to handle this, you’ll sometimes declare the string to be \\nof length NAME_LENGTH and have operations on it with NAME_ LENGTH-1; at other \\ntimes you’ll declare the string to be of length NAME_LENGTH+1 and have operations \\non it work with length NAME_LENGTH. Every time you use a string, you’ll have to \\nremember which way you declared it.\\nWhen you use strings the same way every time, you don’t have to remember how you \\ndealt with each string individually and you eliminate mistakes caused by forgetting \\nthe specifics of an individual string. Having a convention minimizes mental overload \\nand programming errors.\\nCross-Reference For more \\ndetails on initializing data, \\nsee Section 10.3, “Guidelines \\nfor Initializing Variables.”\\nInitialize strings to null to avoid endless strings C determines the end of a string by \\nfinding a null terminator, a byte set to 0 at the end of the string. No matter how long \\nyou think the string is, C doesn’t find the end of the string until it finds a 0 byte. If you \\nforget to put a null at the end of the string, your string operations might not act the \\nway you expect them to.\\nYou can avoid endless strings in two ways. First, initialize arrays of characters to 0 \\nwhen you declare them:\\nC Example of a Good Declaration of a Character Array\\nchar EventName[ MAX_NAME_LENGTH + 1 ] = { 0 };\\nSecond, when you allocate strings dynamically, initialize them to 0 by using calloc() \\ninstead of malloc(). calloc() allocates memory and initializes it to 0. malloc() allocates \\nmemory without initializing it, so you take your chances when you use memory allo-\\ncated by malloc().'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 337}, page_content='12.5 Boolean Variables 301\\nCross-Reference For more \\ndiscussion of arrays, read \\nSection 12.8, “Arrays,” later in \\nthis chapter. \\nUse arrays of characters instead of pointers in C If memory isn’t a constraint—and \\noften it isn’t—declare all your string variables as arrays of characters. This helps to \\navoid pointer problems, and the compiler will give you more warnings when you do \\nsomething wrong.\\nUse strncpy() instead of strcpy() to avoid endless strings String routines in C come \\nin safe versions and dangerous versions. The more dangerous routines such as strcpy() \\nand strcmp() keep going until they run into a null terminator. Their safer companions, \\nstrncpy() and strncmp(), take a parameter for maximum length so that even if the \\nstrings go on forever, your function calls won’t.\\n12.5 Boolean Variables\\nIt’s hard to misuse logical or boolean variables, and using them thoughtfully makes \\nyour program cleaner.\\nCross-Reference For details \\non using comments to docu-\\nment your program, see \\nChapter 32, “Self-Document-\\ning Code.”\\nUse boolean variables to document your program Instead of merely testing a bool-\\nean expression, you can assign the expression to a variable that makes the implication \\nof the test unmistakable. For example, in the next fragment, it’s not clear whether the \\npurpose of the if test is to check for completion, for an error condition, or for some-\\nthing else:\\nCross-Reference For an \\nexample of using a boolean \\nfunction to document your \\nprogram, see “Making Com-\\nplicated Expressions Simple” \\nin Section 19.1.\\nJava Example of Boolean Test in Which the Purpose Is Unclear\\nif ( ( elementIndex < 0 ) || ( MAX_ELEMENTS < elementIndex ) ||\\n   ( elementIndex == lastElementIndex ) \\n   ) {\\n   ...\\n}\\nIn the next fragment, the use of boolean variables makes the purpose of the if test \\nclearer:\\nJava Example of Boolean Test in Which the Purpose Is Clear \\nfinished = ( ( elementIndex < 0 ) || ( MAX_ELEMENTS < elementIndex ) );\\nrepeatedEntry = ( elementIndex == lastElementIndex );\\nif ( finished || repeatedEntry ) {\\n   ...\\n}\\nUse boolean variables to simplify complicated tests Often, when you have to code a \\ncomplicated test, it takes several tries to get it right. When you later try to modify the \\ntest, it can be hard to understand what the test was doing in the first place. Logical \\nvariables can simplify the test. In the previous example, the program is really testing \\nfor two conditions: whether the routine is finished and whether it’s working on a \\nrepeated entry. By creating the boolean variables finished and repeatedEntry, you make \\nthe if test simpler: easier to read, less error prone, and easier to modify.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 338}, page_content=\"302 Chapter 12: Fundamental Data Types\\nHere’s another example of a complicated test:\\nVisual Basic Example of a Complicated Test\\nIf ( ( document.AtEndOfStream() ) And ( Not inputError ) ) And _\\n   ( ( MIN_LINES <= lineCount ) And ( lineCount <= MAX_LINES ) ) And _\\n   ( Not ErrorProcessing() ) Then\\n   ' do something or other\\n   ...\\nEnd If\\nThe test in the example is fairly complicated but not uncommonly so. It places a heavy \\nmental burden on the reader. My guess is that you won’t even try to understand the if \\ntest but will look at it and say, “I’ll figure it out later if I really need to.” Pay attention to \\nthat thought because that’s exactly the same thing other people do when they read \\nyour code and it contains tests like this.\\nHere’s a rewrite of the code with boolean variables added to simplify the test:\\nVisual Basic Example of a Simplified Test\\nallDataRead = ( document.AtEndOfStream() ) And ( Not inputError )\\nlegalLineCount = ( MIN_LINES <= lineCount ) And ( lineCount <= MAX_LINES )\\nHere’s the simplified test. If ( allDataRead ) And ( legalLineCount ) And ( Not ErrorProcessing() ) Then\\n   ' do something or other\\n   ...\\nEnd If \\nThis second version is simpler. My guess is that you’ll read the boolean expression in \\nthe if test without any difficulty.\\nCreate your own boolean type, if necessary Some languages, such as C++, Java, and \\nVisual Basic have a predefined boolean type. Others, such as C, do not. In languages \\nsuch as C, you can define your own boolean type. In C, you’d do it this way:\\nC Example of Defining the BOOLEAN Type Using a Simple typedef\\ntypedef int BOOLEAN;\\nOr you could do it this way, which provides the added benefit of defining true and \\nfalse at the same time:\\nC Example of Defining the Boolean Type Using an Enum\\nenum Boolean { \\n   True=1, \\n   False=(!True) \\n};\\nCODING \\nHORROR\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 339}, page_content='12.6 Enumerated Types 303\\nDeclaring variables to be BOOLEAN rather than int makes their intended use more \\nobvious and makes your program a little more self-documenting.\\n12.6 Enumerated Types\\nAn enumerated type is a type of data that allows each member of a class of objects to \\nbe described in English. Enumerated types are available in C++ and Visual Basic and \\nare generally used when you know all the possible values of a variable and want to \\nexpress them in words. Here are some examples of enumerated types in Visual Basic:\\nVisual Basic Examples of Enumerated Types \\nPublic Enum Color\\n   Color_Red\\n   Color_Green\\n   Color_Blue\\nEnd Enum \\nPublic Enum Country\\n   Country_China\\n   Country_England\\n   Country_France\\n   Country_Germany\\n   Country_India\\n   Country_Japan\\n   Country_Usa\\nEnd Enum \\nPublic Enum Output\\n   Output_Screen\\n   Output_Printer\\n   Output_File\\nEnd Enum \\nEnumerated types are a powerful alternative to shopworn schemes in which you \\nexplicitly say, “1 stands for red, 2 stands for green, 3 stands for blue....” This ability \\nsuggests several guidelines for using enumerated types:\\nUse enumerated types for readability Instead of writing statements like \\nif chosenColor = 1\\nyou can write more readable expressions like \\nif chosenColor = Color_Red\\nAnytime you see a numeric literal, ask whether it makes sense to replace it with an \\nenumerated type.\\nEnumerated types are especially useful for defining routine parameters. Who knows \\nwhat the parameters to this function call are?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 340}, page_content='304 Chapter 12: Fundamental Data Types\\nC+ + Examples of a Routine Call That Would be Better with Enumerated Types\\nint result = RetrievePayrollData( data, true, false, false, true );\\nIn contrast, the parameters to this function call are more understandable:\\nC+ + Examples of a Routine Call That Uses Enumerated Types for Readability\\nint result = RetrievePayrollData( \\n   data, \\n   EmploymentStatus_CurrentEmployee, \\n   PayrollType_Salaried, \\n   SavingsPlan_NoDeduction, \\n   MedicalCoverage_IncludeDependents\\n);\\nUse enumerated types for reliability With a few languages (Ada in particular), an \\nenumerated type lets the compiler perform more thorough type checking than it can \\nwith integer values and constants. With named constants, the compiler has no way of \\nknowing that the only legal values are Color_Red, Color_Green, and Color_Blue. The \\ncompiler won’t object to statements like color = Country_England or country = \\nOutput_Printer. If you use an enumerated type, declaring a variable as Color, the com-\\npiler will allow the variable to be assigned only the values Color_Red, Color_Green, and \\nColor_Blue. \\nUse enumerated types for modifiability Enumerated types make your code easy to \\nmodify. If you discover a flaw in your “1 stands for red, 2 stands for green, 3 stands for \\nblue” scheme, you have to go through your code and change all the 1s, 2s, 3s, and so \\non. If you use an enumerated type, you can continue adding elements to the list just \\nby putting them into the type definition and recompiling.\\nUse enumerated types as an alternative to boolean variables Often, a boolean vari-\\nable isn’t rich enough to express the meanings it needs to. For example, suppose you \\nhave a routine return true if it has successfully performed its task and False otherwise. \\nLater you might find that you really have two kinds of False. The first kind means that \\nthe task failed and the effects are limited to the routine itself; the second kind means \\nthat the task failed and caused a fatal error that will need to be propagated to the rest \\nof the program. In this case, an enumerated type with the values Status_Success, \\nStatus_Warning, and Status_FatalError would be more useful than a boolean with the \\nvalues true and false. This scheme can easily be expanded to handle additional distinc-\\ntions in the kinds of success or failure.\\nCheck for invalid values When you test an enumerated type in an if or case statement, \\ncheck for invalid values. Use the else clause in a case statement to trap invalid values:\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 341}, page_content='12.6 Enumerated Types 305\\nGood Visual Basic Example of Checking for Invalid Values in an Enumerated Type\\nSelect Case screenColor\\n   Case Color_Red\\n      ...\\n   Case Color_Blue\\n      ...\\n   Case Color_Green\\n      ...\\nHere’s the test for the \\ninvalid value.\\n   Case Else\\n      DisplayInternalError( False, \"Internal Error 752: Invalid color.\" )\\nEnd Select\\nDefine the first and last entries of an enumeration for use as loop limits Defining \\nthe first and last elements in an enumeration to be Color_First, Color_Last, \\nCountry_First, Country_Last, and so on allows you to write a loop that loops through \\nthe elements of an enumeration. You set up the enumerated type by using explicit val-\\nues, as shown here:\\nVisual Basic Example of Setting First and Last Values in an Enumerated Type\\nPublic Enum Country\\n   Country_First = 0 \\n   Country_China = 0\\n   Country_England = 1\\n   Country_France = 2\\n   Country_Germany = 3\\n   Country_India = 4\\n   Country_Japan = 5\\n   Country_Usa = 6\\n   Country_Last = 6\\nEnd Enum \\nNow the Country_First and Country_Last values can be used as loop limits:\\nGood Visual Basic Example of Looping Through Elements in an Enumeration\\n\\' compute currency conversions from US currency to target currency\\nDim usaCurrencyConversionRate( Country_Last ) As Single\\nDim iCountry As Country\\nFor iCountry = Country_First To Country_Last\\n   usaCurrencyConversionRate( iCountry ) = ConversionRate( Country_Usa, iCountry )\\nNext\\nReserve the first entry in the enumerated type as invalid When you declare an enu-\\nmerated type, reserve the first value as an invalid value. Many compilers assign the \\nfirst element in an enumerated type to the value 0. Declaring the element that’s \\nmapped to 0 to be invalid helps to catch variables that were not properly initialized \\nbecause they are more likely to be 0 than any other invalid value.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 342}, page_content='306 Chapter 12: Fundamental Data Types\\nHere’s how the Country declaration would look with that approach: \\nVisual Basic Example of Declaring the First Value in an Enumeration to Be Invalid\\nPublic Enum Country\\n   Country_InvalidFirst = 0 \\n   Country_First = 1\\n   Country_China = 1\\n   Country_England = 2\\n   Country_France = 3\\n   Country_Germany = 4\\n   Country_India = 5\\n   Country_Japan = 6\\n   Country_Usa = 7\\n   Country_Last = 7\\nEnd Enum \\nDefine precisely how First and Last elements are to be used in the project coding \\nstandard, and use them consistently Using InvalidFirst, First, and Last elements in \\nenumerations can make array declarations and loops more readable. But it has the \\npotential to create confusion about whether the valid entries in the enumeration \\nbegin at 0 or 1 and whether the first and last elements of the enumeration are valid. If \\nthis technique is used, the project’s coding standard should require that InvalidFirst, \\nFirst, and Last elements be used consistently in all enumerations to reduce errors. \\nBeware of pitfalls of assigning explicit values to elements of an enumeration Some \\nlanguages allow you to assign specific values to elements within an enumeration, as \\nshown in this C++ example:\\nC+ + Example of Explicitly Assigning Values to an Enumeration\\nenum Color {\\n   Color_InvalidFirst = 0,\\n   Color_First = 1,\\n   Color_Red = 1,\\n   Color_Green = 2,\\n   Color_Blue = 4,\\n   Color_Black = 8,\\n   Color_Last = 8\\n};\\nIn this example, if you declared a loop index of type Color and attempted to loop \\nthrough Colors, you would loop through the invalid values of 3, 5, 6, and 7 as well as \\nthe valid values of 1, 2, 4, and 8.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 343}, page_content='12.7 Named Constants 307\\nIf Your Language Doesn’t Have Enumerated Types\\nIf your language doesn’t have enumerated types, you can simulate them with global \\nvariables or classes. For example, you could use these declarations in Java:\\nCross-Reference At the time \\nI’m writing this, Java does \\nnot support enumerated \\ntypes. By the time you read \\nthis, it probably will. This is a \\ngood example of the “rolling \\nwave of technology” dis-\\ncussed in Section 4.3, “Your \\nLocation on the Technology \\nWave.”\\nJava Example of Simulating Enumerated Types\\n// set up Country enumerated type\\nclass Country {\\n   private Country() {}\\n   public static final Country China = new Country();\\n   public static final Country England = new Country();\\n   public static final Country France = new Country();\\n   public static final Country Germany = new Country();\\n   public static final Country India = new Country();\\n   public static final Country Japan = new Country();\\n}\\n// set up Output enumerated type\\nclass Output {\\n   private Output() {}\\n   public static final Output Screen = new Output();\\n   public static final Output Printer = new Output();\\n   public static final Output File = new Output();\\n}\\nThese enumerated types make your program more readable because you can use the \\npublic class members such as Country.England and Output.Screen instead of named \\nconstants. This particular method of creating enumerated types is also typesafe; \\nbecause each type is declared as a class, the compiler will check for invalid assign-\\nments such as Output output = Country.England (Bloch 2001). \\nIn languages that don’t support classes, you can achieve the same basic effect through \\ndisciplined use of global variables for each of the elements of the enumeration. \\n12.7 Named Constants\\nA named constant is like a variable except that you can’t change the constant’s value \\nonce you’ve assigned it. Named constants enable you to refer to fixed quantities, such \\nas the maximum number of employees, by a name rather than a number—\\nMAXIMUM_EMPLOYEES rather than 1000, for instance.\\nUsing a named constant is a way of “parameterizing” your program—putting an aspect \\nof your program that might change into a parameter that you can change in one place \\nrather than having to make changes throughout the program. If you have ever \\ndeclared an array to be as big as you think it will ever need to be and then run out of \\nspace because it wasn’t big enough, you can appreciate the value of named constants.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 344}, page_content='308 Chapter 12: Fundamental Data Types\\nWhen an array size changes, you change only the definition of the constant you used \\nto declare the array. This “single-point control” goes a long way toward making soft-\\nware truly “soft”: easy to work with and change.\\nUse named constants in data declarations Using named constants helps program \\nreadability and maintainability in data declarations and in statements that need to \\nknow the size of the data they are working with. In the following example, you use \\nLOCAL_NUMBER_LENGTH to describe the length of employee phone numbers \\nrather than the literal 7.\\nGood Visual Basic Example of Using a Named Constant in a Data Declaration \\nConst AREA_CODE_LENGTH = 3\\nLOCAL_NUMBER_LENGTH \\nis declared as a constant \\nhere.\\nConst LOCAL_NUMBER_LENGTH = 7\\n...\\nType PHONE_NUMBER\\n   areaCode( AREA_CODE_LENGTH ) As String\\nIt’s used here.    localNumber( LOCAL_NUMBER_LENGTH ) As String\\nEnd Type\\n...\\n\\' make sure all characters in phone number are digits \\nIt’s used here, too. For iDigit = 1 To LOCAL_NUMBER_LENGTH \\n   If ( phoneNumber.localNumber( iDigit ) < \"0\" ) Or _\\n      ( \"9\" < phoneNumber.localNumber( iDigit ) ) Then\\n      \\' do some error processing\\n      ...\\nThis is a simple example, but you can probably imagine a program in which the infor-\\nmation about the phone-number length is needed in many places. \\nAt the time you create the program, the employees all live in one country, so you need \\nonly seven digits for their phone numbers. As the company expands and branches are \\nestablished in different countries, you’ll need longer phone numbers. If you have \\nparameterized, you can make the change in only one place: in the definition of the \\nnamed constant LOCAL_NUMBER_LENGTH.\\nFurther Reading For more \\ndetails on the value of \\nsingle-point control, see \\npages 57–60 of Software \\nConflict (Glass 1991).\\nAs you might expect, the use of named constants has been shown to greatly aid program \\nmaintenance. As a general rule, any technique that centralizes control over things that \\nmight change is a good technique for reducing maintenance efforts (Glass 1991).\\nAvoid literals, even “safe” ones In the following loop, what do you think the 12 \\nrepresents?\\nVisual Basic Example of Unclear Code \\nFor i = 1 To 12\\n   profit( i ) = revenue( i ) – expense( i )\\nNext'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 345}, page_content='12.7 Named Constants 309\\nBecause of the specific nature of the code, it appears that the code is probably looping \\nthrough the 12 months in a year. But are you sure? Would you bet your Monty Python \\ncollection on it? \\nIn this case, you don’t need to use a named constant to support future flexibility: it’s \\nnot very likely that the number of months in a year will change anytime soon. But if \\nthe way the code is written leaves any shadow of a doubt about its purpose, clarify it \\nwith a well-named constant, like this:\\nVisual Basic Example of Clearer Code \\nFor i = 1 To NUM_MONTHS_IN_YEAR \\n   profit( i ) = revenue( i ) – expense( i )\\nNext\\nThis is better, but, to complete the example, the loop index should also be named \\nsomething more informative:\\nVisual Basic Example of Even Clearer Code \\nFor month = 1 To NUM_MONTHS_IN_YEAR \\n   profit( month ) = revenue( month ) – expense( month )\\nNext\\nThis example seems quite good, but we can push it even one step further by using an \\nenumerated type:\\nVisual Basic Example of Very Clear Code \\nFor month = Month_January To Month_December\\n   profit( month ) = revenue( month ) – expense( month )\\nNext\\nWith this final example, there can be no doubt about the purpose of the loop.  Even \\nif you think a literal is safe, use named constants instead. Be a fanatic about rooting \\nout literals in your code. Use a text editor to search for 2, 3, 4, 5, 6, 7, 8, and 9 to make \\nsure you haven’t used them accidentally.\\nCross-Reference For details \\non simulating enumerated \\ntypes, see “If Your Language \\nDoesn’t Have Enumerated \\nTypes” in the previous sec-\\ntion, Section 12.6. \\nSimulate named constants with appropriately scoped variables or classes If your lan-\\nguage doesn’t support named constants, you can create your own. By using an approach \\nsimilar to the approach suggested in the earlier Java example in which enumerated \\ntypes were simulated, you can gain many of the advantages of named constants. Typical \\nscoping rules apply: prefer local scope, class scope, and global scope in that order.\\nUse named constants consistently It’s dangerous to use a named constant in one \\nplace and a literal in another to represent the same entity. Some programming prac-\\ntices beg for errors; this one is like calling an 800 number and having errors delivered'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 346}, page_content='310 Chapter 12: Fundamental Data Types\\nto your door. If the value of the named constant needs to be changed, you’ll change it \\nand think you’ve made all the necessary changes. You’ll overlook the hard-coded liter-\\nals, your program will develop mysterious defects, and fixing them will be a lot harder \\nthan picking up the phone and yelling for help.\\n12.8 Arrays\\nArrays are the simplest and most common type of structured data. In some languages, \\narrays are the only type of structured data. An array contains a group of items that are \\nall of the same type and that are directly accessed through the use of an array index. \\nHere are some tips on using arrays.\\nMake sure that all array indexes are within the bounds of the array In one way or \\nanother, all problems with arrays are caused by the fact that array elements can be \\naccessed randomly. The most common problem arises when a program tries to access \\nan array element that’s out of bounds. In some languages, this produces an error; in \\nothers, it simply produces bizarre and unexpected results.\\nConsider using containers instead of arrays, or think of arrays as sequential \\nstructures Some of the brightest people in computer science have suggested that \\narrays never be accessed randomly, but only sequentially (Mills and Linger 1986). \\nTheir argument is that random accesses in arrays are similar to random gotos in a pro-\\ngram: such accesses tend to be undisciplined, error prone, and hard to prove correct. \\nThey suggest using sets, stacks, and queues, whose elements are accessed sequen-\\ntially, rather than using arrays.\\nIn a small experiment, Mills and Linger found that designs created this way resulted \\nin fewer variables and fewer variable references. The designs were relatively efficient \\nand led to highly reliable software. \\nConsider using container classes that you can access sequentially—sets, stacks, \\nqueues, and so on—as alternatives before you automatically choose an array. \\nCross-Reference Issues in \\nusing arrays and loops are \\nsimilar and related. For \\ndetails on loops, see Chapter \\n16, “Controlling Loops.”\\nCheck the end points of arrays Just as it’s helpful to think through the end points in \\na loop structure, you can catch a lot of errors by checking the end points of arrays. Ask \\nyourself whether the code correctly accesses the first element of the array or mistak-\\nenly accesses the element before or after the first element. What about the last ele-\\nment? Will the code make an off-by-one error? Finally, ask yourself whether the code \\ncorrectly accesses the middle elements of the array.\\nIf an array is multidimensional, make sure its subscripts are used in the correct order\\nIt’s easy to say Array[ i ][ j ] when you mean Array[ j ][ i ], so take the time to double-\\ncheck that the indexes are in the right order. Consider using more meaningful names \\nthan i and j in cases in which their roles aren’t immediately clear.\\nKEY POINT\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 347}, page_content='12.9 Creating Your Own Types (Type Aliasing) 311\\nWatch out for index cross-talk If you’re using nested loops, it’s easy to write Array[ j ] \\nwhen you mean Array[ i ]. Switching loop indexes is called “index cross-talk.” Check for \\nthis problem. Better yet, use more meaningful index names than i and j to make it \\nharder to commit cross-talk mistakes in the first place.\\nIn C, use the ARRAY_LENGTH() macro to work with arrays You can build extra \\nflexibility into your work with arrays by defining an ARRAY_LENGTH() macro that \\nlooks like this:\\nC Example of Defining an ARRAY_LENGTH() Macro \\n#define ARRAY_LENGTH( x )   (sizeof(x)/sizeof(x[0]))\\nWhen you use operations on an array, instead of using a named constant for the \\nupper bound of the array size, use the ARRAY_LENGTH() macro. Here’s an example:\\nC Example of Using the ARRAY_LENGTH() Macro for Array Operations \\nConsistencyRatios[] =\\n   { 0.0, 0.0, 0.58, 0.90, 1.12,\\n   1.24, 1.32, 1.41, 1.45, 1.49,\\n   1.51, 1.48, 1.56, 1.57, 1.59 };\\n   ...\\nHere’s where the macro is \\nused.\\nfor ( ratioIdx = 0; ratioIdx < ARRAY_LENGTH( ConsistencyRatios ); ratioIdx++ );\\n   ...\\nThis technique is particularly useful for dimensionless arrays such as the one in this \\nexample. If you add or subtract entries, you don’t have to remember to change a \\nnamed constant that describes the array’s size. Or course, the technique works with \\ndimensioned arrays too, but if you use this approach, you don’t always need to set up \\nan extra named constant for the array definition. \\n12.9 Creating Your Own Types (Type Aliasing)\\nProgrammer-defined data types are one of the most powerful capabilities a language \\ncan give you to clarify your understanding of a program. They protect your program \\nagainst unforeseen changes and make it easier to read—all without requiring you to \\ndesign, construct, or test new classes. If you’re using C, C++, or another language that \\nallows user-defined types, take advantage of them! \\nCross-Reference In many \\ncases, it’s better to create a \\nclass than to create a simple \\ndata type. For details, see \\nChapter 6, “Working \\nClasses.”\\nTo appreciate the power of type creation, suppose you’re writing a program to convert \\ncoordinates in an x, y, z system to latitude, longitude, and elevation. You think that \\ndouble-precision floating-point numbers might be needed but would prefer to write a \\nprogram with single-precision floating-point numbers until you’re absolutely sure. \\nYou can create a new type specifically for coordinates by using a typedef statement in \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 348}, page_content='312 Chapter 12: Fundamental Data Types\\nC or C++ or the equivalent in another language. Here’s how you’d set up the type def-\\ninition in C++:\\nC+ + Example of Creating a Type\\ntypedef float Coordinate;  // for coordinate variables\\nThis type definition declares a new type, Coordinate, that’s functionally the same as \\nthe type float. To use the new type, you declare variables with it just as you would with \\na predefined type such as float. Here’s an example:\\nC+ + Example of Using the Type You’ve Created\\nRoutine1( ... ) {\\n   Coordinate latitude;     // latitude in degrees\\n   Coordinate longitude;    // longitude in degrees\\n   Coordinate elevation;    // elevation in meters from earth center\\n   ...\\n}\\n...\\nRoutine2( ... ) {\\n   Coordinate x;   // x coordinate in meters\\n   Coordinate y;   // y coordinate in meters\\n   Coordinate z;   // z coordinate in meters\\n   ...\\n}\\nIn this code, the variables latitude, longitude, elevation, x, y, and z are all declared to be \\nof type Coordinate.\\nNow suppose that the program changes and you find that you need to use double-pre-\\ncision variables for coordinates after all. Because you defined a type specifically for \\ncoordinate data, all you have to change is the type definition. And you have to change \\nit in only one place: in the typedef statement. Here’s the changed type definition:\\nC+ + Example of Changed Type Definition\\nThe original float has \\nchanged to double.\\ntypedef double Coordinate;  // for coordinate variables\\nHere’s a second example—this one in Pascal. Suppose you’re creating a payroll system \\nin which employee names are a maximum of 30 characters long. Your users have told \\nyou that no one ever has a name longer than 30 characters. Do you hard-code the \\nnumber 30 throughout your program? If you do, you trust your users a lot more than \\nI trust mine! A better approach is to define a type for employee names:\\nPascal Example of Creating a Type for Employee Names\\nType\\n   employeeName = array[ 1..30 ] of char;'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 349}, page_content='12.9 Creating Your Own Types (Type Aliasing) 313\\nWhen a string or an array is involved, it’s usually wise to define a named constant that \\nindicates the length of the string or array and then use the named constant in the type \\ndefinition. You’ll find many places in your program in which to use the constant—this \\nis just the first place in which you’ll use it. Here’s how it looks:\\nPascal Example of Better Type Creation\\nConst\\nHere’s the declaration of \\nthe named constant.\\n   NAME_LENGTH = 30;\\n   ...\\nType\\nHere’s where the named \\nconstant is used.\\n   employeeName = array[ 1..NAME_LENGTH ] of char;\\nA more powerful example would combine the idea of creating your own types with \\nthe idea of information hiding. In some cases, the information you want to hide is \\ninformation about the type of the data.\\nThe coordinates example in C++ is about halfway to information hiding. If you always \\nuse Coordinate rather than float or double, you effectively hide the type of the data. In \\nC++, this is about all the information hiding the language does for you. For the rest, \\nyou or subsequent users of your code have to have the discipline not to look up the \\ndefinition of Coordinate. C++ gives you figurative, rather than literal, information-hid-\\ning ability.\\nOther languages, such as Ada, go a step further and support literal information hid-\\ning. Here’s how the Coordinate code fragment would look in an Ada package that \\ndeclares it:\\nAda Example of Hiding Details of a Type Inside a Package\\npackage Transformation is\\nThis statement declares \\nCoordinate as private to the \\npackage.\\n   type Coordinate is private;\\n   ...\\nHere’s how Coordinate looks in another package, one that uses it:\\nAda Example of Using a Type from Another Package\\nwith Transformation;\\n...\\nprocedure Routine1(...) ...\\n   latitude:  Coordinate;\\n   longitude: Coordinate;\\nbegin\\n   -- statements using latitude and longitude\\n   ...\\nend Routine1;'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 350}, page_content='314 Chapter 12: Fundamental Data Types\\nNotice that the Coordinate type is declared as private in the package specification. That \\nmeans that the only part of the program that knows the definition of the Coordinate \\ntype is the private part of the Transformation package. In a development environment \\nwith a group of programmers, you could distribute only the package specification, \\nwhich would make it harder for a programmer working on another package to look \\nup the underlying type of Coordinate. The information would be literally hidden. Lan-\\nguages like C++ that require you to distribute the definition of Coordinate in header \\nfiles undermine true information hiding. \\nThese examples have illustrated several reasons to create your own types:\\n■ To make modifications easier It’s little work to create a new type, and it gives \\nyou a lot of flexibility.\\n■ To avoid excessive information distribution Hard typing spreads data-typ-\\ning details around your program instead of centralizing them in one place. This \\nis an example of the information-hiding principle of centralization discussed in \\nSection 6.2.\\n■ To increase reliability In Ada, you can define types such as type Age is range \\n0..99. The compiler then generates run-time checks to verify that any variable of \\ntype Age is always within the range 0..99.\\n■ To make up for language weaknesses If your language doesn’t have the pre-\\ndefined type you want, you can create it yourself. For example, C doesn’t have a \\nboolean or logical type. This deficiency is easy to compensate for by creating the \\ntype yourself:\\ntypedef int Boolean;\\nWhy Are the Examples of Creating Your Own Types in Pascal and Ada?\\nPascal and Ada have gone the way of the stegosaurus and, in general, the languages \\nthat have replaced them are more usable. In the area of simple type definitions, how-\\never, I think C++, Java, and Visual Basic represent a case of three steps forward and \\none step back. An Ada declaration like \\ncurrentTemperature: INTEGER range 0..212;\\ncontains important semantic information that a statement like\\nint temperature;\\ndoes not. Going a step further, a type declaration like\\ntype Temperature is range 0..212;\\n...\\ncurrentTemperature: Temperature;'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 351}, page_content='12.9 Creating Your Own Types (Type Aliasing) 315\\nallows the compiler to ensure that currentTemperature is assigned only to other vari-\\nables with the Temperature type, and very little extra coding is required to provide that \\nextra safety margin. \\nOf course, a programmer could create a Temperature class to enforce the same seman-\\ntics that were enforced automatically by the Ada language, but the step from creating \\na simple data type in one line of code to creating a class is a big step. In many situa-\\ntions, a programmer would create the simple type but would not step up to the addi-\\ntional effort of creating a class.  \\nGuidelines for Creating Your Own Types\\nCross-Reference In each \\ncase, consider whether cre-\\nating a class might work bet-\\nter than a simple data type. \\nFor details, see Chapter 6, \\n“Working Classes.”\\nKeep these guidelines in mind as you create your own “user-defined” types:\\nCreate types with functionally oriented names Avoid type names that refer to the \\nkind of computer data underlying the type. Use type names that refer to the parts of \\nthe real-world problem that the new type represents. In the previous examples, the \\ndefinitions created well-named types for coordinates and names—real-world entities. \\nSimilarly, you could create types for currency, payment codes, ages, and so on—aspects \\nof real-world problems.\\nBe wary of creating type names that refer to predefined types. Type names like BigIn-\\nteger or LongString refer to computer data rather than the real-world problem. The big \\nadvantage of creating your own type is that it provides a layer of insulation between \\nyour program and the implementation language. Type names that refer to the under-\\nlying programming-language types poke holes in that insulation. They don’t give you \\nmuch advantage over using a predefined type. Problem-oriented names, on the other \\nhand, buy you easy modifiability and data declarations that are self-documenting.\\nAvoid predefined types If there is any possibility that a type might change, avoid using \\npredefined types anywhere but in typedef or type definitions. It’s easy to create new types \\nthat are functionally oriented, and it’s hard to change data in a program that uses hard-\\nwired types. Moreover, use of functionally oriented type declarations partially docu-\\nments the variables declared with them. A declaration like Coordinate x tells you a lot \\nmore about x than a declaration like float x. Use your own types as much as you can.\\nDon’t redefine a predefined type Changing the definition of a standard type can cre-\\nate confusion. For example, if your language has a predefined type Integer, don’t create \\nyour own type called Integer. Readers of your code might forget that you’ve redefined \\nthe type and assume that the Integer they see is the Integer they’re used to seeing.\\nDefine substitute types for portability In contrast to the advice that you not change \\nthe definition of a standard type, you might want to define substitutes for the stan-\\ndard types so that on different hardware platforms you can make the variables repre-\\nsent exactly the same entities. For example, you can define a type INT32 and use it'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 352}, page_content='316 Chapter 12: Fundamental Data Types\\ninstead of int, or a type LONG64 instead of long. Originally, the only difference \\nbetween the two types would be their capitalization. But when you moved the pro-\\ngram to a new hardware platform, you could redefine the capitalized versions so that \\nthey could match the data types on the original hardware.\\nBe sure not to define types that are easily mistaken for predefined types. It would be \\npossible to define INT rather than INT32, but you’re better off creating a clean distinc-\\ntion between types you define and types provided by the language.  \\nConsider creating a class rather than using a typedef Simple typedefs can go a long \\nway toward hiding information about a variable’s underlying type. In some cases, \\nhowever, you might want the additional flexibility and control you’ll achieve by creat-\\ning a class. For details, see Chapter 6, “Working Classes.”\\ncc2e.com/1206\\nCross-Reference For a \\nchecklist that applies to \\ngeneral data issues rather \\nthan to issues with specific \\ntypes of data, see the check-\\nlist on page 257 in Chapter \\n10, “General Issues in Using \\nVariables.” For a checklist of \\nconsiderations in naming \\nvarieties, see the checklist on \\npage 288 in Chapter 11, “The \\nPower of Variable Names.”\\nCHECKLIST: Fundamental Data\\nNumbers in General\\n❑ Does the code avoid magic numbers?\\n❑ Does the code anticipate divide-by-zero errors?\\n❑ Are type conversions obvious?\\n❑ If variables with two different types are used in the same expression, will \\nthe expression be evaluated as you intend it to be?\\n❑ Does the code avoid mixed-type comparisons?\\n❑ Does the program compile with no warnings?\\nIntegers\\n❑ Do expressions that use integer division work the way they’re meant to? \\n❑ Do integer expressions avoid integer-overflow problems? \\nFloating-Point Numbers\\n❑ Does the code avoid additions and subtractions on numbers with greatly \\ndifferent magnitudes?\\n❑ Does the code systematically prevent rounding errors?\\n❑ Does the code avoid comparing floating-point numbers for equality? \\nCharacters and Strings\\n❑ Does the code avoid magic characters and strings? \\n❑ Are references to strings free of off-by-one errors?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 353}, page_content='12.9 Creating Your Own Types (Type Aliasing) 317\\n❑ Does C code treat string pointers and character arrays differently? \\n❑ Does C code follow the convention of declaring strings to be length CON-\\nSTANT+1?\\n❑ Does C code use arrays of characters rather than pointers, when appropriate?\\n❑ Does C code initialize strings to NULLs to avoid endless strings?\\n❑ Does C code use strncpy() rather than strcpy()? And strncat() and \\nstrncmp()?\\nBoolean Variables\\n❑ Does the program use additional boolean variables to document condi-\\ntional tests?\\n❑ Does the program use additional boolean variables to simplify conditional \\ntests?\\nEnumerated Types\\n❑ Does the program use enumerated types instead of named constants for \\ntheir improved readability, reliability, and modifiability?\\n❑ Does the program use enumerated types instead of boolean variables \\nwhen a variable’s use cannot be completely captured with true and false?\\n❑ Do tests using enumerated types test for invalid values?\\n❑ Is the first entry in an enumerated type reserved for “invalid”? \\nNamed Constants\\n❑ Does the program use named constants for data declarations and loop \\nlimits rather than magic numbers?\\n❑ Have named constants been used consistently—not used as named con-\\nstants in some places and as literals in others?\\nArrays\\n❑ Are all array indexes within the bounds of the array? \\n❑ Are array references free of off-by-one errors?\\n❑ Are all subscripts on multidimensional arrays in the correct order? \\n❑ In nested loops, is the correct variable used as the array subscript, avoid-\\ning loop-index cross-talk?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 354}, page_content='318 Chapter 12: Fundamental Data Types\\nCreating Types\\n❑ Does the program use a different type for each kind of data that might \\nchange?\\n❑ Are type names oriented toward the real-world entities the types represent \\nrather than toward programming-language types?\\n❑ Are the type names descriptive enough to help document data declarations?\\n❑ Have you avoided redefining predefined types?\\n❑ Have you considered creating a new class rather than simply redefining a \\ntype?\\nKey Points\\n■ Working with specific data types means remembering many individual rules for \\neach type. Use this chapter’s checklist to make sure that you’ve considered the \\ncommon problems.\\n■ Creating your own types makes your programs easier to modify and more self-\\ndocumenting, if your language supports that capability. \\n■ When you create a simple type using typedef or its equivalent, consider whether \\nyou should be creating a new class instead.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 355}, page_content='319\\nChapter 13\\nUnusual Data Types\\ncc2e.com/1378 Contents\\n■ 13.1 Structures: page 319\\n■ 13.2 Pointers: page 323\\n■ 13.3 Global Data: page 335\\nRelated Topics\\n■ Fundamental data types: Chapter 12\\n■ Defensive programming: Chapter 8\\n■ Unusual control structures: Chapter 17\\n■ Complexity in software development: Section 5.2\\nSome languages support exotic kinds of data in addition to the data types discussed \\nin Chapter 12, “Fundamental Data Types.” Section 13.1 describes when you might \\nstill use structures rather than classes in some circumstances. Section 13.2 describes \\nthe ins and outs of using pointers. If you’ve ever encountered problems associated \\nwith using global data, Section 13.3 explains how to avoid such difficulties. If you \\nthink the data types described in this chapter are not the types you normally read \\nabout in modern object-oriented programming books, you’re right. That’s why the \\nchapter is called “Unusual Data Types.”\\n13.1 Structures\\nThe term “structure” refers to data that’s built up from other types. Because arrays are \\na special case, they are treated separately in Chapter 12. This section deals with user-\\ncreated structured data—structs in C and C++ and Structures in Microsoft Visual Basic. \\nIn Java and C++, classes also sometimes perform as structures (when the class con-\\nsists entirely of public data members with no public routines).\\nYou’ll generally want to create classes rather than structures so that you can take \\nadvantage of the privacy and functionality offered by classes in addition to the public \\ndata supported by structures. But sometimes directly manipulating blocks of data can \\nbe useful, so here are some reasons for using structures:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 356}, page_content='320 Chapter 13: Unusual Data Types\\nUse structures to clarify data relationships Structures bundle groups of related \\nitems together. Sometimes the hardest part of figuring out a program is figuring out \\nwhich data goes with which other data. It’s  like going to a small town and asking \\nwho’s related to whom. You come to find out that everybody’s kind of related to every-\\nbody else, but not really, and you never get a good answer.\\nIf the data has been carefully structured, figuring out what goes with what is much \\neasier. Here’s an example of data that hasn’t been structured:\\nVisual Basic Example of Misleading, Unstructured Variables\\nname = inputName\\naddress = inputAddress\\nphone = inputPhone\\ntitle = inputTitle\\ndepartment = inputDepartment\\nbonus = inputBonus\\nBecause this data is unstructured, it looks as if all the assignment statements belong \\ntogether. Actually, name, address, and phone are variables associated with individual \\nemployees, and title, department, and bonus are variables associated with a supervisor. \\nThe code fragment provides no hint that there are two kinds of data at work. In the \\ncode fragment below, the use of structures makes the relationships clearer:\\nVisual Basic Example of More Informative, Structured Variables\\nemployee.name = inputName\\nemployee.address = inputAddress\\nemployee.phone = inputPhone\\nsupervisor.title = inputTitle\\nsupervisor.department = inputDepartment\\nsupervisor.bonus = inputBonus\\nIn the code that uses structured variables, it’s clear that some of the data is associated \\nwith an employee, other data with a supervisor.\\nUse structures to simplify operations on blocks of data You can combine related ele-\\nments into a structure and perform operations on the structure. It’s easier to operate \\non the structure than to perform the same operation on each of the elements. It’s also \\nmore reliable, and it takes fewer lines of code.\\nSuppose you have a group of data items that belong together—for instance, data about \\nan employee in a personnel database. If the data isn’t combined into a structure, \\nmerely copying the group of data can involve a lot of statements. Here’s an example in \\nVisual Basic:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 357}, page_content=\"13.1 Structures 321\\nVisual Basic Example of Copying a Group of Data Items Clumsily\\nnewName = oldName\\nnewAddress = oldAddress\\nnewPhone = oldPhone\\nnewSsn = oldSsn\\nnewGender = oldGender\\nnewSalary = oldSalary\\nEvery time you want to transfer information about an employee, you have to have this \\nwhole group of statements. If you ever add a new piece of employee information—for \\nexample, numWithholdings—you have to find every place at which you have a block of \\nassignments and add an assignment for newNumWithholdings = oldNumWithholdings.\\nImagine how horrible swapping data between two employees would be. You don’t \\nhave to use your imagination—here it is:\\nVisual Basic Example of Swapping Two Groups of Data the Hard Way\\n' swap new and old employee data\\npreviousOldName = oldName\\npreviousOldAddress = oldAddress\\npreviousOldPhone = oldPhone\\npreviousOldSsn = oldSsn\\npreviousOldGender = oldGender\\npreviousOldSalary = oldSalary\\noldName = newName\\noldAddress = newAddress\\noldPhone = newPhone\\noldSsn = newSsn\\noldGender = newGender\\noldSalary = newSalary\\nnewName = previousOldName\\nnewAddress = previousOldAddress\\nnewPhone = previousOldPhone\\nnewSsn = previousOldSsn\\nnewGender = previousOldGender\\nnewSalary = previousOldSalary\\nAn easier way to approach the problem is to declare a structured variable:\\nVisual Basic Example of Declaring Structures\\nStructure Employee\\n   name As String\\n   address As String\\n   phone As String\\n   ssn As String\\n   gender As String\\n   salary As long\\nCODING \\nHORROR\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 358}, page_content='322 Chapter 13: Unusual Data Types\\nEnd Structure\\nDim newEmployee As Employee\\nDim oldEmployee As Employee\\nDim previousOldEmployee As Employee\\nNow you can switch all the elements in the old and new employee structures with \\nthree statements:\\nVisual Basic Example of an Easier Way to Swap Two Groups of Data\\npreviousOldEmployee = oldEmployee\\noldEmployee = newEmployee\\nnewEmployee = previousOldEmployee\\nIf you want to add a field such as numWithholdings, you simply add it to the Structure \\ndeclaration. Neither the three statements above nor any similar statements through-\\nout the program need to be modified. C++ and other languages have similar capabili-\\nties.\\nCross-Reference For details \\non how much data to share \\nbetween routines, see “Keep \\nCoupling Loose” in Section \\n5.3.\\nUse structures to simplify parameter lists You can simplify routine parameter lists \\nby using structured variables. The technique is similar to the one just shown. Rather \\nthan passing each of the elements needed individually, you can group related ele-\\nments into a structure and pass the whole enchilada as a group structure. Here’s an \\nexample of the hard way to pass a group of related parameters:\\nVisual Basic Example of a Clumsy Routine Call Without a Structure\\nHardWayRoutine( name, address, phone, ssn, gender, salary )\\nAnd this is an example of the easy way to call a routine by using a structured variable \\nthat contains the elements of the first parameter list:\\nVisual Basic Example of an Elegant Routine Call with a Structure\\nEasyWayRoutine( employee )\\nIf you want to add numWithholdings to the first kind of call, you have to wade through \\nyour code and change every call to HardWayRoutine(). If you add a numWithholdings ele-\\nment to Employee, you don’t have to change the parameters to EasyWayRoutine() at all.\\nCross-Reference For details \\non the hazards of passing \\ntoo much data, see “Keep \\nCoupling Loose” in Section \\n5.3.\\nYou can carry this technique to extremes, putting all the variables in your program \\ninto one big, juicy variable and then passing it everywhere. Careful programmers \\navoid bundling data any more than is logically necessary. Furthermore, careful pro-\\ngrammers avoid passing a structure as a parameter when only one or two fields from \\nthe structure are needed—they pass the specific fields needed instead. This is an \\naspect of information hiding: some information is hidden in routines, and some is hid-\\nden from routines. Information is passed around on a need-to-know basis.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 359}, page_content='13.2 Pointers 323\\nUse structures to reduce maintenance Because you group related data when you use \\nstructures, changing a structure requires fewer changes throughout a program. This is \\nespecially true in sections of code that aren’t logically related to the change in the \\nstructure. Since changes tend to produce errors, fewer changes mean fewer errors. If \\nyour Employee structure has a title field and you decide to delete it, you don’t need to \\nchange any of the parameter lists or assignment statements that use the whole struc-\\nture. Of course, you have to change any code that deals specifically with employee \\ntitles, but that is conceptually related to deleting the title field and is hard to overlook.\\nThe big advantage of structured the data is found in sections of code that bear no log-\\nical relation to the title field. Sometimes programs have statements that refer concep-\\ntually to a collection of data rather than to individual components. In such cases, \\nindividual components, such as the title field, are referenced merely because they are \\npart of the collection. Such sections of code don’t have any logical reason to work with \\nthe title field specifically, and those sections are easy to overlook when you change \\ntitle. If you use a structure, it’s all right to overlook such sections because the code \\nrefers to the collection of related data rather than to each component individually.\\n13.2 Pointers\\nPointer usage is one of the most error-prone areas of modern programming, to such \\nan extent that modern languages like Java, C#, and Visual Basic don’t provide a \\npointer data type. Using pointers is inherently complicated, and using them correctly \\nrequires that you have an excellent understanding of your compiler’s memory-man-\\nagement scheme. Many common security problems, especially buffer overruns, can be \\ntraced back to erroneous use of pointers (Howard and LeBlanc 2003).\\nEven if your language doesn’t require you to use pointers, a good understanding of \\npointers will help your understanding of how your programming language works. A \\nliberal dose of defensive programming practices will help even further.\\nParadigm for Understanding Pointers\\nConceptually, every pointer consists of two parts: a location in memory and a knowl-\\nedge of how to interpret the contents of that location.\\nLocation in Memory\\nThe location in memory is an address, often expressed in hexadecimal notation. An \\naddress on a 32-bit processor would be a 32-bit value, such as 0x0001EA40. The \\npointer itself contains only this address. To use the data the pointer points to, you \\nhave to go to that address and interpret the contents of memory at that location. If you \\nwere to look at the memory in that location, it would be just a collection of bits. It has \\nto be interpreted to be meaningful.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 360}, page_content='324 Chapter 13: Unusual Data Types\\nKnowledge of How to Interpret the Contents\\nThe knowledge of how to interpret the contents of a location in memory is provided \\nby the base type of the pointer. If a pointer points to an integer, what that really means \\nis that the compiler interprets the memory location given by the pointer as an integer. \\nOf course, you can have an integer pointer, a string pointer, and a floating-point \\npointer all pointing at the same memory loc ation. But only one of the pointers inter-\\nprets the contents at that location correctly.\\nIn thinking about pointers, it’s helpful to remember that memory doesn’t have any \\ninherent interpretation associated with it. It is only through use of a specific type of \\npointer that the bits in a particular location are interpreted as meaningful data.\\nFigure 13-1 shows several views of the same location in memory, interpreted in several \\ndifferent ways.\\nFigure 13-1 The amount of memory used by each data type is shown by double lines.\\nIn each of the cases in Figure 13-1, the pointer points to the location containing the hex \\nvalue 0x0A. The number of bytes used beyond the 0A depends on how the memory is \\ninterpreted. The way memory contents are used also depends on how the memory is \\n0A 61 62 63 64 65 66 67 68 69 6A\\nViewed as: Raw memory contents used for further examples (in hex)\\nInterpreted as: No interpretation possible without associated pointer variable\\n65 66 67 68 69 6A\\n68 69 6A\\n6A\\nViewed as: char\\nInterpreted as: linefeed character (ASCII hex 0A or decimal 10)\\n0A 61 62 63 64 65 66 67 68 69 6A\\nViewed as: 4-byte integer\\nInterpreted as: 1667391754\\n0A 61 62 63 64 65 66 67 68 69\\nViewed as: 4-byte floating point\\nInterpreted as: 4.17595656202980E+0021\\n0A 61 62 63 64 65 66 67\\nViewed as: 2-byte integer\\nInterpreted as: 24842\\n0A 61 62 63 64\\nViewed as: String[10] (in Visual Basic format with length byte first)\\nInterpreted as: abcdefghij\\n0A 61 62 63 64 65 66 67 68 69 6A'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 361}, page_content='13.2 Pointers 325\\ninterpreted. (It also depends on what processor you’re using, so keep that in mind if you \\ntry to duplicate these results on your Desktop Cray.) The same raw memory contents \\ncan be interpreted as a string, an integer, a floating point, or anything else—it all depends \\non the base type of the pointer that points to the memory.\\nGeneral Tips on Pointers\\nWith many types of defects, locating the error is the easiest part of dealing with the error \\nand correcting it is the hard part. Pointer errors are different. A pointer error is usually \\nthe result of a pointer’s pointing somewhere it shouldn’t. When you assign a value to a \\nbad pointer variable, you write data into an area of memory you shouldn’t. This is called \\n“memory corruption.” Sometimes memory corruption produces horrible, fiery system \\ncrashes; sometimes it alters the results of a calculation in another part of the program; \\nsometimes it causes your program to skip routines unpredictably; and sometimes it \\ndoesn’t do anything at all. In the last case, the pointer error is a ticking time bomb, wait-\\ning to ruin your program five minutes before you show it to your most important cus-\\ntomer. Symptoms of pointer errors tend to be unrelated to causes of pointer errors. \\nThus, most of the work in correcting a pointer error is locating the cause.\\nWorking with pointers successfully requires a two-pronged strategy. First, avoid \\ninstalling pointer errors in the first place. Pointer errors are so difficult to find that \\nextra preventive measures are justified. Second, detect pointer errors as soon after \\nthey are coded as possible. Symptoms of pointer errors are so erratic that extra mea-\\nsures to make the symptoms more predictable are justified. Here’s how to achieve \\nthese key goals:\\nIsolate pointer operations in routines or classes Suppose you use a linked list in sev-\\neral places in a program. Rather than traversing the list manually each place it’s used, \\nwrite access routines such as NextLink(), PreviousLink(), InsertLink(), and DeleteLink(). \\nBy minimizing the number of places in which pointers are accessed, you minimize the \\npossibility of making careless mistakes that spread throughout your program and take \\nforever to find. Because the code is then relatively independent of data-implementation \\ndetails, you also improve the chance that you can reuse it in other programs. Writing \\nroutines for pointer allocation is another way to centralize control over your data.\\nDeclare and define pointers at the same time Assigning a variable its initial value \\nclose to where it is declared is generally good programming practice, and it’s all the \\nmore valuable when working with pointers. Here is an example of what not to do:\\nC+ + Example of Bad Pointer Initialization\\nEmployee *employeePtr;\\n// lots of code\\n...\\nemployeePtr = new Employee;\\nKEY POINT\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 362}, page_content='326 Chapter 13: Unusual Data Types\\nIf even this code works correctly initially, it’s error-prone under modification because \\na chance exists that someone will try to use employeePtr between the point where the \\npointer is declared and the time it’s initialized. Here’s a safer approach:\\nC+ + Example of Good Pointer Initialization\\n// lots of code\\n...\\nEmployee *employeePtr = new Employee;\\nDelete pointers at the same scoping level as they were allocated Keep allocation and \\ndeallocation of pointers symmetric. If you use a pointer within a single scope, call new \\nto allocate and delete to deallocate the pointer within the same scope. If you allocate a \\npointer inside a routine, deallocate it inside a sister routine. If you allocate a pointer \\ninside an object’s constructor, deallocate it inside the object’s destructor. A routine \\nthat allocates memory and then expects its client code to deallocate the memory man-\\nually creates an inconsistency that is ripe for error.\\nCheck pointers before using them Before you use a pointer in a critical part of your \\nprogram, make sure the memory location it points to is reasonable. For example, if \\nyou expect memory locations to be between StartData and EndData, you should take \\na suspicious view of a pointer that points before StartData or after EndData. You’ll \\nhave to determine what the values of StartData and EndData are in your environment. \\nYou can set this up to work automatically if you use pointers through access routines \\nrather than manipulate them directly.\\nCheck the variable referenced by the pointer before using it Sometimes you can per-\\nform reasonableness checks on the value the pointer points to. For example, if you’re \\nsupposed to be pointing to an integer value between 0 and 1000, you should be sus-\\npicious of values over 1000. If you’re pointing to a C++-style string, you might be sus-\\npicious of strings with lengths greater than 100. This can also be done automatically \\nif you work with pointers through access routines.\\nUse dog-tag fields to check for corrupted memory A “tag field” or “dog tag” is a field \\nyou add to a structure solely for the purpose of error checking. When you allocate a \\nvariable, put a value that should remain unchanged into its tag field. When you use \\nthe structure—especially when you delete the memory—check the tag field’s value. If \\nthe tag field doesn’t have the expected value, the data has been corrupted.\\nWhen you delete the pointer, corrupt the field so that if you accidentally try to free the \\nsame pointer again, you’ll detect the corruption. For example, let’s say that you need \\nto allocate 100 bytes:\\n1. First, new 104 bytes, 4 bytes more than requested.\\n104 bytes'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 363}, page_content='13.2 Pointers 327\\n2. Set the first 4 bytes to a dog-tag value, and then return a pointer to the memory \\nthat starts after that.\\n3. When the time comes to delete the pointer, check the tag.\\n4. If the tag is OK, set it to 0 or some other value that you and your program recog-\\nnize as an invalid tag value. You don’t want the value to be mistaken for a valid \\ntag after the memory has been freed. Set the data to 0, 0xCC, or some other non-\\nrandom value for the same reason.\\n5. Finally, delete the pointer.\\nPutting a dog tag at the beginning of the memory block you’ve allocated allows you to \\ncheck for redundant attempts to deallocate the memory block without needing to \\nmaintain a list of all the memory blocks you’ve allocated. Putting the dog tag at the \\nend of the memory block allows you to check for overwriting memory beyond the \\nlocation that was supposed to be used. You can use tags at the beginning and the end \\nof the block to accomplish both objectives.\\nYou can use this approach in concert with the reasonableness check suggested ear-\\nlier—checking that the pointers are between StartData and EndData. To be sure that a \\npointer points to a reasonable location, rather than checking for a probable range of \\nmemory, check to see that the pointer is in the list of allocated pointers.\\nYou could check the tag field just once before you delete the variable. A corrupted tag \\nwould then tell you that sometime during the life of that variable its contents were cor-\\nrupted. The more often you check the tag field, however, the closer to the root of the \\nproblem you will detect the corruption.\\nAdd explicit redundancies An alternative to using a tag field is to use certain fields \\ntwice. If the data in the redundant fields doesn’t match, you know memory has been \\ncorrupted. This can result in a lot of overhead if you manipulate pointers directly. If \\nyou isolate pointer operations in routines, however, it adds duplicate code in only a \\nfew places.\\nUse extra pointer variables for clarity By all means, don’t skimp on pointer vari-\\nables. The point is made elsewhere that a variable shouldn’t be used for more than \\none purpose. This is especially true for pointer variables. It’s hard enough to figure out \\ntag\\nSet pointer to here.\\ntag\\nCheck this tag.\\nFree the whole 104 bytes'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 364}, page_content='328 Chapter 13: Unusual Data Types\\nwhat someone is doing with a linked list without having to figure out why one \\ngenericLink variable is used over and over again or what pointer->next->last->next is \\npointing at. Consider this code fragment:\\nC+ + Example of Traditional Node Insertion Code\\nvoid InsertLink(\\n   Node *currentNode,\\n   Node *insertNode\\n   ) {\\n   // insert \"insertNode\" after \"currentNode\"\\n   insertNode->next = currentNode->next;\\n   insertNode->previous = currentNode;\\n   if ( currentNode->next != NULL ) {\\nThis line is needlessly \\ndifficult.\\n      currentNode->next->previous = insertNode;\\n   }\\n   currentNode->next = insertNode;\\n}\\nThis is traditional code for inserting a node in a linked list, and it’s needlessly hard to \\nunderstand. Inserting a new node involves three objects: the current node, the node \\ncurrently following the current node, and the node to be inserted between them. The \\ncode fragment explicitly acknowledges only two objects: insertNode and currentNode. \\nIt forces you to figure out and remember that currentNode->next is also involved. If you \\ntried to diagram what is happening without the node originally following currentNode, \\nyou would get something like this:\\nA better diagram would identify all three objects. It would look like this:\\nHere’s code that explicitly references all three of the objects involved:\\nC+ + Example of More Readable Node-Insertion Code\\nvoid InsertLink(\\n   Node *startNode,\\n   Node *newMiddleNode\\n   ) {\\n   // insert \"newMiddleNode\" between \"startNode\" and \"followingNode\"\\n   Node *followingNode = startNode->next;\\n   newMiddleNode->next = followingNode;\\n   newMiddleNode->previous = startNode;\\n   if ( followingNode != NULL ) {\\n      followingNode->previous = newMiddleNode;\\n   }\\n   startNode->next = newMiddleNode;\\n}\\ncurrentNode insertNode\\nstartNode newMiddleNode followingNode'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 365}, page_content='13.2 Pointers 329\\nThis code fragment has an extra line of code, but without the first fragment’s current-\\nNode->next->previous, it’s easier to follow.\\nSimplify complicated pointer expressions Complicated pointer expressions are hard \\nto read. If your code contains expressions like p->q->r->s.data, think about the person \\nwho has to read the expression. Here’s a particularly egregious example:\\nC+ + Example of a Pointer Expression That’s Hard to Understand\\nfor ( rateIndex = 0; rateIndex < numRates; rateIndex++ ) {\\n   netRate[ rateIndex ] = baseRate[ rateIndex ] * rates->discounts->factors->net;\\n}\\nComplicated expressions like the pointer expression in this example make for code \\nthat has to be figured out rather than read. If your code contains a complicated expres-\\nsion, assign it to a well-named variable to clarify the intent of the operation. Here’s an \\nimproved version of the example:\\nC+ + Example of Simplifying a Complicated Pointer Expression\\nquantityDiscount = rates->discounts->factors->net;\\nfor ( rateIndex = 0; rateIndex < numRates; rateIndex++ ) {\\n   netRate[ rateIndex ] = baseRate[ rateIndex ] * quantityDiscount;\\n}\\nWith this simplification, not only do you get a gain in readability, but you might also get \\na boost in performance from simplifying the pointer operation inside the loop. As usual, \\nyou’d have to measure the performance benefit before you bet any folding money on it.\\nDraw a picture Code descriptions of pointers can get confusing. It usually helps to \\ndraw a picture. For example, a picture of the linked-list insertion problem might look \\nlike the one shown in Figure 13-2.\\nCross-Reference Diagrams \\nsuch as the one in Figure \\n13-2 can become part of the \\nexternal documentation of \\nyour program. For details on \\ngood documentation prac-\\ntices, see Chapter 32, “Self-\\nDocumenting Code.”\\nFigure 13-2 An example of a picture that helps us think through the steps involved in \\nrelinking pointers.\\nCODING \\nHORROR\\nInitial Linkage\\nfollowingNode->previous\\nstartNode->next\\nstartNode followingNode\\nDesired Linkage\\nfollowingNode->previousstartNode->next\\nstartNode followingNode\\nnewMiddleNode\\nnewMiddleNode->previous newMiddleNode->next'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 366}, page_content='330 Chapter 13: Unusual Data Types\\nDelete pointers in linked lists in the right order A common problem in working with \\ndynamically allocated linked lists is freeing the first pointer in the list first and then \\nnot being able to get to the next pointer in the list. To avoid this problem, make sure \\nthat you have a pointer to the next element in a list before you free the current one.\\nAllocate a reserve parachute of memory If your program uses dynamic memory, you \\nneed to avoid the problem of suddenly running out of memory, leaving your user and \\nyour user’s data lost in RAM space. One way to give your program a margin of error is \\nto preallocate a memory parachute. Determine how much memory your program \\nneeds to save work, clean up, and exit gracefully. Allocate that amount of memory at \\nthe beginning of the program as a reserve parachute, and leave it alone. When you run \\nout of memory, free the reserve parachute, clean up, and shut down.\\nFurther Reading For an \\nexcellent discussion of safe \\napproaches to handling \\npointers in C, see Writing \\nSolid Code (Maguire 1993).\\nShred your garbage Pointer errors are hard to debug because the point at which the \\nmemory the pointer points to becomes invalid is not deterministic. Sometimes the \\nmemory contents will look valid long after the pointer is freed. Other times, the mem-\\nory will change right away.\\nIn C, you can force errors related to using deallocated pointers to be more consistent \\nby overwriting memory blocks with junk data right before they’re deallocated. As with \\nmany other operations, you can do this automatically if you use access routines. In C, \\neach time you delete a pointer, you could use code like this:\\nC Example of Forcing a Deallocated Object to Contain Junk Data\\npointer->SetContentsToGarbage();\\ndelete pointer;\\nOf course, this technique will not work in C++ where the pointer points to an object, \\nand it requires you to implement a Set Contents to Garbage routine for each object..\\nSet pointers to null after deleting or freeing them A common type of pointer error is \\nthe “dangling pointer,” use of a pointer that has been delete’d or free’d. One reason \\npointer errors are hard to detect is that sometimes the error doesn’t produce any \\nsymptoms. By setting pointers to null after freeing them, you don’t change the fact \\nthat you can read data pointed to by a dangling pointer. But you do ensure that writing \\ndata to a dangling pointer produces an error. It will probably be an ugly, nasty, disas-\\nter of an error, but at least you’ll find it instead of someone else finding it.\\nThe code preceding the delete operation in the previous example could be augmented \\nto handle this, too:\\nC+ + Example of Setting a Pointer to Null After Deleting It\\npointer->SetContentsToGarbage();\\ndelete pointer;\\npointer = NULL;\\nC13619670.fm  Page 330  Tuesday, April 12, 2011  2:56 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 367}, page_content='13.2 Pointers 331\\nCheck for bad pointers before deleting a variable One of the best ways to ruin a pro-\\ngram is to delete() or free() a pointer after it has already been delete’d or free’d. Unfor-\\ntunately, few languages detect this kind of problem.\\nSetting freed pointers to null also allows you to check whether a pointer is set to null \\nbefore you use it or attempt to delete it again; if you don’t set freed pointers to null, you \\nwon’t have that option. That suggests another addition to the pointer deletion code:\\nC+ + Example of Asserting That a Pointer Is Not Null Before Deleting It\\nASSERT( pointer != NULL, \"Attempting to delete null pointer.\" );\\npointer->SetContentsToGarbage();\\ndelete pointer;\\npointer = NULL;\\nKeep track of pointer allocations Keep a list of the pointers you have allocated. This \\nallows you to check whether a pointer is in the list before you dispose of it. Here’s an \\nexample of how the standard pointer deletion code could be modified to include that:\\nC+ + Example of Checking Whether a Pointer Has Been Allocated\\nASSERT( pointer != NULL, \"Attempting to delete null pointer.\" );\\nif ( IsPointerInList( pointer ) ) {\\n   pointer->SetContentsToGarbage();\\n   RemovePointerFromList( pointer );\\n   delete pointer;\\n   pointer = NULL;\\n}\\nelse {\\n   ASSERT( FALSE, \"Attempting to delete unallocated pointer.\" );\\n}\\nWrite cover routines to centralize your strategy to avoiding pointer problems As you \\ncan see from this example, you can end up with quite a lot of extra code each time a \\npointer is new’d or delete’d. Some of the techniques described in this section are mutu-\\nally exclusive or redundant, and you wouldn’t want to have multiple, conflicting strat-\\negies in use in the same code base. For example, you don’t need to create and check \\ndog-tag values if you’re maintaining your own list of valid pointers.\\nYou can minimize programming overhead and reduce chance of errors by creating cover \\nroutines for common pointer operations. In C++, you could use these two routines:\\nI SAFE_NEW This routine calls new to allocate the pointer, adds the new \\npointer to a list of allocated pointers, and returns the newly allocated pointer to \\nthe calling routine. It can also be checked for an exception or a null return from \\nnew (aka an “out-of-memory” error) in this one place only, which simplifies \\nerror processing in other parts of your program.\\nC13619670.fm  Page 331  Tuesday, April 12, 2011  2:56 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 368}, page_content='332 Chapter 13: Unusual Data Types\\nI SAFE_DELETE This routine checks to see whether the pointer passed to it is \\nin the list of allocated pointers. If it is in the list, it sets the variable the pointer \\npointed at to garbage values, removes the pointer from the list, calls C++’s delete \\noperator to deallocate the pointer, and sets the pointer to null. If the pointer isn’t \\nin the list, SAFE_DELETE displays a diagnostic message and stops the program.\\nImplemented here as a macro, the SAFE_DELETE routine looks like this:\\nC+ + Example of Putting a Wrapper Around Pointer Deletion Code\\n#define SAFE_DELETE( pointer ) { \\\\\\n   ASSERT( pointer != NULL, \"Attempting to delete null pointer.\"); \\\\\\n   if ( IsPointerInList( pointer ) ) { \\\\\\n      pointer->SetContentsToGarbage();\\n      RemovePointerFromList( pointer ); \\\\\\n      delete pointer; \\\\\\n      pointer = NULL; \\\\\\n   } \\\\\\n   else { \\\\\\n      ASSERT( FALSE, \"Attempting to delete unallocated pointer.\" ); \\\\\\n   } \\\\\\n}\\nCross-Reference For details \\non planning to remove code \\nused for debugging, see \\n“Plan to Remove Debugging \\nAids” in Section 8.6.\\nIn C++, this routine will delete individual pointers, but you would also need to imple-\\nment a similar SAFE_DELETE_ARRAY routine to delete arrays.\\nBy centralizing memory handling in these two routines, you can also make \\nSAFE_NEW and SAFE_DELETE behave differently in debug mode vs. production \\nmode. For example, when SAFE_DELETE detects an attempt to free a null pointer dur-\\ning development, it might stop the program, but during production it might simply \\nlog an error and continue processing.\\nYou can easily adapt this scheme to calloc and free in C and to other languages that use \\npointers.\\nUse a nonpointer technique Pointers are harder than average to understand, they’re \\nerror-prone, and they tend to require machine-dependent, unportable code. If you can \\nthink of an alternative to using a pointer that works reasonably, save yourself a few \\nheadaches and use it instead.\\nC++-Pointer Pointers\\nFurther Reading For many \\nmore tips on using pointers \\nin C++, see Effective C++, 2d \\ned. (Meyers 1998) and More \\nEffective C++ (Meyers 1996).\\nC++ introduces some specific wrinkles related to using pointers and references. The \\nfollowing subsections describe guidelines that apply to using pointers in C++:\\nUnderstand the difference between pointers and references In C++, both pointers \\n(*) and the references ( &) refer indirectly to an object. To the uninitiated the only \\ndifference appears to be a purely cosmetic distinction between referring to fields as \\nC13619670.fm  Page 332  Tuesday, April 12, 2011  2:57 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 369}, page_content='13.2 Pointers 333\\nobject->field vs. object.field . The most significant differences are that a reference must \\nalways refer to an object, whereas a pointer can point to null, and what a reference \\nrefers to can’t be changed after the reference is initialized.\\nUse pointers for “pass by reference” parameters and use const references for “pass by \\nvalue” parameters C++ defaults to passing arguments to routines by value rather \\nthan by reference. When you pass an object to a routine by value, C++ creates a copy \\nof the object, and when the object is passed back to the calling routine, a copy is cre-\\nated again. For large objects, that copying can eat up time and other resources. Conse-\\nquently, when passing objects to a routine, you usually want to avoid copying the \\nobject, which means you want to pass it by reference rather than by value.\\nSometimes, however, you would like to have the semantics of a pass by value—that is, \\nthat the passed object should not be altered—with the implementation of a pass by \\nreference—that is, passing the actual object rather than a copy.\\nIn C++, the resolution to this issue is that you use pointers for pass by reference and—\\nodd as the terminology might sound—“const references” for pass by value! Here’s an \\nexample:\\nC+ + Example of Passing Parameters by Reference and by Value\\nvoid SomeRoutine(\\n   const LARGE_OBJECT &nonmodifiableObject,\\n   LARGE_OBJECT *modifiableObject\\n);\\nThis approach provides the additional benefit of providing a syntactic differentiation \\nwithin the called routine between objects that are supposed to be treated as modifi-\\nable and those that aren’t. In a modifiable object, the references to members will use \\nthe object->member notation, whereas for nonmodifiable objects references to mem-\\nbers will use object.member notation.\\nThe limitation of this approach is difficulties propagating const references. If you control \\nyour own code base, it’s good discipline to use const whenever possible (Meyers 1998), \\nand you should be able to declare pass-by-value parameters as const references. For \\nlibrary code or other code you don’t control, you’ll run into problems using const routine \\nparameters. The fallback position is still to use references for read-only parameters but \\nnot declare them const. With that approach, you won’t realize the full benefits of the com-\\npiler checking for attempts to modify nonmodifiable arguments to a routine, but you’ll at \\nleast give yourself the visual distinction between object->member and object.member.\\nUse auto_ptrs If you haven’t developed the habit of using auto_ptrs, get into the \\nhabit! By deleting memory automatically when the auto_ptr goes out of scope, \\nauto_ptrs avoid many of the memory-leakage problems associated with regular point-\\ners. In Scott Meyers’s More Effective C++, Item #9 contains a good discussion of \\nauto_ptr (Meyers 1996).\\nC13619670.fm  Page 333  Tuesday, April 12, 2011  2:58 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 370}, page_content='334 Chapter 13: Unusual Data Types\\nGet smart about smart pointers Smart pointers are a replacement for regular point-\\ners or “dumb” pointers (Meyers 1996). They operate similarly to regular pointers, but \\nthey provide more control over resource management, copy operations, assignment \\noperations, object construction, and object destruction. The issues involved are spe-\\ncific to C++. More Effective C++, Item #28, contains a complete discussion.\\nC-Pointer Pointers\\nHere are a few tips on using pointers that apply specifically to the C language:\\nUse explicit pointer types rather than the default type C lets you use char or void \\npointers for any type of variable. As long as the pointer points, the language doesn’t \\nreally care what it points at. If you use explicit types for your pointers, however, the \\ncompiler can give you warnings about mismatched pointer types and inappropriate \\ndereferences. If you don’t, it can’t. Use the specific pointer type whenever you can.\\nThe corollary to this rule is to use explicit type casting when you have to make a type \\nconversion. For example, in this fragment, it’s clear that a variable of type NODE_ PTR \\nis being allocated:\\nC Example of Explicit Type Casting\\nNodePtr = (NODE_PTR) calloc( 1, sizeof( NODE ) );\\nAvoid type casting Avoiding type casting doesn’t have anything to do with going to \\nacting school or getting out of always playing “the heavy.” It has to do with avoiding \\nsqueezing a variable of one type into the space for a variable of another type. Type \\ncasting turns off your complier’s ability to check for type mismatches and therefore \\ncreates a hole in your defensive-programming armor. A program that requires many \\ntype casts probably has some architectural gaps that need to be revisited. Redesign if \\nthat’s possible; otherwise, try to avoid type casts as much as you can.\\nFollow the asterisk rule for parameter passing You can pass an argument back from \\na routine in C only if you have an asterisk (*) in front of the argument in the assign-\\nment statement. Many C programmers have difficulty determining when C allows a \\nvalue to be passed back to a calling routine. It’s easy to remember that, as long as you \\nhave an asterisk in front of the parameter when you assign it a value, the value is \\npassed back to the calling routine. Regardless of how many asterisks you stack up in \\nthe declaration, you must have at least one in the assignment statement if you want to \\npass back a value. For example, in the following fragment, the value assigned to \\nparameter isn’t passed back to the calling routine because the assignment statement \\ndoesn’t use an asterisk:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 371}, page_content='13.3 Global Data 335\\nC Example of Parameter Passing That Won’t Work\\nvoid TryToPassBackAValue( int *parameter ) {\\n   parameter = SOME_VALUE;\\n}\\nHere, the value assigned to parameter is passed back because parameter has an asterisk \\nin front of it:\\nC Example of Parameter Passing That Will Work\\nvoid TryToPassBackAValue( int *parameter ) {\\n   *parameter = SOME_VALUE;\\n}\\nUse sizeof() to determine the size of a variable in a memory allocation It’s easier to \\nuse sizeof() than to look up the size in a manual, and sizeof() works for structures you \\ncreate yourself, which aren’t in the manual. Because it’s calculated at compile time, \\nsizeof() doesn’t carry a performance penalty. It’s portable—recompiling in a different \\nenvironment automatically changes the value calculated by sizeof(). And it requires lit-\\ntle maintenance since you can change types you have defined and allocations will be \\nadjusted automatically.\\n13.3 Global Data\\nCross-Reference For details \\non the differences between \\nglobal data and class data, \\nsee “Class data mistaken for \\nglobal data” in Section 5.3.\\nGlobal variables are accessible anywhere in a program. The term is also sometimes \\nused sloppily to refer to variables with a broader scope than local variables—such as \\nclass variables that are accessible anywhere within a class. But accessibility anywhere \\nwithin a single class does not by itself mean that a variable is global.\\nMost experienced programmers have concluded that using global data is riskier than \\nusing local data. Most experienced programmers have also concluded that access to \\ndata from several routines is pretty useful.\\nEven if global variables don’t always produce errors, however, they’re hardly ever the \\nbest way to program. The rest of this section fully explores the issues involved.\\nCommon Problems with Global Data\\nIf you use global variables indiscriminately or you feel that not being able to use them \\nis restrictive, you probably haven’t caught on to the full value of information hiding \\nand modularity yet. Modularity, information hiding, and the associated use of well-\\ndesigned classes might not be revealed truths, but they go a long way toward making \\nlarge programs understandable and maintainable. Once you get the message, you’ll \\nwant to write routines and classes with as little connection as possible to global vari-\\nables and the outside world.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 372}, page_content='336 Chapter 13: Unusual Data Types\\nPeople cite numerous problems in using global data, but the problems boil down to a \\nsmall number of major issues:\\nInadvertent changes to global data You might change the value of a global variable \\nin one place and mistakenly think that it has remained unchanged somewhere else. \\nSuch a problem is known as a “side effect.” For example, in this example, theAnswer is \\na global variable:\\ntheAnswer is a global variable. Visual Basic Example of a Side-Effect Problem\\nGetOtherAnswer() changes \\ntheAnswer.\\naverageAnswer is wrong.\\ntheAnswer = GetTheAnswer()\\notherAnswer = GetOtherAnswer()\\naverageAnswer = (theAnswer + otherAnswer) / 2\\nYou might assume that the call to GetOtherAnswer() doesn’t change the value of theAn-\\nswer; if it does, the average in the third line will be wrong. And, in fact, GetOtherAn-\\nswer() does change the value of theAnswer, so the program has an error to be fixed.\\nBizarre and exciting aliasing problems with global data “Aliasing” refers to calling \\nthe same variable by two or more different names. This happens when a global vari-\\nable is passed to a routine and then used by the routine both as a global variable and \\nas a parameter. Here’s a routine that uses a global variable:\\nVisual Basic Example of a Routine That’s Ripe for an Aliasing Problem\\nSub WriteGlobal( ByRef inputVar As Integer )\\n   inputVar = 0\\n   globalVar = inputVar + 5\\n   MsgBox( \"Input Variable:  \" & Str( inputVar ) )\\n   MsgBox( \"Global Variable: \" & Str( globalVar ) )\\nEnd Sub\\nHere’s the code that calls the routine with the global variable as an argument:\\nVisual Basic Example of Calling the Routine with an Argument, Which Exposes \\nan Aliasing Problem\\nWriteGlobal( globalVar )\\nSince inputVar is initialized to 0 and WriteGlobal() adds 5 to inputVar to get globalVar, \\nyou’d expect globalVar to be 5 more than inputVar. But here’s the surprising result:\\nThe Result of the Aliasing Problem in Visual Basic\\nInput Variable:  5\\nGlobal Variable: 5\\nThe subtlety here is that globalVar and inputVar are actually the same variable! Since \\nglobalVar is passed into WriteGlobal() by the calling routine, it’s referenced or \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 373}, page_content='13.3 Global Data 337\\n“aliased” by two different names. The effect of the MsgBox() lines is thus quite differ-\\nent from the one intended: they display the same variable twice, even though they \\nrefer to two different names.\\nRe-entrant code problems with global data Code that can be entered by more than \\none thread of control is becoming increasingly common. Multithreaded code creates \\nthe possibility that global data will be shared not only among routines, but among dif-\\nferent copies of the same program. In such an environment, you have to make sure \\nthat global data keeps its meaning even when multiple copies of a program are run-\\nning. This is a significant problem, and you can avoid it by using techniques suggested \\nlater in this section.\\nCode reuse hindered by global data To use code from one program in another pro-\\ngram, you have to be able to pull it out of the first program and plug it into the second. \\nIdeally, you’d be able to lift out a single routine or class, plug it into another program, \\nand continue merrily on your way.\\nGlobal data complicates the picture. If the class you want to reuse reads or writes glo-\\nbal data, you can’t just plug it into the new program. You have to modify the new pro-\\ngram or the old class so that they’re compatible. If you take the high road, you’ll \\nmodify the old class so that it doesn’t use global data. If you do that, the next time you \\nneed to reuse the class you’ll be able to plug it in with no extra fuss. If you take the low \\nroad, you’ll modify the new program to create the global data that the old class needs \\nto use. This is like a virus; not only does the global data affect the original program, \\nbut it also spreads to new programs that use any of the old program’s classes.\\nUncertain initialization-order issues with global data The order in which data is ini-\\ntialized among different “translation units” (files) is not defined in some languages, \\nnotably C++. If the initialization of a global variable in one file uses a global variable that \\nwas initialized in a different file, all bets are off on the second variable’s value unless you \\ntake explicit steps to ensure the two variables are initialized in the right sequence.\\nThis problem is solvable with a workaround that Scott Meyers describes in Effective \\nC++, Item #47 (Meyers 1998). But the trickiness of the solution is representative of the \\nextra complexity that using global data introduces.\\nModularity and intellectual manageability damaged by global data The essence of \\ncreating programs that are larger than a few hundred lines of code is managing com-\\nplexity. The only way you can intellectually manage a large program is to break it into \\npieces so that you only have to think about one part at a time. Modularization is the \\nmost powerful tool at your disposal for breaking a program into pieces.\\nGlobal data pokes holes in your ability to modularize. If you use global data, can you \\nconcentrate on one routine at a time? No. You have to concentrate on one routine and \\nevery other routine that uses the same global data. Although global data doesn’t com-\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 374}, page_content='338 Chapter 13: Unusual Data Types\\npletely destroy a program’s modularity, it weakens it, and that’s reason enough to try \\nto find better solutions to your problems.\\nReasons to Use Global Data\\nData purists sometimes argue that programmers should never use global data, but \\nmost programs use “global data” when the term is broadly construed. Data in a data-\\nbase is global data, as is data in configuration files such as the Windows registry. \\nNamed constants are global data, just not global variables.\\nUsed with discipline, global variables are useful in several situations:\\nPreservation of global valuesSometimes you have data that applies conceptually to \\nyour whole program. This might be a variable that reflects the state of a program—for \\nexample, interactive vs. command-line mode, or normal vs. error-recovery mode. Or it \\nmight be information that’s needed throughout a program—for example, a data table \\nthat every routine in the program uses.\\nCross-Reference For more \\ndetails on named constants, \\nsee Section 12.7, “Named \\nConstants.”\\nEmulation of named constants Although C++, Java, Visual Basic, and most modern \\nlanguages support named constants, some languages such as Python, Perl, Awk, and \\nUNIX shell script still don’t. You can use global variables as substitutes for named \\nconstants when your language doesn’t support them. For example, you can replace \\nthe literal values 1 and 0 with the global variables TRUE and FALSE set to 1 and 0, or \\nyou can replace 66 as the number of lines per page with LINES_PER_PAGE = 66. It’s \\neasier to change code later when this approach is used, and the code tends to be easier \\nto read. This disciplined use of global data is a prime example of the distinction \\nbetween programming in vs. programming into a language, which is discussed more \\nin Section 34.4, “Program into Your Language, Not in It.”\\nEmulation of enumerated types You can also use global variables to emulate enumer-\\nated types in languages such as Python that don’t support enumerated types directly.\\nStreamlining use of extremely common data Sometimes you have so many refer-\\nences to a variable that it appears in the parameter list of every routine you write. \\nRather than including it in every paramete r list, you can make it a global variable. \\nHowever, in cases in which a variable seems to be accessed everywhere, it rarely is. \\nUsually it’s accessed by a limited set of routines you can package into a class with the \\ndata they work on. More on this later.\\nEliminating tramp data Sometimes you pass data to a routine or class merely so that \\nit can be passed to another routine or class. For example, you might have an error-pro-\\ncessing object that’s used in each routine. When the routine in the middle of the call \\nchain doesn’t use the object, the object is called “tramp data.” Use of global variables \\ncan eliminate tramp data.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 375}, page_content='13.3 Global Data 339\\nUse Global Data Only as a Last Resort\\nBefore you resort to using global data, consider a few alternatives:\\nBegin by making each variable local and make variables global only as you need to\\nMake all variables local to individual routines initially. If you find they’re needed else-\\nwhere, make them private or protected class variables before you go so far as to make \\nthem global. If you finally find that you have to make them global, do it, but only when \\nyou’re sure you have to. If you start by making a variable global, you’ll never make it \\nlocal, whereas if you start by making it local, you might never need to make it global.\\nDistinguish between global and class variables Some variables are truly global in that \\nthey are accessed throughout a whole program. Others are really class variables, used \\nheavily only within a certain set of routines. It’s OK to access a class variable any way you \\nwant to within the set of routines that use it heavily. If routines outside the class need to \\nuse it, provide the variable’s value by means of an access routine. Don’t access class val-\\nues directly—as if they were global variables—even if your programming language allows \\nyou to. This advice is tantamount to saying “Modularize! Modularize! Modularize!”\\nUse access routines Creating access routines is the workhorse approach to getting \\naround problems with global data. More on that in the next section.\\nUsing Access Routines Instead of Global Data\\nAnything you can do with global data, you can do better with access routines. The use \\nof access routines is a core technique for implementing abstract data types and achiev-\\ning information hiding. Even if you don’t want to use a full-blown abstract data type, \\nyou can still use access routines to centralize control over your data and to protect \\nyourself against changes.\\nAdvantages of Access Routines\\nUsing access routines has multiple advantages:\\n■ You get centralized control over the data. If you discover a more appropriate \\nimplementation of the structure later, you don’t have to change the code every-\\nwhere the data is referenced. Changes don’t ripple through your whole pro-\\ngram. They stay inside the access routines.\\nCross-Reference For more \\ndetails on barricading, see \\nSection 8.5, “Barricade Your \\nProgram to Contain the \\nDamage Caused by Errors.”\\n■ You can ensure that all references to the variable are barricaded. If you push ele-\\nments onto the stack with statements like stack.array[ stack.top ] = newElement, \\nyou can easily forget to check for stack overflow and make a serious mistake. If \\nyou use access routines—for example, PushStack( newElement )—you can write \\nthe check for stack overflow into the PushStack() routine. The check will be done \\nautomatically every time the routine is called, and you can forget about it.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 376}, page_content='340 Chapter 13: Unusual Data Types\\nCross-Reference For details \\non information hiding, see \\n“Hide Secrets (Information \\nHiding)” in Section 5.3.\\n■ You get the general benefits of information hiding automatically. Access routines \\nare an example of information hiding, even if you don’t design them for that rea-\\nson. You can change the interior of an access routine without changing the rest \\nof the program. Access routines allow you to redecorate the interior of your \\nhouse and leave the exterior unchanged so that your friends still recognize it.\\n■ Access routines are easy to convert to an abstract data type. One advantage of \\naccess routines is that you can create a level of abstraction that’s harder to do when \\nyou’re working with global data directly. For example, instead of writing code that \\nsays if lineCount > MAX_LINES, an access routine allows you to write code that says \\nif PageFull(). This small change documents the intent of the if lineCount test, and it \\ndoes so in the code. It’s a small gain in readability, but consistent attention to \\nsuch details makes the difference between beautifully crafted software and code \\nthat’s just hacked together.\\nHow to Use Access Routines\\nHere’s the short version of the theory and practice of access routines: Hide data in a \\nclass. Declare that data by using the static keyword or its equivalent to ensure only a \\nsingle instance of the data exists. Write routines that let you look at the data and \\nchange it. Require code outside the class to use the access routines rather than work-\\ning directly with the data.\\nFor example, if you have a global status variable g_globalStatus that describes your pro-\\ngram’s overall status, you can create two access routines: globalStatus.Get() and global-\\nStatus.Set(), each of which does what it sounds like it does. Those routines access a \\nvariable hidden within the class that replaces g_globalStatus. The rest of the program \\ncan get all the benefit of the formerly global variable by accessing globalStatus.Get() \\nand globalStatus.Set().\\nCross-Reference Restricting \\naccess to global variables \\neven when your language \\ndoesn’t directly support that \\nis an example of program-\\nming into a language vs. \\nprogramming in a language. \\nFor more details, see Section \\n34.4, “Program into Your \\nLanguage, Not in It.”\\nIf your language doesn’t support classes, you can still create access routines to manip-\\nulate the global data but you’ll have to enforce restrictions on the use of the global \\ndata through coding standards in lieu of built-in programming language enforcement.\\nHere are a few detailed guidelines for using access routines to hide global variables \\nwhen your language doesn’t have built-in support:\\nRequire all code to go through the access routines for the data A good convention is \\nto require all global data to begin with the g_ prefix, and to further require that no \\ncode access a variable with the g_ prefix except that variable’s access routines. All \\nother code reaches the data through the access routines.\\nDon’t just throw all your global data into the same barrel If you throw all your glo-\\nbal data into a big pile and write access routines for it, you eliminate the problems of \\nglobal data but you miss out on some of the advantages of information hiding and \\nabstract data types. As long as you’re writing access routines, take a moment to think'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 377}, page_content='13.3 Global Data 341\\nabout which class each global variable belongs in and then package the data and its \\naccess routines with the other data and routines in that class.\\nUse locking to control access to global variables Similar to concurrency control in a \\nmultiuser database environment, locking requires that before the value of a global \\nvariable can be used or updated, the variable must be “checked out.” After the variable \\nis used, it’s checked back in. During the time it’s in use (checked out), if some other \\npart of the program tries to check it out, the lock/unlock routine displays an error \\nmessage or fires an assertion.\\nCross-Reference For details \\non planning for differences \\nbetween developmental and \\nproduction versions of a pro-\\ngram, see “Plan to Remove \\nDebugging Aids” in Section \\n8.6 and Section 8.7, “Deter-\\nmining How Much Defensive \\nProgramming to Leave in \\nProduction Code.”\\nThis description of locking ignores many of the subtleties of writing code to fully sup-\\nport concurrency. For that reason, simplified locking schemes like this one are most \\nuseful during the development stage. Unless the scheme is very well thought out, it \\nprobably won’t be reliable enough to be put into production. When the program is \\nput into production, the code is modified to do something safer and more graceful \\nthan displaying error messages. For example, it might log an error message to a file \\nwhen it detects multiple parts of the program trying to lock the same global variable.\\nThis sort of development-time safeguard is fairly easy to implement when you use \\naccess routines for global data, but it would be awkward to implement if you were \\nusing global data directly.\\nBuild a level of abstraction into your access routines Build access routines at the \\nlevel of the problem domain rather than at the level of the implementation details. \\nThat approach buys you improved readability as well as insurance against changes in \\nthe implementation details.\\nCompare the pairs of statements in Table 13-1:\\nIn the first three examples, the point is that an abstract access routine tells you a lot \\nmore than a generic structure. If you use the structure directly, you do too much at \\nonce: you show both what the structure itself is doing (moving to the next link in a \\nlinked list) and what’s being done with respect to the entity it represents (getting an \\naccount, next employee, or rate level). This is a big burden to put on a simple data-\\nstructure assignment. Hiding the information behind abstract access routines lets the \\ncode speak for itself and makes the code read at the level of the problem domain, \\nrather than at the level of implementation details.\\nTable 13-1 Accessing Global Data Directly and Through Access Routines\\nDirect Use of Global Data Use of Global Data Through Access Routines\\nnode = node.next account = NextAccount( account )\\nnode = node.next employee = NextEmployee( employee )\\nnode = node.next rateLevel = NextRateLevel( rateLevel ) \\nevent = eventQueue[ queueFront ] e vent = HighestPriorityEvent() \\nevent = eventQueue[ queueBack ] event = LowestPriorityEvent()'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 378}, page_content='342 Chapter 13: Unusual Data Types\\nKeep all accesses to the data at the same level of abstraction If you use an access \\nroutine to do one thing to a structure, you should use an access routine to do every-\\nthing else to it too. If you read from the structure with an access routine, write to it \\nwith an access routine. If you call InitStack() to initialize a stack and PushStack() to \\npush an item onto the stack, you’ve created a consistent view of the data. If you pop \\nthe stack by writing value = array[ stack.top ], you’ve created an inconsistent view of the \\ndata. The inconsistency makes it harder for others to understand the code. Create a \\nPopStack() routine instead of writing value = array[ stack top ].\\nCross-Reference Using \\naccess routines for an event \\nqueue suggests the need to \\ncreate a class. For details, \\nsee Chapter 6, “Working \\nClasses.”\\nIn the example pairs of statements in Table 13-1, the two event-queue operations \\noccurred in parallel. Inserting an event into the queue would be trickier than either of \\nthe two operations in the table, requiring several lines of code to find the place to \\ninsert the event, adjust existing events to make room for the new event, and adjust the \\nfront or back of the queue. Removing an event from the queue would be just as com-\\nplicated. During coding, the complex operations would be put into routines and the \\nothers would be left as direct data manipulations. This would create an ugly, nonpar-\\nallel use of the structure. Now compare the pairs of statements in Table 13-2:\\nAlthough you might think that these guidel ines apply only to large programs, access \\nroutines have shown themselves to be a productive way of avoiding the problems of \\nglobal data. As a bonus, they make the code more readable and add flexibility.\\nHow to Reduce the Risks of Using Global Data\\nIn most instances, global data is really class data for a class that hasn’t been designed \\nor implemented very well. In a few instances, data really does need to be global, but \\naccesses to it can be wrapped with access routines to minimize potential problems. In \\na tiny number of remaining instances, you really do need to use global data. In those \\ncases, you might think of following the guidelines in this section as getting shots so \\nthat you can drink the water when you travel to a foreign country: they’re kind of pain-\\nful, but they improve the odds of staying healthy.\\nCross-Reference For details \\non naming conventions for \\nglobal variables, see “Iden-\\ntify global variables” in Sec-\\ntion 11.4.\\nDevelop a naming convention that makes global variables obvious You can avoid \\nsome mistakes just by making it obvious that you’re working with global data. If \\nyou’re using global variables for more than one purpose (for example, as variables and \\nas substitutes for named constants), make sure your naming convention differentiates \\namong the types of uses.\\nTable 13-2  Parallel and Nonparallel Uses of Complex Data\\nNonparallel Use of Complex Data Parallel Use of Complex Data \\nevent = EventQueue[ queueFront ] event = HighestPriorityEvent()\\nevent = EventQueue[ queueBack ] event = LowestPriorityEvent()\\nAddEvent( event ) AddEvent( event )\\neventCount = eventCount - 1 RemoveEvent( event )'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 379}, page_content='Additional Resources 343\\nCreate a well-annotated list of all your global variables Once your naming conven-\\ntion indicates that a variable is global, it’s helpful to indicate what the variable does. A \\nlist of global variables is one of the most useful tools that someone working with your \\nprogram can have.\\nDon’t use global variables to contain intermediate results If you need to compute a \\nnew value for a global variable, assign the global variable the final value at the end of \\nthe computation rather than using it to hold  the result of intermediate calculations.\\nDon’t pretend you’re not using global data by putting all your data into a monster \\nobject and passing it everywhere Putting everything into one huge object might sat-\\nisfy the letter of the law by avoiding global variables, but it’s pure overhead, producing \\nnone of the benefits of true encapsulation. If you use global data, do it openly. Don’t \\ntry to disguise it with obese objects.\\nAdditional Resources\\ncc2e.com/1385 Following are more resources that cover unusual data types:\\nMaguire, Steve. Writing Solid Code. Redmond, WA: Microsoft Press, 1993. Chapter 3 \\ncontains an excellent discussion of the hazards of pointer use and numerous specific \\ntips for avoiding problems with pointers.\\nMeyers, Scott. Effective C++, 2d ed. Reading, MA: Addison-Wesley, 1998;  Meyers, Scott, \\nMore Effective C++. Reading, MA: Addison-Wesley, 1996. As the titles suggest, these \\nbooks contain numerous specific tips for improving C++ programs, including guide-\\nlines for using pointers safely and effectively. More Effective C++ in particular contains \\nan excellent discussion of C++’s memory management issues.\\ncc2e.com/1392 CHECKLIST: Considerations in Using Unusual Data Types\\nStructures\\n❑ Have you used structures instead of naked variables to organize and \\nmanipulate groups of related data?\\n❑ Have you considered creating a class as an alternative to using a structure?\\nGlobal Data\\n❑ Are all variables local or of class scope unless they absolutely need to be \\nglobal?\\n❑ Do variable naming conventions differentiate among local, class, and glo-\\nbal data?\\n❑ Are all global variables documented?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 380}, page_content='344 Chapter 13: Unusual Data Types\\n❑ Is the code free of pseudoglobal data—mammoth objects containing a \\nmishmash of data that’s passed to every routine?\\n❑ Are access routines used instead of global data?\\n❑ Are access routines and data organized into classes?\\n❑ Do access routines provide a level of abstraction beyond the underlying \\ndata type implementations?\\n❑ Are all related access routines at the same level of abstraction?\\nPointers\\n❑ Are pointer operations isolated in routines?\\n❑ Are pointer references valid, or could the pointer be dangling?\\n❑ Does the code check pointers for validity before using them?\\n❑ Is the variable that the pointer references checked for validity before it’s \\nused?\\n❑ Are pointers set to null after they’re freed?\\n❑ Does the code use all the pointer variables needed for the sake of readabil-\\nity?\\n❑ Are pointers in linked lists freed in the right order?\\n❑ Does the program allocate a reserve parachute of memory so that it can \\nshut down gracefully if it runs out of memory?\\n❑ Are pointers used only as a last resort, when no other method is available?\\nKey Points\\n■ Structures can help make programs less complicated, easier to understand, and \\neasier to maintain.\\n■ Whenever you consider using a structure, consider whether a class would work \\nbetter.\\n■ Pointers are error-prone. Protect yourself by using access routines or classes and \\ndefensive-programming practices.\\n■ Avoid global variables, not just because they’re dangerous, but because you can \\nreplace them with something better.\\n■ If you can’t avoid global variables, work with them through access routines. \\nAccess routines give you everything that global variables give you, and more.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 381}, page_content='Part IV\\nStatements\\nIn this part:\\nChapter 14: Organizing Straight-Line Code . . . . . . . . . . . . . . . . . . . . . . . .347\\nChapter 15: Using Conditionals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .355\\nChapter 16: Controlling Loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .367\\nChapter 17: Unusual Control Structures . . . . . . . . . . . . . . . . . . . . . . . . . . .391\\nChapter 18: Table-Driven Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .411\\nChapter 19: General Control Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .431'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 383}, page_content='347\\nChapter 14\\nOrganizing Straight-Line \\nCode\\ncc2e.com/1465 Contents\\n■ 14.1 Statements That Must Be in a Specific Order: page 347\\n■ 14.2 Statements Whose Order Doesn’t Matter: page 351\\nRelated Topics\\n■ General control topics: Chapter 19\\n■ Code with conditionals: Chapter 15\\n■ Code with loops: Chapter 16\\n■ Scope of variables and objects: Section 10.4, “Scope”\\nThis chapter turns from a data-centered view of programming to a statement-centered \\nview. It introduces the simplest kind of control flow: putting statements and blocks of \\nstatements in sequential order.\\nAlthough organizing straight-line code is a relatively simple task, some organizational \\nsubtleties influence code quality, correctness, readability, and maintainability.\\n14.1 Statements That Must Be in a Specific Order\\nThe easiest sequential statements to order are those in which the order counts. Here’s \\nan example:\\nJava Example of Statements in Which Order Counts\\ndata = ReadData();\\nresults = CalculateResultsFromData( data );\\nPrintResults( results );\\nUnless something mysterious is happening with this code fragment, the statement \\nmust be executed in the order shown. The data must be read before the results can be \\ncalculated, and the results must be calculated before they can be printed.\\nThe underlying concept in this example is that of dependencies. The third statement \\ndepends on the second, the second on the fi rst. In this example, the fact that one'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 384}, page_content='348 Chapter 14: Organizing Straight-Line Code\\nstatement depends on another is obvious from the routine names. In the following \\ncode fragment, the dependencies are less obvious:\\nJava Example of Statements in Which Order Counts, but Not Obviously\\nrevenue.ComputeMonthly();\\nrevenue.ComputeQuarterly();\\nrevenue.ComputeAnnual();\\nIn this case, the quarterly revenue calculation assumes that the monthly revenues \\nhave already been calculated. A familiarity with accounting—or even common sense—\\nmight tell you that quarterly revenues have to be calculated before annual revenues. \\nThere is a dependency, but it’s not obvious merely from reading the code. And here, \\nthe dependencies aren’t obvious—they’re literally hidden:\\nVisual Basic Example of Statements in Which Order Dependencies Are Hidden\\nComputeMarketingExpense\\nComputeSalesExpense\\nComputeTravelExpense\\nComputePersonnelExpense\\nDisplayExpenseSummary\\nSuppose that ComputeMarketingExpense() initializes the class member variables that \\nall the other routines put their data into. In such a case, it needs to be called before the \\nother routines. How could you know that from reading this code? Because the routine \\ncalls don’t have any parameters, you might be able to guess that each of these routines \\naccesses class data. But you can’t know for sure from reading this code. \\nWhen statements have dependencies that require you to put them in a certain order, \\ntake steps to make the dependencies clear. Here are some simple guidelines for order-\\ning statements:\\nOrganize code so that dependencies are obvious In the Microsoft Visual Basic exam-\\nple just presented, ComputeMarketingExpense() shouldn’t initialize the class member \\nvariables. The routine names suggest that ComputeMarketingExpense() is similar to \\nComputeSalesExpense(), ComputeTravelExpense(), and the other routines except that it \\nworks with marketing data rather than with sales data or other data. Having Comp-\\nuteMarketingExpense() initialize the member variable is an arbitrary practice you \\nshould avoid. Why should initialization be done in that routine instead of one of the \\nother two? Unless you can think of a good reason, you should write another routine, \\nInitializeExpenseData(), to initialize the member variable. The routine’s name is a clear \\nindication that it should be called before the other expense routines.\\nName routines so that dependencies are obvious In the Visual Basic example, Comp-\\nuteMarketingExpense() is misnamed because it does more than compute marketing \\nexpenses; it also initializes member data. If you’re opposed to creating an additional \\nroutine to initialize the data, at least give ComputeMarketingExpense() a name that \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 385}, page_content='14.1 Statements That Must Be in a Specific Order 349\\ndescribes all the functions it performs. In this case, ComputeMarketingExpenseAndIni-\\ntializeMemberData() would be an adequate name. You might say it’s a terrible name \\nbecause it’s so long, but the name describes what the routine does and is not terrible. \\nThe routine itself is terrible!\\nCross-Reference For details \\non using routines and their \\nparameters, see Chapter 5, \\n“Design in Construction.”\\nUse routine parameters to make dependencies obvious Again in the Visual Basic \\nexample, since no data is passed between routines, you don’t know whether any of \\nthe routines use the same data. By rewriting the code so that data is passed between \\nthe routines, you set up a clue that the execution order is important. The new code \\nwould look like this:\\nVisual Basic Example of Data That Suggests an Order Dependency\\nInitializeExpenseData( expenseData )\\nComputeMarketingExpense( expenseData )\\nComputeSalesExpense( expenseData )\\nComputeTravelExpense( expenseData )\\nComputePersonnelExpense( expenseData )\\nDisplayExpenseSummary( expenseData )\\nBecause all the routines use expenseData, you have a hint that they might be working \\non the same data and that the order of the statements might be important. \\nIn this particular example, a better approach might be to convert the routines to func-\\ntions that take expenseData as inputs and return updated expenseData as outputs, \\nwhich makes it even clearer that the code includes order dependencies. \\nVisual Basic Example of Data and Routine Calls That Suggest an Order Dependency\\nexpenseData = InitializeExpenseData( expenseData )\\nexpenseData = ComputeMarketingExpense( expenseData )\\nexpenseData = ComputeSalesExpense( expenseData )\\nexpenseData = ComputeTravelExpense( expenseData )\\nexpenseData = ComputePersonnelExpense( expenseData )\\nDisplayExpenseSummary( expenseData )\\nData can also indicate that execution order isn’t important, as in this case:\\nVisual Basic Example of Data That Doesn’t Indicate an Order Dependency\\nComputeMarketingExpense( marketingData )\\nComputeSalesExpense( salesData )\\nComputeTravelExpense( travelData )\\nComputePersonnelExpense( personnelData )\\nDisplayExpenseSummary( marketingData, salesData, travelData, personnelData )\\nSince the routines in the first four lines don’t have any data in common, the code \\nimplies that the order in which they’re called doesn’t matter. Because the routine in \\nthe fifth line uses data from each of the first four routines, you can assume that it \\nneeds to be executed after the first four routines.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 386}, page_content=\"350 Chapter 14: Organizing Straight-Line Code\\nDocument unclear dependencies with comments Try first to write code without \\norder dependencies.Try second to write code that makes dependencies obvious. If \\nyou’re still concerned that an order dependency isn’t explicit enough, document it. \\nDocumenting unclear dependencies is one aspect of documenting coding assump-\\ntions, which is critical to writing maintainable, modifiable code. In the Visual Basic \\nexample, comments along these lines would be helpful:\\nVisual Basic Example of Statements in Which Order Dependencies Are Hidden but \\nClarified with Comments\\n' Compute expense data. Each of the routines accesses the\\n' member data expenseData. DisplayExpenseSummary \\n' should be called last because it depends on data calculated \\n' by the other routines.\\nInitializeExpenseData\\nComputeMarketingExpense\\nComputeSalesExpense\\nComputeTravelExpense\\nComputePersonnelExpense\\nDisplayExpenseSummary\\nThis code doesn’t use the techniques for making order dependencies obvious. It’s bet-\\nter to rely on such techniques rather than on comments, but if you’re maintaining \\ntightly controlled code or you can’t improve the code itself for some other reason, use \\ndocumentation to compensate for code weaknesses.\\nCheck for dependencies with assertions or error-handling code If the code is critical \\nenough, you might use status variables and error-handling code or assertions to doc-\\nument critical sequential dependencies. For example, in the class’s constructor, you \\nmight initialize a class member variable isExpenseDataInitialized to false. Then in Ini-\\ntializeExpenseData(), you can set isExpenseDataInitialized to true. Each function that \\ndepends on expenseData being initialized can then check whether isExpenseDataIni-\\ntialized has been set to true before performing additional operations on expenseData. \\nDepending on how extensive the dependencies are, you might also need variables like \\nisMarketingExpenseComputed, isSalesExpenseComputed, and so on. \\nThis technique creates new variables, new initialization code, and new error-checking \\ncode, all of which create additional possibilities for error. The benefits of this tech-\\nnique should be weighed against the additional complexity and increased chance of \\nsecondary errors that this technique creates. \\nKEY POINT\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 387}, page_content='14.2 Statements Whose Order Doesn’t Matter 351\\n14.2 Statements Whose Order Doesn’t Matter\\nYou might encounter cases in which it seems as if the order of a few statements or a \\nfew blocks of code doesn’t matter at all. One statement doesn’t depend on, or logi-\\ncally follow, another statemen t. But ordering affects readability, performance, and \\nmaintainability, and in the absence of ex ecution-order dependencies, you can use \\nsecondary criteria to determine the order of statements or blocks of code. The guid-\\ning principle is the Principle of Proximity: Keep related actions together.\\nMaking Code Read from Top to Bottom\\nAs a general principle, make the program read from top to bottom rather than jump-\\ning around. Experts agree that top-to-bottom order contributes most to readability. \\nSimply making the control flow from top to bottom at run time isn’t enough. If some-\\none who is reading your code has to search the whole program to find needed infor-\\nmation, you should reorganize the code. Here’s an example:\\nC++ Example of Bad Code That Jumps Around\\nMarketingData marketingData; \\nSalesData salesData;\\nTravelData travelData;\\ntravelData.ComputeQuarterly();\\nsalesData.ComputeQuarterly();\\nmarketingData.ComputeQuarterly();\\nsalesData.ComputeAnnual();\\nmarketingData.ComputeAnnual();\\ntravelData.ComputeAnnual();\\nsalesData.Print();\\ntravelData.Print();\\nmarketingData.Print();\\nSuppose that you want to determine how marketingData is calculated. You have to \\nstart at the last line and track all references to marketingData back to the first line. mar-\\nketingData is used in only a few other places, but you have to keep in mind how mar-\\nketingData is used everywhere between the first and last references to it. In other \\nwords, you have to look at and think about every line of code in this fragment to figure \\nout how marketingData is calculated. And of course this example is simpler than code \\nyou see in life-size systems. Here’s the same code with better organization:\\nC++ Example of Good, Sequential Code That Reads from Top to Bottom\\nMarketingData marketingData;\\nmarketingData.ComputeQuarterly();\\nmarketingData.ComputeAnnual();\\nmarketingData.Print();'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 388}, page_content='352 Chapter 14: Organizing Straight-Line Code\\nSalesData salesData;\\nsalesData.ComputeQuarterly();\\nsalesData.ComputeAnnual();\\nsalesData.Print();\\nTravelData travelData;\\ntravelData.ComputeQuarterly();\\ntravelData.ComputeAnnual();\\ntravelData.Print();\\nCross-Reference A more \\ntechnical definition of “live” \\nvariables is given in “Mea-\\nsuring the Live Time of a \\nVariable” in Section 10.4.\\nThis code is better in several ways. References to each object are kept close together; \\nthey’re “localized.” The number of lines of code in which the objects are “live” is small. \\nAnd perhaps most important, the code now looks as if it could be broken into sepa-\\nrate routines for marketing, sales, and travel data. The first code fragment gave no hint \\nthat such a decomposition was possible.\\nGrouping Related Statements\\nCross-Reference If you fol-\\nlow the Pseudocode Pro-\\ngramming Process, your \\ncode will automatically be \\ngrouped into related state-\\nments. For details on the \\nprocess, see Chapter 9, “The \\nPseudocode Programming \\nProcess.”\\nPut related statements together. They can be related because they operate on the same \\ndata, perform similar tasks, or depend on  each other’s being performed in order.\\nAn easy way to test whether related statements are grouped well is to print out a listing \\nof your routine and then draw boxes around the related statements. If the statements \\nare ordered well, you’ll get a picture like that shown in Figure 14-1, in which the boxes \\ndon’t overlap.\\nFigure 14-1 If the code is well organized into groups, boxes drawn around related sections \\ndon’t overlap. They might be nested.\\nCross-Reference For more \\non keeping operations on \\nvariables together, see Sec-\\ntion 10.4, “Scope.”\\nIf statements aren’t ordered well, you’ll get a picture something like that shown in Fig-\\nure 14-2, in which the boxes do overlap. If you find that your boxes overlap, reorganize \\nyour code so that related statements are grouped better.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 389}, page_content='Key Points 353\\nFigure 14-2 If the code is organized poorly, boxes drawn around related sections overlap. \\nOnce you’ve grouped related statements, you might find that they’re strongly related and \\nhave no meaningful relationship to the statements that precede or follow them. In such a \\ncase, you might want to refactor the strongly related statements into their own routine.\\ncc2e.com/1472 Checklist: Organizing Straight-Line Code\\n❑ Does the code make dependencies among statements obvious? \\n❑ Do the names of routines make dependencies obvious?\\n❑ Do parameters to routines make dependencies obvious?\\n❑ Do comments describe any dependencies that would otherwise be \\nunclear?\\n❑ Have housekeeping variables been used to check for sequential dependen-\\ncies in critical sections of code? \\n❑ Does the code read from top to bottom?\\n❑ Are related statements grouped together?\\n❑ Have relatively independent groups of statements been moved into their \\nown routines?\\nKey Points\\n■ The strongest principle for organizing straight-line code is ordering dependencies.\\n■ Dependencies should be made obvious through the use of good routine names, \\nparameter lists, comments, and—if the code is critical enough—housekeeping \\nvariables.\\n■ If code doesn’t have order dependencies, keep related statements as close \\ntogether as possible.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 391}, page_content='355\\nChapter 15\\nUsing Conditionals \\ncc2e.com/1538 Contents\\n■ 15.1 if Statements: page 355\\n■ 15.2 case Statements: page 361\\nRelated Topics\\n■ Taming deep nesting: Section 19.4\\n■ General control issues: Chapter 19\\n■ Code with loops: Chapter 16\\n■ Straight-line code: Chapter 14\\n■ Relationship between data types and control structures: Section 10.7\\nA conditional is a statement that controls the execution of other statements; execution \\nof the other statements is “conditioned” on statements such as if, else, case, and switch. \\nAlthough it makes sense logically to refer to loop controls such as while and for as con-\\nditionals too, by convention they’ve been treated separately. Chapter 16, “Controlling \\nLoops,” will examine while and for statements.\\n15.1 if Statements\\nDepending on the language you’re using, you might be able to use any of several kinds \\nof if statements. The simplest is the plain if or if-then statement. The if-then-else is a lit-\\ntle more complex, and chains of if-then-else-if are the most complex.\\nPlain if-then Statements\\nFollow these guidelines when writing if statements:\\nWrite the nominal path through the code first; then write the unusual cases Write \\nyour code so that the normal path through th e code is clear. Make sure that the rare \\ncases don’t obscure the normal path of execution. This is important for both readabil-\\nity and performance.\\nMake sure that you branch correctly on equality Using > instead of >= or < instead \\nof <= is analogous to making an off-by-one error in accessing an array or computing a \\nloop index. In a loop, think through the endpoints to avoid an off-by-one error. In a \\nconditional statement, think through the equals case to avoid one.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 392}, page_content='356 Chapter 15: Using Conditionals\\nCross-Reference For other \\nways to handle error-pro-\\ncessing code, see \"Summary \\nof Techniques for Reducing \\nDeep Nesting\" in Section \\n19.4.\\nPut the normal case after the if rather than after the else Put the case you nor-\\nmally expect to process first. This is in line with the general principle of putting code \\nthat results from a decision as close as possible to the decision. Here’s a code example \\nthat does a lot of error processing, haphazardly checking for errors along the way:\\nVisual Basic Example of Code That Processes a Lot of Errors Haphazardly\\nOpenFile( inputFile, status )\\nIf ( status = Status_Error ) Then\\nError case.    errorType = FileOpenError\\nElse\\nNominal case.    ReadFile( inputFile, fileData, status )\\n   If ( status = Status_Success ) Then\\nNominal case.       SummarizeFileData( fileData, summaryData, status )\\n      If ( status = Status_Error ) Then\\nError case.          errorType = ErrorType_DataSummaryError\\n      Else\\nNominal case.          PrintSummary( summaryData )\\n         SaveSummaryData( summaryData, status )\\n         If ( status = Status_Error ) Then\\nError case.             errorType = ErrorType_SummarySaveError\\n         Else\\nNominal case.             UpdateAllAccounts()\\n            EraseUndoFile()\\n            errorType = ErrorType_None\\n         End If\\n      End If\\n   Else\\n      errorType = ErrorType_FileReadError\\n   End If\\nEnd If\\nThis code is hard to follow because the nominal cases and the error cases are all mixed \\ntogether. It’s hard to find the path that is normally taken through the code. In addi-\\ntion, because the error conditions are sometimes processed in the if clause rather than \\nthe else clause, it’s hard to figure out which if test the normal case goes with. In the fol-\\nlowing rewritten code, the normal path is consistently coded first and all the error \\ncases are coded last. This makes it easier to find and read the nominal case.\\nVisual Basic Example of Code That Processes a Lot of Errors Systematically\\nOpenFile( inputFile, status )\\nIf ( status = Status_Success ) Then\\nNominal case.    ReadFile( inputFile, fileData, status )\\n   If ( status = Status_Success ) Then\\nNominal case.       SummarizeFileData( fileData, summaryData, status )\\n      If ( status = Status_Success ) Then\\nNominal case.          PrintSummary( summaryData )\\n         SaveSummaryData( summaryData, status )\\n         If ( status = Status_Success ) Then\\nNominal case.             UpdateAllAccounts()\\n            EraseUndoFile()'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 393}, page_content='15.1 if Statements 35715.1 if Statements\\n            errorType = ErrorType_None\\n         Else\\nError case.             errorType = ErrorType_SummarySaveError\\n         End If\\n      Else\\nError case.          errorType = ErrorType_DataSummaryError\\n      End If\\n   Else\\nError case.       errorType = ErrorType_FileReadError\\n   End If\\nElse\\nError case.    errorType = ErrorType_FileOpenError\\nEnd If\\nIn the revised example, you can read the main flow of the if tests to find the normal \\ncase. The revision puts the focus on reading the main flow rather than on wading \\nthrough the exceptional cases, so the code is easier to read overall. The stack of error \\nconditions at the bottom of the nest is a sign of well-written error-processing code.\\nThis example illustrates one systematic approach to handling normal cases and error \\ncases. A variety of other solutions to this problem are discussed throughout this book, \\nincluding using guard clauses, converting to polymorphic dispatch, and extracting \\nthe inner part of the test into a separate routine. For a complete list of available \\napproaches, see “Summary of Techniques for Reducing Deep Nesting” in Section 19.4.\\nFollow the if clause with a meaningful statement Sometimes you see code like the \\nnext example, in which the if clause is null:\\nJava Example of a Null if Clause\\nif ( SomeTest )\\n   ;\\nelse {\\n   // do something\\n   ...\\n}\\nCross-Reference One key to \\nconstructing an effective if \\nstatement is writing the right \\nboolean expression to con-\\ntrol it. For details on using \\nboolean expressions effec-\\ntively, see Section 19.1, \\n“Boolean Expressions.”\\nMost experienced programmers would avoid code like this if only to avoid the work of \\ncoding the extra null line and the else line. It looks silly and is easily improved by \\nnegating the predicate in the if statement, moving the code from the else clause to the \\nif clause, and eliminating the else clause. Here’s how the code would look after those \\nchanges:\\nJava Example of a Converted Null if Clause\\nif ( ! someTest ) {\\n   // do something\\n   ...\\n}\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 394}, page_content=\"358 Chapter 15: Using Conditionals\\nConsider the else clause If you think you need a plain if statement, consider \\nwhether you don’t actually need an if-then-else statement. A classic General Motors \\nanalysis found that 50 to 80 percent of if statements should have had an else clause \\n(Elshoff 1976).\\nOne option is to code the else clause—with a null statement if necessary—to show that \\nthe else case has been considered. Coding null elses just to show that that case has \\nbeen considered might be overkill, but at the very least, take the else case into account. \\nWhen you have an if test without an else, unless the reason is obvious, use comments \\nto explain why the else clause isn’t necessary, like so:\\nJava Example of a Helpful, Commented else Clause\\n// if color is valid\\nif ( COLOR_MIN <= color && color <= COLOR_MAX ) {\\n   // do something\\n   ...\\n}\\nelse {\\n   // else color is invalid\\n   // screen not written to –- safely ignore command\\n}\\nTest the else clause for correctness When testing your code, you might think that \\nthe main clause, the if, is all that needs to be tested. If it’s possible to test the else \\nclause, however, be sure to do that.\\nCheck for reversal of the if and else clauses A common mistake in programming if-\\nthens is to flip-flop the code that’s supposed to follow the if clause and the code that’s \\nsupposed to follow the else clause or to get the logic of the if test backward. Check \\nyour code for this common error.\\nChains of if-then-else Statements\\nIn languages that don’t support case statements—or that support them only partially—\\nyou’ll often find yourself writing chains of if-then-else tests. For example, the code to \\ncategorize a character might use a chain like this one:\\nCross-Reference For more \\ndetails on simplifying com-\\nplicated expressions, see \\nSection 19.1, “Boolean \\nExpressions.”\\nC+ + Example of Using an if-then-else Chain to Categorize a Character\\nif ( inputCharacter < SPACE ) {\\n   characterType = CharacterType_ControlCharacter;\\n}\\nelse if ( \\n   inputCharacter == ' ' || \\n   inputCharacter == ',' || \\n   inputCharacter == '.' ||\\n   inputCharacter == '!' || \\n   inputCharacter == '(' || \\n   inputCharacter == ')' || \\n1\\n2\\n3\\nHARD DATA\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 395}, page_content=\"15.1 if Statements 35915.1 if Statements\\n   inputCharacter == ':' ||\\n   inputCharacter == ';' || \\n   inputCharacter == '?' || \\n   inputCharacter == '-' \\n   ) {\\n   characterType = CharacterType_Punctuation;\\n}\\nelse if ( '0' <= inputCharacter && inputCharacter <= '9' ) {\\n   characterType = CharacterType_Digit;\\n}\\nelse if ( \\n   ( 'a' <= inputCharacter && inputCharacter <= 'z' ) ||\\n   ( 'A' <= inputCharacter && inputCharacter <= 'Z' ) \\n   ) {\\n   characterType = CharacterType_Letter;\\n}\\nConsider these guidelines when writing such if-then-else chains: \\nSimplify complicated tests with boolean function calls One reason the code in the \\nprevious example is hard to read is that the tests that categorize the character are compli-\\ncated. To improve readability, you can replace them with calls to boolean functions. \\nHere’s how the example’s code looks when the tests are replaced with boolean functions:\\nC+ + Example of an if-then-else Chain That Uses Boolean Function Calls\\nif ( IsControl( inputCharacter ) ) {\\n   characterType = CharacterType_ControlCharacter;\\n}\\nelse if ( IsPunctuation( inputCharacter ) ) {\\n   characterType = CharacterType_Punctuation;\\n}\\nelse if ( IsDigit( inputCharacter ) ) {\\n   characterType = CharacterType_Digit;\\n}\\nelse if ( IsLetter( inputCharacter ) ) {\\n   characterType = CharacterType_Letter;\\n}\\nPut the most common cases first By putting the most common cases first, you mini-\\nmize the amount of exception-case handling code someone has to read to find the \\nusual cases. You improve efficiency because you minimize the number of tests the \\ncode does to find the most common cases. In the example just shown, letters would \\nbe more common than punctuation but the test for punctuation is made first. Here’s \\nthe code revised so that it tests for letters first:\\nC+ + Example of Testing the Most Common Case First\\nThis test, the most common, \\nis now done first.\\nif ( IsLetter( inputCharacter ) ) {\\n   characterType = CharacterType_Letter;\\n}\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 396}, page_content='360 Chapter 15: Using Conditionals\\nelse if ( IsPunctuation( inputCharacter ) ) {\\n   characterType = CharacterType_Punctuation;\\n}\\nelse if ( IsDigit( inputCharacter ) ) {\\n   characterType = CharacterType_Digit;\\n}\\nThis test, the least common, \\nis now done last.\\nelse if ( IsControl( inputCharacter ) ) {\\n   characterType = CharacterType_ControlCharacter;\\n}\\nMake sure that all cases are covered Code a final else clause with an error message \\nor assertion to catch cases you didn’t plan for. This error message is intended for you \\nrather than for the user, so word it appropriately. Here’s how you can modify the char-\\nacter-classification example to perform an “other cases” test: \\nCross-Reference This is also \\na good example of how you \\ncan use a chain of if-then-\\nelse tests instead of deeply \\nnested code. For details on \\nthis technique, see Section \\n19.4, “Taming Dangerously \\nDeep Nesting.”\\nC+ + Example of Using the Default Case to Trap Errors\\nif ( IsLetter( inputCharacter ) ) {\\n   characterType = CharacterType_Letter;\\n}\\nelse if ( IsPunctuation( inputCharacter ) ) {\\n   characterType = CharacterType_Punctuation;\\n}\\nelse if ( IsDigit( inputCharacter ) ) {\\n   characterType = CharacterType_Digit;\\n}\\nelse if ( IsControl( inputCharacter ) ) {\\n   characterType = CharacterType_ControlCharacter;\\n}\\nelse {\\n   DisplayInternalError( \"Unexpected type of character detected.\" );\\n}\\nReplace if-then-else chains with other constructs if your language supports them A \\nfew languages—Microsoft Visual Basic and Ada, for example—provide case statements \\nthat support use of strings, enums, and logical functions. Use them—they are easier to \\ncode and easier to read than if-then-else chains. Code for classifying character types by \\nusing a case statement in Visual Basic would be written like this:\\nVisual Basic Example of Using a case Statement Instead of an if-then-else Chain\\nSelect Case inputCharacter\\n   Case \"a\" To \"z\"\\n      characterType = CharacterType_Letter\\n   Case \" \", \",\", \".\", \"!\", \"(\", \")\", \":\", \";\", \"?\", \"-\"\\n      characterType = CharacterType_Punctuation\\n   Case \"0\" To \"9\"\\n      characterType = CharacterType_Digit\\n   Case FIRST_CONTROL_CHARACTER To LAST_CONTROL_CHARACTER\\n      characterType = CharacterType_Control\\n   Case Else\\n      DisplayInternalError( \"Unexpected type of character detected.\" )\\nEnd Select'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 397}, page_content='15.2 case Statements 361\\n15.2 case Statements\\nThe case or switch statement is a construct that varies a great deal from language to lan-\\nguage. C++ and Java support case only for ordinal types taken one value at a time. \\nVisual Basic supports case for ordinal types and has powerful shorthand notations for \\nexpressing ranges and combinations of values. Many scripting languages don’t sup-\\nport case statements at all. \\nThe following sections present guidelines for using case statements effectively:\\nChoosing the Most Effective Ordering of Cases\\nYou can choose from among a variety of ways to organize the cases in a case statement. \\nIf you have a small case statement with three options and three corresponding lines of \\ncode, the order you use doesn’t matter much. If you have a long case statement—for \\nexample, a case statement that handles dozens of events in an event-driven program—\\norder is significant. Following are some ordering possibilities:\\nOrder cases alphabetically or numerically If cases are equally important, putting \\nthem in A-B-C order improves readability. That way a specific case is easy to pick out \\nof the group.\\nPut the normal case first If you have one normal case and several exceptions, put \\nthe normal case first. Indicate with comment s that it’s the normal case and that the \\nothers are unusual.\\nOrder cases by frequency Put the most frequently executed cases first and the least \\nfrequently executed last. This approach has two advantages. First, human readers can \\nfind the most common cases easily. Readers scanning the list for a specific case are \\nlikely to be interested in one of the most common cases, and putting the common \\nones at the top of the code makes the search quicker. \\nTips for Using case Statements \\nHere are several tips for using case statements: \\nCross-Reference For other \\ntips on simplifying code, see \\nChapter 24, \"Refactoring.\"\\nKeep the actions of each case simple Keep the code associated with each case short. \\nShort code following each case helps make the structure of the case statement clear. If \\nthe actions performed for a case are complicated, write a routine and call the routine \\nfrom the case rather than putting the code into the case itself.\\nDon’t make up phony variables to be able to use the case statement A case state-\\nment should be used for simple data that’s easily categorized. If your data isn’t simple, \\nuse chains of if-then-elses instead. Phony variables are confusing, and you should avoid \\nthem. For example, don’t do this:\\n15.1 case Statements'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 398}, page_content=\"362 Chapter 15: Using Conditionals\\nJava Example of Creating a Phony case Variable—Bad Practice\\naction = userCommand[ 0 ];\\nswitch ( action ) {\\n   case 'c': \\n      Copy(); \\n      break;\\n   case 'd': \\n      DeleteCharacter(); \\n      break;\\n   case 'f': \\n      Format(); \\n      break;\\n   case 'h': \\n      Help(); \\n      break;\\n   ...\\n   default: \\n      HandleUserInputError( ErrorType.InvalidUserCommand );\\n} \\nThe variable that controls the case statement is action. In this case, action is created by peel-\\ning off the first character of the userCommand string, a string that was entered by the user.\\nCross-Reference In contrast \\nto this advice, sometimes \\nyou can improve readability \\nby assigning a complicated \\nexpression to a well-named \\nboolean variable or function. \\nFor details, see “Making \\nComplicated Expressions \\nSimple” in Section 19.1.\\nThis troublemaking code is from the wrong side of town and invites problems. In gen-\\neral, when you manufacture a variable to use in a case statement, the real data might \\nnot map onto the case statement the way you want it to. In this example, if the user \\ntypes copy, the case statement peels off the first “c” and correctly calls the Copy() rou-\\ntine. On the other hand, if the user types cement overshoes, clambake, or cellulite, \\nthe case statement also peels off the “c” and calls Copy(). The test for an erroneous \\ncommand in the case statement’s else clause won’t work very well because it will miss \\nonly erroneous first letters rather than erroneous commands.\\nRather than making up a phony variable, this code should use a chain of if-then-else-if \\ntests to check the whole string. A virtuous rewrite of the code looks like this:\\nJava Example of Using if-then-elses Instead of a Phony case Variable—Good Practice\\nif ( UserCommand.equals( COMMAND_STRING_COPY ) ) {\\n   Copy();\\n}\\nelse if ( UserCommand.equals( COMMAND_STRING_DELETE ) ) {\\n   DeleteCharacter();\\n}\\nelse if ( UserCommand.equals( COMMAND_STRING_FORMAT ) ) {\\n   Format();\\n}\\nelse if ( UserCommand.equals( COMMAND_STRING_HELP ) ) {\\n   Help();\\n}\\n...\\nelse {\\n   HandleUserInputError( ErrorType_InvalidCommandInput );\\n}\\nCODING \\nHORROR\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 399}, page_content='15.2 case Statements 36315.1 case Statements\\nUse the default clause only to detect legitimate defaults You might sometimes have \\nonly one case remaining and decide to code that case as the default clause. Though \\nsometimes tempting, that’s dumb. You lose the automatic documentation provided by \\ncase-statement labels, and you lose the ability to detect errors with the default clause.\\nSuch case statements break down under modification. If you use a legitimate default, \\nadding a new case is trivial—you just add the case and the corresponding code. If you \\nuse a phony default, the modification is more difficult. You have to add the new case, \\npossibly making it the new default, and then change the case previously used as the \\ndefault so that it’s a legitimate case. Use a legitimate default in the first place.\\nUse the default clause to detect errors If the default clause in a case  statement isn’t \\nbeing used for other processing and isn’t supposed to occur, put a diagnostic mes-\\nsage in it:\\nJava Example of Using the Default Case to Detect Errors—Good Practice\\nswitch ( commandShortcutLetter ) {\\n   case \\'a\\': \\n      PrintAnnualReport();\\n      break;\\n   case \\'p\\': \\n      // no action required, but case was considered\\n      break;\\n   case \\'q\\': \\n      PrintQuarterlyReport();\\n      break;\\n   case \\'s\\': \\n      PrintSummaryReport();\\n      break;\\n   default: \\n      DisplayInternalError( \"Internal Error 905: Call customer support.\" );\\n} \\nMessages like this are useful in both debugging and production code. Most users pre-\\nfer a message like “Internal Error: Please call customer support” to a system crash or, \\nworse, subtly incorrect results that look right until the user’s boss checks them.\\nIf the default clause is used for some purpose other than error detection, the implica-\\ntion is that every case selector is correct. Double-check to be sure that every value that \\ncould possibly enter the case statement would be legitimate. If you come up with some \\nthat wouldn’t be legitimate, rewrite the statements so that the default clause will \\ncheck for errors.\\nIn C++ and Java, avoid dropping through the end of a case statement C-like lan-\\nguages (C, C++, and Java) don’t automatically break out of each case. Instead, you \\nhave to code the end of each case explicitly. If you don’t code the end of a case, the'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 400}, page_content='364 Chapter 15: Using Conditionals\\nprogram drops through the end and executes the code for the next case. This can lead \\nto some particularly egregious coding practices, including the following horrible \\nexample:\\n                 \\nCross-Reference This code’s \\nformatting makes it look bet-\\nter than it is. For details on \\nhow to use formatting to \\nmake good code look good \\nand bad code look bad, see \\n“Endline Layout” in Section \\n31.3  and the rest of Chapter \\n31, “Layout and Style.”\\nC+ + Example of Abusing the case Statement\\nswitch ( InputVar ) {\\n   case \\'A\\': if ( test ) {\\n                   // statement 1\\n                   // statement 2\\n   case \\'B\\':       // statement 3\\n                   // statement 4\\n                   ...\\n                   } \\n                ...\\n             break;\\n   ...\\n}\\nThis practice is bad because it intermingles control constructs. Nested control con-\\nstructs are hard enough to understand; overlapping constructs are all but impossible. \\nModifications of case \\'A\\' or case \\'B\\' will be harder than brain surgery, and it’s likely that \\nthe cases will need to be cleaned up before any modifications will work. You might as \\nwell do it right the first time. In general, it’s a good idea to avoid dropping through the \\nend of a case statement.\\nIn C++, clearly and unmistakably identify flow-throughs at the end of a case \\nstatement If you intentionally write code to drop through the end of a case, clearly \\ncomment the place at which it happens and explain why it needs to be coded that way. \\nC+ + Example of Documenting Falling Through the End of a case Statement\\nswitch ( errorDocumentationLevel ) {\\n   case DocumentationLevel_Full:\\n      DisplayErrorDetails( errorNumber );\\n      // FALLTHROUGH -- Full documentation also prints summary comments\\n   case DocumentationLevel_Summary:\\n      DisplayErrorSummary( errorNumber );\\n      // FALLTHROUGH -- Summary documentation also prints error number\\n   case DocumentationLevel_NumberOnly:\\n      DisplayErrorNumber( errorNumber );\\n      break;\\n   default: \\n      DisplayInternalError( \"Internal Error 905: Call customer support.\" );\\n} \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 401}, page_content='15.2 case Statements 365\\nThis technique is useful about as often as you find someone who would rather have a \\nused Pontiac Aztek than a new Corvette. Generally, code that falls through from one \\ncase to another is an invitation to make mistakes as the code is modified, and it \\nshould be avoided. \\ncc2e.com/1545 CHECKLIST: Using Conditionals\\nif-then Statements\\n❑ Is the nominal path through the code clear?\\n❑ Do if-then tests branch correctly on equality?\\n❑ Is the else clause present and documented?\\n❑ Is the else clause correct?\\n❑ Are the if and else clauses used correctly—not reversed?\\n❑ Does the normal case follow the if rather than the else? \\nif-then-else-if Chains\\n❑ Are complicated tests encapsulated in boolean function calls?\\n❑ Are the most common cases tested first?\\n❑ Are all cases covered?\\n❑ Is the if-then-else-if  chain the best implementation—better than a case  \\nstatement?\\ncase Statements\\n❑ Are cases ordered meaningfully?\\n❑ Are the actions for each case simple—calling other routines if necessary?\\n❑ Does the case statement test a real variable, not a phony one that’s made \\nup solely to use and abuse the case statement?\\n❑ Is the use of the default clause legitimate?\\n❑ Is the default clause used to detect and report unexpected cases?\\n❑ In C, C++, or Java, does the end of each case have a break?\\n15.1 case Statements'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 402}, page_content='366 Chapter 15: Using Conditionals\\nKey Points\\n■ For simple if-else statements, pay attention to the order of the if and else clauses, \\nespecially if they process a lot of errors. Make sure the nominal case is clear.\\n■ For if-then-else chains and case statements, choose an order that maximizes read-\\nability.\\n■ To trap errors, use the default clause in a case statement or the last else in a chain \\nof if-then-else statements.\\n■ All control constructs are not created equal. Choose the control construct that’s \\nmost appropriate for each section of code.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 403}, page_content='367\\nChapter 16\\nControlling Loops\\ncc2e.com/1609 Contents\\n■ 16.1 Selecting the Kind of Loop: page 367\\n■ 16.2 Controlling the Loop: page 373\\n■ 16.3 Creating Loops Easily—From the Inside Out: page 385\\n■ 16.4 Correspondence Between Loops and Arrays: page 387\\nRelated Topics\\n■ Taming deep nesting: Section 19.4\\n■ General control issues: Chapter 19\\n■ Code with conditionals: Chapter 15\\n■ Straight-line code: Chapter 14\\n■ Relationship between control structures and data types: Section 10.7\\n“Loop” is an informal term that refers to any kind of iterative control structure—any \\nstructure that causes a program to repe atedly execute a block of code. Common \\nloop types are for, while, and do-while in C++ and Java, and For-Next, While-Wend, and \\nDo-Loop-While  in Microsoft Visual Basic. Usin g loops is one of the most complex \\naspects of programming; knowing how and when to use each kind of loop is a deci-\\nsive factor in constructing high-quality software.\\n16.1 Selecting the Kind of Loop\\nIn most languages, you’ll use a few kinds of loops:\\n■ The counted loop is performed a specific number of times, perhaps one time for \\neach employee.\\n■ The continuously evaluated loop doesn’t know ahead of time how many times it \\nwill be executed and tests whether it has finished on each iteration. For example, it \\nruns while money remains, until the user selects quit, or until it encounters an error.\\n■ The endless loop executes forever once it has started. It’s the kind you find in \\nembedded systems such as pacemakers, microwave ovens, and cruise controls.\\n■ The iterator loop performs its action once for each element in a container class.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 404}, page_content='368 Chapter 16: Controlling Loops\\nThe kinds of loops are differentiated first by flexibility—whether the loop executes a \\nspecified number of times or whether it tests for completion on each iteration.\\nThe kinds of loops are also differentiated by the location of the test for completion. \\nYou can put the test at the beginning, the middle, or the end of the loop. This charac-\\nteristic tells you whether the loop executes at least once. If the loop is tested at the \\nbeginning, its body isn’t necessarily executed. If the loop is tested at the end, its body \\nis executed at least once. If the loop is tested in the middle, the part of the loop that \\nprecedes the test is executed at least once, but the part of the loop that follows the test \\nisn’t necessarily executed at all.\\nFlexibility and the location of the test determine the kind of loop to choose as a con-\\ntrol structure. Table 16-1 shows the kinds of loops in several languages and describes \\neach loop’s flexibility and test location.\\nWhen to Use a while Loop\\nNovice programmers sometimes think that a while loop is continuously evaluated and \\nthat it terminates the instant the while condition becomes false, regardless of which \\nstatement in the loop is being executed (Curtis et al. 1986). Although it’s not quite \\nthat flexible, a while loop is a flexible loop choice. If you don’t know ahead of time \\nexactly how many times you’ll want the loop to iterate, use a while loop. Contrary to \\nwhat some novices think, the test for the loop exit is performed only once each time \\nthrough the loop, and the main issue with respect to while loops is deciding whether \\nto test at the beginning or the end of the loop.\\nTable 16-1 The Kinds of Loops\\nLanguage Kind of Loop Flexibility Test Location\\nVisual Basic For-Next rigid beginning\\nWhile-Wend flexible beginning\\nDo-Loop-While flexible beginning or end\\nFor-Each rigid beginning\\nC, C++, C#, Java for flexible beginning\\nwhile flexible beginning\\ndo-while flexible end\\nforeach*\\n* Available only in C#. Planned for other languages, including Java, at the time of this writing.\\nrigid beginning'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 405}, page_content='16.1 Selecting the Kind of Loop 369\\nLoop with Test at the Beginning\\nFor a loop that tests at the beginning, you can use a while loop in C++, C#, Java, Visual \\nBasic, and most other languages. You can emulate a while loop in other languages.\\nLoop with Test at the End\\nYou might occasionally have a situation in which you want a flexible loop, but the \\nloop needs to execute at least one time. In such a case, you can use a while loop that is \\ntested at its end. You can use do-while in C++, C#, and Java, Do-Loop-While in Visual \\nBasic, or you can emulate end-tested loops in other languages.\\nWhen to Use a Loop-With-Exit Loop\\nA loop-with-exit loop is a loop in which the exit condition appears in the middle of the \\nloop rather than at the beginning or at th e end. The loop-with-exit loop is available \\nexplicitly in Visual Basic, and you can emulate it with the structured constructs while \\nand break in C++, C, and Java or with gotos in other languages.\\nNormal Loop-With-Exit Loops\\nA loop-with-exit loop usually consists of the loop beginning, the loop body (including \\nan exit condition), and the loop end, as in this Visual Basic example:\\nVisual Basic Example of a Generic Loop-With-Exit Loop\\nDo\\nStatements.    ...\\n   If ( some exit condition ) Then Exit Do\\nMore statements.    ...\\nLoop\\nThe typical use of a loop-with-exit loop is for the case in which testing at the beginning \\nor at the end of the loop requires coding a loop-and-a-half. Here’s a C++ example of a \\ncase that warrants a loop-with-exit loop but doesn’t use one:\\nC+ + Example of Duplicated Code That Will Break Down Under Maintenance\\n// Compute scores and ratings.\\nscore  = 0;\\nThese lines appear here... GetNextRating( &ratingIncrement );\\nrating = rating + ratingIncrement;\\nwhile ( ( score < targetScore ) && ( ratingIncrement != 0 ) ) {\\n   GetNextScore( &scoreIncrement );\\n   score = score + scoreIncrement;\\n…and are repeated here.    GetNextRating( &ratingIncrement );\\n   rating = rating + ratingIncrement;\\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 406}, page_content=\"370 Chapter 16: Controlling Loops\\nThe two lines of code at the top of the example are repeated in the last two lines of \\ncode of the while loop. During modification, you can easily forget to keep the two sets \\nof lines parallel. Another programmer modifying the code probably won’t even realize \\nthat the two sets of lines are supposed to be modified in parallel. Either way, the result \\nwill be errors arising from incomplete modifications. Here’s how you can rewrite the \\ncode more clearly:\\nC+ + Example of a Loop-With-Exit Loop That’s Easier to Maintain\\n// Compute scores and ratings. The code uses an infinite loop\\n// and a break statement to emulate a loop-with-exit loop.\\nscore = 0;\\nwhile ( true ) {\\n   GetNextRating( &ratingIncrement );\\n   rating = rating + ratingIncrement;\\nThis is the loop-exit condi-\\ntion (and now it could be \\nsimplified using DeMorgan’s \\nTheorems, described in \\nSection 19.1).\\n   if ( !( ( score < targetScore ) && ( ratingIncrement != 0 ) ) ) {\\n      break;\\n   }\\n   GetNextScore( &scoreIncrement );\\n   score = score + scoreIncrement;\\n}\\nHere’s how the same code is written in Visual Basic:\\nVisual Basic Example of a Loop-With-Exit Loop\\n' Compute scores and ratings\\nscore = 0\\nDo\\n   GetNextRating( ratingIncrement )\\n   rating = rating + ratingIncrement\\n   If ( not ( score < targetScore and ratingIncrement <> 0 ) ) Then Exit Do\\n   GetNextScore( ScoreIncrement )\\n   score = score + scoreIncrement\\nLoop\\nConsider these finer points when you use this kind of loop:\\nCross-Reference Details on \\nexit conditions are presented \\nlater in this chapter. For \\ndetails on using comments \\nwith loops, see “Comment-\\ning Control Structures” in \\nSection 32.5.\\nPut all the exit conditions in one place. Spreading them around practically guarantees \\nthat one exit condition or another will be overlooked during debugging, modification, \\nor testing.\\nUse comments for clarification. If you use the loop-with-exit loop technique in a lan-\\nguage that doesn’t support it directly, use comments to make what you’re doing clear.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 407}, page_content='16.1 Selecting the Kind of Loop 371\\nThe loop-with-exit loop is a one-entry, one-exit, structured control construct, and it is \\nthe preferred kind of loop control (Software Productivity Consortium 1989). It has \\nbeen shown to be easier to understand than other kinds of loops. A study of student \\nprogrammers compared this kind of loop with those that exited at either the top or \\nthe bottom (Soloway, Bonar, and Ehrlich 1983). Students scored 25 percent higher on \\na test of comprehension when loop-with-exit loops were used, and the authors of the \\nstudy concluded that the loop-with-exit structure more closely models the way people \\nthink about iterative control than other loop structures do.\\nIn common practice, the loop-with-exit loop isn’t widely used yet. The jury is still \\nlocked in a smoky room arguing about whether it’s a good practice for production \\ncode. Until the jury is in, the loop-with-exit loop is a good technique to have in your \\nprogrammer’s toolbox—as long as you use it carefully.\\nAbnormal Loop-With-Exit Loops\\nAnother kind of loop-with-exit loop that’s used to avoid a loop-and-a-half is shown here:\\nC+ + Example of Entering the Middle of a Loop with a goto—Bad Practice\\ngoto Start;\\nwhile ( expression ) {\\n   // do something\\n   ...\\n   Start:\\n   // do something else\\n   ...\\n}\\nAt first glance, this seems to be similar to the previous loop-with-exit examples. It’s \\nused in simulations in which // do something doesn’t need to be executed at the first \\npass through the loop but  // do something else does. It’s a one-in, one-out control con-\\nstruct: the only way into the loop is through the goto at the top, and the only way out \\nof the loop is through the while test. This  approach has two problems: it uses a goto, \\nand it’s unusual enough to be confusing.\\nIn C++, you can accomplish the same effect without using a goto, as demonstrated in \\nthe following example. If the language you’re using doesn’t support a break command, \\nyou can emulate one with a goto.\\nC+ + Example of Code Rewritten Without a goto—Better Practice\\nwhile ( true ) {\\nThe blocks before and after \\nthe break have been \\nswitched.\\n   // do something else\\n   ...\\n1\\n2\\n3\\nHARD DATA\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 408}, page_content='372 Chapter 16: Controlling Loops\\n   if ( !( expression ) ) {\\n      break;\\n   }\\n   // do something\\n   ...\\n}\\nWhen to Use a for Loop\\nFurther Reading For more \\ngood guidelines on using for \\nloops, see Writing Solid \\nCode (Maguire 1993).\\nA for loop is a good choice when you need a loop that executes a specified number of \\ntimes. You can use for in C++, C, Java, Visual Basic, and most other languages.\\nUse for loops for simple activities that don’t require internal loop controls. Use them \\nwhen the loop control involves simple increments or simple decrements, such as iter-\\nating through the elements in a container. The point of a for loop is that you set it up \\nat the top of the loop and then forget about it. You don’t have to do anything inside the \\nloop to control it. If you have a condition under which execution has to jump out of a \\nloop, use a while loop instead.\\nLikewise, don’t explicitly change the index value of a for loop to force it to terminate. \\nUse a while loop instead. The for loop is for simple uses. Most complicated looping \\ntasks are better handled by a while loop.\\nWhen to Use a foreach Loop\\nThe foreach loop or its equivalent (foreach in C#, For-Each in Visual Basic, for-in in \\nPython) is useful for performing an operation on each member of an array or other \\ncontainer. It has the advantage of eliminating loop-housekeeping arithmetic and \\ntherefore eliminating any chance of errors in the loop-housekeeping arithmetic. \\nHere’s an example of this kind of loop:\\nC# Example of a foreach Loop\\nint [] fibonacciSequence = new int [] { 0, 1, 1, 2, 3, 5, 8, 13, 21, 34 };\\nint oddFibonacciNumbers = 0;\\nint evenFibonacciNumbers = 0;\\n// count the number of odd and even numbers in a Fibonacci sequence\\nforeach ( int fibonacciNumber in fibonacciSequence ) {\\n   if ( fibonacciNumber % 2 ) == 0 ) {\\n      evenFibonacciNumbers++;\\n   }\\n   else {\\n      oddFibonacciNumbers++;\\n   }\\n}\\nConsole.WriteLine( \"Found {0} odd numbers and {1} even numbers.\", \\n   oddFibonacciNumbers, evenFibonacciNumbers );'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 409}, page_content='16.2 Controlling the Loop 373\\n16.2 Controlling the Loop\\nWhat can go wrong with a loop? Any answer would have to include incorrect or omit-\\nted loop initialization, omitted initialization of accumulators or other variables related \\nto the loop, improper nesting, incorrect termination of the loop, forgetting to incre-\\nment a loop variable or incrementing the variable incorrectly, and indexing an array \\nelement from a loop index incorrectly.\\nYou can forestall these problems by observing two practices. First, minimize the num-\\nber of factors that affect the loop. Simplify! Simplify! Simplify! Second, treat the inside \\nof the loop as if it were a routine—keep as much of the control as possible outside the \\nloop. Explicitly state the conditions under which the body of the loop is to be exe-\\ncuted. Don’t make the reader look inside the loop to understand the loop control. \\nThink of a loop as a black box: the surrounding program knows the control condi-\\ntions but not the contents.\\nCross-Reference If you use \\nthe while ( true )-break tech-\\nnique described earlier, the \\nexit condition is inside the \\nblack box. Even if you use \\nonly one exit condition, you \\nlose the benefit of treating \\nthe loop as a black box.\\nC+ + Example of Treating a Loop as a Black Box\\nwhile ( !inputFile.EndOfFile() && moreDataAvailable ) {\\n}\\nWhat are the conditions under which this loop terminates? Clearly, all you know is \\nthat either inputFile.EndOfFile() becomes true or MoreDataAvailable becomes false.\\nEntering the Loop\\nUse these guidelines when entering a loop:\\nEnter the loop from one location only A variety of loop-control structures allows you to \\ntest at the beginning, middle, or end of a loop. These structures are rich enough to allow \\nyou to enter the loop from the top every time. You don’t need to enter at multiple locations.\\nPut initialization code directly before the loopThe Principle of Proximity advocates \\nputting related statements together. If related statements are strewn across a routine, it’s \\neasy to overlook them during modification and to make the modifications incorrectly. If \\nrelated statements are kept together, it’s easier to avoid errors during modification.\\nCross-Reference For more \\non limiting the scope of loop \\nvariables, see “Limit the \\nscope of loop-index vari-\\nables to the loop itself” later \\nin this chapter.\\nKeep loop-initialization statements with the loop they’re related to. If you don’t, you’re \\nmore likely to cause errors when you generalize the loop into a bigger loop and forget \\nto modify the initialization code. The same kind of error can occur when you move or \\ncopy the loop code into a different routine without moving or copying its initialization \\ncode. Putting initializations away from the loop—in the data-declaration section or in \\na housekeeping section at the top of the routine that contains the loop—invites initial-\\nization troubles.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 410}, page_content='374 Chapter 16: Controlling Loops\\nUse while( true ) for infinite loops You might have a loop that runs without termi-\\nnating—for example, a loop in firmware such as a pacemaker or a microwave oven. Or \\nyou might have a loop that terminates only in response to an event—an “event loop.” \\nYou could code such an infinite loop in several ways. Faking an infinite loop with a \\nstatement like for i = 1 to 99999 is a poor choice because the specific loop limits muddy \\nthe intent of the loop—99999 could be a legitimate value. Such a fake infinite loop can \\nalso break down under maintenance.\\nThe while( true ) idiom is considered a standard way of writing an infinite loop in C++, \\nJava, Visual Basic, and other languages that support comparable structures. Some pro-\\ngrammers prefer to use for( ;; ), which is an accepted alternative.\\nPrefer for loops when they’re appropriate The for loop packages loop-control code \\nin one place, which makes for easily readable loops. One mistake programmers com-\\nmonly make when modifying software is changing the loop-initialization code at the \\ntop of a while loop but forgetting to change related code at the bottom. In a for loop, all \\nthe relevant code is together at the top of the loop, which makes correct modifications \\neasier. If you can use the for loop appropriately instead of another kind of loop, do it.\\nDon’t use a for loop when a while loop is more appropriate A common abuse of the \\nflexible for loop structure in C++, C#, and Java is haphazardly cramming the contents \\nof a while loop into a for loop header. The following example shows a while loop \\ncrammed into a for loop header:\\nC+ + Example of a while Loop Abusively Crammed into a for Loop Header\\n// read all the records from a file \\nfor ( inputFile.MoveToStart(), recordCount = 0; !inputFile.EndOfFile(); \\n   recordCount++ ) {\\n   inputFile.GetRecord();\\n}\\nThe advantage of C++’s for loop over for loops in other languages is that it’s more flex-\\nible about the kinds of initialization and termination information it can use. The weak-\\nness inherent in such flexibility is that you can put statements into the loop header \\nthat have nothing to do with controlling the loop.\\nReserve the for loop header for loop-control statements—statements that initialize the \\nloop, terminate it, or move it toward termination. In the example just shown, the \\ninputFile.GetRecord() statement in the body of the loop moves the loop toward termi-\\nnation, but the recordCount statements don’t; they’re housekeeping statements that \\ndon’t control the loop’s progress. Putting the recordCount statements in the loop \\nheader and leaving the inputFile.GetRecord() statement out is misleading; it creates the \\nfalse impression that recordCount controls the loop.\\nIf you want to use the for loop rather than the while loop in this case, put the loop-con-\\ntrol statements in the loop header and leave everything else out. Here’s the right way \\nto use the loop header:\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 411}, page_content='16.2 Controlling the Loop 375\\nC+ + Example of Logical if Unconventional Use of a for Loop Header\\nrecordCount = 0;\\nfor ( inputFile.MoveToStart(); !inputFile.EndOfFile(); inputFile.GetRecord() ) {\\n   recordCount++;\\n}\\nThe contents of the loop header in this example are all related to control of the loop. \\nThe inputFile.MoveToStart() statement initializes the loop, the !inputFile.EndOfFile() \\nstatement tests whether the loop has finished, and the inputFile.GetRecord() statement \\nmoves the loop toward termination. The statements that affect recordCount don’t \\ndirectly move the loop toward termination and are appropriately not included in the \\nloop header. The while loop is probably still more appropriate for this job, but at least \\nthis code uses the loop header logically. For the record, here’s how the code looks \\nwhen it uses a while loop:\\nC+ + Example of Appropriate Use of a while Loop\\n// read all the records from a file \\ninputFile.MoveToStart();\\nrecordCount = 0;\\nwhile ( !inputFile.EndOfFile() ) {\\n   inputFile.GetRecord();\\n   recordCount++;\\n}\\nProcessing the Middle of the Loop\\nThe following subsections describe handling the middle of a loop:\\nUse { and } to enclose the statements in a loop Use code brackets every time. They \\ndon’t cost anything in speed or space at run time, they help readability, and they help \\nprevent errors as the code is modified. They’re a good defensive-programming practice.\\nAvoid empty loops In C++ and Java, it’s possible to create an empty loop, one in \\nwhich the work the loop is doing is coded on the same line as the test that checks \\nwhether the work is finished. Here’s an example:\\nC+ + Example of an Empty Loop\\nwhile ( ( inputChar = dataFile.GetChar() ) != CharType_Eof ) {\\n   ;\\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 412}, page_content='376 Chapter 16: Controlling Loops\\nIn this example, the loop is empty because the while expression includes two things: \\nthe work of the loop—inputChar = dataFile.GetChar()—and a test for whether the loop \\nshould terminate—inputChar !=  CharType_Eof. The loop would be clearer if it were \\nrecoded so that the work it does is evident to the reader:\\nC+ + Example of an Empty Loop Converted to an Occupied Loop\\ndo {\\n   inputChar = dataFile.GetChar();\\n} while ( inputChar != CharType_Eof  );\\nThe new code takes up three full lines rather than one line and a semicolon, which is \\nappropriate since it does the work of three lines rather than that of one line and a \\nsemicolon.\\nKeep loop-housekeeping chores at either the beginning or the end of the loop Loop-\\nhousekeeping chores are expressions like i = i + 1 or j++, expressions whose main pur-\\npose isn’t to do the work of the loop but to control the loop. The housekeeping is \\ndone at the end of the loop in this example:\\nC+ + Example of Housekeeping Statements at the End of a Loop\\nnameCount = 0;\\ntotalLength = 0;\\nwhile ( !inputFile.EndOfFile() ) {\\n   // do the work of the loop\\n   inputFile >> inputString;\\n   names[ nameCount ] = inputString;\\n   ...\\n   // prepare for next pass through the loop--housekeeping\\nHere are the housekeeping \\nstatements.\\n   nameCount++;\\n   totalLength = totalLength + inputString.length();\\n}\\nAs a general rule, the variables you initialize before the loop are the variables you’ll \\nmanipulate in the housekeeping part of the loop.\\nCross-Reference For more \\non optimization, see Chapter \\n25, “Code-Tuning Strate-\\ngies,” and Chapter 26, \\n“Code-Tuning Techniques.”\\nMake each loop perform only one function The mere fact that a loop can be used to \\ndo two things at once isn’t sufficient justification for doing them together. Loops \\nshould be like routines in that each one should do only one thing and do it well. If it \\nseems inefficient to use two loops where one would suffice, write the code as two \\nloops, comment that they could be combined for efficiency, and then wait until bench-\\nmarks show that the section of the prog ram poses a performance problem before \\nchanging the two loops into one.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 413}, page_content='16.2 Controlling the Loop 377\\nExiting the Loop\\nThese subsections describe handling the end of a loop:\\nAssure yourself that the loop ends This is fundamental. Mentally simulate the execu-\\ntion of the loop until you are confident that, in all circumstances, it ends. Think \\nthrough the nominal cases, the endpoints, and each of the exceptional cases.\\nMake loop-termination conditions obviousIf you use a for loop and don’t fool \\naround with the loop index and don’t use a goto or break to get out of the loop, the ter-\\nmination condition will be obvious. Likewise, if you use a while or repeat-until loop \\nand put all the control in the while or repeat-until clause, the termination condition \\nwill be obvious. The key is putting the control in one place.\\nDon’t monkey with the loop index of a for loop to make the loop terminate Some \\nprogrammers jimmy the value of a for loop index to make the loop terminate early. \\nHere’s an example:\\nJava Example of Monkeying with a Loop Index\\nfor ( int i = 0; i < 100; i++ ) {\\n   // some code\\n   ...\\n   if ( ... ) {\\nHere’s the monkeying.       i = 100;\\n   }\\n   // more code\\n   ...\\n}\\nThe intent in this example is to terminate the loop under some condition by setting i \\nto 100, a value that’s larger than the end of the for loop’s range of 0 through 99. Virtu-\\nally all good programmers avoid this practice; it’s the sign of an amateur. When you \\nset up a for loop, the loop counter is off limits. Use a while loop to provide more con-\\ntrol over the loop’s exit conditions.\\nAvoid code that depends on the loop index’s final value It’s bad form to use the value \\nof the loop index after the loop. The terminal value of the loop index varies from lan-\\nguage to language and implementation to implementation. The value is different \\nwhen the loop terminates normally and when it terminates abnormally. Even if you \\nhappen to know what the final value is without stopping to think about it, the next \\nperson to read the code will probably have to think about it. It’s better form and more \\nself-documenting if you assign the final value to a variable at the appropriate point \\ninside the loop.\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 414}, page_content='378 Chapter 16: Controlling Loops\\nThis code misuses the index’s final value:\\nC+ + Example of Code That Misuses a Loop Index’s Terminal Value\\nfor ( recordCount = 0; recordCount < MAX_RECORDS; recordCount++ ) {\\n   if ( entry[ recordCount ] == testValue ) {\\n      break;\\n   }\\n}\\n// lots of code \\n...\\nHere’s the misuse of the loop \\nindex’s terminal value.\\nif ( recordCount < MAX_RECORDS ) {\\n   return( true );\\n}\\nelse {\\n   return( false );\\n}\\nIn this fragment, the second test for recordCount < MaxRecords makes it appear that the \\nloop is supposed to loop though all the values in entry[] and return true if it finds the \\none equal to testValue and false otherwise. It’s hard to remember whether the index \\ngets incremented past the end of the loop, so it’s easy to make an off-by-one error. \\nYou’re better off writing code that doesn’t depend on the index’s final value. Here’s \\nhow to rewrite the code:\\nC+ + Example of Code That Doesn’t Misuse a Loop Index’s Terminal Value\\nfound = false;\\nfor ( recordCount = 0; recordCount < MAX_RECORDS; recordCount++ ) {\\n   if ( entry[ recordCount ] == testValue ) {\\n      found = true;\\n      break;\\n   }\\n}\\n// lots of code \\n...\\nreturn( found );\\nThis second code fragment uses an extra variable and keeps references to recordCount \\nmore localized. As is often the case when an extra boolean variable is used, the result-\\ning code is clearer.\\nConsider using safety counters A safety counter is a variable you increment each \\npass through a loop to determine whether a loop has been executed too many times. \\nIf you have a program in which an error would be catastrophic, you can use safety \\ncounters to ensure that all loops end. This C++ loop could profitably use a safety \\ncounter:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 415}, page_content='16.2 Controlling the Loop 379\\nC+ + Example of a Loop That Could Use a Safety Counter\\ndo {\\n   node = node->Next;\\n   ...\\n} while ( node->Next != NULL );\\nHere’s the same code with the safety counters added:\\nC+ + Example of Using a Safety Counter\\nsafetyCounter = 0;\\ndo {\\n   node = node->Next;\\n   ...\\nHere’s the safety-counter \\ncode.\\n   safetyCounter++;\\n   if ( safetyCounter >= SAFETY_LIMIT ) {\\n      Assert( false, \"Internal Error: Safety-Counter Violation.\" );\\n   }\\n   ...\\n} while ( node->Next != NULL );\\nSafety counters are not a cure-all. Introduced into the code one at a time, safety \\ncounters increase complexity and can lead to additional errors. Because they aren’t \\nused in every loop, you might forget to maintain safety-counter code when you modify \\nloops in parts of the program that do use th em. If safety counters are instituted as a \\nprojectwide standard for critical loops, however, you learn to expect them and the \\nsafety-counter code is no more prone to produce errors later than any other code is.\\nExiting Loops Early\\nMany languages provide a means of causing a loop to terminate in some way other than \\ncompleting the for or while condition. In this discussion, break is a generic term for break \\nin C++, C, and Java; for Exit-Do and Exit-For in Visual Basic; and for similar constructs, \\nincluding those simulated with gotos in languages that don’t support break directly. The \\nbreak statement (or equivalent) causes a loop to terminate through the normal exit \\nchannel; the program resumes execution at the first statement following the loop.\\nThe continue statement is similar to break in that it’s an auxiliary loop-control state-\\nment. Rather than causing a loop exit, however, continue causes the program to skip \\nthe loop body and continue executing at the beginning of the next iteration of the \\nloop. A continue statement is shorthand for an if-then clause that would prevent the \\nrest of the loop from being executed.\\nConsider using break statements rather than boolean flags in a while loop In some \\ncases, adding boolean flags to a while loop to emulate exits from the body of the loop \\nmakes the loop hard to read. Sometimes you can remove several levels of indentation \\ninside a loop and simplify loop control just by using a break instead of a series of if tests.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 416}, page_content='380 Chapter 16: Controlling Loops\\nPutting multiple break conditions into separate statements and placing them near the \\ncode that produces the break can reduce nesting and make the loop more readable.\\nBe wary of a loop with a lot of breaks scattered through it A loop’s containing a lot \\nof breaks can indicate unclear thinking about the structure of the loop or its role in the \\nsurrounding code. A proliferation of breaks raises the possibility that the loop could \\nbe more clearly expressed as a series of loops rather than as one loop with many exits.\\nAccording to an article in Software Engineering Notes, the software error that brought \\ndown the New York City phone systems for 9 hours on January 15, 1990, was due to \\nan extra break statement (SEN 1990):\\nC+ + Example of Erroneous Use of a break Statement Within a do-switch-if Block\\ndo {\\n   ...\\n   switch\\n      ...\\n      if () {\\n         ...\\nThis break was intended for \\nthe if but broke out of the \\nswitch instead.\\n          break; \\n         ...\\n      }\\n      ...\\n} while ( ... );\\nMultiple breaks don’t necessarily indicate an error, but their existence in a loop is a \\nwarning sign, a canary in a coal mine that’s  gasping for air instead of singing as loud \\nas it should be.\\nUse continue for tests at the top of a loop A good use of continue is for moving exe-\\ncution past the body of the loop after testing a condition at the top. For example, if the \\nloop reads records, discards records of one kind, and processes records of another \\nkind, you could put a test like this one at the top of the loop:\\nPseudocode Example of a Relatively Safe Use of continue\\nwhile ( not eof( file ) ) do\\n   read( record, file )\\n   if ( record.Type <> targetType ) then\\n      continue\\n   -- process record of targetType\\n   ...\\nend while\\nUsing continue in this way lets you avoid an if test that would effectively indent the \\nentire body of the loop. If, on the other hand, the continue occurs toward the middle \\nor end of the loop, use an if instead.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 417}, page_content='16.2 Controlling the Loop 381\\nUse the labeled break structure if your language supports it Java supports use of \\nlabeled breaks to prevent the kind of problem experienced with the New York City \\ntelephone outage. A labeled break can be used to exit a for loop, an if statement, or any \\nblock of code enclosed in braces (Arnold, Gosling, and Holmes 2000).\\nHere’s a possible solution to the New York City telephone code problem, with the pro-\\ngramming language changed from C++ to Java to show the labeled break:\\nJava Example of a Better Use of a Labeled break Statement Within a \\ndo-switch-if Block\\ndo {\\n   ...\\n   switch\\n      ...\\n      CALL_CENTER_DOWN:\\n      if () {\\n         ...\\nThe target of the labeled \\nbreak is unambiguous.\\n          break CALL_CENTER_DOWN; \\n         ...\\n      }\\n      ...\\n} while ( ... );\\nUse break and continue only with caution Use of break eliminates the possibility of \\ntreating a loop as a black box. Limiting yourself to only one statement to control a \\nloop’s exit condition is a powerful way to simplify your loops. Using a break forces the \\nperson reading your code to look inside the loop for an understanding of the loop \\ncontrol. That makes the loop more difficult to understand.\\nUse break only after you have considered the alternatives. You don’t know with cer-\\ntainty whether continue and break are virtuous or evil constructs. Some computer sci-\\nentists argue that they are a legitimate technique in structured programming; some \\nargue that they aren’t. Because you don’t know in general whether continue and break \\nare right or wrong, use them, but only with a fear that you might be wrong. It really is \\na simple proposition: if you can’t defend a break or a continue, don’t use it.\\nChecking Endpoints\\nA single loop usually has three cases of interest: the first case, an arbitrarily selected \\nmiddle case, and the last case. When you create a loop, mentally run through the first, \\nmiddle, and last cases to make sure that the loop doesn’t have any off-by-one errors. If \\nyou have any special cases that are different from the first or last case, check those too. \\nIf the loop contains complex computations, get out your calculator and manually \\ncheck the calculations.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 418}, page_content='382 Chapter 16: Controlling Loops\\nWillingness to perform this kind of check is a key difference between efficient and \\ninefficient programmers. Efficient programmers do the work of mental simulations \\nand hand calculations because they know that such measures help them find errors.\\nInefficient programmers tend to experiment randomly until they find a combination \\nthat seems to work. If a loop isn’t working the way it’s supposed to, the inefficient pro-\\ngrammer changes the < sign to a <= sign. If that fails, the inefficient programmer \\nchanges the loop index by adding or subtracting 1. Eventually the programmer using \\nthis approach might stumble onto the right combination or simply replace the origi-\\nnal error with a more subtle one. Even if this random process results in a correct pro-\\ngram, it doesn’t result in the programmer’s knowing why the program is correct.\\nYou can expect several benefits from mental simulations and hand calculations. The \\nmental discipline results in fewer errors during initial coding, in more rapid detection \\nof errors during debugging, and in a better overall understanding of the program. The \\nmental exercise means that you understand how your code works rather than guess-\\ning about it.\\nUsing Loop Variables\\nHere are some guidelines for using loop variables:\\nCross-Reference For details \\non naming loop variables, \\nsee “Naming Loop Indexes” \\nin Section 11.2.\\nUse ordinal or enumerated types for limits on both arrays and loops Generally, loop \\ncounters should be integer values. Floating-point values don’t increment well. For exam-\\nple, you could add 1.0 to 26,742,897.0 and get 26,742,897.0 instead of 26,742,898.0. If \\nthis incremented value were a loop counter, you’d have an infinite loop.\\nUse meaningful variable names to make nested loops readable Arrays are often \\nindexed with the same variables that are used for loop indexes. If you have a one-\\ndimensional array, you might be able to get away with using i, j, or k to index it. But if \\nyou have an array with two or more dimensions, you should use meaningful index \\nnames to clarify what you’re doing. Meaningful array-index names clarify both the \\npurpose of the loop and the part of the array you intend to access.\\nHere’s code that doesn’t put this principle to work; it uses the meaningless names i, j, \\nand k instead:\\nJava Example of Bad Loop Variable Names\\nfor ( int i = 0; i < numPayCodes; i++ ) {\\n   for ( int j = 0; j < 12; j++ ) {\\n      for ( int k = 0; k < numDivisions; k++ ) {\\n         sum = sum + transaction[ j ][ i ][ k ];\\n      }\\n   }\\n}\\nKEY POINT\\nKEY POINT\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 419}, page_content='16.2 Controlling the Loop 383\\nWhat do you think the array indexes in transaction mean? Do i, j, and k tell you any-\\nthing about the contents of transaction? If you had the declaration of transaction, could \\nyou easily determine whether the indexes were in the right order? Here’s the same \\nloop with more readable loop variable names:\\nJava Example of Good Loop Variable Names\\nfor ( int payCodeIdx = 0; payCodeIdx < numPayCodes; payCodeIdx++ ) {\\n   for (int month = 0; month < 12; month++ ) {\\n      for ( int divisionIdx = 0; divisionIdx < numDivisions; divisionIdx++ ) {\\n         sum = sum + transaction[ month ][ payCodeIdx ][ divisionIdx ];\\n      }\\n   }\\n}\\nWhat do you think the array indexes in transaction mean this time? In this case, the \\nanswer is easier to come by because the variable names payCodeIdx, month, and divi-\\nsionIdx tell you a lot more than i, j, and k did. The computer can read the two versions \\nof the loop equally easily. People can read the second version more easily than the \\nfirst, however, and the second version is better since your primary audience is made \\nup of humans, not computers.\\nUse meaningful names to avoid loop-index cross-talk Habitual use of i, j, and k can \\ngive rise to index cross-talk—using the same index name for two different purposes. \\nTake a look at this example:\\nC+ + Example of Index Cross-Talk\\ni is used first here... for ( i = 0;  i < numPayCodes; i++ ) {\\n   // lots of code\\n   ...\\n   for ( j = 0; j < 12; j++ ) {\\n      // lots of code \\n      ...\\n...and again here.       for ( i = 0; i < numDivisions; i++ ) {\\n         sum = sum + transaction[ j ][ i ][ k ];\\n      }\\n   }\\n}\\nThe use of i is so habitual that it’s used twice in the same nesting structure. The sec-\\nond for loop controlled by i conflicts with the first, and that’s index cross-talk. Using \\nmore meaningful names than i, j, and k would have prevented the problem. In general, \\nif the body of a loop has more than a couple of lines, if it might grow, or if it’s in a \\ngroup of nested loops, avoid i, j, and k.\\nLimit the scope of loop-index variables to the loop itself Loop-index cross-talk and \\nother uses of loop indexes outside their loops is such a significant problem that the'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 420}, page_content='384 Chapter 16: Controlling Loops\\ndesigners of Ada decided to make for loop indexes invalid outside their loops; trying \\nto use one outside its for loop generates an error at compile time.\\nC++ and Java implement the same idea to some extent—they allow loop indexes to be \\ndeclared within a loop, but they don’t require it. In the example on page 378, the \\nrecordCount variable could be declared inside the for statement, which would limit its \\nscope to the for loop, like this:\\nC+ + Example of Declaring a Loop-Index Variable Within a for loop\\nfor ( int recordCount = 0; recordCount < MAX_RECORDS; recordCount++ ) {\\n   // looping code that uses recordCount\\n}\\nIn principle, this technique should allow creation of code that redeclares recordCount \\nin multiple loops without any risk of misusing the two different recordCounts. That \\nusage would give rise to code that looks like this:\\nC+ + Example of Declaring Loop-Indexes Within for loops and Reusing Them Safely—\\nMaybe!\\nfor ( int recordCount = 0; recordCount < MAX_RECORDS; recordCount++ ) {\\n   // looping code that uses recordCount\\n}\\n// intervening code\\nfor ( int recordCount = 0; recordCount < MAX_RECORDS; recordCount++ ) {\\n   // additional looping code that uses a different recordCount\\n}\\nThis technique is helpful for documenting the purpose of the recordCount variable; \\nhowever, don’t rely on your compiler to enforce recordCount’s scope. Section 6.3.3.1 of \\nThe C++ Programming Language (Stroustrup 1997) says that recordCount should have a \\nscope limited to its loop. When I checked this functionality with three different C++ \\ncompilers, however, I got three different results:\\n■ The first compiler flagged recordCount in the second for loop for multiple vari-\\nable declarations and generated an error.\\n■ The second compiler accepted recordCount in the second for loop but allowed it \\nto be used outside the first for loop.\\n■ The third compiler allowed both usages of recordCount and did not allow either \\none to be used outside the for loop in which it was declared.\\nAs is often the case with more esoteric language features, compiler implementations \\ncan vary.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 421}, page_content='16.3 Creating Loops Easily—From the Inside Out 385\\nHow Long Should a Loop Be?\\nLoop length can be measured in lines of code or depth of nesting. Here are some \\nguidelines:\\nMake your loops short enough to view all at once If you usually look at loops on \\nyour monitor and your monitor displays 50 lines, that puts a 50-line restriction on \\nyou. Experts have suggested a loop-length limit of one page. When you begin to appre-\\nciate the principle of writing simple code, however, you’ll rarely write loops longer \\nthan 15 or 20 lines.\\nCross-Reference For details \\non simplifying nesting, see \\nSection 19.4, “Taming Dan-\\ngerously Deep Nesting.”\\nLimit nesting to three levels Studies have shown that the ability of programmers to \\ncomprehend a loop deteriorates significantly beyond three levels of nesting (Yourdon \\n1986a). If you’re going beyond that number of levels, make the loop shorter (concep-\\ntually) by breaking part of it into a routine or simplifying the control structure.\\nMove loop innards of long loops into routines If the loop is well designed, the code \\non the inside of a loop can often be moved into one or more routines that are called \\nfrom within the loop.\\nMake long loops especially clear Length adds complexity. If you write a short loop, \\nyou can use riskier control structures such as break and continue, multiple exits, com-\\nplicated termination conditions, and so on. If you write a longer loop and feel any con-\\ncern for your reader, you’ll give the loop a single exit and make the exit condition \\nunmistakably clear.\\n16.3 Creating Loops Easily—From the Inside Out\\nIf you sometimes have trouble coding a complex loop—which most programmers do—\\nyou can use a simple technique to get it right the first time. Here’s the general process. \\nStart with one case. Code that case with lite rals. Then indent it, put a loop around it, \\nand replace the literals with loop indexes or computed expressions. Put another loop \\naround that, if necessary, and replace more literals. Continue the process as long as \\nyou have to. When you finish, add all the necessary initializations. Since you start at \\nthe simple case and work outward to generalize it, you might think of this as coding \\nfrom the inside out.\\nCross-Reference Coding a \\nloop from the inside out is \\nsimilar to the process \\ndescribed in Chapter 9, “The \\nPseudocode Programming \\nProcess.”\\nSuppose you’re writing a program for an insurance company. It has life-insurance \\nrates that vary according to a person’s age and sex. Your job is to write a routine that \\ncomputes the total life-insurance premium for a group. You need a loop that takes the \\nrate for each person in a list and adds it to a total. Here’s how you’d do it.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 422}, page_content='386 Chapter 16: Controlling Loops\\nFirst, in comments, write the steps the body of the loop needs to perform. It’s easier to \\nwrite down what needs to be done when you’re not thinking about details of syntax, \\nloop indexes, array indexes, and so on.\\nStep 1: Creating a Loop from the Inside Out (Pseudocode Example)\\n-- get rate from table\\n-- add rate to total\\nSecond, convert the comments in the body of the loop to code, as much as you can \\nwithout actually writing the whole loop. In this case, get the rate for one person and \\nadd it to the overall total. Use concrete, specific data rather than abstractions.\\nStep 2: Creating a Loop from the Inside Out (Pseudocode Example)\\ntable doesn’t have any \\nindexes yet.\\nrate = table[ ]\\ntotalRate = totalRate + rate\\nThe example assumes that table is an array that holds the rate data. You don’t have to \\nworry about the array indexes at first. rate is the variable that holds the rate data selected \\nfrom the rate table. Likewise, totalRate is a variable that holds the total of the rates.\\nNext, put in indexes for the table array:\\nStep 3: Creating a Loop from the Inside Out (Pseudocode Example)\\nrate = table[ census.Age ][ census.Gender ]\\ntotalRate = totalRate + rate\\nThe array is accessed by age and sex, so census.Age and census.Gender are used to index \\nthe array. The example assumes that census is a structure that holds information about \\npeople in the group to be rated.\\nThe next step is to build a loop around the existing statements. Since the loop is sup-\\nposed to compute the rates for each person in a group, the loop should be indexed by \\nperson.\\nStep 4: Creating a Loop from the Inside Out (Pseudocode Example)\\nFor person = firstPerson to lastPerson\\n   rate = table[ census.Age, census.Gender ]\\n   totalRate = totalRate + rate\\nEnd For\\nAll you have to do here is put the for loop around the existing code and then indent \\nthe existing code and put it inside a begin-end pair. Finally, check to make sure that the \\nvariables that depend on the person loop index have been generalized. In this case, the \\ncensus variable varies with person, so it should be generalized appropriately.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 423}, page_content='16.4 Correspondence Between Loops and Arrays 387\\nStep 5: Creating a Loop from the Inside Out (Pseudocode Example)\\nFor person = firstPerson to lastPerson\\n   rate = table[ census[ person ].Age, census[ person ].Gender ]\\n   totalRate = totalRate + rate\\nEnd For\\nFinally, write any initializations that are needed. In this case, the totalRate variable \\nneeds to be initialized.\\nFinal Step: Creating a Loop from the Inside Out (Pseudocode Example)\\ntotalRate = 0\\nFor person = firstPerson to lastPerson\\n   rate = table[ census[ person ].Age, census[ person ].Gender ]\\n   totalRate = totalRate + rate\\nEnd For\\nIf you had to put another loop around the person loop, you would proceed in the same \\nway. You don’t need to follow the steps rigidly. The idea is to start with something con-\\ncrete, worry about only one thing at a time, and build up the loop from simple com-\\nponents. Take small, understandable steps as you make the loop more general and \\ncomplex. That way, you minimize the amount of code you have to concentrate on at \\nany one time and therefore minimize the chance of error.\\n16.4 Correspondence Between Loops and Arrays\\nCross-Reference For further \\ndiscussion of the correspon-\\ndence between loops and \\narrays, see Section 10.7, \\n“Relationship Between Data \\nTypes and Control \\nStructures.”\\nLoops and arrays are often related. In many instances, a loop is created to perform an \\narray manipulation, and loop counters correspond one-to-one with array indexes. For \\nexample, these Java for loop indexes correspond to the array indexes:\\nJava Example of an Array Multiplication\\nfor ( int row = 0; row < maxRows; row++ ) {\\n   for ( int column = 0; column < maxCols; column++ ) {\\n      product[ row ][ column ] = a[ row ][ column ] * b[ row ][ column ];\\n   }\\n}\\nIn Java, a loop is necessary for this array operation. But it’s worth noting that looping \\nstructures and arrays aren’t inherently connected. Some languages, especially APL \\nand Fortran 90 and later, provide powerful array operations that eliminate the need \\nfor loops like the one just shown. Here’s an APL code fragment that performs the \\nsame operation:\\nAPL Example of an Array Multiplication\\nproduct <- a x b'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 424}, page_content='388 Chapter 16: Controlling Loops\\nThe APL is simpler and less error-prone. It uses only three operands, whereas the Java \\nfragment uses 17. It doesn’t have loop variables, array indexes, or control structures to \\ncode incorrectly.\\nOne point of this example is that you do some programming to solve a problem and \\nsome to solve it in a particular language. The language you use to solve a problem sub-\\nstantially affects your solution.\\ncc2e.com/1616 CHECKLIST: Loops\\nLoop Selection and Creation\\n❑ Is a while loop used instead of a for loop, if appropriate?\\n❑ Was the loop created from the inside out?\\nEntering the Loop\\n❑ Is the loop entered from the top?\\n❑ Is initialization code directly before the loop?\\n❑ If the loop is an infinite loop or an event loop, is it constructed cleanly \\nrather than using a kludge such as for i = 1 to 9999?\\n❑ If the loop is a C++, C, or Java for loop, is the loop header reserved for loop-\\ncontrol code?\\nInside the Loop\\n❑ Does the loop use { and } or their equivalent to enclose the loop body and \\nprevent problems arising from improper modifications?\\n❑ Does the loop body have something in it? Is it nonempty?\\n❑ Are housekeeping chores grouped, at either the beginning or the end of \\nthe loop?\\n❑ Does the loop perform one and only one function, as a well-defined rou-\\ntine does?\\n❑ Is the loop short enough to view all at once?\\n❑ Is the loop nested to three levels or less?\\n❑ Have long loop contents been moved into their own routine?\\n❑ If the loop is long, is it especially clear?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 425}, page_content='Key Points 389\\nLoop Indexes\\n❑ If the loop is a for loop, does the code inside it avoid monkeying with the \\nloop index?\\n❑ Is a variable used to save important loop-index values rather than using \\nthe loop index outside the loop?\\n❑ Is the loop index an ordinal type or an enumerated type—not floating-\\npoint?\\n❑ Does the loop index have a meaningful name?\\n❑ Does the loop avoid index cross-talk?\\nExiting the Loop\\n❑ Does the loop end under all possible conditions?\\n❑ Does the loop use safety counters—if you’ve instituted a safety-counter \\nstandard?\\n❑ Is the loop’s termination condition obvious?\\n❑ If break or continue are used, are they correct?\\nKey Points\\n■ Loops are complicated. Keeping them simple helps readers of your code.\\n■ Techniques for keeping loops simple include avoiding exotic kinds of loops, \\nminimizing nesting, making entries and exits clear, and keeping housekeeping \\ncode in one place.\\n■ Loop indexes are subjected to a great deal of abuse. Name them clearly, and use \\nthem for only one purpose.\\n■ Think through the loop carefully to verify that it operates normally under each \\ncase and terminates under all possible conditions.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 427}, page_content='391\\nChapter 17\\nUnusual Control Structures\\ncc2e.com/1778 Contents\\n■ 17.1 Multiple Returns from a Routine: page 391\\n■ 17.2 Recursion: page 393\\n■ 17.3 goto: page 398\\n■ 17.4 Perspective on Unusual Control Structures: page 408\\nRelated Topics\\n■ General control issues: Chapter 19\\n■ Straight-line code: Chapter 14\\n■ Code with conditionals: Chapter 15\\n■ Code with loops: Chapter 16\\n■ Exception handling: Section 8.4\\nSeveral control constructs exist in a hazy twilight zone somewhere between being \\nleading-edge and being discredited and disproved—often in both places at the same \\ntime! These constructs aren’t available in all languages but can be useful when used \\nwith care in those languages that do offer them.\\n17.1 Multiple Returns from a Routine\\nMost languages support some means of exiting from a routine partway through the \\nroutine. The return and exit statements are control constructs that enable a program to \\nexit from a routine at will. They cause the routine to terminate through the normal \\nexit channel, returning control to the calling routine. The word return is used here as \\na generic term for return in C++ and Java, Exit Sub and Exit Function in Microsoft Visual \\nBasic, and similar constructs. Here are guidelines for using the return statement:\\nUse a return when it enhances readability In certain routines, once you know the \\nanswer, you want to return it to the calling routine immediately. If the routine is \\ndefined in such a way that it doesn’t require any further cleanup once it detects an \\nerror, not returning immediately means that you have to write more code.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 428}, page_content=\"392 Chapter 17: Unusual Control Structures\\nThe following is a good example of a case in which returning from multiple places in \\na routine makes sense:\\nC+ + Example of a Good Multiple Return from a Routine\\nThis routine returns a \\nComparison enumerated \\ntype. \\nComparison Compare( int value1, int value2 ) {\\n   if ( value1 < value2 ) {\\n      return Comparison_LessThan;\\n   }\\n   else if ( value1 > value2 ) {\\n      return Comparison_GreaterThan;\\n   }\\n   return Comparison_Equal;\\n}\\nOther examples are less clear-cut, as the next subsection illustrates. \\nUse guard clauses (early returns or exits) to simplify complex error processing\\nCode that has to check for numerous error conditions before performing its nominal \\nactions can result in deeply indented code and can obscure the nominal case, as \\nshown here:\\nVisual Basic Code That Obscures the Nominal Case\\nIf file.validName() Then\\n   If file.Open() Then\\n      If encryptionKey.valid() Then\\n         If file.Decrypt( encryptionKey ) Then\\nThis is the code for the \\nnominal case.\\n            ' lots of code\\n            ...\\n         End If\\n      End If\\n   End If\\nEnd If\\nIndenting the main body of the routine inside four if statements is aesthetically ugly, \\nespecially if there’s much code inside the innermost if statement. In such cases, the \\nflow of the code is sometimes clearer if the erroneous cases are checked first, clearing \\nthe way for the nominal path through the code. Here’s how that might look:\\nSimple Visual Basic Code That Uses Guard Clauses to Clarify the Nominal Case\\n' set up, bailing out if errors are found\\nIf Not file.validName() Then Exit Sub\\nIf Not file.Open() Then Exit Sub\\nIf Not encryptionKey.valid() Then Exit Sub\\nIf Not file.Decrypt( encryptionKey ) Then Exit Sub\\n' lots of code\\n...\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 429}, page_content=\"17.2 Recursion 393\\nThis simple code makes this technique look like a tidy solution, but production code \\noften requires more extensive housekeeping or cleanup when an error condition is \\ndetected. Here is a more realistic example:\\nMore Realistic Visual Basic Code That Uses Guard Clauses to Clarify the Nominal Case\\n' set up, bailing out if errors are found\\nIf Not file.validName() Then \\n   errorStatus = FileError_InvalidFileName\\n   Exit Sub\\nEnd If \\nIf Not file.Open() Then \\n   errorStatus = FileError_CantOpenFile\\n   Exit Sub\\nEnd If \\nIf Not encryptionKey.valid() Then \\n   errorStatus = FileError_InvalidEncryptionKey\\n   Exit Sub\\nEnd If \\nIf Not file.Decrypt( encryptionKey ) Then \\n   errorStatus = FileError_CantDecryptFile\\n   Exit Sub\\nEnd If \\nThis is the code for the \\nnominal case. \\n' lots of code\\n...\\nWith production-size code, the Exit Sub approach creates a noticeable amount of code \\nbefore the nominal case is handled. The Exit Sub approach does avoid the deep nest-\\ning of the first example, however, and, if the code in the first example were expanded \\nto show setting an errorStatus variable, the Exit Sub approach would do a better job of \\nkeeping related statements together. When all the dust settles, the Exit Sub approach \\ndoes appear more readable and maintainable, just not by a very wide margin. \\nMinimize the number of returns in each routine It’s harder to understand a routine \\nwhen, reading it at the bottom, you’re unaware of the possibility that it returned some-\\nwhere above. For that reason, use returns judiciously—only when they improve readability. \\n17.2 Recursion\\nIn recursion, a routine solves a small part of a problem itself, divides the problem into \\nsmaller pieces, and then calls itself to solve each of the smaller pieces. Recursion is \\nusually called into play when a small part of the problem is easy to solve and a large \\npart is easy to decompose into smaller pieces.\\nRecursion isn’t useful often, but when used judiciously it produces elegant solutions, \\nas in this example in which a sorting algorithm makes excellent use of recursion:\\nKEY POINT\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 430}, page_content='394 Chapter 17: Unusual Control Structures\\nJava Example of a Sorting Algorithm That Uses Recursion\\nvoid QuickSort( int firstIndex, int lastIndex, String [] names ) {\\n   if ( lastIndex > firstIndex ) {\\n      int midPoint = Partition( firstIndex, lastIndex, names );\\nHere are the recursive calls.       QuickSort( firstIndex, midPoint-1, names );\\n      QuickSort( midPoint+1, lastIndex, names )\\n   }\\n}\\nIn this case, the sorting algorithm chops an array in two and then calls itself to sort \\neach half of the array. When it calls itself with a subarray that’s too small to sort—such \\nas ( lastIndex <= firstIndex )—it stops calling itself.\\nFor a small group of problems, recursion can produce simple, elegant solutions. For a \\nslightly larger group of problems, it can produce simple, elegant, hard-to-understand \\nsolutions. For most problems, it produces massively complicated solutions—in those \\ncases, simple iteration is usually more understandable. Use recursion selectively.\\nExample of Recursion\\nSuppose you have a data type that represents a maze. A maze is basically a grid, and at \\neach point on the grid you might be able to turn left, turn right, move up, or move \\ndown. You’ll often be able to move in more than one direction.\\nHow do you write a program to find its way through the maze, as shown in Figure 17-\\n1? If you use recursion, the answer is fairly straightforward. You start at the beginning \\nand then try all possible paths until you find your way out of the maze. The first time \\nyou visit a point, you try to move left. If you can’t move left, you try to go up or down, \\nand if you can’t go up or down, you try to go right. You don’t have to worry about get-\\nting lost because you drop a few bread crumbs on each spot as you visit it, and you \\ndon’t visit the same spot twice.\\nFigure 17-1 Recursion can be a valuable tool in the battle against complexity—when used \\nto attack suitable problems. \\nLeft\\nDown\\nUp\\nRight\\nGo up because left\\nis unavailable.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 431}, page_content=\"17.2 Recursion 395\\nThe recursive code looks like this:\\nC+ + Example of Moving Through a Maze Recursively\\nbool FindPathThroughMaze( Maze maze, Point position ) {\\n   // if the position has already been tried, don't try it again\\n   if ( AlreadyTried( maze, position ) ) {\\n      return false;\\n   }\\n   \\n   // if this position is the exit, declare success\\n   if ( ThisIsTheExit( maze, position ) ) {\\n      return true;\\n   }\\n   \\n   // remember that this position has been tried\\n   RememberPosition( maze, position );\\n   \\n   // check the paths to the left, up, down, and to the right; if\\n   // any path is successful, stop looking \\n   if ( MoveLeft( maze, position, &newPosition ) ) {\\n      if ( FindPathThroughMaze( maze, newPosition ) ) {\\n         return true;\\n      }\\n   }\\n   \\n   if ( MoveUp( maze, position, &newPosition ) ) {\\n      if ( FindPathThroughMaze( maze, newPosition ) ) {\\n         return true;\\n      }\\n   }\\n   \\n   if ( MoveDown( maze, position, &newPosition ) ) {\\n      if ( FindPathThroughMaze( maze, newPosition ) ) {\\n         return true;\\n      }\\n   }\\n   \\n   if ( MoveRight( maze, position, &newPosition ) ) {\\n      if ( FindPathThroughMaze( maze, newPosition ) ) {\\n         return true;\\n      }\\n   }\\n   return false;\\n}\\nThe first line of code checks to see whether the position has already been tried. One \\nkey aim in writing a recursive routine is the prevention of infinite recursion. In this \\ncase, if you don’t check for having tried a point, you might keep trying it infinitely.\\nThe second statement checks to see whether the position is the exit from the maze. If \\nThisIsTheExit() returns true, the routine itself returns true.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 432}, page_content='396 Chapter 17: Unusual Control Structures\\nThe third statement remembers that the position has been visited. This prevents the \\ninfinite recursion that would result from a circular path.\\nThe remaining lines in the routine try to find a path to the left, up, down, and to the \\nright. The code stops the recursion if the routine ever returns true—that is, when the \\nroutine finds a path through the maze.\\nThe logic used in this routine is fairly straightforward. Most people experience some \\ninitial discomfort using recursion because it’s self-referential. In this case, however, an \\nalternative solution would be much more complicated and recursion works well.\\nTips for Using Recursion\\nKeep these tips in mind when using recursion:\\nMake sure the recursion stopsCheck the routine to make sure that it includes a non-\\nrecursive path. That usually means that the routine has a test that stops further recur-\\nsion when it’s not needed. In the maze example, the tests for AlreadyTried() and \\nThisIsTheExit() ensure that the recursion stops.\\nUse safety counters to prevent infinite recursion If you’re using recursion in a situa-\\ntion that doesn’t allow a simple test such as the one just described, use a safety \\ncounter to prevent infinite recursion. The safety counter has to be a variable that’s not \\nre-created each time you call the routine. Use a class member variable or pass the \\nsafety counter as a parameter. Here’s an example:\\nVisual Basic Example of Using a Safety Counter to Prevent Infinite Recursion\\nThe recursive routine must \\nbe able to change the value \\nof safetyCounter, so in Visual \\nBasic it’s a ByRef parameter.\\nPublic Sub RecursiveProc( ByRef safetyCounter As Integer )\\n   If ( safetyCounter > SAFETY_LIMIT ) Then\\n      Exit Sub\\n   End If\\n   safetyCounter = safetyCounter + 1\\n   ...\\n   RecursiveProc( safetyCounter )\\nEnd Sub\\nIn this case, if the routine exceeds the safety limit, it stops recursing.\\nIf you don’t want to pass the safety counter as an explicit parameter, you could use a \\nmember variable in C++, Java, or Visual Basic, or the equivalent in other languages. \\nLimit recursion to one routine Cyclic recursion (A calls B calls C calls A) is danger-\\nous because it’s hard to detect. Mentally managing recursion in one routine is tough \\nenough; understanding recursion that spans routines is too much. If you have cyclic \\nrecursion, you can usually redesign the routines so that the recursion is restricted to a'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 433}, page_content='17.2 Recursion 397\\nsingle routine. If you can’t and you still think that recursion is the best approach, use \\nsafety counters as a recursive insurance policy.\\nKeep an eye on the stack With recursion, you have no guarantees about how much \\nstack space your program uses and it’s hard to predict in advance how the program \\nwill behave at run time. You can take a couple of steps to control its run-time behavior, \\nhowever.\\nFirst, if you use a safety counter, one of the considerations in setting a limit for it \\nshould be how much stack you’re willing to allocate to the recursive routine. Set the \\nsafety limit low enough to prevent a stack overflow.\\nSecond, watch for allocation of local variables in recursive functions, especially mem-\\nory-intensive objects. In other words, use new to create objects on the heap rather \\nthan letting the compiler create auto objects on the stack. \\nDon’t use recursion for factorials or Fibonacci numbers One problem with com-\\nputer-science textbooks is that they present silly examples of recursion. The typical \\nexamples are computing a factorial or computing a Fibonacci sequence. Recursion is \\na powerful tool, and it’s really dumb to use it in either of those cases. If a programmer \\nwho worked for me used recursion to compute a factorial, I’d hire someone else. \\nHere’s the recursive version of the factorial routine:\\nJava Example of an Inappropriate Solution: Using Recursion to Compute a Factorial\\nint Factorial( int number ) {\\n   if ( number == 1 ) {\\n      return 1;\\n   }\\n   else {\\n      return number * Factorial( number - 1 );\\n   }\\n}\\nIn addition to being slow and making the use of run-time memory unpredictable, the \\nrecursive version of this routine is harder to understand than the iterative version, \\nwhich follows:\\nJava Example of an Appropriate Solution: Using Iteration to Compute a Factorial\\nint Factorial( int number ) {\\n   int intermediateResult = 1;\\n   for ( int factor = 2; factor <= number; factor++ ) {\\n      intermediateResult = intermediateResult * factor;\\n   }\\n   return intermediateResult;\\n}\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 434}, page_content='398 Chapter 17: Unusual Control Structures\\nYou can draw three lessons from this example. First, computer-science textbooks \\naren’t doing the world any favors with their examples of recursion. Second, and more \\nimportant, recursion is a much more powerful tool than its confusing use in comput-\\ning factorials or Fibonacci numbers would suggest. Third, and most important, you \\nshould consider alternatives to recursion before using it. You can do anything with \\nstacks and iteration that you can do with recursion. Sometimes one approach works \\nbetter; sometimes the other does. Consider both before you choose either one.\\n17.3 goto\\ncc2e.com/1785 You might think the debate related to gotos is extinct, but a quick trip through modern \\nsource-code repositories like SourceForge.net shows that the goto is still alive and well \\nand living deep in your company’s server. Moreover, modern equivalents of the goto \\ndebate still crop up in various guises, including debates about multiple returns, mul-\\ntiple loop exits, named loop exits, error processing, and exception handling. \\nThe Argument Against gotos\\nThe general argument against gotos is that code without gotos is higher-quality code. \\nThe famous letter that sparked the original controversy was Edsger Dijkstra’s “Go To \\nStatement Considered Harmful” in the March 1968 Communications of the ACM. \\nDijkstra observed that the quality of code was inversely proportional to the number of \\ngotos the programmer used. In subsequent work, Dijkstra has argued that code that \\ndoesn’t contain gotos can more easily be proven correct.\\nCode containing gotos is hard to format. Indentation should be used to show logical \\nstructure, and gotos have an effect on logical structure. Using indentation to show the \\nlogical structure of a goto and its target, however, is difficult or impossible.\\nUse of gotos defeats compiler optimizations. Some optimizations depend on a pro-\\ngram’s flow of control residing within a few statements. An unconditional goto makes \\nthe flow harder to analyze and reduces the ability of the compiler to optimize the \\ncode. Thus, even if introducing a goto produces an efficiency at the source-language \\nlevel, it may well reduce overall efficiency by thwarting compiler optimizations.\\nProponents of gotos sometimes argue that they make code faster or smaller. But code \\ncontaining gotos is rarely the fastest or smallest possible. Donald Knuth’s marvelous, \\nclassic article “Structured Programming with go to Statements” gives several examples \\nof cases in which using gotos makes for slower and larger code (Knuth 1974).\\nIn practice, the use of gotos leads to the violation of the principle that code should \\nflow strictly from top to bottom. Even if gotos aren’t confusing when used carefully, \\nonce gotos are introduced, they spread through the code like termites through a rot-\\nting house. If any gotos are allowed, the bad creep in with the good, so it’s better not \\nto allow any of them.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 435}, page_content='17.3 goto 399\\nOverall, experience in the two decades that followed the publication of Dijkstra’s letter \\nshowed the folly of producing goto-laden code. In a survey of the literature, Ben Shneider-\\nman concluded that the evidence supports Dijkstra’s view that we’re better off without \\nthe goto (1980), and many modern languages, including Java, don’t even have gotos.\\nThe Argument for gotos\\nThe argument for the goto is characterized by an advocacy of its careful use in specific \\ncircumstances rather than its indiscriminate use. Most arguments against gotos speak \\nagainst indiscriminate use. The goto controversy erupted when Fortran was the most \\npopular language. Fortran had no presentable loop structures, and in the absence of \\ngood advice on programming loops with gotos, programmers wrote a lot of spaghetti \\ncode. Such code was undoubtedly correlated with the production of low-quality pro-\\ngrams, but it has little to do with the careful use of a goto to make up for a gap in a \\nmodern language’s capabilities.\\nA well-placed goto can eliminate the need for duplicate code. Duplicate code leads to \\nproblems if the two sets of code are modified differently. Duplicate code increases the \\nsize of source and executable files. The bad effects of the goto are outweighed in such \\na case by the risks of duplicate code.\\nCross-Reference For details \\non using gotos in code that \\nallocates resources, see “Error \\nProcessing and gotos” in this \\nsection. See also the discus-\\nsion of exception handling in \\nSection 8.4, “Exceptions.”\\nThe goto is useful in a routine that allocates resources, performs operations on those \\nresources, and then deallocates the resources. With a goto, you can clean up in one \\nsection of code. The goto reduces the likelihood of your forgetting to deallocate the \\nresources in each place you detect an error.\\nIn some cases, the goto can result in faster and smaller code. Knuth’s 1974 article cited \\na few cases in which the goto produced a legitimate gain.\\nGood programming doesn’t mean eliminating gotos. Methodical decomposition, \\nrefinement, and selection of control structures automatically lead to goto-free pro-\\ngrams in most cases. Achieving goto-less code is not the aim but the outcome, and put-\\nting the focus on avoiding gotos isn’t helpful.\\nThe evidence suggests only \\nthat deliberately chaotic \\ncontrol structure degrades \\n[programmer] performance. \\nThese experiments provide \\nvirtually no evidence for the \\nbeneficial effect of any spe-\\ncific method of structuring \\ncontrol flow. \\n—B. A. Sheil\\nDecades’ worth of research with gotos failed to demonstrate their harmfulness. In a \\nsurvey of the literature, B. A. Sheil concluded that unrealistic test conditions, poor \\ndata analysis, and inconclusive results failed to support the claim of Shneiderman and \\nothers that the number of bugs in code was proportional to the number of gotos \\n(1981). Sheil didn’t go so far as to conclude that using gotos is a good idea—rather, that \\nexperimental evidence against them was not conclusive.\\nFinally, the goto has been incorporated into many modern languages, including Visual \\nBasic, C++, and the Ada language, the most carefully engineered programming lan-\\nguage in history. Ada was developed long after the arguments on both sides of the goto \\ndebate had been fully developed, and after considering all sides of the issue, Ada’s \\nengineers decided to include the goto.  \\n17.3 goto'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 436}, page_content='400 Chapter 17: Unusual Control Structures\\nThe Phony goto Debate\\nA primary feature of most goto discussions is a shallow approach to the question. The \\narguer on the “gotos are evil” side presents a trivial code fragment that uses gotos and \\nthen shows how easy it is to rewrite the fragment without gotos. This proves mainly \\nthat it’s easy to write trivial code without gotos.\\nThe arguer on the “I can’t live without gotos” side usually presents a case in which \\neliminating a goto results in an extra comparison or the duplication of a line of code. \\nThis proves mainly that there’s a case in which using a goto results in one less compar-\\nison—not a significant gain on today’s computers.\\nMost textbooks don’t help. They provide a trivial example of rewriting some code \\nwithout a goto as if that covers the subject. Here’s a disguised example of a trivial piece \\nof code from such a textbook:\\nC+ + Example of Code That’s Supposed to Be Easy to Rewrite Without gotos\\ndo {\\n   GetData( inputFile, data );\\n   if ( eof( inputFile ) ) {\\n      goto LOOP_EXIT;\\n   }\\n   DoSomething( data );\\n} while ( data != -1 );\\nLOOP_EXIT:\\nThe book quickly replaces this code with goto-less code:\\nC+ + Example of Supposedly Equivalent Code, Rewritten Without gotos\\nGetData( inputFile, data );\\nwhile ( ( !eof( inputFile ) ) && ( ( data != -1 ) ) ) {\\n   DoSomething( data );\\n   GetData( inputFile, data )\\n}\\nThis so-called “trivial” example contains an error. In the case in which data equals -1 \\nentering the loop, the translated code detects the -1 and exits the loop before executing \\nDoSomething(). The original code executes DoSomething() before the -1 is detected. The \\nprogramming book trying to show how easy it is to code without gotos translated its own \\nexample incorrectly. But the author of that book shouldn’t feel too bad; other books \\nmake similar mistakes. Even the pros have difficulty translating code that uses gotos.\\nHere’s a faithful translation of the code with no gotos:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 437}, page_content=\"17.3 goto 40117.3 goto\\nC+ + Example of Truly Equivalent Code, Rewritten Without gotos\\ndo {\\n   GetData( inputFile, data );\\n   if ( !eof( inputFile )) {\\n      DoSomething( data );\\n   }\\n} while ( ( data != -1 ) && ( !eof( inputFile ) ) );\\nEven with a correct translation of the code, the example is still phony because it \\nshows a trivial use of the goto. Such cases are not the ones for which thoughtful pro-\\ngrammers choose a goto as their preferred form of control.\\nIt would be hard at this late date to add anything worthwhile to the theoretical goto \\ndebate. What’s not usually addressed, however, is the situation in which a program-\\nmer fully aware of the goto-less alternatives chooses to use a goto to enhance readabil-\\nity and maintainability.\\nThe following sections present cases in which some experienced programmers have \\nargued for using gotos. The discussions provide examples of code with gotos and code \\nrewritten without gotos and evaluate the tradeoffs between the versions.\\nError Processing and gotos\\nWriting highly interactive code calls for paying a lot of attention to error processing \\nand cleaning up resources when errors occur. The following code example purges a \\ngroup of files. The routine first gets a group of files to be purged, and then it finds each \\nfile, opens it, overwrites it, and erases it. The routine checks for errors at each step.\\nVisual Basic Code with gotos That Processes Errors and Cleans Up Resources\\n' This routine purges a group of files.\\nSub PurgeFiles( ByRef errorState As Error_Code )\\n   Dim fileIndex As Integer\\n   Dim fileToPurge As Data_File\\n   Dim fileList As File_List\\n   Dim numFilesToPurge As Integer\\n   MakePurgeFileList( fileList, numFilesToPurge )\\n   errorState = FileStatus_Success\\n   fileIndex = 0\\n   While ( fileIndex < numFilesToPurge ) \\n      fileIndex = fileIndex + 1\\n      If Not ( FindFile( fileList( fileIndex ), fileToPurge ) ) Then\\n         errorState = FileStatus_FileFindError\\nHere’s a GoTo.          GoTo END_PROC\\n      End If\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 438}, page_content=\"402 Chapter 17: Unusual Control Structures\\n      If Not OpenFile( fileToPurge ) Then\\n         errorState = FileStatus_FileOpenError\\nHere’s a GoTo.          GoTo END_PROC\\n      End If\\n      If Not OverwriteFile( fileToPurge ) Then\\n         errorState = FileStatus_FileOverwriteError\\nHere’s a GoTo.          GoTo END_PROC\\n      End If\\n      if Not Erase( fileToPurge ) Then\\n         errorState = FileStatus_FileEraseError\\nHere’s a GoTo.          GoTo END_PROC\\n      End If\\n   End While\\nHere’s the GoTo label. END_PROC:\\n   DeletePurgeFileList( fileList, numFilesToPurge )\\nEnd Sub\\nThis routine is typical of circumstances in which experienced programmers decide to \\nuse a goto. Similar cases come up when a routine needs to allocate and clean up \\nresources like database connections, memory, or temporary files. The alternative to \\ngotos in those cases is usually duplicating code to clean up the resources. In such \\ncases, a programmer might balance the evil of the goto against the headache of dupli-\\ncate-code maintenance and decide that the goto is the lesser evil.\\nYou can rewrite the previous routine in a couple of ways to avoid gotos, and both ways \\ninvolve tradeoffs. The possible rewrite strategies follow:\\nRewrite with nested if statements To rewrite with nested if statements, nest the if \\nstatements so that each is executed only if the previous test succeeds. This is the stan-\\ndard, textbook programming approach to eliminating gotos. Here’s a rewrite of the \\nroutine using the standard approach:\\nCross-Reference This rou-\\ntine could also be rewritten \\nwith break and no gotos. For \\ndetails on that approach, see \\n“Exiting Loops Early” in Sec-\\ntion 16.2.\\nVisual Basic Code That Avoids gotos by Using Nested ifs\\n' This routine purges a group of files.\\nSub PurgeFiles( ByRef errorState As Error_Code )\\n   Dim fileIndex As Integer\\n   Dim fileToPurge As Data_File\\n   Dim fileList As File_List\\n   Dim numFilesToPurge As Integer\\n   MakePurgeFileList( fileList, numFilesToPurge )\\n   errorState = FileStatus_Success\\n   fileIndex = 0\\nThe While test has been \\nchanged to add a test for \\nerrorState.\\n   While ( fileIndex < numFilesToPurge And errorState = FileStatus_Success ) \\n      \\n      fileIndex = fileIndex + 1\\nC17619670.fm  Page 402  Tuesday, April 12, 2011  3:01 PM\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 439}, page_content=\"17.3 goto 403\\n      If FindFile( fileList( fileIndex ), fileToPurge ) Then\\n         If OpenFile( fileToPurge ) Then\\n            If OverwriteFile( fileToPurge ) Then\\n               If Not Erase( fileToPurge ) Then\\n                  errorState = FileStatus_FileEraseError\\n               End If\\n            Else ' couldn't overwrite file\\n               errorState = FileStatus_FileOverwriteError\\n            End If\\n         Else ' couldn't open file\\n            errorState = FileStatus_FileOpenError\\n         End If\\n      Else ' couldn't find file \\nThis line is 13 lines away \\nfrom the If statement that \\ninvokes it.\\n            errorState = FileStatus_FileFindError\\n      End If\\n   End While \\n   DeletePurgeFileList( fileList, numFilesToPurge )\\nEnd Sub\\nFor people used to programming without gotos, this code might be easier to read than \\nthe goto version, and if you use it, you won’t have to face an inquisition from the goto \\ngoon squad.\\nCross-Reference For more \\ndetails on indentation and \\nother coding layout issues, \\nsee Chapter 31, “Layout and \\nStyle.” For details on nesting \\nlevels, see Section 19.4, \\n“Taming Dangerously Deep \\nNesting.”\\nThe main disadvantage of this nested-if approach is that the nesting level is deep, very \\ndeep. To understand the code, you have to keep the whole set of nested ifs in your \\nmind at once. Moreover, the distance between the error-processing code and the code \\nthat invokes it is too great: the code that sets errorState to FileStatus_FileFindError, for \\nexample, is 13 lines from the if statement that invokes it.\\nWith the goto version, no statement is more than four lines from the condition that \\ninvokes it. And you don’t have to keep the whole structure in your mind at once. You \\ncan essentially ignore any preceding conditions that were successful and focus on the \\nnext operation. In this case, the goto version is more readable and more maintainable \\nthan the nested-if version.\\nRewrite with a status variable To rewrite with a status variable (also called a state \\nvariable), create a variable that indicates whether the routine is in an error state. In \\nthis case, the routine already uses the errorState status variable, so you can use that.\\nVisual Basic Code That Avoids gotos by Using a Status Variable\\n' This routine purges a group of files.\\nSub PurgeFiles( ByRef errorState As Error_Code )\\n   Dim fileIndex As Integer\\n   Dim fileToPurge As Data_File\\n   Dim fileList As File_List\\n   Dim numFilesToPurge As Integer\\n   MakePurgeFileList( fileList, numFilesToPurge )\\n   errorState = FileStatus_Success\\n   fileIndex = 0\\n17.3 goto\\nC17619670.fm  Page 403  Tuesday, April 12, 2011  3:02 PM\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 440}, page_content='404 Chapter 17: Unusual Control Structures\\nThe While test has been \\nchanged to add a test for \\nerrorState.\\n   While ( fileIndex < numFilesToPurge ) And ( errorState = FileStatus_Success ) \\n      \\n      fileIndex = fileIndex + 1\\n      If Not FindFile( fileList( fileIndex ), fileToPurge ) Then\\n         errorState = FileStatus_FileFindError\\n      End If \\nThe status variable is tested.       If ( errorState = FileStatus_Success ) Then\\n         If Not OpenFile( fileToPurge ) Then\\n            errorState = FileStatus_FileOpenError\\n         End If \\n      End If\\nThe status variable is tested.       If ( errorState = FileStatus_Success ) Then\\n         If Not OverwriteFile( fileToPurge ) Then\\n            errorState = FileStatus_FileOverwriteError\\n         End If\\n      End If\\nThe status variable is tested.       If ( errorState = FileStatus_Success ) Then\\n         If Not Erase( fileToPurge ) Then\\n            errorState = FileStatus_FileEraseError\\n         End If \\n      End If \\n   End While \\n   DeletePurgeFileList( fileList, numFilesToPurge )\\nEnd Sub\\nThe advantage of the status-variable approach is that it avoids the deeply nested if-\\nthen-else structures of the first rewrite and is thus easier to understand. It also places \\nthe action following the if-then-else test closer to the test than the nested-if approach \\ndid, and it completely avoids else clauses.\\nUnderstanding the nested-if version requires some mental gymnastics. The status-\\nvariable version is easier to understand because it closely models the way people \\nthink about the problem. You find the file. If everything is OK, you open the file. If \\neverything is still OK, you overwrite the file. If everything is still OK...\\nThe disadvantage of this approach is that using status variables isn’t as common a \\npractice as it should be. Document their use fully, or some programmers might not \\nunderstand what you’re up to. In this example, the use of well-named enumerated \\ntypes helps significantly.\\nRewrite with try-finally Some languages, including Visual Basic and Java, provide a \\ntry-finally statement that can be used to clean up resources under error conditions. \\nTo rewrite using the try-finally approach,enclose the code that would otherwise need \\nto check for errors inside a try block, and place the cleanup code inside a finally block. \\nThe try block specifies the scope of the exception handling, and the finally block per-\\nforms any resource cleanup.The finally block will always be called regardless of \\nwhether an exception is thrown and regardless of whether the PurgeFiles() routine \\nCatches any exception that’s thrown. \\nC17619670.fm  Page 404  Tuesday, April 12, 2011  3:03 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 441}, page_content=\"17.3 goto 405\\nVisual Basic Code That Avoids gotos by Using try-finally\\n' This routine purges a group of files. Exceptions are passed to the caller.\\nSub PurgeFiles()\\n Dim fileIndex As Integer\\n Dim fileToPurge As Data_File\\n Dim fileList As File_List\\n Dim numFilesToPurge As Integer\\n MakePurgeFileList( fileList, numFilesToPurge )\\n Try\\n fileIndex = 0\\n While ( fileIndex < numFilesToPurge ) \\n fileIndex = fileIndex + 1\\n FindFile( fileList( fileIndex ), fileToPurge )\\n OpenFile( fileToPurge )\\n OverwriteFile( fileToPurge )\\n Erase( fileToPurge )\\n End While\\n Finally\\n DeletePurgeFileList( fileList, numFilesToPurge )\\n End Try\\nEnd Sub\\nThis approach assumes that all function calls throw exceptions for failures rather than \\nreturning error codes. \\nThe advantage of the try-finally approach is that it is simpler than the goto approach \\nand doesn’t use gotos. It also avoids the deeply nested if-then-else structures.\\nThe limitation of the try-finally approach is that it must be implemented consistently \\nthroughout a code base. If the previous code were part of a code base that used error \\ncodes in addition to exceptions, the exception code would be required to set error \\ncodes for each possible error, and that requirement would make the code about as \\ncomplicated as the other approaches. \\nComparison of the Approaches\\nCross-Reference For a com-\\nplete list of techniques that \\ncan be applied to situations \\nlike this, see “Summary of \\nTechniques for Reducing \\nDeep Nesting” in Section \\n19.4.\\nEach of the four methods has something to be said for it. The goto approach avoids \\ndeep nesting and unnecessary tests but of course has gotos. The nested-if approach \\navoids gotos but is deeply nested and gives an exaggerated picture of the logical com-\\nplexity of the routine. The status-variable approach avoids gotos and deep nesting but \\nintroduces extra tests. And the try-finally approach avoids both gotos and deep nesting \\nbut isn’t available in all languages. \\nThe try-finally approach is the most straightforward in languages that provide try-\\nfinally and in code bases that haven’t already standardized on another approach. If \\ntry-finally isn’t an option, the status-variable approach is slightly preferable to the goto \\nand nested-if approaches because it’s more readable and it models the problem better, \\nbut that doesn’t make it the best approach in all circumstances. \\nAny of these techniques works well when applied consistently to all the code in a proj-\\nect. Consider all the tradeoffs, and then make a projectwide decision about which \\nmethod to favor.\\n17.3 goto\\nC17619670.fm  Page 405  Tuesday, April 12, 2011  3:03 PM\\nDownload from Wow! eBook <www.wowebook.com>\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 442}, page_content='406 Chapter 17: Unusual Control Structures\\ngotos and Sharing Code in an else Clause\\nOne challenging situation in which some programmers would use a goto is the case in \\nwhich you have two conditional tests and an else clause and you want to execute code \\nin one of the conditions and in the else clause. Here’s an example of a case that could \\ndrive someone to goto:\\nC+ + Example of Sharing Code in an else Clause with a goto\\nif ( statusOk ) {\\n   if ( dataAvailable ) {\\n      importantVariable = x;\\n      goto MID_LOOP;\\n   }\\n}\\nelse {\\n   importantVariable = GetValue();\\n   MID_LOOP:\\n   // lots of code\\n   ...\\n}\\nThis is a good example because it’s logically tortuous—it’s nearly impossible to read it \\nas it stands, and it’s hard to rewrite it correctly without a goto. If you think you can eas-\\nily rewrite it without gotos, ask someone to review your code! Several expert program-\\nmers have rewritten it incorrectly.\\nYou can rewrite the code in several ways. You can duplicate code, put the common code \\ninto a routine and call it from two places, or retest the conditions. In most languages, the \\nrewrite will be a tiny bit larger and slower than the original, but it will be extremely close. \\nUnless the code is in a really hot loop, rewrite it without thinking about efficiency.\\nThe best rewrite would be to put the // lots of code part into its own routine. Then you can \\ncall the routine from the places you would otherwise have used as origins or destinations \\nof gotos and preserve the original structure of the conditional. Here’s how it looks:\\nC+ + Example of Sharing Code in an else Clause by Putting Common Code \\ninto a Routine\\nif ( statusOk ) {\\n   if ( dataAvailable ) {\\n      importantVariable = x;\\n      DoLotsOfCode( importantVariable );\\n   }\\n}\\nelse {\\n   importantVariable = GetValue();\\n   DoLotsOfCode( importantVariable );\\n}\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 443}, page_content='17.3 goto 407\\nNormally, writing a new routine is the best approach. Sometimes, however, it’s not \\npractical to put duplicated code into its own routine. In this case, you can work \\naround the impractical solution by restructuring the conditional so that you keep the \\ncode in the same routine rather than putting it into a new routine:\\nC+ + Example of Sharing Code in an else Clause Without a goto\\nif ( ( statusOk && dataAvailable ) || !statusOk ) {\\n   if ( statusOk && dataAvailable ) {\\n      importantVariable = x;\\n   }\\n   else {\\n      importantVariable = GetValue();\\n   }\\n   // lots of code\\n   ...\\n}\\nCross-Reference Another \\napproach to this problem is \\nto use a decision table. For \\ndetails, see Chapter 18, \\n“Table-Driven Methods. ”\\nThis is a faithful and mechanical translation of the logic in the goto version. It tests statu-\\nsOK two extra times and dataAvailable once, but the code is equivalent. If retesting the \\nconditionals bothers you, notice that the value of statusOK doesn’t need to be tested \\ntwice in the first if test. You can also drop the test for dataAvailable in the second if test.\\nSummary of Guidelines for Using gotos\\nUse of gotos is a matter of religion. My dogma is that in modern languages, you can \\neasily replace nine out of ten gotos with equivalent sequential constructs. In these sim-\\nple cases, you should replace gotos out of habit. In the hard cases, you can still exorcise \\nthe goto in nine out of ten cases: You can break the code into smaller routines, use try-\\nfinally, use nested ifs, test and retest a status variable, or restructure a conditional. \\nEliminating the goto is harder in these cases, but it’s good mental exercise and the \\ntechniques discussed in this section give you the tools to do it.\\nIn the remaining one case out of 100 in which a goto is a legitimate solution to the prob-\\nlem, document it clearly and use it. If you have your rain boots on, it’s not worth walking \\naround the block to avoid a mud puddle. But keep your mind open to goto-less \\napproaches suggested by other programmers. They might see something you don’t.\\nHere’s a summary of guidelines for using gotos:\\n■ Use gotos to emulate structured control constructs in languages that don’t sup-\\nport them directly. When you do, emulate them exactly. Don’t abuse the extra \\nflexibility the goto gives you.\\n■ Don’t use the goto when an equivalent built-in construct is available.\\nCross-Reference For details \\non improving efficiency, see \\nChapter 25, “Code-Tuning \\nStrategies,” and Chapter 26, \\n“Code-Tuning Techniques.”\\n■ Measure the performance of any goto used to improve efficiency. In most cases, \\nyou can recode without gotos for improved readability and no loss in efficiency. \\nIf your case is the exception, document the efficiency improvement so that goto-\\nless evangelists won’t remove the goto when they see it.\\nKEY POINT\\n17.3 goto'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 444}, page_content='408 Chapter 17: Unusual Control Structures\\n■ Limit yourself to one goto label per routine unless you’re emulating structured \\nconstructs.\\n■ Limit yourself to gotos that go forward, not backward, unless you’re emulating \\nstructured constructs.\\n■ Make sure all goto labels are used. Unused labels might be an indication of missing \\ncode, namely the code that goes to the labels. If the labels aren’t used, delete them.\\n■ Make sure a goto doesn’t create unreachable code.\\n■ If you’re a manager, adopt the perspective that a battle over a single goto isn’t \\nworth the loss of the war. If the programmer is aware of the alternatives and is \\nwilling to argue, the goto is probably OK.\\n17.4 Perspective on Unusual Control Structures\\nAt one time or another, someone thought that each of the following control structures \\nwas a good idea:\\n■ Unrestricted use of gotos\\n■ Ability to compute a goto target dynamically and jump to the computed location\\n■ Ability to use goto to jump from the middle of one routine into the middle of \\nanother routine\\n■ Ability to call a routine with a line number or label that allowed execution to \\nbegin somewhere in the middle of the routine\\n■ Ability to have the program generate code on the fly and then execute the code \\nit just wrote \\nAt one time, each of these ideas was regarded as acceptable or even desirable, even \\nthough now they all look hopelessly quaint, outdated, or dangerous. The field of soft-\\nware development has advanced largely through restricting what programmers can do \\nwith their code. Consequently, I view unconventional control structures with strong \\nskepticism. I suspect that the majority of constructs in this chapter will eventually find \\ntheir way onto the programmer’s scrap heap along with computed goto labels, variable \\nroutine entry points, self-modifying code, and other structures that favored flexibility \\nand convenience over structure and the ability to manage complexity. \\nAdditional Resources\\ncc2e.com/1792 The following resources also address unusual control structures:\\nReturns\\nFowler, Martin. Refactoring: Improving the Design of Existing Code. Reading, MA: \\nAddison-Wesley, 1999. In the description of the refactoring called “Replace Nested \\nConditional with Guard Clauses,” Fowler suggests using multiple return statements'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 445}, page_content='Additional Resources 409\\nfrom a routine to reduce nesting in a set of if statements. Fowler argues that multiple \\nreturns are an appropriate means of achieving greater clarity, and that no harm arises \\nfrom having multiple returns from a routine. \\ngotos\\nThese articles contain the whole goto debate. It erupts from time to time in most work-\\nplaces, textbooks, and magazines, but you won’t hear anything that wasn’t fully \\nexplored 20 years ago.\\ncc2e.com/1799 Dijkstra, Edsger. “Go To Statement Considered Harmful.” Communications of the ACM \\n11, no. 3 (March 1968): 147–48, also available from www.cs.utexas.edu/users/EWD/. \\nThis is the famous letter in which Dijkstra put the match to the paper and ignited one \\nof the longest-running controversies in software development.\\nWulf, W. A. “A Case Against the GOTO.” Proceedings of the 25th National ACM Confer-\\nence, August 1972: 791–97. This paper was another argument against the indiscrimi-\\nnate use of gotos. Wulf argued that if programming languages provided adequate control \\nstructures, gotos would become largely unnecessary. Since 1972, when the paper was \\nwritten, languages such as C++, Java, and Visual Basic have proven Wulf correct.\\nKnuth, Donald. “Structured Programming with go to Statements,” 1974. In Classics in \\nSoftware Engineering, edited by Edward Yourdon. Englewood Cliffs, NJ: Yourdon Press, \\n1979. This long paper isn’t entirely about gotos, but it includes a horde of code exam-\\nples that are made more efficient by eliminating gotos and another horde of code \\nexamples that are made more efficient by adding gotos.\\nRubin, Frank. “‘GOTO Considered Harmful’ Considered Harmful.” Communications \\nof the ACM 30, no. 3 (March 1987): 195–96. In this rather hotheaded letter to the edi-\\ntor, Rubin asserts that goto-less programming has cost businesses “hundreds of mil-\\nlions of dollars.” He then offers a short code fragment that uses a goto and argues that \\nit’s superior to goto-less alternatives.\\nThe response that Rubin’s letter generated was more interesting than the letter itself. \\nFor five months, Communications of the ACM (CACM) published letters that offered \\ndifferent versions of Rubin’s original seven-line program. The letters were evenly \\ndivided between those defending gotos and those castigating them. Readers suggested \\nroughly 17 different rewrites, and the rewritten code fully covered the spectrum of \\napproaches to avoiding gotos. The editor of CACM noted that the letter had generated \\nmore response by far than any other issue ever considered in the pages of CACM.\\nFor the follow-up letters, see\\n■ Communications of the ACM 30, no. 5 (May 1987): 351–55.\\n■ Communications of the ACM 30, no. 6 (June 1987): 475–78.\\n■ Communications of the ACM 30, no. 7 (July 1987): 632–34.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 446}, page_content='410 Chapter 17: Unusual Control Structures\\n■ Communications of the ACM 30, no. 8 (August 1987): 659–62.\\n■ Communications of the ACM 30, no. 12 (December 1987): 997, 1085.\\ncc2e.com/1706 Clark, R. Lawrence, “A Linguistic Contribution of GOTO-less Programming,” Datama-\\ntion, December 1973. This classic paper humorously argues for replacing the “go to” \\nstatement with the “come from” statement. It was also reprinted in the April 1974 edi-\\ntion of Communications of the ACM. \\ncc2e.com/1713 CHECKLIST: Unusual Control Structures\\nreturn\\n❑ Does each routine use return only when necessary?\\n❑ Do returns enhance readability?\\nRecursion\\n❑ Does the recursive routine include code to stop the recursion?\\n❑ Does the routine use a safety counter to guarantee that the routine stops?\\n❑ Is recursion limited to one routine?\\n❑ Is the routine’s depth of recursion within the limits imposed by the size of \\nthe program’s stack?\\n❑ Is recursion the best way to implement the routine? Is it better than simple \\niteration?\\ngoto\\n❑ Are gotos used only as a last resort, and then only to make code more read-\\nable and maintainable?\\n❑ If a goto is used for the sake of efficiency, has the gain in efficiency been \\nmeasured and documented?\\n❑ Are gotos limited to one label per routine?\\n❑ Do all gotos go forward, not backward?\\n❑ Are all goto labels used?\\nKey Points\\n■ Multiple returns can enhance a routine’s readability and maintainability, and they \\nhelp prevent deeply nested logic. They should, nevertheless, be used carefully.\\n■ Recursion provides elegant solutions to a small set of problems. Use it carefully, too.\\n■ In a few cases, gotos are the best way to write code that’s readable and maintain-\\nable. Such cases are rare. Use gotos only as a last resort.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 447}, page_content='411\\nChapter 18\\nTable-Driven Methods\\ncc2e.com/1865 Contents\\n■ 18.1 General Considerations in Using Table-Driven Methods: page 411\\n■ 18.2 Direct Access Tables: page 413\\n■ 18.3 Indexed Access Tables: page 425\\n■ 18.4 Stair-Step Access Tables: page 426\\n■ 18.5 Other Examples of Table Lookups: page 429\\nRelated Topics\\n■ Information hiding: “Hide Secrets (Information Hiding)” in Section 5.3\\n■ Class design: Chapter 6\\n■ Using decision tables to replace complicated logic: in Section 19.1\\n■ Substitute table lookups for complicated expressions: in Section 26.1\\nA table-driven method is a scheme that allows you to look up information in a table \\nrather than using logic statements (if and case) to figure it out. Virtually anything you \\ncan select with logic statements, you can select with tables instead. In simple cases, \\nlogic statements are easier and more direct. As the logic chain becomes more complex, \\ntables become increasingly attractive.\\nIf you’re already familiar with table-driven methods, this chapter might be just a \\nreview. In that case, you might examine “Flexible-Message-Format Example” in Sec-\\ntion 18.2 for a good example of how an object-oriented design isn’t necessarily better \\nthan any other kind of design just because it’s object-oriented, and then you might \\nmove on to the discussion of general control issues in Chapter 19. \\n18.1 General Considerations in Using Table-Driven Methods\\nUsed in appropriate circumstances, table-driven code is simpler than complicated \\nlogic, easier to modify, and more efficient. Suppose you wanted to classify characters \\ninto letters, punctuation marks, and digits; you might use a complicated chain of logic \\nlike this one: \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 448}, page_content=\"412 Chapter 18: Table-Driven Methods\\nJava Example of Using Complicated Logic to Classify a Character\\nif ( ( ( 'a' <= inputChar ) && ( inputChar <= 'z' ) ) ||\\n   ( ( 'A' <= inputChar ) && ( inputChar <= 'Z' ) ) ) {\\n   charType = CharacterType.Letter;\\n} \\nelse if ( ( inputChar == ' ' ) || ( inputChar == ',' ) ||\\n   ( inputChar == '.' ) || ( inputChar == '!' ) || ( inputChar == '(' ) ||\\n   ( inputChar == ')' ) || ( inputChar == ':' ) || ( inputChar == ';' ) ||\\n   ( inputChar == '?' ) || ( inputChar == '-' ) ) {\\n   charType = CharacterType.Punctuation;\\n}\\nelse if ( ( '0' <= inputChar ) && ( inputChar <= '9' ) ) {\\n   charType = CharacterType.Digit;\\n}\\nIf you used a lookup table instead, you’d store the type of each character in an array \\nthat’s accessed by character code. The complicated code fragment just shown  would \\nbe replaced by this:\\nJava Example of Using a Lookup Table to Classify a Character \\ncharType = charTypeTable[ inputChar ];\\nThis fragment assumes that the charTypeTable array has been set up earlier. You put \\nyour program’s knowledge into its data rather than into its logic—in the table instead \\nof in the if tests. \\nTwo Issues in Using Table-Driven Methods\\nWhen you use table-driven methods, you have to address two issues. First you have to \\naddress the question of how to look up entries in the table. You can use some data to \\naccess a table directly. If you need to classify data by month, for example, keying into \\na month table is straightforward. You can use an array with indexes 1 through 12.\\nOther data is too awkward to be used to look up a table entry directly. If you need to \\nclassify data by Social Security Number, for example, you can’t use the Social Security \\nNumber to key into the table directly unless you can afford to store 999-99-9999 \\nentries in your table. You’re forced to use a more complicated approach. Here’s a list of \\nways to look up an entry in a table:\\n■ Direct access\\n■ Indexed access \\n■ Stair-step access \\nEach of these kinds of accesses is described in more detail in subsections later in this \\nchapter.\\nKEY POINT\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 449}, page_content='18.2 Direct Access Tables 413\\nThe second issue you have to address if you’re using a table-driven method is what \\nyou should store in the table. In some cases, the result of a table lookup is data. If \\nthat’s the case, you can store the data in the table. In other cases, the result of a table \\nlookup is an action. In such a case, you can store a code that describes the action or, \\nin some languages, you can store a reference to the routine that implements the action. \\nIn either of these cases, tables become more complicated.\\n18.2 Direct Access Tables\\nLike all lookup tables, direct-access tables replace more complicated logical control \\nstructures. They are “direct access” because you don’t have to jump through any com-\\nplicated hoops to find the information you want in the table. As Figure 18-1 suggests, \\nyou can pick out the entry you want directly.\\nFigure 18-1 As the name suggests, a direct-access table allows you to access the table ele-\\nment you’re interested in directly. \\nDays-in-Month Example\\nSuppose you need to determine the number of days per month (forgetting about leap \\nyear, for the sake of argument). A clumsy way to do it, of course, is to write a large if \\nstatement:\\nVisual Basic Example of a Clumsy Way to Determine the Number of Days in a Month\\nIf ( month = 1 ) Then\\n   days = 31\\nElseIf ( month = 2 ) Then\\n   days = 28\\nElseIf ( month = 3 ) Then\\n   days = 31\\nElseIf ( month = 4 ) Then\\n   days = 30\\nElseIf ( month = 5 ) Then\\n   days = 31\\nElseIf ( month = 6 ) Then\\n   days = 30\\nElseIf ( month = 7 ) Then\\n   days = 31\\nKEY POINT\\n(age, year)\\nLookup Table'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 450}, page_content='414 Chapter 18: Table-Driven Methods\\nElseIf ( month = 8 ) Then\\n   days = 31\\nElseIf ( month = 9 ) Then\\n   days = 30\\nElseIf ( month = 10 ) Then\\n   days = 31\\nElseIf ( month = 11 ) Then\\n   days = 30\\nElseIf ( month = 12 ) Then\\n   days = 31\\nEnd If \\nAn easier and more modifiable way to perform the same function is to put the data in \\na table. In Microsoft Visual Basic, you’d first set up the table:\\nVisual Basic Example of an Elegant Way to Determine the Number of Days in a \\nMonth\\n\\' Initialize Table of \"Days Per Month\" Data\\nDim daysPerMonth() As Integer = _\\n   { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 }\\nNow, instead of using the long if statement, you can just use a simple array access to \\nfind out the number of days in a month:\\nVisual Basic Example of an Elegant Way to Determine the Number of Days in a \\nMonth (continued)\\ndays = daysPerMonth( month-1 )\\nIf you wanted to account for leap year in the table-lookup version, the code would still \\nbe simple, assuming LeapYearIndex() has a value of either 0 or 1:\\nVisual Basic Example of an Elegant Way to Determine the Number of Days in a \\nMonth (continued)\\ndays = daysPerMonth( month-1, LeapYearIndex() )\\nIn the if-statement version, the long string of ifs would grow even more complicated if \\nleap year were considered.\\nDetermining the number of days per month is a convenient example because you can \\nuse the month variable to look up an entry in the table. You can often use the data that \\nwould have controlled a lot of if statements to access a table directly.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 451}, page_content='18.2 Direct Access Tables 415\\nInsurance Rates Example\\nSuppose you’re writing a program to compute medical insurance rates and you have \\nrates that vary by age, gender, marital status, and whether a person smokes. If you had \\nto write a logical control structure for the rates, you’d get something like this:\\nJava Example of a Clumsy Way to Determine an Insurance Rate\\nif ( gender == Gender.Female ) {\\n   if ( maritalStatus == MaritalStatus.Single ) {\\n      if ( smokingStatus == SmokingStatus.NonSmoking ) {\\n         if ( age < 18 ) {\\n            rate = 200.00;\\n         }\\n         else if ( age == 18 ) {\\n            rate = 250.00;\\n         }\\n         else if ( age == 19 ) {\\n            rate = 300.00;\\n         }\\n         ...\\n         else if ( 65 < age ) {\\n            rate = 450.00;\\n      }\\n      else { \\n         if ( age < 18 ) {\\n            rate = 250.00;\\n         }\\n         else if ( age == 18 ) {\\n            rate = 300.00;\\n         }\\n         else if ( age == 19 ) {\\n            rate = 350.00;\\n         }\\n         ...\\n         else if ( 65 < age ) {\\n            rate = 575.00;\\n         }\\n      }\\n   else if ( maritalStatus == MaritalStatus.Married )\\n   ...\\n} \\nThe abbreviated version of the logic structure should be enough to give you an idea of \\nhow complicated this kind of thing can get. It doesn’t show married females, any \\nmales, or most of the ages between 18 and 65. You can imagine how complicated it \\nwould get when you programmed the whole rate table.\\nYou might say, “Yeah, but why did you do a test for each age? Why don’t you just put \\nthe rates in arrays for each age?” That’s a good question, and one obvious improve-\\nment would be to put the rates into separate arrays for each age.\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 452}, page_content='416 Chapter 18: Table-Driven Methods\\nA better solution, however, is to put the rates into arrays for all the factors, not just age. \\nHere’s how you would declare the array in Visual Basic: \\nVisual Basic Example of Declaring Data to Set Up an Insurance Rates Table\\nPublic Enum SmokingStatus\\n   SmokingStatus_First = 0\\n   SmokingStatus_Smoking = 0\\n   SmokingStatus_NonSmoking = 1\\n   SmokingStatus_Last = 1\\nEnd Enum\\nPublic Enum Gender\\n   Gender_First = 0\\n   Gender_Male = 0\\n   Gender_Female = 1\\n   Gender_Last = 1\\nEnd Enum\\nPublic Enum MaritalStatus\\n   MaritalStatus_First = 0\\n   MaritalStatus_Single = 0\\n   MaritalStatus_Married = 1\\n   MaritalStatus_Last = 1\\nEnd Enum\\nConst MAX_AGE As Integer = 125\\nDim rateTable ( SmokingStatus_Last, Gender_Last, MaritalStatus_Last, _\\n   MAX_AGE ) As Double\\nCross-Reference One \\nadvantage of a table-driven \\napproach is that you can put \\nthe table’s data in a file and \\nread it at run time. That \\nallows you to change some-\\nthing like an insurance rates \\ntable without changing the \\nprogram itself. For more on \\nthe idea, see Section 10.6, \\n“Binding Time.”\\nOnce you declare the array, you have to figure out some way of putting data into it. \\nYou can use assignment statements, read the data from a disk file, compute the data, \\nor do whatever is appropriate. After you’ve set up the data, you’ve got it made when \\nyou need to calculate a rate. The complicated logic shown earlier is replaced with a \\nsimple statement like this one:\\nVisual Basic Example of an Elegant Way to Determine an Insurance Rate \\nrate = rateTable( smokingStatus, gender, maritalStatus, age )\\nThis approach has the general advantages of replacing complicated logic with a table \\nlookup. The table lookup is more readable and easier to change.\\nFlexible-Message-Format Example\\nYou can use a table to describe logic that’s too dynamic to represent in code. With the \\ncharacter-classification example, the days-in-the-month example, and the insurance \\nrates example, you at least knew that you could write a long string of if statements if'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 453}, page_content='18.2 Direct Access Tables 417\\nyou needed to. In some cases, however, the data is too complicated to describe with \\nhard-coded if statements. \\nIf you think you’ve got the idea of how direct-access tables work, you might want to \\nskip the next example. It’s a little more complicated than the earlier examples, \\nthough, and it further demonstrates the power of table-driven approaches.\\nSuppose you’re writing a routine to print messages that are stored in a file. The file \\nusually has about 500 messages, and each file has about 20 kinds of messages. The \\nmessages originally come from a buoy and give water temperature, the buoy’s loca-\\ntion, and so on.\\nEach of the messages has several fields, and each message starts with a header that has \\nan ID to let you know which of the 20 or so kinds of messages you’re dealing with. Fig-\\nure 18-2 illustrates how the messages are stored.\\nFigure 18-2 Messages are stored in no particular order, and each one is identified with a \\nmessage ID.\\nThe format of the messages is volatile, determined by your customer, and you don’t \\nhave enough control over your customer to stabilize it. Figure 18-3 shows what a few \\nof the messages look like in detail.\\nID for Buoy\\nTemperature Message\\nMessage Contents\\nID for Buoy\\nDrift Message\\nMessage Contents\\nID for Buoy\\nLocation Message\\nMessage Contents'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 454}, page_content='418 Chapter 18: Table-Driven Methods\\nFigure 18-3 Aside from the Message ID, each kind of message has its own format.\\nLogic-Based Approach\\nIf you used a logic-based approach, you’d probably read each message, check the ID, \\nand then call a routine that’s designed to read, interpret, and print each kind of mes-\\nsage. If you had 20 kinds of messages, you’d have 20 routines.  You’d also have who-\\nknows-how-many lower-level routines to support them—for example, you’d have a \\nPrintBuoyTemperatureMessage() routine to print the buoy temperature message. An \\nobject-oriented approach wouldn’t be much better: you’d typically use an abstract \\nmessage object with a subclass for each message type. \\nEach time the format of any message changed, you’d have to change the logic in the \\nroutine or class responsible for that message. In the detailed message earlier, if the \\naverage-temperature field changed from a floating point to something else, you’d have \\nto change the logic of PrintBuoyTemperatureMessage(). (If the buoy itself changed from \\na “floating point” to something else, you’d have to get a new buoy!)\\nIn the logic-based approach, the message-reading routine consists of a loop to read \\neach message, decode the ID, and then call one of 20 routines based on the message \\nID. Here’s the pseudocode for the logic-based approach:\\nCross-Reference This low-\\nlevel pseudocode is used for \\na different purpose than the \\npseudocode you use for rou-\\ntine design. For details on \\ndesigning in pseudocode, \\nsee Chapter 9, “The \\nPseudocode Programming \\nProcess.”\\nWhile more messages to read\\n   Read a message header\\n   Decode the message ID from the message header\\n   If the message header is type 1 then\\n      Print a type 1 message\\n   Else if the message header is type 2 then\\n      Print a type 2 message\\n   ...\\n   Else if the message header is type 19 then\\n      Print a type 19 message\\n   Else if the message header is type 20 then\\n      Print a type 20 message\\nID for Buoy\\nTemperature Message\\nAverage Temperature\\n(floating point)\\nTemperature Range\\n(floating point)\\nNumber of Samples \\n(integer)\\nLocation \\n(character string)\\nTime of Measurement \\n(time of day)\\nID for Buoy\\nDrift Message\\nChange in Latitude \\n(floating point)\\nChange in Longitude\\n(floating point)\\nTime of Measurement \\n(time of day)\\nID for Buoy\\nLocation Message\\nLatitude\\n(floating point)\\nLongitude \\n(floating point)\\nDepth \\n(integer)\\nTime of Measurement \\n(time of day)'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 455}, page_content='18.2 Direct Access Tables 419\\nThe pseudocode is abbreviated because you can get the idea without seeing all 20 cases.\\nObject-Oriented Approach\\nIf you were using a rote object-oriented approach, the logic would be hidden in the \\nobject inheritance structure but the basic structure would be just as complicated: \\nWhile more messages to read\\n   Read a message header\\n   Decode the message ID from the message header\\n   If the message header is type 1 then\\n      Instantiate a type 1 message object\\n   Else if the message header is type 2 then\\n      Instantiate a type 2 message object\\n   ...\\n   Else if the message header is type 19 then\\n      Instantiate a type 19 message object\\n   Else if the message header is type 20 then\\n      Instantiate a type 20 message object\\n   End if\\nEnd While\\nRegardless of whether the logic is written directly or contained within specialized \\nclasses, each of the 20 kinds of messages will have its own routine for printing its mes-\\nsage. Each routine could also be expressed in pseudocode. This is the pseudocode for \\nthe routine to read and print the buoy temperature message:\\nPrint \"Buoy Temperature Message\"\\nRead a floating-point value\\nPrint \"Average Temperature\"\\nPrint the floating-point value\\nRead a floating-point value\\nPrint \"Temperature Range\"\\nPrint the floating-point value\\nRead an integer value\\nPrint \"Number of Samples\"\\nPrint the integer value\\nRead a character string\\nPrint \"Location\"\\nPrint the character string\\nRead a time of day\\nPrint \"Time of Measurement\"\\nPrint the time of day\\nThis is the code for just one kind of message. Each of the other 19 kinds of messages \\nwould require similar code. And if a 21st kind of message was added, either a 21st rou-\\ntine or a 21st subclass would need to be added—either way a new message type would \\nrequire the code to be changed.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 456}, page_content='420 Chapter 18: Table-Driven Methods\\nTable-Driven Approach\\nThe table-driven approach is more economical than the previous approach. The mes-\\nsage-reading routine consists of a loop that reads each message header, decodes the \\nID, looks up the message description in the Message array, and then calls the same \\nroutine every time to decode the message. With a table-driven approach, you can \\ndescribe the format of each message in a table rather than hard-coding it in program \\nlogic. This makes it easier to code originally, generates less code, and makes it easier to \\nmaintain without changing code. \\nTo use this approach, you start by listing the kinds of messages and the types of fields. \\nIn C++, you could define the types of all the possible fields this way:\\nC+ + Example of Defining Message Data Types \\nenum FieldType { \\n   FieldType_FloatingPoint, \\n   FieldType_Integer,\\n   FieldType_String,\\n   FieldType_TimeOfDay, \\n   FieldType_Boolean, \\n   FieldType_BitField,\\n   FieldType_Last = FieldType_BitField\\n};\\nRather than hard-coding printing routines for each of the 20 kinds of messages, you \\ncan create a handful of routines that print each of the primary data types—floating \\npoint, integer, character string, and so on. You can describe the contents of each kind \\nof message in a table (including the name of each field) and then decode each mes-\\nsage based on the description in the table. A table entry to describe one kind of mes-\\nsage might look like this:\\nExample of Defining a Message Table Entry\\nMessage Begin\\n   NumFields 5\\n   MessageName \"Buoy Temperature Message\"\\n   Field 1, FloatingPoint, \"Average Temperature\"\\n   Field 2, FloatingPoint, \"Temperature Range\"\\n   Field 3, Integer, \"Number of Samples\"\\n   Field 4, String, \"Location\"\\n   Field 5, TimeOfDay, \"Time of Measurement\"\\nMessage End\\nThis table could be hard-coded in the program (in which case, each of the elements \\nshown would be assigned to variables), or it could be read from a file at program star-\\ntup time or later. \\nOnce message definitions are read into the program, instead of having all the informa-\\ntion embedded in a program’s logic, you have it embedded in data. Data tends to be'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 457}, page_content='18.2 Direct Access Tables 421\\nmore flexible than logic. Data is easy to change when a message format changes. If you \\nhave to add a new kind of message, you can just add another element to the data table.\\nHere’s the pseudocode for the top-level loop in the table-driven approach:\\nThe first three lines here \\nare the same as in the \\nlogic-based approach.\\nWhile more messages to read\\n   Read a message header\\n   Decode the message ID from the message header\\n   Look up the message description in the message-description table\\n   Read the message fields and print them based on the message description\\nEnd While\\nUnlike the pseudocode for the logic-based approach, the pseudocode in this case isn’t \\nabbreviated because the logic is so much less complicated. In the logic below this \\nlevel, you’ll find one routine that’s capable of interpreting a message description from \\nthe message description table, reading message data, and printing a message. That \\nroutine is more general than any of the logic-based message-printing routines but not \\nmuch more complicated, and it will be one routine instead of 20:\\nWhile more fields to print\\n   Get the field type from the message description\\n   case ( field type )\\n      of ( floating point )\\n         read a floating-point value\\n         print the field label\\n         print the floating-point value\\n      of ( integer )\\n         read an integer value\\n         print the field label\\n         print the integer value\\n      of ( character string )\\n         read a character string\\n         print the field label\\n         print the character string\\n      of ( time of day )\\n         read a time of day\\n         print the field label\\n         print the time of day\\n      of ( boolean )\\n         read a single flag\\n         print the field label\\n         print the single flag\\n      of ( bit field )\\n         read a bit field\\n         print the field label\\n         print the bit field\\n   End Case\\nEnd While'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 458}, page_content='422 Chapter 18: Table-Driven Methods\\nAdmittedly, this routine with its six cases is longer than the single routine needed to \\nprint the buoy temperature message. But this is the only routine you need. You don’t \\nneed 19 other routines for the 19 other kinds of messages. This routine handles the \\nsix field types and takes care of all the kinds of messages.\\nThis routine also shows the most complicated way of implementing this kind of table \\nlookup because it uses a case statement. Another approach would be to create an \\nabstract class AbstractField and then create subclasses for each field type. You won’t need \\na case statement; you can call the member routine of the appropriate type of object. \\nHere’s how you would set up the object types in C++:\\nC+ + Example of Setting Up Object Types\\nclass AbstractField {\\n   public:\\n   virtual void ReadAndPrint( string, FileStatus & ) = 0;\\n};\\nclass FloatingPointField : public AbstractField {\\n   public:\\n   virtual void ReadAndPrint( string, FileStatus & ) {\\n   ...\\n   }\\n};\\nclass IntegerField ...\\nclass StringField ...\\n...\\nThis code fragment declares a member routine for each class that has a string param-\\neter and a FileStatus parameter.\\nThe next step is to declare an array to hold the set of objects. The array is the lookup \\ntable, and here’s how it looks:\\nC+ + Example of Setting Up a T able to Hold an Object of Each Type\\nAbstractField* field[ Field_Last+1];\\nThe final step required to set up the table of objects is to assign the names of specific \\nobjects to the Field  array:\\nC+ + Example of Setting Up a List of Objects\\nfield[ Field_FloatingPoint ] = new FloatingPointField();\\nfield[ Field_Integer ] = new IntegerField();\\nfield[ Field_String ] = new StringField();\\nfield[ Field_TimeOfDay ] = new TimeOfDayField();\\nfield[ Field_Boolean ] = new BooleanField();\\nfield[ Field_BitField ] = new BitFieldField();\\nC18619670.fm  Page 422  Tuesday, April 12, 2011  5:37 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 459}, page_content='18.2 Direct Access Tables 423\\nThis code fragment assumes that FloatingPointField and the other identifiers on the \\nright side of the assignment statements are names of objects of type AbstractField. \\nAssigning the objects to array elements in the array means that you can call the cor-\\nrect ReadAndPrint() routine by referencing an array element instead of by using a spe-\\ncific kind of object directly.\\nOnce the table of routines is set up, you can handle a field in the message simply by \\naccessing the table of objects and calling one of the member routines in the table. The \\ncode looks like this:\\nC+ + Example of Looking Up Objects and Member Routines in a T able\\nThis stuff is just house-\\nkeeping for each field in \\na message.\\nfieldIdx = 1;\\nwhile ( ( fieldIdx <= numFieldsInMessage ) && ( fileStatus == OK ) ) {\\n   fieldType = fieldDescription[ fieldIdx ].FieldType; \\n   fieldName = fieldDescription[ fieldIdx ].FieldName;\\nThis is the table lookup that \\ncalls a routine depending \\non the type of the field—\\njust by looking it up in a \\ntable of objects.\\n   field[ fieldType ].ReadAndPrint( fieldName, fileStatus );\\n   fieldIdx++;\\n}\\nRemember the original 34 lines of table-lookup pseudocode containing the case state-\\nment? If you replace the case statement with a table of objects, this is all the code you’d \\nneed to provide the same functionality. Incredibly, it’s also all the code needed to \\nreplace all 20 of the individual routines in the logic-based approach. Moreover, if the \\nmessage descriptions are read from a file, new message types won’t require code \\nchanges unless there’s a new field type. \\nYou can use this approach in any object-oriented language. It’s less error-prone, more \\nmaintainable, and more efficient than lengthy if statements, case statements, or copi-\\nous subclasses. \\nThe fact that a design uses inheritance and polymorphism doesn’t make it a good \\ndesign. The rote object-oriented design described earlier in the “Object-Oriented \\nApproach” section would require as much code as a rote functional design—or more. \\nThat approach made the solution space more complicated, rather than less. The key \\ndesign insight in this case is neither object orientation nor functional orientation—it’s \\nthe use of a well thought out lookup table. \\nFudging Lookup Keys\\nIn each of the three previous examples, you could use the data to key into the table \\ndirectly. That is, you could use messageID as a key without alteration, as you could use \\nmonth in the days-per-month example and gender, maritalStatus, and smokingStatus in \\nthe insurance rates example.\\nYou’d always like to key into a table directly because it’s simple and fast. Sometimes, \\nhowever, the data isn’t cooperative. In the insurance rates example, age wasn’t well \\nbehaved. The original logic had one rate for people under 18, individual rates for ages \\nC18619670.fm  Page 423  Tuesday, April 12, 2011  3:08 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 460}, page_content='424 Chapter 18: Table-Driven Methods\\n18 through 65, and one rate for people over 65. This meant that for ages 0 through 17 \\nand 66 and over, you couldn’t use the age to key directly into a table that stored only \\none set of rates for several ages. \\nThis leads to the topic of fudging table-lookup keys. You can fudge keys in several ways:\\nDuplicate information to make the key work directly One straightforward way to \\nmake age work as a key into the rates table is to duplicate the under-18 rates for each \\nof the ages 0 through 17 and then use the age to key directly into the table. You can do \\nthe same thing for ages 66 and over. The benefits of this approach are that the table \\nstructure itself is straightforward and the table accesses are also straightforward. If \\nyou needed to add age-specific rates for ages 17 and below, you could just change the \\ntable. The drawbacks are that the duplication would waste space for redundant infor-\\nmation and increase the possibility of errors in the table—if only because the table \\nwould contain redundant data.\\nTransform the key to make it work directly A second way to make Age work as a \\ndirect key is to apply a function to Age so that it works well. In this case, the function \\nwould have to change all ages 0 through 17 to one key, say 17, and all ages above 66 to \\nanother key, say 66. This particular range is well behaved enough that you could use \\nmin() and max() functions to make the transformation. For example, you could use \\nthe expression\\nmax( min( 66, Age ), 17 )\\nto create a table key that ranges from 17 to 66.\\nCreating the transformation function requ ires that you recognize a pattern in the \\ndata you want to use as a key, and that’s not always as simple as using the min() and \\nmax() routines. Suppose that in this example the rates were for five-year age bands \\ninstead of one-year bands. Unless you wanted  to duplicate all your data five times, \\nyou’d have to come up with a function that divided Age by 5 properly and used the \\nmin() and max() routines.\\nIsolate the key transformation in its own routine If you have to fudge data to make \\nit work as a table key, put the operation that changes the data to a key into its own rou-\\ntine. A routine eliminates the possibility of using different transformations in different \\nplaces. It makes modifications easier when the transformation changes. A good name \\nfor the routine, like KeyFromAge(), also clarifies and documents the purpose of the \\nmathematical machinations. \\nIf your environment provides ready-made key transformations, use them. For exam-\\nple, Java provides HashMap, which can be used to associate key/value pairs.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 461}, page_content='18.3 Indexed Access Tables 425\\n18.3 Indexed Access Tables\\nSometimes a simple mathematical transformation isn’t powerful enough to make the \\njump from data like Age to a table key. Some such cases are suited to the use of an \\nindexed access scheme.\\nWhen you use indexes, you use the primary data to look up a key in an index table and \\nthen you use the value from the index table to look up the main data you’re interested in.\\nSuppose you run a warehouse and have an inventory of about 100 items. Suppose fur-\\nther that each item has a four-digit part number that ranges from 0000 through 9999. \\nIn this case, if you want to use the part number to key directly into a table that \\ndescribes some aspect of each item, you set up an index array with 10,000 entries \\n(from 0 through 9999). The array is empty except for the 100 entries that correspond \\nto part numbers of the 100 items in your warehouse. As Figure 18-4 shows, those \\nentries point to an item-description table that has far fewer than 10,000 entries.\\nFigure 18-4 Rather than being accessed directly, an indexed access table is accessed via an \\nintermediate index. \\nIndexed access schemes offer two main advantages. First, if each of the entries in the \\nmain lookup table is large, it takes a lot less space to create an index array with a lot of \\nwasted space than it does to create a main lookup table with a lot of wasted space. For \\nexample, suppose that the main table takes 100 bytes per entry and that the index \\nArray of Indexes into \\nLookup Table \\n(mostly empty)\\nLookup Table \\n(mostly full)'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 462}, page_content='426 Chapter 18: Table-Driven Methods\\narray takes 2 bytes per entry. Suppose that the main table has 100 entries and that the \\ndata used to access it has 10,000 possible values. In such a case, the choice is between \\nhaving an index with 10,000 entries or a main data member with 10,000 entries. If \\nyou use an index, your total memory use is 30,000 bytes. If you forgo the index struc-\\nture and waste space in the main table, your total memory use is 1,000,000 bytes.\\nThe second advantage, even if you don’t save space by using an index, is that it’s some-\\ntimes cheaper to manipulate entries in an index than entries in a main table. For \\nexample, if you have a table with employee names, hiring dates, and salaries, you can \\ncreate one index that accesses the table by employee name, another that accesses the \\ntable by hiring date, and a third that accesses the table by salary.\\nA final advantage of an index-access scheme is the general table-lookup advantage of \\nmaintainability. Data encoded in tables is easier to maintain than data embedded in \\ncode. To maximize the flexibility, put the index-access code in its own routine and call \\nthe routine when you need to get a table key from a part number. When it’s time to \\nchange the table, you might decide to switch the index-accessing scheme or switch to \\nanother table-lookup scheme altogether. The access scheme will be easier to change if \\nyou don’t spread index accesses throughout your program.\\n18.4 Stair-Step Access Tables\\nYet another kind of table access is the stair-step method. This access method isn’t as \\ndirect as an index structure, but it doesn’t waste as much data space.\\nThe general idea of stair-step structures, illustrated in Figure 18-5, is that entries in a \\ntable are valid for ranges of data rather than for distinct data points. \\nFigure 18-5 The stair-step approach categorizes each entry by determining the level at \\nwhich it hits a “staircase.” The “step” it hits determines its category.\\nFor example, if you’re writing a grading program, the “B” entry range might be from 75 \\npercent to 90 percent. Here’s a range of grades you might have to program someday:\\n≥ 90.0% A\\n< 90.0% B\\n< 75.0% C\\n< 65.0% D\\n< 50.0% F'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 463}, page_content='18.4 Stair-Step Access Tables 427\\nThis is an ugly range for a table lookup because you can’t use a simple data-transfor-\\nmation function to key into the letters A through F. An index scheme would be awk-\\nward because the numbers are floating point. You might consider converting the \\nfloating-point numbers to integers, and in this case that would be a valid design \\noption, but for the sake of illustration, this example will stick with floating point.\\nTo use the stair-step method, you put the upper end of each range into a table and \\nthen write a loop to check a score against the upper end of each range. When you find \\nthe point at which the score first exceeds the top of a range, you know what the grade \\nis. With the stair-step technique, you have to be careful to handle the endpoints of the \\nranges properly. Here’s the code in Visual Basic that assigns grades to a group of stu-\\ndents based on this example:\\nVisual Basic Example of a Stair-Step Table Lookup\\n\\' set up data for grading table\\nDim rangeLimit() As Double = { 50.0, 65.0, 75.0, 90.0, 100.0 }\\nDim grade() As String =  { \"F\",  \"D\",  \"C\",  \"B\",  \"A\"  }\\nmaxGradeLevel = grade.Length – 1\\n...\\n\\' assign a grade to a student based on the student\\'s score\\ngradeLevel = 0\\nstudentGrade = \"A\"\\nWhile ( ( studentGrade = \"A\" ) and ( gradeLevel < maxGradeLevel ) )\\n   If ( studentScore < rangeLimit( gradeLevel ) ) Then\\n      studentGrade = grade( gradeLevel )\\n   End If\\n   gradeLevel = gradeLevel + 1\\nWend\\nAlthough this is a simple example, you can easily generalize it to handle multiple stu-\\ndents, multiple grading schemes (for example, different grades for different point lev-\\nels on different assignments), and changes in the grading scheme. \\nThe advantage of this approach over other table-driven methods is that it works well \\nwith irregular data. The grading example is simple in that, although grades are \\nassigned at irregular intervals, the numbers are “round,” ending with 5s and 0s. The \\nstair-step approach is equally well suited to data that doesn’t end neatly with 5s and \\n0s. You can use the stair-step approach in statistics work for probability distributions \\nwith numbers like this:\\nProbability Insurance Claim Amount\\n0.458747 $0.00\\n0.547651 $254.32\\n0.627764 $514.77\\n0.776883 $747.82\\n0.893211 $1,042.65'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 464}, page_content='428 Chapter 18: Table-Driven Methods\\nUgly numbers like these defy any attempt to come up with a function to neatly trans-\\nform them into table keys. The stair-step approach is the answer. \\nThis approach also enjoys the general advantages of table-driven approaches: it’s flex-\\nible and modifiable. If the grading ranges in the grading example were to change, the \\nprogram could easily be adapted by modifying the entries in the RangeLimit array. You \\ncould easily generalize the grade-assignment part of the program so that it would \\naccept a table of grades and corresponding cut-off scores. The grade-assignment part \\nof the program wouldn’t have to use scores expressed as percentages; it could use raw \\npoints rather than percentages, and the program wouldn’t have to change much.\\nHere are a few subtleties to consider as you use the stair-step technique: \\nWatch the endpoints Make sure you’ve covered the case at the top end of each stair-\\nstep range. Run the stair-step search so that it finds items that map to any range other \\nthan the uppermost range, and then have the rest fall into the uppermost range. \\nSometimes this requires creating an artificial value for the top of the uppermost range.\\nBe careful about mistaking < for <=. Make sure that the loop terminates properly with \\nvalues that fall into the top ranges and that the range boundaries are handled correctly.\\nConsider using a binary search rather then a sequential search  In the grading \\nexample, the loop that assigns the grade se arches sequentially through the list of \\ngrading limits. If you had a larger list, the cost of the sequential search might become \\nprohibitive. If it does, you can replace it with a quasi-binary search. It’s a “quasi” \\nbinary search because the point of most binary searches is to find a value. In this case, \\nyou don’t expect to find the value; you expect to find the right category for the value. \\nThe binary-search algorithm must correctly  determine where the value should go. \\nRemember also to treat the endpoint as a special case.\\nConsider using indexed access instead of the stair-step technique An index-access \\nscheme such as the ones described in Section 18.3 might be a good alternative to a stair-\\nstep technique. The searching required in the stair-step method can add up, and if exe-\\ncution speed is a concern, you might be willing to trade the space an extra index struc-\\nture takes up for the time advantage you get with a more direct access method.\\nObviously, this alternative isn’t a good choice in all cases. In the grading example, you \\ncould probably use it; if you had only 100 discrete percentage points, the memory cost \\nof setting up an index array wouldn’t be prohibitive. If, on the other hand, you had the \\n0.957665 $5,887.55\\n0.976544 $12,836.98\\n0.987889 $27,234.12\\n...\\nProbability Insurance Claim Amount'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 465}, page_content='18.5 Other Examples of Table Lookups 429\\nprobability data listed earlier, you couldn’t set up an indexing scheme because you \\ncan’t key into entries with numbers like 0.458747 and 0.547651.\\nCross-Reference For more \\non good approaches to \\nchoosing design alternatives, \\nsee Chapter 5, “Design in \\nConstruction.”\\nIn some cases, any of the several options might work. The point of design is choosing \\none of the several good options for your case. Don’t worry too much about choosing \\nthe best one. As Butler Lampson, a distinguished engineer at Microsoft, says, it’s better \\nto strive for a good solution and avoid disaster rather than trying to find the best solu-\\ntion (Lampson 1984).\\nPut the stair-step table lookup into its own routine When you create a transforma-\\ntion function that changes a value like StudentGrade into a table key, put it into its own \\nroutine.\\n18.5 Other Examples of Table Lookups\\nA few other examples of table lookups appear in other sections of the book. They’re \\nused in the course of discussing other techniques, and the contexts don’t emphasize \\nthe table lookups per se. Here’s where you’ll find them:\\n■ Looking up rates in an insurance table: Section 16.3, “Creating Loops Easily—\\nFrom the Inside Out”\\n■ Using decision tables to replace complicated logic: “Use decision tables to \\nreplace complicated conditions” in Section 19.1.\\n■ Cost of memory paging during a table lookup: Section 25.3, “Kinds of Fat and \\nMolasses”\\n■ Combinations of boolean values (A or B or C): “Substitute Table Lookups for \\nComplicated Expressions” in Section 26.1\\n■ Precomputing values in a loan repayment table: Section 26.4, “Expressions.”\\ncc2e.com/1872 CHECKLIST: Table-Driven Methods\\n❑ Have you considered table-driven methods as an alternative to compli-\\ncated logic? \\n❑ Have you considered table-driven methods as an alternative to compli-\\ncated inheritance structures? \\n❑ Have you considered storing the table’s data externally and reading it at \\nrun time so that the data can be  modified without changing code? \\n❑ If the table cannot be accessed directly via a straightforward array index \\n(as in the age example), have you put the access-key calculation into a rou-\\ntine rather than duplicating the index calculation in the code?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 466}, page_content='430 Chapter 18: Table-Driven Methods\\nKey Points\\n■ Tables provide an alternative to complicated logic and inheritance structures. If \\nyou find that you’re confused by a program’s logic or inheritance tree, ask your-\\nself whether you could simplify by using a lookup table.\\n■ One key consideration in using a table is deciding how to access the table. You \\ncan access tables by using direct access, indexed access, or stair-step access. \\n■ Another key consideration in using a table is deciding what exactly to put into \\nthe table.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 467}, page_content='431\\nChapter 19\\nGeneral Control Issues\\ncc2e.com/1978 Contents\\n■ 19.1 Boolean Expressions: page 431\\n■ 19.2 Compound Statements (Blocks): page 443\\n■ 19.3 Null Statements: page 444\\n■ 19.4 Taming Dangerously Deep Nesting: page 445\\n■ 19.5 A Programming Foundation: Structured Programming: page 454\\n■ 19.6 Control Structures and Complexity: page 456\\nRelated Topics\\n■ Straight-line code: Chapter 14\\n■ Code with conditionals: Chapter 15\\n■ Code with loops: Chapter 16\\n■ Unusual control structures: Chapter 17\\n■ Complexity in software development: “Software’s Primary Technical Imperative: \\nManaging Complexity” in Section 5.2\\nNo discussion of control would be complete unless it went into several general issues \\nthat crop up when you think about control constructs. Most of the information in this \\nchapter is detailed and pragmatic. If you’re reading for the theory of control structures \\nrather than for the gritty details, concentrate on the historical perspective on struc-\\ntured programming in Section 19.5 and on the relationships between control struc-\\ntures in Section 19.6.\\n19.1 Boolean Expressions\\nExcept for the simplest control structure, the one that calls for the execution of statements \\nin sequence, all control structures depend on the evaluation of boolean expressions.\\nUsing true and false for Boolean Tests\\nUse the identifiers true and false in boolean expressions rather than using values like \\n0 and 1. Most modern languages have a boolean data type and provide predefined \\nidentifiers for true and false. They make it easy—they don’t even allow you to assign'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 468}, page_content='432 Chapter 19: General Control Issues\\nvalues other than true or false to boolean variables. Languages that don’t have a bool-\\nean data type require you to have more discipline to make boolean expressions read-\\nable. Here’s an example of the problem:\\nVisual Basic Examples of Using Ambiguous Flags for Boolean Values\\nDim printerError As Integer\\nDim reportSelected As Integer\\nDim summarySelected As Integer\\n...\\nIf printerError = 0 Then InitializePrinter()\\nIf printerError = 1 Then NotifyUserOfError()\\nIf reportSelected = 1 Then PrintReport()\\nIf summarySelected = 1 Then PrintSummary()\\nIf printerError = 0 Then CleanupPrinter()\\nIf using flags like 0 and 1 is common practice, what’s wrong with it? It’s not clear from \\nreading the code whether the function calls are executed when the tests are true or \\nwhen they’re false. Nothing in the code fragment itself tells you whether 1 represents \\ntrue and 0 false or whether the opposite is true. It’s not even clear that the values 1 and \\n0 are being used to represent true and false. For example, in the If reportSelected = 1 line, \\nthe 1 could easily represent the first report, a 2 the second, a 3 the third; nothing in the \\ncode tells you that 1 represents either true or false. It’s also easy to write 0 when you \\nmean 1 and vice versa.\\nUse terms named true and false for tests with boolean expressions. If your language \\ndoesn’t support such terms directly, create them using preprocessor macros or global \\nvariables. The previous code example is rewritten here using Microsoft Visual Basic’s \\nbuilt-in True and False:\\nGood, but Not Great Visual Basic Examples of Using True and False for Tests Instead \\nof Numeric Values\\nCross-Reference For an \\neven better approach to \\nmaking these same tests, \\nsee the next code example. \\nDim printerError As Boolean\\nDim reportSelected As ReportType\\nDim summarySelected As Boolean\\n...\\nIf ( printerError = False ) Then InitializePrinter()\\nIf ( printerError = True ) Then NotifyUserOfError()\\nIf ( reportSelected = ReportType_First ) Then PrintReport()\\nIf ( summarySelected = True ) Then PrintSummary()\\nIf ( printerError = False ) Then CleanupPrinter()\\nUse of the True and False constants makes the intent clearer. You don’t have to remem-\\nber what 1 and 0 represent, and you won’t accidentally reverse them. Moreover, in the \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 469}, page_content='19.1 Boolean Expressions 433\\nrewritten code, it’s now clear that some of the 1s and 0s in the original Visual Basic \\nexample weren’t being used as boolean flags. The If reportSelected = 1 line was not a \\nboolean test at all; it tested whether the first report had been selected.\\nThis approach tells the reader that you’re making a boolean test. It’s also harder to \\nwrite true when you mean false than it is to write 1 when you mean 0, and you avoid \\nspreading the magic numbers 0 and 1 throughout your code. Here are some tips on \\ndefining true and false in boolean tests:\\nCompare boolean values to true and false implicitly You can write clearer tests by \\ntreating the expressions as boolean expressions. For example, write\\nwhile ( not done ) ...\\nwhile ( a > b ) ...\\nrather than\\nwhile ( done = false ) ...\\nwhile ( (a > b) = true ) ...\\nUsing implicit comparisons reduces the number of terms that someone reading your \\ncode has to keep in mind, and the resulting expressions read more like conversational \\nEnglish. The previous example could be rewritten with even better style like this:\\nBetter Visual Basic Examples of Testing for True and False Implicitly\\nDim printerError As Boolean\\nDim reportSelected As ReportType\\nDim summarySelected As Boolean\\n...\\nIf ( Not printerError ) Then InitializePrinter()\\nIf ( printerError ) Then NotifyUserOfError()\\nIf ( reportSelected = ReportType_First ) Then PrintReport()\\nIf ( summarySelected ) Then PrintSummary()\\nIf ( Not printerError ) Then CleanupPrinter()\\nCross-Reference For details, \\nsee Section 12.5, “Boolean \\nVariables.”\\nIf your language doesn’t support boolean variables and you have to emulate them, you \\nmight not be able to use this technique because emulations of true and false can’t \\nalways be tested with statements like while ( not done ).\\nMaking Complicated Expressions Simple\\nYou can take several steps to simplify complicated expressions:\\nBreak complicated tests into partial tests with new boolean variables Rather than \\ncreating a monstrous test with half a dozen terms, assign intermediate values to terms \\nthat allow you to perform a simpler test.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 470}, page_content=\"434 Chapter 19: General Control Issues\\nMove complicated expressions into boolean functions If a test is repeated often or \\ndistracts from the main flow of the program, move the code for the test into a function \\nand test the value of the function. For example, here’s a complicated test:\\nVisual Basic Example of a Complicated Test\\nIf ( ( document.AtEndOfStream ) And ( Not inputError ) ) And _\\n   ( ( MIN_LINES <= lineCount ) And ( lineCount <= MAX_LINES ) ) And _\\n   ( Not ErrorProcessing(  ) ) Then\\n   ' do something or other\\n   ...\\nEnd If\\nThis is an ugly test to have to read through if you’re not interested in the test itself. By \\nputting it into a boolean function, you can isolate the test and allow the reader to for-\\nget about it unless it’s important. Here’s how you could put the if test into a function:\\nCross-Reference For details \\non the technique of using \\nintermediate variables to \\nclarify a boolean test, see \\n“Use boolean variables to \\ndocument your program” in \\nSection 12.5.\\nVisual Basic Example of a Complicated Test Moved into a Boolean Function, with \\nNew Intermediate Variables to Make the Test Clearer\\nFunction DocumentIsValid( _\\n   ByRef documentToCheck As Document, _\\n   lineCount As Integer, _\\n   inputError As Boolean _\\n   ) As Boolean\\n   \\n   Dim allDataRead As Boolean\\n   Dim legalLineCount As Boolean\\nIntermediate variables are \\nintroduced here to clarify the \\ntest on the final line, below. \\n   allDataRead = ( documentToCheck.AtEndOfStream ) And ( Not inputError )\\n   legalLineCount = ( MIN_LINES <= lineCount ) And ( lineCount <= MAX_LINES )\\n   DocumentIsValid = allDataRead And legalLineCount And ( Not ErrorProcessing() )\\nEnd Function\\nThis example assumes that ErrorProcessing() is a boolean function that indicates the \\ncurrent processing status. Now, when you read through the main flow of the code, \\nyou don’t have to read the complicated test:\\nVisual Basic Example of the Main Flow of the Code Without the Complicated Test\\nIf ( DocumentIsValid( document, lineCount, inputError ) ) Then\\n   ' do something or other\\n   ...\\nEnd If \\nIf you use the test only once, you might not think it’s worthwhile to put it into a rou-\\ntine. But putting the test into a well-named function improves readability and makes \\nit easier for you to see what your code is doing, and that’s a sufficient reason to do it. \\nKEY POINT\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 471}, page_content='19.1 Boolean Expressions 435\\nThe new function name introduces an abstraction into the program that documents \\nthe purpose of the test in code. That’s even better than documenting the test with \\ncomments because the code is more likely to be read than the comments and it’s \\nmore likely to be kept up to date, too. \\nCross-Reference For details \\non using tables as substi-\\ntutes for complicated logic, \\nsee Chapter 18, “Table-\\nDriven Methods.”\\nUse decision tables to replace complicated conditions Sometimes you have a compli-\\ncated test involving several variables. It can be helpful to use a decision table to per-\\nform the test rather than using ifs or cases. A decision-table lookup is easier to code \\ninitially, having only a couple of lines of code and no tricky control structures. This \\nminimization of complexity minimizes the opportunity for mistakes. If your data \\nchanges, you can change a decision table without changing the code; you only need to \\nupdate the contents of the data structure.\\nForming Boolean Expressions Positively\\nI ain’t not no undummy.\\n—Homer Simpson\\nNot a few people don’t have not any trouble understanding a nonshort string of \\nnonpositives—that is, most people have trouble understanding a lot of negatives. \\nYou can do several things to avoid complicated negative boolean expressions in \\nyour programs:\\nIn if statements, convert negatives to positives and flip-flop the code in the if and else \\nclauses Here’s an example of a negatively expressed test:\\nJava Example of a Confusing Negative Boolean Test\\nHere’s the negative not. if ( !statusOK ) {\\n   // do something\\n   ...\\n}\\nelse {\\n   // do something else\\n   ...\\n}\\nYou can change this to the following positively expressed test:\\nThe test in this line has \\nbeen reversed.\\nJava Example of a Clearer Positive Boolean Test\\nif ( statusOK ) {\\n   // do something else\\nThe code in this block has \\nbeen switched...\\n   ...\\n}\\nelse {\\n...with the code in this block.    // do something\\n   ...\\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 472}, page_content='436 Chapter 19: General Control Issues\\nCross-Reference The rec-\\nommendation to frame \\nboolean expressions posi-\\ntively sometimes contradicts \\nthe recommendation to \\ncode the nominal case after \\nthe if rather than the else. \\n(See Section 15.1, “if State-\\nments.”) In such a case, you \\nhave to think about the ben-\\nefits of each approach and \\ndecide which is better for \\nyour situation.\\nThe second code fragment is logically the same as the first but is easier to read \\nbecause the negative expression has been changed to a positive.\\nAlternatively, you could choose a different variable name, one that would reverse the \\ntruth value of the test. In the example, you could replace statusOK with ErrorDetected, \\nwhich would be true when statusOK was false.\\nApply DeMorgan’s Theorems to simplify boolean tests with negatives DeMorgan’s \\nTheorems let you exploit the logical relationship between an expression and a version \\nof the expression that means the same thing because it’s doubly negated. For exam-\\nple, you might have a code fragment that contains the following test:\\nJava Example of a Negative Test\\nif ( !displayOK || !printerOK ) ...\\nThis is logically equivalent to the following:\\nJava Example After Applying DeMorgan’s Theorems\\nif ( !( displayOK && printerOK ) ) ...\\nHere you don’t have to flip-flop if and else clauses; the expressions in the last two code \\nfragments are logically equivalent. To apply DeMorgan’s Theorems to the logical oper-\\nator and or the logical operator or and a pair of operands, you negate each of the oper-\\nands, switch the ands and ors, and negate the entire expression. Table 19-1 \\nsummarizes the possible transformations under DeMorgan’s Theorems.\\nTable 19-1 Transformations of Logical Expressions Under DeMorgan’s Theorems\\nInitial Expression Equivalent Expression\\nnot A and not B not ( A or B )\\nnot A and B not ( A or not B )\\nA and not B not ( not A or B )\\nA and B not ( not A or not B )\\nnot A or not B*\\n* This is the expression used in the example.\\nnot ( A and B )\\nnot A or B not ( A and not B )\\nA or not B not ( not A and B )\\nA or B not ( not A and not B )'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 473}, page_content='19.1 Boolean Expressions 437\\nUsing Parentheses to Clarify Boolean Expressions\\nCross-Reference For an \\nexample of using parenthe-\\nses to clarify other kinds of \\nexpressions, see “Parenthe-\\nses” in Section 31.2.\\nIf you have a complicated boolean expression, rather than relying on the language’s \\nevaluation order, parenthesize to make your meaning clear. Using parentheses makes \\nless of a demand on your reader, who might not understand the subtleties of how \\nyour language evaluates boolean expressions. If you’re smart, you won’t depend on \\nyour own or your reader’s in-depth memorization of evaluation precedence—espe-\\ncially when you have to switch among two or more languages. Using parentheses isn’t \\nlike sending a telegram: you’re not charged for each character—the extra characters are \\nfree.\\nHere’s an expression with too few parentheses:\\nJava Example of an Expression Containing Too Few Parentheses\\nif ( a < b == c == d ) ...\\nThis is a confusing expression to begin with, and it’s even more confusing because it’s \\nnot clear whether the coder means to test ( a < b ) == ( c == d ) or ( ( a < b ) == c ) == d. \\nThe following version of the expression is still a little confusing, but the parentheses \\nhelp:\\nJava Example of an Expression Better Parenthesized\\nif ( ( a < b ) == ( c == d ) ) ...\\nIn this case, the parentheses help readability and the program’s correctness—the com-\\npiler wouldn’t have interpreted the first code fragment this way. When in doubt, \\nparenthesize.\\nCross-Reference Many pro-\\ngrammer-oriented text edi-\\ntors have commands that \\nmatch parentheses, brack-\\nets, and braces. For details \\non programming editors, see \\n“Editing” in Section 30.2.\\nUse a simple counting technique to balance parentheses If you have trouble telling \\nwhether parentheses balance, here’s a simple counting trick that helps. Start by saying \\n“zero.” Move along the expression, left to right. When you encounter an opening \\nparenthesis, say “one.” Each time you encounter another opening parenthesis, \\nincrease the number you say. Each time you encounter a closing parenthesis, decrease \\nthe number you say. If, at the end of the expression, you’re back to 0, your parentheses \\nare balanced.\\nJava Example of Balanced Parentheses\\nRead this. if ( ( ( a < b ) == ( c == d ) ) && !done ) ...\\n   | | |       |    |        | |          |\\nSay this. 0  1 2 3       2    3        2 1          0'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 474}, page_content='438 Chapter 19: General Control Issues\\nIn this example, you ended with a 0, so the parentheses are balanced. In the next \\nexample, the parentheses aren’t balanced:\\nJava Example of Unbalanced Parentheses\\nRead this. if ( ( a < b ) == ( c == d ) ) && !done ) ...\\n   | |       |    |        | |          |\\nSay this. 0  1 2       1    2        1 0         -1\\nThe 0 before you get to the last closing parenthesis is a tip-off that a parenthesis is \\nmissing before that point. You shouldn’t get a 0 until the last parenthesis of the \\nexpression.\\nFully parenthesize logical expressions Parentheses are cheap, and they aid readabil-\\nity. Fully parenthesizing logical expressions as a matter of habit is good practice. \\nKnowing How Boolean Expressions Are Evaluated\\nMany languages have an implied form of control that comes into play in the evalua-\\ntion of boolean expressions. Compilers for some languages evaluate each term in a \\nboolean expression before combining the terms and evaluating the whole expression. \\nCompilers for other languages have “short-circuit” or “lazy” evaluation, evaluating \\nonly the pieces necessary. This is particularly significant when, depending on the \\nresults of the first test, you might not want the second test to be executed. For exam-\\nple, suppose you’re checking the elements of an array and you have the following test:\\nPseudocode Example of an Erroneous Test\\nwhile ( i < MAX_ELEMENTS and item[ i ] <> 0 ) ...\\nIf this whole expression is evaluated, you’ll get an error on the last pass through the \\nloop. The variable i equals maxElements, so the expression item[ i ] is equivalent to \\nitem[ maxElements ], which is an array-index error. You might argue that it doesn’t mat-\\nter since you’re only looking at the value, not changing it. But it’s sloppy program-\\nming practice and could confuse someone reading the code. In many environments it \\nwill also generate either a run-time error or a protection violation. \\nIn pseudocode, you could restructure the test so that the error doesn’t occur:\\nPseudocode Example of a Correctly Restructured Test\\nwhile ( i < MAX_ELEMENTS ) \\n   if ( item[ i ] <> 0 ) then\\n      ...\\nThis is correct because item[ i ] isn’t evaluated unless i is less than maxElements.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 475}, page_content='19.1 Boolean Expressions 439\\nMany modern languages provide facilities that prevent this kind of error from hap-\\npening in the first place. For example, C++ uses short-circuit evaluation: if the first \\noperand of the and is false, the second isn’t evaluated because the whole expression \\nwould be false anyway. In other words, in C++ the only part of\\nif ( SomethingFalse && SomeCondition ) ...\\nthat’s evaluated is SomethingFalse. Evaluation stops as soon as SomethingFalse is iden-\\ntified as false.\\nEvaluation is similarly short-circuited with the or operator. In C++ and Java, the only \\npart of\\nif ( somethingTrue || someCondition ) ...\\nthat is evaluated is somethingTrue. The evaluation stops as soon as somethingTrue is \\nidentified as true because the expression is always true if any part of it is true. As a \\nresult of this method of evaluation, the following statement is a fine, legal statement.\\nJava Example of a Test That Works Because of Short-Circuit Evaluation\\nif ( ( denominator != 0 ) && ( ( item / denominator ) > MIN_VALUE ) ) ...\\nIf this full expression were evaluated when denominator equaled 0, the division in the \\nsecond operand would produce a divide-by-zero error. But since the second part isn’t \\nevaluated unless the first part is true, it is never evaluated when denominator equals 0, \\nso no divide-by-zero error occurs.\\nOn the other hand, because the && (and)  is evaluated left to right, the following log-\\nically equivalent statement doesn’t work:\\nJava Example of a Test That Short-Circuit Evaluation Doesn’t Rescue\\nif ( ( ( item / denominator ) > MIN_VALUE ) && ( denominator != 0 ) ) ...\\nIn this case, item / denominator is evaluated before denominator != 0. Consequently, \\nthis code commits the divide-by-zero error.\\nJava further complicates this picture by providing “logical” operators. Java’s logical & \\nand | operators guarantee that all terms will be fully evaluated regardless of whether \\nthe truth or falsity of the expression could be determined without a full evaluation. In \\nother words, in Java, this is safe:\\nJava Example of a Test That Works Because of Short-Circuit (Conditional) Evaluation\\nif ( ( denominator != 0 ) && ( ( item / denominator ) > MIN_VALUE ) ) ...'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 476}, page_content='440 Chapter 19: General Control Issues\\nBut this is not safe: \\nJava Example of a Test That Doesn’t Work Because Short-Circuit Evaluation Isn’t \\nGuaranteed\\nif ( ( denominator != 0 ) & ( ( item / denominator ) > MIN_VALUE ) ) ...\\nDifferent languages use different kinds of evaluation, and language implementers tend \\nto take liberties with expression evaluation, so check the manual for the specific ver-\\nsion of the language you’re using to find out what kind of evaluation your language \\nuses. Better yet, since a reader of your code might not be as sharp as you are, use \\nnested tests to clarify your intentions instead of depending on evaluation order and \\nshort-circuit evaluation.\\nWriting Numeric Expressions in Number-Line Order\\nOrganize numeric tests so that they follow the points on a number line. In general, \\nstructure your numeric tests so that you have comparisons like these:\\nMIN_ELEMENTS <= i and i <= MAX_ELEMENTS\\ni < MIN_ELEMENTS or MAX_ELEMENTS < i\\nThe idea is to order the elements left to right, from smallest to largest. In the first line, \\nMIN_ELEMENTS and MAX_ELEMENTS are the two endpoints, so they go at the ends. \\nThe variable i is supposed to be between them, so it goes in the middle. In the second \\nexample, you’re testing whether i is outside the range, so i goes on the outside of the \\ntest at either end and MIN_ELEMENTS and MAX_ELEMENTS go on the inside. This \\napproach maps easily to a visual image of the comparison in Figure 19-1:\\nFigure 19-1 Examples of using number-line ordering for boolean tests. \\nIf you’re testing i against MIN_ELEMENTS only, the position of i varies depending on \\nwhere i is when the test is successful. If i is supposed to be smaller, you’ll have a test \\nlike this:\\nwhile ( i < MIN_ELEMENTS ) ...\\nBut if i is supposed to be larger, you’ll have a test like this:\\nwhile ( MIN_ELEMENTS < i ) ...\\nKEY POINT\\nMIN_ELEMENTS <= i and i <= MAX_ELEMENTS\\nMIN_ELEMENTS Valid values for i MAX_ELEMENTS\\ni < MIN_ELEMENTS or MAX_ELEMENTS < i\\nMIN_ELEMENTS\\nValid values for i\\nMAX_ELEMENTS'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 477}, page_content=\"19.1 Boolean Expressions 441\\nThis approach is clearer than tests like\\n( i > MIN_ELEMENTS ) and ( i < MAX_ELEMENTS )\\nwhich give the reader no help in visualizing what is being tested.\\nGuidelines for Comparisons to 0 \\nProgramming languages use 0 for several purposes. It’s a numeric value. It’s a null ter-\\nminator in a string. It’s the value of a null pointer. It’s the value of the first item in an \\nenumeration. It’s false in logical expressions. Because it’s used for so many purposes, \\nyou should write code that highlights the specific way 0 is used.\\nCompare logical variables implicitly As mentioned earlier, it’s appropriate to write \\nlogical expressions such as\\nwhile ( !done ) ...\\nThis implicit comparison to 0 is appropriate because the comparison is in a logical \\nexpression.\\nCompare numbers to 0 Although it’s appropriate to compare logical expressions \\nimplicitly, you should compare numeric expressions explicitly. For numbers, write\\nwhile ( balance != 0 ) ...\\nrather than\\nwhile ( balance ) ...\\nCompare characters to the null terminator ('\\\\0') explicitly in C Characters, like \\nnumbers, aren’t logical expressions. Thus, for characters, write\\nwhile ( *charPtr != '\\\\0' ) ...\\nrather than\\nwhile ( *charPtr ) ...\\nThis recommendation goes against the common C convention for handling character \\ndata (as in the second example here), but it reinforces the idea that the expression is \\nworking with character data rather than logical data. Some C conventions aren’t \\nbased on maximizing readability or maintainability, and this is an example of one. \\nFortunately, this whole issue is fading into the sunset as more code is written using \\nC++ and STL strings. \\nCompare pointers to NULL For pointers, write\\nwhile ( bufferPtr != NULL ) ...\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 478}, page_content='442 Chapter 19: General Control Issues\\nrather than\\nwhile ( bufferPtr ) ...\\nLike the recommendation for characters, this one goes against the established C con-\\nvention, but the gain in readability justifies it.\\nCommon Problems with Boolean Expressions\\nBoolean expressions are subject to a few additional pitfalls that pertain to specific \\nlanguages: \\nIn C-derived languages, put constants on the left side of comparisons C-derived lan-\\nguages pose some special problems with boolean expressions. If you have problems \\nmistyping = instead of ==, consider the programming convention of putting constants \\nand literals on the left sides of expressions, like this:\\nC+ + Example of Putting a Constant on the Left Side of an Expression—An Error the \\nCompiler Will Catch\\nif ( MIN_ELEMENTS = i ) ...\\nIn this expression, the compiler should flag the single = as an error since assigning any-\\nthing to a constant is invalid. In contrast, in the following expression, the compiler will \\nflag this only as a warning, and only if you have compiler warnings fully turned on:\\nC+ + Example of Putting a Constant on the Right Side of an Expression—An Error the \\nCompiler Might Not Catch\\nif ( i = MIN_ELEMENTS ) ...\\nThis recommendation conflicts with the recommendation to use number-line order-\\ning. My personal preference is to use number-line ordering and let the compiler warn \\nme about unintended assignments. \\nIn C++, consider creating preprocessor macro substitutions for &&, ||, and == (but \\nonly as a last resort) If you have such a problem, it’s possible to create #define macros \\nfor boolean and and or, and use AND and OR instead of && and ||. Similarly, using = \\nwhen you mean == is an easy mistake to make. If you get stung often by this one, you \\nmight create a macro like EQUALS for logical equals (==).\\nMany experienced programmers view this approach as aiding readability for the pro-\\ngrammer who can’t keep details of the programming language straight but as degrad-\\ning readability for the programmer who is more fluent in the language. In addition, \\nmost compilers will provide error warnings for usages of assignment and bitwise'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 479}, page_content='19.2 Compound Statements (Blocks) 443\\noperators that seem like errors. Turning on full compiler warnings is usually a better \\noption than creating nonstandard macros. \\nIn Java, know the difference between a==b and a.equals(b) In Java, a==b tests for \\nwhether a and b refer to the same object, whereas a.equals(b) tests for whether the \\nobjects have the same logical value. In general, Java programs should use expressions \\nlike a.equals(b) rather than a==b. \\n19.2 Compound Statements (Blocks)\\nA “compound statement” or “block” is a collection of statements that are treated as a \\nsingle statement for purposes of controlling the flow of a program. Compound state-\\nments are created by writing { and } around a group of statements in C++, C#, C, and \\nJava. Sometimes they are implied by the keywords of a command, such as For and \\nNext in Visual Basic. Guidelines for using compound statements effectively follow:\\nCross-Reference Many pro-\\ngrammer-oriented text edi-\\ntors have commands that \\nmatch braces, brackets, and \\nparentheses. For details, see \\n“Editing” in Section 30.2.\\nWrite pairs of braces together Fill in the middle after you write both the opening \\nand closing parts of a block. People often complain about how hard it is to match pairs \\nof braces or begin-and-end pairs, and that’s a completely unnecessary problem. If you \\nfollow this guideline, you will never have trouble matching such pairs again.\\nWrite this first: \\nfor ( i = 0; i < maxLines; i++ )\\nWrite this next: \\nfor ( i = 0; i < maxLines; i++ ) {   }\\nWrite this last: \\nfor ( i = 0; i < maxLines; i++ ) {\\n   // whatever goes in here   ...   \\n}\\nThis applies to all blocking structures, including if, for, and while in C++ and Java and \\nthe If-Then-Else, For-Next, and While-Wend combinations in Visual Basic.\\nUse braces to clarify conditionals Conditionals are hard enough to read without \\nhaving to determine which statements go with the if test. Putting a single statement \\nafter an if test is sometimes appealing aesthetically, but under maintenance such state-\\nments tend to become more complicated blocks, and single statements are error-\\nprone when that happens. \\nUse blocks to clarify your intentions regardless of whether the code inside the block is \\n1 line or 20.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 480}, page_content='444 Chapter 19: General Control Issues\\n19.3 Null Statements\\nIn C++, it’s possible to have a null statement, a statement consisting entirely of a semi-\\ncolon, as shown here:\\nC+ + Example of a Traditional Null Statement\\nwhile ( recordArray.Read( index++ ) != recordArray.EmptyRecord() )\\n   ;\\nThe while in C++ requires that a statement follow, but it can be a null statement. The \\nsemicolon on a line by itself is a null statement. Here are guidelines for handling null \\nstatements in C++:\\nCross-Reference The best \\nway to handle null state-\\nments is probably to avoid \\nthem. For details, see “Avoid \\nempty loops” in Section 16.2.\\nCall attention to null statements Null statements are uncommon, so make them \\nobvious. One way is to give the semicolon of a null statement a line of its own. Indent \\nit, just as you would any other statement. This is the approach shown in the previous \\nexample. Alternatively, you can use a set of empty braces to emphasize the null state-\\nment. Here are two examples:\\nC+ + Examples of a Null Statement That’s Emphasized\\nThis is one way to show the \\nnull statement.\\nThis is another way to show \\nit.\\nwhile ( recordArray.Read( index++ ) ) != recordArray.EmptyRecord() ) {}\\nwhile ( recordArray.Read( index++ ) != recordArray.EmptyRecord() ) {\\n   ;\\n}\\nCreate a preprocessor DoNothing() macro or inline function for null statements\\nThe statement doesn’t do anything but make indisputably clear the fact that nothing \\nis supposed to be done. This is similar to marking blank document pages with the \\nstatement “This page intentionally left blank.” The page isn’t really blank, but you \\nknow nothing else is supposed to be on it.\\nHere’s how you can make your own null statement in C++ by using #define. (You \\ncould also create it as an inline function, which would have the same effect.)\\nC+ + Example of a Null Statement That’s Emphasized with DoNothing() \\n#define DoNothing()\\n...\\nwhile ( recordArray.Read( index++ ) != recordArray.EmptyRecord() ) {\\n   DoNothing();\\n}\\nIn addition to using DoNothing()in empty while and for loops, you can use it for unim-\\nportant choices of a switch statement; including DoNothing() makes it clear that the \\ncase was considered and nothing is supposed to be done.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 481}, page_content='19.4 Taming Dangerously Deep Nesting 445\\nIf your language doesn’t support preprocessor macros or inline functions, you could \\ncreate a DoNothing() routine that simply immediately returns control back to the call-\\ning routine. \\nConsider whether the code would be clearer with a non-null loop body Most of the \\ncode that results in loops with empty bodies relies on side effects in the loop-control \\ncode. In most cases, the code is more readable when the side effects are made explicit, \\nas shown here:\\nC+ + Examples of Rewriting Code More Clearly with a Non-Null Loop Body\\nRecordType record = recordArray.Read( index );\\nindex++;\\nwhile ( record != recordArray.EmptyRecord() ) {\\n   record = recordArray.Read( index );\\n   index++;\\n}\\nThis approach introduces an additional loop-control variable and requires more lines \\nof code, but it emphasizes straightforward programming practice rather than clever \\nuse of side effects. Such emphasis is preferable in production code. \\n19.4 Taming Dangerously Deep Nesting\\nExcessive indentation, or “nesting,” has been pilloried in computing literature for 25 \\nyears and is still one of the chief culprits in confusing code. Studies by Noam Chom-\\nsky and Gerald Weinberg suggest that few people can understand more than three \\nlevels of nested ifs (Yourdon 1986a), and many researchers recommend avoiding nest-\\ning to more than three or four levels (Myers 1976, Marca 1981, and Ledgard and Tauer \\n1987a). Deep nesting works against what Chapter 5, “Design in Construction,” \\ndescribes as Software’s Primary Technical Imperative: Managing Complexity. That is \\nreason enough to avoid deep nesting. \\nIt’s not hard to avoid deep nesting. If you have deep nesting, you can redesign the tests \\nperformed in the if and else clauses or you can refactor code into simpler routines. The \\nfollowing subsections present several ways to reduce the nesting depth:\\nSimplify a nested if by retesting part of the condition If the nesting gets too deep, \\nyou can decrease the number of nesting levels by retesting some of the conditions. \\nThis code example has nesting that’s deep enough to warrant restructuring:\\nC+ + Example of Bad, Deeply Nested Code\\nif ( inputStatus == InputStatus_Success ) {\\n   // lots of code\\n   ...\\n   if ( printerRoutine != NULL ) {\\n1\\n2\\n3\\nHARD DATA\\nKEY POINT\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 482}, page_content='446 Chapter 19: General Control Issues\\nCross-Reference Retesting \\npart of the condition to \\nreduce complexity is similar \\nto retesting a status variable. \\nThat technique is demon-\\nstrated in “Error Processing \\nand gotos” in Section 17.3.\\n      // lots of code\\n      ...\\n      if ( SetupPage() ) {\\n         // lots of code\\n         ...\\n         if ( AllocMem( &printData ) ) {\\n            // lots of code\\n            ...\\n         } \\n      } \\n   } \\n} \\nThis example is contrived to show nesting levels. The // lots of code parts are intended \\nto suggest that the routine has enough code to stretch across several screens or across \\nthe page boundary of a printed code listing. Here’s the code revised to use retesting \\nrather than nesting:\\nC+ + Example of Code Mercifully Unnested by Retesting\\nif ( inputStatus == InputStatus_Success ) {\\n   // lots of code\\n   ...\\n   if ( printerRoutine != NULL ) {\\n      // lots of code\\n      ...\\n   }\\n}\\nif ( ( inputStatus == InputStatus_Success ) && \\n   ( printerRoutine != NULL ) && SetupPage() ) {\\n   // lots of code\\n   ...\\n   if ( AllocMem( &printData ) ) {\\n      // lots of code\\n      ...\\n   }\\n}\\nThis is a particularly realistic example because it shows that you can’t reduce the nest-\\ning level for free; you have to put up with a more complicated test in return for the \\nreduced level of nesting. A reduction from four levels to two is a big improvement in \\nreadability, however, and is worth considering.\\nSimplify a nested if by using a break block An alternative to the approach just \\ndescribed is to define a section of code that will be executed as a block. If some con-\\ndition in the middle of the block fails, execution skips to the end of the block. \\nC+ + Example of Using a break Block\\ndo { \\n   // begin break block\\n   if ( inputStatus != InputStatus_Success ) {\\n      break; // break out of block\\n   }'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 483}, page_content='19.4 Taming Dangerously Deep Nesting 447\\n   // lots of code\\n   ...\\n   if ( printerRoutine == NULL ) {\\n      break; // break out of block\\n   }\\n   // lots of code\\n   ...\\n   if ( !SetupPage() ) {\\n      break; // break out of block\\n   }\\n   // lots of code\\n   ...\\n   if ( !AllocMem( &printData ) ) {\\n      break; // break out of block\\n   }\\n   // lots of code\\n   ...\\n} while (FALSE); // end break block\\nThis technique is uncommon enough that it should be used only when your entire \\nteam is familiar with it and when it has been adopted by the team as an accepted cod-\\ning practice. \\nConvert a nested if to a set of if-then-elses If you think about a nested if test criti-\\ncally, you might discover that you can reorganize it so that it uses if-then-elses rather \\nthan nested ifs. Suppose you have a bushy decision tree like this:\\nJava Example of an Overgrown Decision Tree\\nif ( 10 < quantity ) {\\n   if ( 100 < quantity ) {\\n      if ( 1000 < quantity ) {\\n         discount = 0.10;\\n      }\\n      else {\\n         discount = 0.05;\\n      }\\n   }\\n   else {\\n      discount = 0.025;\\n   }\\n}\\nelse {\\n   discount = 0.0;\\n}\\nThis test is poorly organized in several ways, one of which is that the tests are redundant. \\nWhen you test whether quantity is greater than 1000, you don’t also need to test whether \\nit’s greater than 100 and greater than 10. Consequently, you can reorganize the code:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 484}, page_content='448 Chapter 19: General Control Issues\\nJava Example of a Nested if Converted to a Set of if-then-elses\\nif ( 1000 < quantity ) {\\n   discount = 0.10;\\n}\\nelse if ( 100 < quantity ) {\\n   discount = 0.05;\\n}\\nelse if ( 10 < quantity ) {\\n   discount = 0.025;\\n}\\nelse {\\n   discount = 0;\\n}\\nThis solution is easier than some because the numbers increase neatly. Here’s how \\nyou could rework the nested if if the numbers weren’t so tidy:\\nJava Example of a Nested if Converted to a Set of if-then-elses When the \\nNumbers Are “Messy”\\nif ( 1000 < quantity ) {\\n   discount = 0.10;\\n}\\nelse if ( ( 100 < quantity ) && ( quantity <= 1000 ) ) {\\n   discount = 0.05;\\n}\\nelse if ( ( 10 < quantity ) && ( quantity <= 100 ) ) {\\n   discount = 0.025;\\n}\\nelse if ( quantity <= 10 ) {\\n   discount = 0;\\n}\\nThe main difference between this code and the previous code is that the expressions \\nin the else-if clauses don’t rely on previous tests. This code doesn’t need the else \\nclauses to work, and the tests actually could be performed in any order. The code \\ncould consist of four ifs and no elses. The only reason the else version is preferable is \\nthat it avoids repeating tests unnecessarily.\\nConvert a nested if to a case statement You can recode some kinds of tests, particu-\\nlarly those with integers, to use a case statement rather than chains of ifs and elses. You \\ncan’t use this technique in some languages, but it’s a powerful technique for those in \\nwhich you can. Here’s how to recode the example in Visual Basic:\\nVisual Basic Example of Converting a Nested if to a case Statement\\nSelect Case quantity\\n   Case 0 To 10\\n      discount = 0.0\\n   Case 11 To 100\\n      discount = 0.025'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 485}, page_content='19.4 Taming Dangerously Deep Nesting 449\\n   Case 101 To 1000\\n      discount = 0.05\\n   Case Else\\n      discount = 0.10\\nEnd Select\\nThis example reads like a book. When you compare it to the two examples of multiple \\nindentations a few pages earlier, it seems like a particularly clean solution.\\nFactor deeply nested code into its own routine If deep nesting occurs inside a loop, \\nyou can often improve the situation by putting the inside of the loop into its own rou-\\ntine. This is especially effective if the nesting is a result of both conditionals and itera-\\ntions. Leave the if-then-else branches in the main loop to show the decision branching, \\nand then move the statements within the branches to their own routines. This code \\nneeds to be improved by such a modification:\\nC+ + Example of Nested Code That Needs to Be Broken into Routines\\nwhile ( !TransactionsComplete() ) {\\n   // read transaction record\\n   transaction = ReadTransaction();\\n   // process transaction depending on type of transaction\\n   if ( transaction.Type == TransactionType_Deposit ) {\\n      // process a deposit\\n      if ( transaction.AccountType == AccountType_Checking ) {\\n         if ( transaction.AccountSubType == AccountSubType_Business )\\n            MakeBusinessCheckDep( transaction.AccountNum, transaction.Amount );\\n         else if ( transaction.AccountSubType == AccountSubType_Personal )\\n            MakePersonalCheckDep( transaction.AccountNum, transaction.Amount );\\n         else if ( transaction.AccountSubType == AccountSubType_School )\\n            MakeSchoolCheckDep( transaction.AccountNum, transaction.Amount );\\n      }\\n      else if ( transaction.AccountType == AccountType_Savings )\\n         MakeSavingsDep( transaction.AccountNum, transaction.Amount );\\n      else if ( transaction.AccountType == AccountType_DebitCard )\\n         MakeDebitCardDep( transaction.AccountNum, transaction.Amount );\\n      else if ( transaction.AccountType == AccountType_MoneyMarket )\\n         MakeMoneyMarketDep( transaction.AccountNum, transaction.Amount );\\n      else if ( transaction.AccountType == AccountType_Cd )\\n         MakeCDDep( transaction.AccountNum, transaction.Amount );\\n   }\\n   else if ( transaction.Type == TransactionType_Withdrawal ) {\\n      // process a withdrawal\\n      if ( transaction.AccountType == AccountType_Checking )\\n         MakeCheckingWithdrawal( transaction.AccountNum, transaction.Amount );\\n      else if ( transaction.AccountType == AccountType_Savings )\\n         MakeSavingsWithdrawal( transaction.AccountNum, transaction.Amount );\\n      else if ( transaction.AccountType == AccountType_DebitCard )\\n         MakeDebitCardWithdrawal( transaction.AccountNum, transaction.Amount );\\n   }'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 486}, page_content='450 Chapter 19: General Control Issues\\nHere’s the \\nTransactionType_Transfer \\ntransaction type.\\n   else if ( transaction.Type == TransactionType_Transfer ) {\\n      MakeFundsTransfer( \\n         transaction.SourceAccountType, \\n         transaction.TargetAccountType, \\n         transaction.AccountNum, \\n         transaction.Amount \\n      );\\n   }\\n   else {\\n      // process unknown kind of transaction\\n      LogTransactionError( \"Unknown Transaction Type\", transaction );\\n   }\\n}\\nAlthough it’s complicated, this isn’t the worst code you’ll ever see. It’s nested to only \\nfour levels, it’s commented, it’s logically indented, and the functional decomposition \\nis adequate, especially for the TransactionType_Transfer transaction type. In spite of its \\nadequacy, however, you can improve it by breaking the contents of the inner if tests \\ninto their own routines.\\nCross-Reference This kind of \\nfunctional decomposition is \\nespecially easy if you initially \\nbuilt the routine using the \\nsteps described in Chapter 9, \\n“The Pseudocode Program-\\nming Process.” Guidelines \\nfor functional decomposition \\nare given in “Divide and \\nConquer” in Section 5.4.\\nC+ + Example of Good, Nested Code After Decomposition into Routines\\nwhile ( !TransactionsComplete() ) {\\n   // read transaction record\\n   transaction = ReadTransaction();\\n   // process transaction depending on type of transaction\\n   if ( transaction.Type == TransactionType_Deposit ) {\\n      ProcessDeposit( \\n         transaction.AccountType, \\n         transaction.AccountSubType,\\n         transaction.AccountNum, \\n         transaction.Amount \\n      );\\n   }\\n   else if ( transaction.Type == TransactionType_Withdrawal ) {\\n      ProcessWithdrawal( \\n         transaction.AccountType, \\n         transaction.AccountNum,\\n         transaction.Amount \\n      );\\n   }\\n   else if ( transaction.Type == TransactionType_Transfer ) {\\n      MakeFundsTransfer( \\n         transaction.SourceAccountType, \\n         transaction.TargetAccountType,\\n         transaction.AccountNum, \\n         transaction.Amount \\n      );\\n   }\\n   else {\\n      // process unknown transaction type\\n      LogTransactionError(\"Unknown Transaction Type\", transaction );\\n   }\\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 487}, page_content='19.4 Taming Dangerously Deep Nesting 451\\nThe code in the new routines has simply been lifted out of the original routine and \\nformed into new routines. (The new routines aren’t shown here.) The new code has \\nseveral advantages. First, two-level nesting makes the structure simpler and easier to \\nunderstand. Second, you can read, modify, and debug the shorter while loop on one \\nscreen—it doesn’t need to be broken across screen or printed-page boundaries. Third, \\nputting the functionality of ProcessDeposit() and ProcessWithdrawal() into routines \\naccrues all the other general advantages of modularization. Fourth, it’s now easy to \\nsee that the code could be broken into a case statement, which would make it even eas-\\nier to read, as shown below:\\nC+ + Example of Good, Nested Code After Decomposition and Use of a \\ncase Statement\\nwhile ( !TransactionsComplete() ) {\\n   // read transaction record\\n   transaction = ReadTransaction();\\n   // process transaction depending on type of transaction\\n   switch ( transaction.Type ) {\\n      case ( TransactionType_Deposit ):\\n         ProcessDeposit( \\n            transaction.AccountType, \\n            transaction.AccountSubType,\\n            transaction.AccountNum, \\n            transaction.Amount \\n            );\\n         break;\\n      case ( TransactionType_Withdrawal ):\\n         ProcessWithdrawal( \\n            transaction.AccountType, \\n            transaction.AccountNum,\\n            transaction.Amount \\n            );\\n         break;\\n      case ( TransactionType_Transfer ):\\n         MakeFundsTransfer( \\n            transaction.SourceAccountType,\\n            transaction.TargetAccountType,\\n            transaction.AccountNum, \\n            transaction.Amount \\n            );\\n         break;\\n      default:\\n         // process unknown transaction type\\n         LogTransactionError(\"Unknown Transaction Type\", transaction );\\n         break;\\n   }\\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 488}, page_content='452 Chapter 19: General Control Issues\\nUse a more object-oriented approach A straightforward way to simplify this particu-\\nlar code in an object-oriented environment is to create an abstract Transaction base \\nclass and subclasses for Deposit, Withdrawal, and Transfer. \\nC+ + Example of Good Code That Uses Polymorphism\\nTransactionData transactionData;\\nTransaction *transaction; \\nwhile ( !TransactionsComplete() ) {\\n   // read transaction record\\n   transactionData = ReadTransaction();\\n   // create transaction object, depending on type of transaction\\n   switch ( transactionData.Type ) {\\n      case ( TransactionType_Deposit ):\\n         transaction = new Deposit( transactionData );\\n         break;\\n      case ( TransactionType_Withdrawal ):\\n         transaction = new Withdrawal( transactionData );\\n         break;\\n      case ( TransactionType_Transfer ):\\n         transaction = new Transfer( transactionData );\\n         break;\\n      default:\\n         // process unknown transaction type\\n         LogTransactionError(\"Unknown Transaction Type\", transactionData );\\n         return;\\n   }\\n   transaction->Complete(); \\n   delete transaction;\\n}\\nIn a system of any size, the switch statement would be converted to use a factory \\nmethod that could be reused anywhere an object of Transaction type needed to be cre-\\nated. If this code were in such a system, this part of it would become even simpler:\\nCross-Reference For more \\nbeneficial code improve-\\nments like this, see Chapter \\n24, \"Refactoring.\"\\nC+ + Example of Good Code That Uses Polymorphism and an Object Factory\\nTransactionData transactionData;\\nTransaction *transaction; \\nwhile ( !TransactionsComplete() ) {\\n   // read transaction record and complete transaction\\n   transactionData = ReadTransaction();\\n   transaction = TransactionFactory.Create( transactionData );\\n   transaction->Complete(); \\n   delete transaction;\\n}\\nFor the record, the code in the TransactionFactory.Create() routine is a simple adapta-\\ntion of the code from the prior example’s switch statement:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 489}, page_content='19.4 Taming Dangerously Deep Nesting 453\\nC+ + Example of Good Code for an Object Factory\\nTransaction *TransactionFactory::Create( \\n   TransactionData transactionData \\n   ) {\\n \\n   // create transaction object, depending on type of transaction\\n   switch ( transactionData.Type ) {\\n      case ( TransactionType_Deposit ):\\n         return new Deposit( transactionData );\\n         break;\\n \\n      case ( TransactionType_Withdrawal ):\\n         return new Withdrawal( transactionData );\\n         break;\\n \\n      case ( TransactionType_Transfer ):\\n         return new Transfer( transactionData );\\n         break;\\n \\n      default:\\n         // process unknown transaction type\\n         LogTransactionError( \"Unknown Transaction Type\", transactionData );\\n         return NULL; \\n   }\\n}\\nRedesign deeply nested code Some experts argue that case statements virtually \\nalways indicate poorly factored code in object-oriented programming and are rarely, if \\never, needed (Meyer 1997). This transformation from case statements that invoke rou-\\ntines to an object factory with polymorphic method calls is one such example.\\nMore generally, complicated code is a sign that you don’t understand your program \\nwell enough to make it simple. Deep nesting is a warning sign that indicates a need to \\nbreak out a routine or redesign the part of the code that’s complicated. It doesn’t \\nmean you have to modify the routine, but you should have a good reason for not \\ndoing so if you don’t.\\nSummary of Techniques for Reducing Deep Nesting\\nThe following is a list of the techniques you can use to reduce deep nesting, along with \\nreferences to the sections in this book that discuss the techniques:\\n■ Retest part of the condition (this section)\\n■ Convert to if-then-elses (this section)\\n■ Convert to a case statement (this section)\\n■ Factor deeply nested code into its own routine (this section)\\n■ Use objects and polymorphic dispatch (this section)'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 490}, page_content='454 Chapter 19: General Control Issues\\n■ Rewrite the code to use a status variable (in Section 17.3)\\n■ Use guard clauses to exit a routine and make the nominal path through the code \\nclearer (in Section 17.1)\\n■ Use exceptions (Section 8.4)\\n■ Redesign deeply nested code entirely (this section)\\n19.5 A Programming Foundation: Structured Programming\\nThe term “structured programming” originated in a landmark paper, “Structured Pro-\\ngramming,” presented by Edsger Dijkstra at the 1969 NATO conference on software \\nengineering (Dijkstra 1969). By the time structured programming came and went, the \\nterm “structured” had been applied to every software-development activity, including \\nstructured analysis, structured design, and structured goofing off. The various struc-\\ntured methodologies weren’t joined by any common thread except that they were all \\ncreated at a time when the word “structured” gave them extra cachet.\\nThe core of structured programming is the simple idea that a program should use \\nonly one-in, one-out control constructs (also called single-entry, single-exit control \\nconstructs). A one-in, one-out control construct is a block of code that has only one \\nplace it can start and only one place it can end. It has no other entries or exits. Struc-\\ntured programming isn’t the same as structured, top-down design. It applies only at \\nthe detailed coding level.\\nA structured program progresses in an orderly, disciplined way, rather than jumping \\naround unpredictably. You can read it from top to bottom, and it executes in much the \\nsame way. Less disciplined approaches result in source code that provides a less \\nmeaningful, less readable picture of how a program executes in the machine. Less \\nreadability means less understanding and, ultimately, lower program quality.\\nThe central concepts of structured programming are still useful today and apply to \\nconsiderations in using break, continue, throw, catch, return, and other topics. \\nThe Three Components of Structured Programming\\nThe next few sections describe the three constructs that constitute the core of struc-\\ntured programming.\\nSequence\\nCross-Reference For details \\non using sequences, see \\nChapter 14, “Organizing \\nStraight-Line Code.”\\nA sequence is a set of statements executed in order. Typical sequential statements \\ninclude assignments and calls to routines. Here are two examples:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 491}, page_content='19.5 A Programming Foundation: Structured Programming 455\\nJava Examples of Sequential Code\\n// a sequence of assignment statements\\na = \"1\";\\nb = \"2\";\\nc = \"3\";\\n// a sequence of calls to routines\\nSystem.out.println( a );\\nSystem.out.println( b );\\nSystem.out.println( c );\\nSelection\\nCross-Reference For details \\non using selections, see \\nChapter 15, “Using Condi-\\ntionals.”\\nA selection is a control structure that causes statements to be executed selectively. The \\nif-then-else statement is a common example. Either the if-then clause or the else clause \\nis executed, but not both. One of the clauses is “selected” for execution.\\nA case statement is another example of selection control. The switch statement in C++ \\nand Java and the select statement in Visual Basic are all examples of case. In each \\ninstance, one of several cases is selected for execution. Conceptually, if statements and \\ncase statements are similar. If your language doesn’t support case statements, you can \\nemulate them with if statements. Here are two examples of selection:\\nJava Examples of Selection\\n// selection in an if statement\\nif ( totalAmount > 0.0 ) {\\n   // do something\\n   ...\\n}\\nelse {\\n   // do something else\\n   ...\\n}\\n// selection in a case statement\\nswitch ( commandShortcutLetter ) {\\n   case \\'a\\': \\n      PrintAnnualReport();\\n      break;\\n   case \\'q\\': \\n      PrintQuarterlyReport();\\n      break;\\n   case \\'s\\': \\n      PrintSummaryReport();\\n      break;\\n   default: \\n      DisplayInternalError( \"Internal Error 905: Call customer support.\" );\\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 492}, page_content=\"456 Chapter 19: General Control Issues\\nIteration\\nCross-Reference For details \\non using iterations, see \\nChapter 16, “Controlling \\nLoops.”\\nAn iteration is a control structure that causes a group of statements to be executed \\nmultiple times. An iteration is commonly referred to as a “loop.” Kinds of iterations \\ninclude For-Next in Visual Basic and while and for in C++ and Java. This code fragment \\nshows examples of iteration in Visual Basic:\\nVisual Basic Examples of Iteration\\n' example of iteration using a For loop\\nFor index = first To last \\n   DoSomething( index )\\nNext\\n' example of iteration using a while loop\\nindex = first\\nWhile ( index <= last ) \\n   DoSomething ( index )\\n   index = index + 1\\nWend\\n' example of iteration using a loop-with-exit loop\\nindex = first\\nDo \\n   If ( index > last ) Then Exit Do\\n   DoSomething ( index )\\n   index = index + 1\\nLoop\\nThe core thesis of structured programming is that any control flow whatsoever can be \\ncreated from these three constructs of sequence, selection, and iteration (Böhm Jaco-\\npini 1966). Programmers sometimes favor language structures that increase conve-\\nnience, but programming seems to have advanced largely by restricting what we are \\nallowed to do with our programming languages. Prior to structured programming, \\nuse of gotos provided the ultimate in control-flow convenience, but code written that \\nway turned out to be incomprehensible and unmaintainable. My belief is that use of \\nany control structure other than the three standard structured programming con-\\nstructs—that is, the use of break, continue, return, throw-catch, and so on—should be \\nviewed with a critical eye. \\n19.6 Control Structures and Complexity\\nOne reason so much attention has been paid to control structures is that they are a big \\ncontributor to overall program complexity. Poor use of control structures increases \\ncomplexity; good use decreases it.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 493}, page_content='19.6 Control Structures and Complexity 457\\nMake things as simple as \\npossible—but no simpler. \\n—Albert Einstein\\nOne measure of “programming complexity” is the number of mental objects you have \\nto keep in mind simultaneously in order to understand a program. This mental jug-\\ngling act is one of the most difficult aspects of programming and is the reason pro-\\ngramming requires more concentration than other activities. It’s the reason \\nprogrammers get upset about “quick interruptions”—such interruptions are tanta-\\nmount to asking a juggler to keep three balls in the air and hold your groceries at the \\nsame time.\\nIntuitively, the complexity of a program would seem to largely determine the amount \\nof effort required to understand it. Tom McCabe published an influential paper argu-\\ning that a program’s complexity is defined by its control flow (1976). Other research-\\ners have identified factors other than McCabe’s cyclomatic complexity metric (such as \\nthe number of variables used in a routine), but they agree that control flow is at least \\none of the largest contributors to complexity, if not the largest.\\nHow Important Is Complexity?\\nCross-Reference For more \\non complexity, see “Soft-\\nware’s Primary Technical \\nImperative: Managing Com-\\nplexity” in Section 5.2.\\nComputer-science researchers have been aware of the importance of complexity for at \\nleast two decades. Many years ago, Edsger Dijkstra cautioned against the hazards of \\ncomplexity: “The competent programmer is fully aware of the strictly limited size of \\nhis own skull; therefore, he approaches the programming task in full humility” (Dijk-\\nstra 1972). This does not imply that you should increase the capacity of your skull to \\ndeal with enormous complexity. It implies that you can never deal with enormous \\ncomplexity and must take steps to reduce it wherever possible.\\nControl-flow complexity is important because it has been correlated with low reliabil-\\nity and frequent errors (McCabe 1976, Shen et al. 1985). William T. Ward reported a \\nsignificant gain in software reliability resulting from using McCabe’s complexity met-\\nric at Hewlett-Packard (1989b). McCabe’s metric was used on one 77,000-line pro-\\ngram to identify problem areas. The program had a post-release defect rate of 0.31 \\ndefects per thousand lines of code. A 125,000-line program had a post-release defect \\nrate of 0.02 defects per thousand lines of code. Ward reported that because of their \\nlower complexity, both programs had substantially fewer defects than other programs \\nat Hewlett-Packard. My own company, Construx Software, has experienced similar \\nresults using complexity measures to identify problematic routines in the 2000s.  \\nGeneral Guidelines for Reducing Complexity\\nYou can better deal with complexity in one of two ways. First, you can improve your \\nown mental juggling abilities by doing mental exercises. But programming itself is \\nusually enough exercise, and people seem to have trouble juggling more than about \\nfive to nine mental entities (Miller 1956). The potential for improvement is small. Sec-\\nond, you can decrease the complexity of your programs and the amount of concentra-\\ntion required to understand them.\\nKEY POINT\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 494}, page_content='458 Chapter 19: General Control Issues\\nHow to Measure Complexity\\nFurther Reading The \\napproach described here is \\nbased on Tom McCabe’s \\ninfluential paper “A Com-\\nplexity Measure” (1976).\\nYou probably have an intuitive feel for what makes a routine more or less complex. \\nResearchers have tried to formalize their intuitive feelings and have come up with several \\nways of measuring complexity. Perhaps the most influential of the numeric techniques is \\nTom McCabe’s, in which complexity is measured by counting the number of “decision \\npoints” in a routine. Table 19-2 describes a method for counting decision points.\\nHere’s an example:\\nif ( ( (status = Success) and done ) or\\n     ( not done and ( numLines >= maxLines ) ) ) then ...\\nIn this fragment, you count 1 to start, 2 for the if, 3 for the and, 4 for the or, and 5 for \\nthe and. Thus, this fragment contains a total of five decision points.\\nWhat to Do with Your Complexity Measurement\\nAfter you have counted the decision points, you can use the number to analyze your \\nroutine’s complexity:\\nMoving part of a routine into another routine doesn’t reduce the overall complexity of \\nthe program; it just moves the decision points around. But it reduces the amount of \\ncomplexity you have to deal with at any one time. Since the important goal is to min-\\nimize the number of items you have to juggle mentally, reducing the complexity of a \\ngiven routine is worthwhile.\\nThe maximum of 10 decision points isn’t an absolute limit. Use the number of deci-\\nsion points as a warning flag that indicates a routine might need to be redesigned. \\nDon’t use it as an inflexible rule. A case statement with many cases could be more than \\n10 elements long, and, depending on the purpose of the case statement, it might be \\nfoolish to break it up. \\nTable 19-2 Techniques for Counting the Decision Points in a Routine\\n1. Start with 1 for the straight path through the routine.\\n2. Add 1 for each of the following keywords, or their equivalents: if  while  repeat  for  \\nand  or\\n3. Add 1 for each case in a case  statement.\\n0–5 The routine is probably fine.\\n6–10 Start to think about ways to simplify the routine.\\n10+ Break part of the routine into a second routine and call it from the first \\nroutine.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 495}, page_content='19.6 Control Structures and Complexity 459\\nOther Kinds of Complexity\\nFurther Reading For an \\nexcellent discussion of com-\\nplexity metrics, see Software \\nEngineering Metrics and \\nModels (Conte, Dunsmore, \\nand Shen 1986).\\nThe McCabe measure of complexity isn’t the only sound measure, but it’s the measure \\nmost discussed in computing literature and it’s especially helpful when you’re think-\\ning about control flow. Other measures include the amount of data used, the number \\nof nesting levels in control constructs, the number of lines of code, the number of \\nlines between successive references to variables (“span”),  the number of lines that a \\nvariable is in use (“live time”), and the amount of input and output. Some researchers \\nhave developed composite metrics based on combinations of these simpler ones.\\ncc2e.com/1985 CHECKLIST: Control-Structure Issues\\n❑ Do expressions use true and false rather than 1 and 0?\\n❑ Are boolean values compared to true and false implicitly?\\n❑ Are numeric values compared to their test values explicitly?\\n❑ Have expressions been simplified by the addition of new boolean vari-\\nables and the use of boolean functions and decision tables?\\n❑ Are boolean expressions stated positively?\\n❑ Do pairs of braces balance?\\n❑ Are braces used everywhere they’re needed for clarity?\\n❑ Are logical expressions fully parenthesized? \\n❑ Have tests been written in number-line order? \\n❑ Do Java tests uses a.equals(b) style instead of a == b when appropriate? \\n❑ Are null statements obvious?\\n❑ Have nested statements been simplified by retesting part of the condi-\\ntional, converting to if-then-else or case statements, moving nested code \\ninto its own routine, converting to a more object-oriented design, or have \\nthey been improved in some other way?\\n❑ If a routine has a decision count of more than 10, is there a good reason for \\nnot redesigning it?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 496}, page_content='460 Chapter 19: General Control Issues\\nKey Points\\n■ Making boolean expressions simple and readable contributes substantially to \\nthe quality of your code.\\n■ Deep nesting makes a routine hard to understand. Fortunately, you can avoid it \\nrelatively easily.\\n■ Structured programming is a simple idea that is still relevant: you can build any \\nprogram out of a combination of sequences, selections, and iterations. \\n■ Minimizing complexity is a key to writing high-quality code.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 497}, page_content='Part V\\nCode Improvements\\nIn this part:\\nChapter 20: The Software-Quality Landscape  . . . . . . . . . . . . . . . . . . . . . .463\\nChapter 21: Collaborative Construction . . . . . . . . . . . . . . . . . . . . . . . . . . .479\\nChapter 22: Developer Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .499\\nChapter 23: Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .535\\nChapter 24: Refactoring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .563\\nChapter 25: Code-Tuning Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .587\\nChapter 26: Code-Tuning Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . .609'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 499}, page_content='463\\nChapter 20\\nThe Software-Quality \\nLandscape\\ncc2e.com/2036 Contents\\n■ 20.1 Characteristics of Software Quality: page 463\\n■ 20.2 Techniques for Improving Software Quality: page 466\\n■ 20.3 Relative Effectiveness of Quality Techniques: page 469\\n■ 20.4 When to Do Quality Assurance: page 473\\n■ 20.5 The General Principle of Software Quality: page 474\\nRelated Topics\\n■ Collaborative construction: Chapter 21\\n■ Developer testing: Chapter 22\\n■ Debugging: Chapter 23\\n■ Prerequisites to construction: Chapters 3 and 4\\n■ Do prerequisites apply to modern software projects?: in Section 3.1\\nThis chapter surveys software-quality techniques from a construction point of view. \\nThe entire book is about improving software quality, of course, but this chapter \\nfocuses on quality and quality assurance per se. It focuses more on big-picture issues \\nthan it does on hands-on techniques. If you’re looking for practical advice about col-\\nlaborative development, testing, and debugging, move on to the next three chapters.\\n20.1 Characteristics of Software Quality\\nSoftware has both external and internal quality characteristics. External characteristics \\nare characteristics that a user of the software product is aware of, including the following:\\n■ Correctness The degree to which a system is free from faults in its specifica-\\ntion, design, and implementation.\\n■ Usability The ease with which users can learn and use a system.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 500}, page_content='464 Chapter 20: The Software-Quality Landscape\\n■ Efficiency Minimal use of system resources, including memory and execution \\ntime.\\n■ Reliability The ability of a system to perform its required functions under \\nstated conditions whenever required—having a long mean time between failures.\\n■ Integrity The degree to which a system prevents unauthorized or improper \\naccess to its programs and its data. The idea of integrity includes restricting \\nunauthorized user accesses as well as ensuring that data is accessed properly—\\nthat is, that tables with parallel data are modified in parallel, that date fields con-\\ntain only valid dates, and so on.\\n■ Adaptability The extent to which a system can be used, without modification, \\nin applications or environments other than those for which it was specifically \\ndesigned.\\n■ Accuracy The degree to which a system, as built, is free from error, especially \\nwith respect to quantitative outputs. Accuracy differs from correctness; it is a \\ndetermination of how well a system does the job it’s built for rather than \\nwhether it was built correctly.\\n■ Robustness The degree to which a system continues to function in the pres-\\nence of invalid inputs or stressful environmental conditions.\\nSome of these characteristics overlap, but all have different shades of meaning that are \\napplicable more in some cases, less in others.\\nExternal characteristics of quality are the only kind of software characteristics that \\nusers care about. Users care about whether the software is easy to use, not about \\nwhether it’s easy for you to modify. They care about whether the software works cor-\\nrectly, not about whether the code is readable or well structured.\\nProgrammers care about the internal characteristics of the software as well as the \\nexternal ones. This book is code-centered, so it focuses on the internal quality charac-\\nteristics, including\\n■ Maintainability The ease with which you can modify a software system to \\nchange or add capabilities, improve performance, or correct defects.\\n■ Flexibility The extent to which you can modify a system for uses or environ-\\nments other than those for which it was specifically designed.\\n■ Portability The ease with which you can modify a system to operate in an \\nenvironment different from that for which it was specifically designed.\\n■ Reusability The extent to which and the ease with which you can use parts of \\na system in other systems.\\n■ Readability The ease with which you can read and understand the source \\ncode of a system, especially at the detailed-statement level.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 501}, page_content='20.1 Characteristics of Software Quality 465\\n■ Testability The degree to which you can unit-test and system-test a system; \\nthe degree to which you can verify that the system meets its requirements.\\n■ Understandability The ease with which you can comprehend a system at both \\nthe system-organizational and detailed-statement levels. Understandability has to \\ndo with the coherence of the system at a more general level than readability does.\\nAs in the list of external quality characteristics, some of these internal characteristics \\noverlap, but they too each have different shades of meaning that are valuable.\\nThe internal aspects of system quality are the main subject of this book and aren’t dis-\\ncussed further in this chapter.\\nThe difference between internal and external characteristics isn’t completely clear-cut \\nbecause at some level internal characteristics affect external ones. Software that isn’t \\ninternally understandable or maintainable impairs your ability to correct defects, \\nwhich in turn affects the external characteristics of correctness and reliability. Soft-\\nware that isn’t flexible can’t be enhanced in response to user requests, which in turn \\naffects the external characteristic of usability. The point is that some quality character-\\nistics are emphasized to make life easier for the user and some are emphasized to \\nmake life easier for the programmer. Try to know which is which and when and how \\nthese characteristics interact.\\nThe attempt to maximize certain characteristics inevitably conflicts with the attempt to \\nmaximize others. Finding an optimal solution from a set of competing objectives is one \\nactivity that makes software development a true engineering discipline. Figure 20-1 \\nshows the way in which focusing on some external quality characteristics affects others. \\nThe same kinds of relationships can be found among the internal characteristics of soft-\\nware quality.\\nThe most interesting aspect of this chart is that focusing on a specific characteristic \\ndoesn’t always mean a tradeoff with another characteristic. Sometimes one hurts \\nanother, sometimes one helps another, and sometimes one neither hurts nor helps \\nanother. For example, correctness is the characteristic of functioning exactly to speci-\\nfication. Robustness is the ability to continue functioning even under unanticipated \\nconditions. Focusing on correctness hurts robustness and vice versa. In contrast, \\nfocusing on adaptability helps robustness and vice versa.\\nThe chart shows only typical relationships among the quality characteristics. On any \\ngiven project, two characteristics might have a relationship that’s different from their \\ntypical relationship. It’s useful to think about your specific quality goals and whether \\neach pair of goals is mutually beneficial or antagonistic.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 502}, page_content='466 Chapter 20: The Software-Quality Landscape\\nFigure 20-1 Focusing on one external characteristic of software quality can affect other \\ncharacteristics positively, adversely, or not at all.\\n20.2 Techniques for Improving Software Quality\\nSoftware quality assurance is a planned and systematic program of activities designed \\nto ensure that a system has the desired characteristics. Although it might seem that \\nthe best way to develop a high-quality product would be to focus on the product itself, \\nin software quality assurance you also need to focus on the software-development pro-\\ncess. Some of the elements of a software-quality program are described in the follow-\\ning subsections:\\nSoftware-quality objectives One powerful technique for improving software quality \\nis setting explicit quality objectives from among the external and internal characteristics \\ndescribed in the previous section. Without explicit goals, programmers might work to \\nmaximize characteristics different from the ones you expect them to maximize. The \\npower of setting explicit goals is discussed in more detail later in this section.\\nExplicit quality-assurance activity One common problem in assuring quality is that \\nquality is perceived as a secondary goal. Indeed, in some organizations, quick and \\ndirty programming is the rule rather than the exception. Programmers like Global \\nGary, who litter their code with defects and “complete” their programs quickly, are \\nrewarded more than programmers like High-Quality Henry, who write excellent pro-\\ngrams and make sure that they are usable before releasing them. In such organiza-\\ntions, it shouldn’t be surprising that programmers don’t make quality their first \\npriority. The organization must show programmers that quality is a priority. Making \\nthe quality-assurance activity explicit makes the priority clear, and programmers will \\nrespond accordingly.\\nCorrectness\\nUsability\\nEfficiency\\nReliability\\nIntegrity\\nAdaptability\\nAccuracyRobustnessCorrectness\\nUsability\\nEfficiency\\nReliability\\nIntegrity\\nAdaptability\\nAccuracy\\nRobustness\\nHow focusing \\non the factor \\nbelow affects \\nthe factor to \\nthe right\\nHelps it\\nHurts it'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 503}, page_content='20.2 Techniques for Improving Software Quality 467\\nCross-Reference For details \\non testing, see Chapter 22, \\n“Developer Testing.”\\nTesting strategy Execution testing can provide a detailed assessment of a product’s \\nreliability. Part of quality assurance is developing a test strategy in conjunction with \\nthe product requirements, architecture, and design. Developers on many projects rely \\non testing as the primary method of bo th quality assessment and quality improve-\\nment. The rest of this chapter demonstrates in more detail that this is too heavy a bur-\\nden for testing to bear by itself. \\nCross-Reference For a dis-\\ncussion of one class of soft-\\nware-engineering guidelines \\nappropriate for construction, \\nsee Section 4.2, “Program-\\nming Conventions.”\\nSoftware-engineering guidelines Guidelines should control the technical character \\nof the software as it’s developed. Such guidelines apply to all software development \\nactivities, including problem definition, requirements development, architecture, con-\\nstruction, and system testing. The guidelines in this book are, in one sense, a set of \\nsoftware-engineering guidelines for construction.\\nInformal technical reviews Many software developers review their work before turn-\\ning it over for formal review. Informal reviews include desk-checking the design or the \\ncode or walking through the code with a few peers.\\nCross-Reference Reviews \\nand inspections are dis-\\ncussed in Chapter 21, “Col-\\nlaborative Construction.”\\nFormal technical reviews One part of managing a software-engineering process is \\ncatching problems at the “lowest-value” stage—that is, at the time at which the least \\ninvestment has been made and at which problems cost the least to correct. To achieve \\nsuch a goal, developers use “quality gates,” periodic tests or reviews that determine \\nwhether the quality of the product at one stage is sufficient to support moving on to \\nthe next. Quality gates are usually used to transition between requirements develop-\\nment and architecture, architecture and construction, and construction and system \\ntesting. The “gate” can be an inspection, a peer review, a customer review, or an audit.\\nCross-Reference For more \\ndetails on how development \\napproaches vary depending \\non the kind of project, see \\nSection 3.2, “Determine the \\nKind of Software You’re \\nWorking On.”\\nA “gate” does not mean that architecture or requirements need to be 100 percent com-\\nplete or frozen; it does mean that you will use the gate to determine whether the \\nrequirements or architecture are good enough to support downstream development. \\n“Good enough” might mean that you’ve sketched out the most critical 20 percent of \\nthe requirements or architecture, or it might mean you’ve specified 95 percent in \\nexcruciating detail—which end of the scale you should aim for depends on the nature \\nof your specific project. \\nExternal audits An external audit is a specific kind of technical review used to deter-\\nmine the status of a project or the quality of a product being developed. An audit team \\nis brought in from outside the organization and reports its findings to whoever com-\\nmissioned the audit, usually management.\\nDevelopment Process\\nFurther Reading For a dis-\\ncussion of software develop-\\nment as a process, see \\nProfessional Software Devel-\\nopment (McConnell 1994).\\nEach of the elements mentioned so far has something to do explicitly with assuring \\nsoftware quality and implicitly with the process of software development. Develop-\\nment efforts that include quality-assurance activities produce better software than \\nthose that do not. Other processes that aren’t explicitly quality-assurance activities \\nalso affect software quality.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 504}, page_content='468 Chapter 20: The Software-Quality Landscape\\nCross-Reference For details \\non change control, see \\nSection 28.2, “Configuration \\nManagement.”\\nChange-control procedures One big obstacle to achieving software quality is uncon-\\ntrolled changes. Uncontrolled requirements changes can result in disruption to \\ndesign and coding. Uncontrolled changes in design can result in code that doesn’t \\nagree with its requirements, inconsistencies in the code, or more time spent modify-\\ning code to meet the changing design than spent moving the project forward. Uncon-\\ntrolled changes in the code itself can result in internal inconsistencies and uncertain-\\nties about which code has been fully reviewed and tested and which hasn’t. The \\nnatural effect of change is to destabilize and degrade quality, so handling changes \\neffectively is a key to achieving high quality levels.\\nMeasurement of results Unless results of a quality-assurance plan are measured, \\nyou’ll have no way to know whether the plan is working. Measurement tells you \\nwhether your plan is a success or a failure and also allows you to vary your process in \\na controlled way to see how it can be improved. You can also measure quality \\nattributes themselves—correctness, usability, efficiency, and so on—and it’s useful to \\ndo so. For details on measuring quality attributes, see Chapter 9 of Principles of Soft-\\nware Engineering (Gilb 1988). \\nPrototyping Prototyping is the development of realistic models of a system’s key \\nfunctions. A developer can prototype parts of a user interface to determine usability, \\ncritical calculations to determine execution time, or typical data sets to determine \\nmemory requirements. A survey of 16 published and 8 unpublished case studies com-\\npared prototyping to traditional, specification-development methods. The compari-\\nson revealed that prototyping can lead to better designs, better matches with user \\nneeds, and improved maintainability (Gordon and Bieman 1991).\\nSetting Objectives\\nExplicitly setting quality objectives is a simple, obvious step in achieving quality soft-\\nware, but it’s easy to overlook. You might wonder whether, if you set explicit quality \\nobjectives, programmers will actually work to  achieve them? The answer is, yes, they \\nwill, if they know what the objectives ar e and that the objectives are reasonable. \\nProgrammers can’t respond to a set of objectives that change daily or that are impos-\\nsible to meet.\\nGerald Weinberg and Edward Schulman conducted a fascinating experiment to inves-\\ntigate the effect on programmer performance of setting quality objectives (1974). They \\nhad five teams of programmers work on five versions of the same program. The same \\nfive quality objectives were given to each of the five teams, and each team was told to \\noptimize a different objective. One team was told to minimize the memory required, \\nanother was told to produce the clearest possible output, another was told to build \\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 505}, page_content='20.3 Relative Effectiveness of Quality Techniques 469\\nthe most readable code, another was told to use the minimum number of statements, \\nand the last group was told to complete the program in the least amount of time pos-\\nsible. Table 20-1 shows how each team was ranked according to each objective.\\nThe results of this study were remarkable. Four of the five teams finished first in the \\nobjective they were told to optimize. The other team finished second in its objective. \\nNone of the teams did consistently well in all objectives.\\nThe surprising implication is that people actually do what you ask them to do. Pro-\\ngrammers have high achievement motivation: They will work to the objectives speci-\\nfied, but they must be told what the objectives are. The second implication is that, as \\nexpected, objectives conflict and it’s generally not possible to do well on all of them.\\n20.3 Relative Effectiveness of Quality Techniques\\nThe various quality-assurance practices don’t all have the same effectiveness. Many \\ntechniques have been studied, and their effectiveness at detecting and removing \\ndefects is known. This and several other aspects of the “effectiveness” of the quality-\\nassurance practices are discussed in this section.\\nPercentage of Defects Detected\\nIf builders built buildings the \\nway programmers wrote \\nprograms, then the first \\nwoodpecker that came along \\nwould destroy civilization.\\n—Gerald Weinberg\\nSome practices are better at detecting defects than others, and different methods find \\ndifferent kinds of defects. One way to evaluate defect-detection methods is to deter-\\nmine the percentage of defects they detect out of the total defects that exist at that \\nTable 20-1 Team Ranking on Each Objective\\nObjective Team Was Told \\nto Optimize\\nMinimum \\nmemory \\nuse\\nMost \\nreadable \\noutput\\nMost \\nreadable \\ncode\\nLeast \\ncode\\nMinimum \\nprogramming \\ntime\\nMinimum memory 1 4 4 2 5\\nOutput readability 5 1 1 5 3\\nProgram readability 3 2 2 3 4\\nLeast code 2 5 3 1 3\\nMinimum programming \\ntime\\n43 5 4 1\\nSource: Adapted from “Goals and Performance in Computer Programming” (Weinberg and Schulman\\n1974).\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 506}, page_content='470 Chapter 20: The Software-Quality Landscape\\npoint in the project. Table 20-2 shows the percentages of defects detected by several \\ncommon defect-detection techniques.\\nThe most interesting facts that this data reveals is that the modal rates don’t rise above \\n75 percent for any single technique and that the techniques average about 40 percent. \\nMoreover, for the most common kinds of defect detection—unit testing and integra-\\ntion testing—the modal rates are only 30–35 percent. The typical organization uses a \\ntest-heavy defect-removal approach and achieves only about 85 percent defect-\\nremoval efficiency. Leading organizations use a wider variety of techniques and \\nachieve defect-removal efficiencies of 95 percent or higher (Jones 2000). \\nThe strong implication is that if project developers are striving for a higher defect-\\ndetection rate, they need to use a combination of techniques. A classic study by Glen-\\nford Myers confirmed this implication (1978b). Myers studied a group of program-\\nmers with a minimum of 7 and an average of 11 years of professional experience. \\nUsing a program with 15 known errors, he had each programmer look for errors by \\nusing one of these techniques:\\n■ Execution testing against the specification\\n■ Execution testing against the specification with the source code\\n■ Walk-through/inspection using the specification and the source code\\nTable 20-2 Defect-Detection Rates\\nRemoval Step Lowest Rate Modal Rate Highest Rate\\nInformal design reviews 25% 35% 40%\\nFormal design inspections 45% 55% 65%\\nInformal code reviews 20% 25% 35%\\nFormal code inspections 45% 60% 70%\\nModeling or prototyping 35% 65% 80%\\nPersonal desk-checking of code 20% 40% 60%\\nUnit test 15% 30% 50%\\nNew function (component) test 20% 30% 35%\\nIntegration test 25% 35% 40%\\nRegression test 15% 25% 30%\\nSystem test 25% 40% 55%\\nLow-volume beta test (<10 sites) 25% 35% 40%\\nHigh-volume beta test (>1,000 sites) 60% 75% 85%\\nSource: Adapted from Programming Productivity (Jones 1986a), “Software Defect-Removal Effi-\\nciency” (Jones 1996), and “What We Have Learned About Fighting Defects” (Shull et al. 2002).\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 507}, page_content='20.3 Relative Effectiveness of Quality Techniques 471\\nMyers found a huge variation in the number of defects detected in the program, rang-\\ning from 1.0 to 9.0 defects found. The average number found was 5.1, or about a third \\nof those known.\\nWhen used individually, no method had a statistically significant advantage over any \\nof the others. The variety of errors people found was so great, however, that any com-\\nbination of two methods—including having two independent groups using the same \\nmethod—increased the total number of defect s found by a factor of almost 2. Studies \\nat NASA’s Software Engineering Labora tory, Boeing, and other companies have \\nreported that different people tend to fi nd different defects. Only about 20 percent \\nof the errors found by inspections were found by more than one inspector \\n(Kouchakdjian, Green, and Basili 1989; Tripp, Struck, and Pflug 1991; Schneider, \\nMartin, and Tsai 1992).\\nGlenford Myers points out that human processes (inspections and walk-throughs, for \\ninstance) tend to be better than computer-based testing at finding certain kinds of \\nerrors and that the opposite is true for other kinds of errors (1979). This result was con-\\nfirmed in a later study, which found that code reading detected more interface defects \\nand functional testing detected more control defects (Basili, Selby, and Hutchens 1986). \\nTest guru Boris Beizer reports that inform al test approaches typically achieve only \\n50–60 percent test coverage unless you’re using a coverage analyzer (Johnson 1994).\\nThe upshot is that defect-detection methods work better in combination than they do \\nsingly. Jones made the same point when he observed that cumulative defect-detection \\nefficiency is significantly higher than that of any individual technique. The outlook for \\nthe effectiveness of testing used by itself is bleak. Jones points out that a combination \\nof unit testing, functional testing, and system testing often results in a cumulative \\ndefect detection of less than 60 percent, which is usually inadequate for production \\nsoftware.\\nThis data can also be used to understand why programmers who begin working with a \\ndisciplined defect-removal technique such as Extreme Programming experience higher \\ndefect-removal levels than they have experienced previously. As Table 20-3 illustrates, the \\nset of defect-removal practices used in Extreme Programming would be expected to \\nachieve about 90 percent defect-removal efficiency in the average case and 97 percent in \\nthe best case, which is far better than the industry average of 85 percent defect removal. \\nAlthough some people have linked this effectiveness to synergy among Extreme Pro-\\ngramming’s practices, it is really just a predictable outcome of using these specific defect-\\nremoval practices. Other combinations of practices can work equally well or better, and \\nthe determination of which specific defect-removal practices to use to achieve a desired \\nquality level is one part of effective project planning. \\n1\\n2\\n3\\nHARD DATA\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 508}, page_content='472 Chapter 20: The Software-Quality Landscape\\nCost of Finding Defects\\nSome defect-detection practices cost more than others. The most economical practices \\nresult in the least cost per defect found, all other things being equal. The qualification \\nthat all other things must be equal is important because per-defect cost is influenced by \\nthe total number of defects found, the stage at which each defect is found, and other fac-\\ntors besides the economics of a specific defect-detection technique.\\nMost  studies have found that inspections are cheaper than testing. A study at the Soft-\\nware Engineering Laboratory found that code reading detected about 80 percent \\nmore faults per hour than testing (Basili and Selby 1987). Another organization found \\nthat it cost six times as much to detect design defects by using testing as by using \\ninspections (Ackerman, Buchwald, and Lewski 1989). A later study at IBM found that \\nonly 3.5 staff hours were needed to find each error when using code inspections, \\nwhereas 15–25 hours were needed to find each error through testing (Kaplan 1995).\\nCost of Fixing Defects\\nThe cost of finding defects is only one part of the cost equation. The other is the cost \\nof fixing defects. It might seem at first glance that how the defect is found wouldn’t \\nmatter—it would always cost the same amount to fix.\\nCross-Reference For details \\non the fact that defects \\nbecome more expensive the \\nlonger they stay in a system, \\nsee “Appeal to Data” in Sec-\\ntion 3.1. For an up-close look \\nat errors themselves, see \\nSection 22.4, “Typical Errors.”\\nThat isn’t true because the longer a defect remains in the system, the more expensive it \\nbecomes to remove. A detection technique that finds the error earlier therefore results in \\na lower cost of fixing it. Even more important, some techniques, such as inspections, \\ndetect the symptoms and causes of defects in one step; others, such as testing, find \\nsymptoms but require additional work to diagnose and fix the root cause. The result is \\nthat one-step techniques are substantially cheaper overall than two-step ones.\\nTable 20-3 Extreme Programming’s Estimated Defect-Detection Rate \\nRemoval Step Lowest Rate Modal Rate Highest Rate\\nInformal design reviews \\n(pair programming)\\n25% 35% 40%\\nInformal code reviews \\n(pair programming)\\n20% 25% 35%\\nPersonal desk-checking of code 20% 40% 60%\\nUnit test 15% 30% 50%\\nIntegration test 25% 35% 40%\\nRegression test 15% 25% 30%\\nExpected cumulative defect-removal \\nefficiency\\n~74% ~90% ~97%\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 509}, page_content='20.4 When to Do Quality Assurance 473\\nMicrosoft’s applications division has found that it takes three hours to find and fix a \\ndefect by using code inspection, a one-step technique, and 12 hours to find and fix a \\ndefect by using testing, a two-step technique (Moore 1992). Collofello and Woodfield \\nreported on a 700,000-line program built by over 400 developers (1989). They found \\nthat code reviews were several times as cost-effective as testing—a 1.38 return on \\ninvestment vs. 0.17.\\nThe bottom line is that an effective software-quality program must include a combina-\\ntion of techniques that apply to all stages of development. Here’s a recommended \\ncombination for achieving higher-than-average quality:\\n■ Formal inspections of all requirements, all architecture, and designs for critical \\nparts of a system \\n■ Modeling or prototyping \\n■ Code reading or inspections\\n■ Execution testing\\n20.4 When to Do Quality Assurance\\nCross-Reference Quality \\nassurance of upstream activ-\\nities—requirements and \\narchitecture, for instance—\\nis outside the scope of this \\nbook. The “Additional \\nResources” section at the \\nend of the chapter describes \\nbooks you can turn to for \\nmore information about \\nthem.\\nAs Chapter 3 (“Measure Twice, Cut Once: Upstream Prerequisites”) noted, the earlier \\nan error is inserted into software, the more entangled it becomes in other parts of the \\nsoftware and the more expensive it becomes to remove. A fault in requirements can \\nproduce one or more corresponding faults in design, which can produce many corre-\\nsponding faults in code. A requirements error can result in extra architecture or in bad \\narchitectural decisions. The extra architecture results in extra code, test cases, and \\ndocumentation. Or a requirements error can result in architecture, code, and test \\ncases that are thrown away. Just as it’s a good idea to work out the defects in the blue-\\nprints for a house before pouring the foundation in concrete, it’s a good idea to catch \\nrequirements and architecture errors before they affect later activities.\\nIn addition, errors in requirements or architecture tend to be more sweeping than \\nconstruction errors. A single architectural error can affect several classes and dozens \\nof routines, whereas a single construction error is unlikely to affect more than one rou-\\ntine or class. For this reason, too, it’s cost-effective to catch errors as early as you can.\\nDefects creep into software at all stages. Consequently, you should emphasize quality-\\nassurance work in the early stages and throughout the rest of the project. It should be \\nplanned into the project as work begins; it should be part of the technical fiber of the \\nproject as work continues; and it should punctuate the end of the project, verifying \\nthe quality of the product as work ends.\\n1\\n2\\n3\\nHARD DATA\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 510}, page_content='474 Chapter 20: The Software-Quality Landscape\\n20.5 The General Principle of Software Quality\\nThere’s no such thing as a free lunch, and even if there were, there’s no guarantee that \\nit would be any good. Software development is a far cry from haute cuisine, however, \\nand software quality is unusual in a significant way. The General Principle of Software \\nQuality is that improving quality reduces development costs.\\nUnderstanding this principle depends on understanding a key observation: the best \\nway to improve productivity and quality is to reduce the time spent reworking code, \\nwhether the rework arises from changes in requirements, changes in design, or debug-\\nging. The industry-average productivity for a software product is about 10 to 50 of \\nlines of delivered code per person per day (including all noncoding overhead). It \\ntakes only a matter of minutes to type in 10 to 50 lines of code, so how is the rest of the \\nday spent?\\nCross-Reference For details \\non the difference between \\nwriting an individual program \\nand writing a software prod-\\nuct, see “Programs, Products, \\nSystems, and System Prod-\\nucts” in Section 27.5.\\nPart of the reason for these seemingly low productivity figures is that industry average \\nnumbers like these factor nonprogrammer time into the lines-of-code-per-day figure. \\nTester time, project manager time, and administrative support time are all included. \\nNoncoding activities, such as requirements development and architecture work, are \\nalso typically factored into those lines-of-code-per-day figures. But none of that is what \\ntakes up so much time. \\nThe single biggest activity on most projects is debugging and correcting code that \\ndoesn’t work properly. Debugging and associated refactoring and other rework con-\\nsume about 50 percent of the time on a traditional, naive software-development cycle. \\n(See Section 3.1, “Importance of Prerequisites,” for more details.) Reducing debug-\\nging by preventing errors improves productivity. Therefore, the most obvious method \\nof shortening a development schedule is to improve the quality of the product and \\ndecrease the amount of time spent debugging and reworking the software.\\nThis analysis is confirmed by field data. In a review of 50 development projects involv-\\ning over 400 work-years of effort and almost 3 million lines of code, a study at NASA’s \\nSoftware Engineering Laboratory found that increased quality assurance was associated \\nwith decreased error rate but did not increase overall development cost (Card 1987).\\nA study at IBM produced similar findings:\\nSoftware projects with the lowest levels of defects had the shortest development \\nschedules and the highest development productivity.... software defect removal is \\nactually the most expensive and time-consuming form of work for software \\n(Jones 2000).\\nKEY POINT\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 511}, page_content='20.5 The General Principle of Software Quality 475\\nThe same effect holds true at the small end of the scale. In a 1985 study, 166 profes-\\nsional programmers wrote programs from the same specification. The resulting pro-\\ngrams averaged 220 lines of code and a little under five hours to write. The fascinating \\nresult was that programmers who took the median time to complete their programs \\nproduced programs with the greatest number of errors. The programmers who took \\nmore or less than the median time produced programs with significantly fewer errors \\n(DeMarco and Lister 1985). Figure 20-2 graphs the results.\\nFigure 20-2 Neither the fastest nor the slowest development approach produces the soft-\\nware with the most defects.\\nThe two slowest groups took about five times as long to achieve roughly the same \\ndefect rate as the fastest group. It’s not necessarily the case that writing software with-\\nout defects takes more time than writing software with defects. As the graph shows, it \\ncan take less.\\nAdmittedly, on certain kinds of projects, quality assurance costs money. If you’re writ-\\ning code for the space shuttle or for a medical life-support system, the degree of reli-\\nability required makes the project more expensive.\\nCompared to the traditional code-test-debug cycle, an enlightened software-quality \\nprogram saves money. It redistributes resources away from debugging and refactoring \\ninto upstream quality-assurance activities. Upstream activities have more leverage on \\nproduct quality than downstream activities, so the time you invest upstream saves \\nmore time downstream. The net effect is fewer defects, shorter development time, and \\nlower costs. You’ll see several more examples of the General Principle of Software \\nQuality in the next three chapters.\\n1\\n2\\n3\\nHARD DATA\\nAverage \\nDefects\\n1.0\\n0.8\\n0.6\\n0.4\\n0.2\\n1.2\\n1.4\\nTime to Complete the Program in Minutes\\n100 500 Over \\n500'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 512}, page_content='476 Chapter 20: The Software-Quality Landscape\\ncc2e.com/2043 CHECKLIST: A Quality-Assurance Plan\\n❑ Have you identified specific quality characteristics that are important to \\nyour project?\\n❑ Have you made others aware of the project’s quality objectives?\\n❑ Have you differentiated between external and internal quality characteristics?\\n❑ Have you thought about the ways in which some characteristics might \\ncompete with or complement others?\\n❑ Does your project call for the use of several different error-detection tech-\\nniques suited to finding several different kinds of errors?\\n❑ Does your project include a plan to take steps to assure software quality \\nduring each stage of software development?\\n❑ Is the quality measured in some way so that you can tell whether it’s \\nimproving or degrading?\\n❑ Does management understand that quality assurance incurs additional \\ncosts up front in order to save costs later?\\nAdditional Resources\\ncc2e.com/2050 It’s not hard to list books in this section because virtually any book on effective software \\nmethodologies describes techniques that result in improved quality and productivity. \\nThe difficulty is finding books that deal with software quality per se. Here are two:\\nGinac, Frank P. Customer Oriented Software Quality Assurance. Englewood Cliffs, NJ: Pren-\\ntice Hall, 1998. This is a very short book that describes quality attributes, quality metrics, \\nQA programs, and the role of testing in quality, as well as well-known quality improve-\\nment programs, including the Software Engineering Institute’s CMM and ISO 9000. \\nLewis, William E. Software Testing and Continuous Quality Improvement, 2d ed. Auer-\\nbach Publishing, 2000. This book provides a comprehensive discussion of a quality \\nlife cycle, as well as extensive discussion of testing techniques. It also provides numer-\\nous forms and checklists.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 513}, page_content='Key Points 477\\nRelevant Standards\\ncc2e.com/2057 IEEE Std 730-2002, IEEE Standard for Software Quality Assurance Plans. \\nIEEE Std 1061-1998, IEEE Standard for a Software Quality Metrics Methodology. \\nIEEE Std 1028-1997, Standard for Software Reviews.\\nIEEE Std 1008-1987 (R1993), Standard for Software Unit Testing.\\nIEEE Std 829-1998, Standard for Software Test Documentation.\\nKey Points\\n■ Quality is free, in the end, but it requires a reallocation of resources so that \\ndefects are prevented cheaply instead of fixed expensively.\\n■ Not all quality-assurance goals are simultaneously achievable. Explicitly decide \\nwhich goals you want to achieve, and communicate the goals to other people on \\nyour team.\\n■ No single defect-detection technique is completely effective by itself. Testing by \\nitself is not optimally effective at removing errors. Successful quality-assurance \\nprograms use several different techniques to detect different kinds of errors.\\n■ You can apply effective techniques during construction and many equally power-\\nful techniques before construction. The earlier you find a defect, the less inter-\\ntwined it will become with the rest of your code and the less damage it will cause.\\n■ Quality assurance in the software arena is process-oriented. Software develop-\\nment doesn’t have a repetitive phase that affects the final product like manufac-\\nturing does, so the quality of the result is controlled by the process used to \\ndevelop the software.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 515}, page_content='479\\nChapter 21\\nCollaborative Construction\\ncc2e.com/2185 Contents\\n■ 21.1 Overview of Collaborative Development Practices: page 480\\n■ 21.2 Pair Programming: page 483\\n■ 21.3 Formal Inspections: page 485\\n■ 21.4 Other Kinds of Collaborative Development Practices: page 492\\nRelated Topics\\n■ The software-quality landscape: Chapter 20\\n■ Developer testing: Chapter 22\\n■ Debugging: Chapter 23\\n■ Prerequisites to construction: Chapters 3 and 4\\nYou might have had an experience common to many programmers. You walk into \\nanother programmer’s cubicle and say, “Would you mind looking at this code? I’m hav-\\ning some trouble with it.” You start to explain the problem: “It can’t be a result of this \\nthing, because I did that. And it can’t be the result of this other thing, because I did this. \\nAnd it can’t be the result of—wait a minute. It could be the result of that. Thanks!” You’ve \\nsolved your problem before your “helper” has had a chance to say a word.\\nIn one way or another, all collaborative construction techniques are attempts to for-\\nmalize the process of showing your work to someone else for the purpose of flushing \\nout errors.\\nIf you’ve read about inspections and pair programming before, you won’t find much \\nnew information in this chapter. The extent of the hard data about the effectiveness of \\ninspections in Section 21.3 might surprise you, and you might not have considered \\nthe code-reading alternative described in Section 21.4. You might also take a look at \\nTable 21-1, “Comparison of Collaborative Construction Techniques,” at the end of the \\nchapter. If your knowledge is all from your own experience, read on! Other people \\nhave had different experiences, and you’ll find some new ideas.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 516}, page_content='480 Chapter 21: Collaborative Construction\\n21.1 Overview of Collaborative Development Practices\\n“Collaborative construction” refers to pair programming, formal inspections, informal \\ntechnical reviews, and document reading, as well as other techniques in which develop-\\ners share responsibility for creating code and other work products. At my company, the \\nterm “collaborative construction” was coined by Matt Peloquin in about 2000. The term \\nappears to have been coined independently by others in the same time frame.\\nAll collaborative construction techniques, despite their differences, are based on the \\nideas that developers are blind to some of the trouble spots in their work, that other \\npeople don’t have the same blind spots, and that it’s beneficial for developers to have \\nsomeone else look at their work. Studies at the Software Engineering Institute have \\nfound that developers insert an average of 1 to 3 defects per hour into their designs \\nand 5 to 8 defects per hour into code (Humphrey 1997), so attacking these blind \\nspots is a key to effective construction.\\nCollaborative Construction Complements Other Quality-Assurance \\nTechniques\\nThe primary purpose of collaborative construction is to improve software quality. As \\nnoted in Chapter 20, “The Software-Quality Landscape,” software testing has limited \\neffectiveness when used alone—the average defect-detection rate is only about 30 per-\\ncent for unit testing, 35 percent for integration testing, and 35 percent for low-volume \\nbeta testing. In contrast, the average effectivenesses of design and code inspections are \\n55 and 60 percent (Jones 1996). The secondary benefit of collaborative construction \\nis that it decreases development time, which in turn lowers development costs.\\nEarly reports on pair programming suggest that it can achieve a code-quality level simi-\\nlar to formal inspections (Shull et al 2002). The cost of full-up pair programming is \\nprobably higher than the cost of solo development—on the order of 10–25 percent \\nhigher—but the reduction in development time appears to be on the order of 45 percent, \\nwhich in some cases may be a decisive advantage over solo development (Boehm and \\nTurner 2004), although not over inspections which have produced similar results.\\nTechnical reviews have been studied much longer than pair programming, and their \\nresults, as described in case studies and elsewhere, have been impressive:\\n■ IBM found that each hour of inspection prevented about 100 hours of related \\nwork (testing and defect correction) (Holland 1999).\\n■ Raytheon reduced its cost of defect correction (rework) from about 40 percent \\nof total project cost to about 20 percent through an initiative that focused on \\ninspections (Haley 1996).\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA\\nKEY POINT\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 517}, page_content='21.1 Overview of Collaborative Development Practices 481\\n■ Hewlett-Packard reported that its inspection program saved an estimated $21.5 \\nmillion per year (Grady and Van Slack 1994).\\n■ Imperial Chemical Industries found that the cost of maintaining a portfolio of \\nabout 400 programs was only about 10 percent as high as the cost of maintaining \\na similar set of programs that had not been inspected (Gilb and Graham 1993).\\n■ A study of large programs found that each hour spent on inspections avoided an \\naverage of 33 hours of maintenance work and that inspections were up to 20 \\ntimes more efficient than testing (Russell 1991).\\n■ In a software-maintenance organization, 55 percent of one-line maintenance \\nchanges were in error before code reviews were introduced. After reviews were \\nintroduced, only 2 percent of the changes were in error (Freedman and Wein-\\nberg 1990). When all changes were considered, 95 percent were correct the first \\ntime after reviews were introduced. Before reviews were introduced, under 20 \\npercent were correct the first time.\\n■ A group of 11 programs were developed by the same group of people, and all \\nwere released to production. The first five were developed without reviews and \\naveraged 4.5 errors per 100 lines of code. The other six were inspected and aver-\\naged only 0.82 errors per 100 lines of code. Reviews cut the errors by over 80 \\npercent (Freedman and Weinberg 1990).\\n■ Capers Jones reports that of all the software projects he has studied that have \\nachieved 99 percent defect-removal rates or better, all have used formal inspec-\\ntions. Also, none of the projects that achieved less than 75 percent defect-\\nremoval efficiency used formal inspections (Jones 2000).\\nA number of these cases illustrate the General Principle of Software Quality, which holds \\nthat reducing the number of defects in the software also improves development time.\\nVarious studies have shown that in addition to being more effective at catching errors \\nthan testing, collaborative practices find different kinds of errors than testing does \\n(Myers 1978; Basili, Selby, and Hutchens 1986). As Karl Wiegers points out, “A \\nhuman reviewer can spot unclear error messages, inadequate comments, hard-coded \\nvariable values, and repeated code patterns that should be consolidated. Testing \\nwon’t” (Wiegers 2002). A secondary effect is that when people know their work will \\nbe reviewed, they scrutinize it more carefully. Thus, even when testing is done effec-\\ntively, reviews or other kinds of collaboration are needed as part of a comprehensive \\nquality program.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 518}, page_content='482 Chapter 21: Collaborative Construction\\nCollaborative Construction Provides Mentoring in Corporate Culture \\nand Programming Expertise\\nInformal review procedures \\nwere passed on from person \\nto person in the general cul-\\nture of computing for many \\nyears before they were \\nacknowledged in print. The \\nneed for reviewing was so \\nobvious to the best pro-\\ngrammers that they rarely \\nmentioned it in print, while \\nthe worst programmers \\nbelieved they were so good \\nthat their work did not need \\nreviewing. \\n—Daniel Freedman and \\nGerald Weinberg\\nSoftware standards can be written down and distributed, but if no one talks about \\nthem or encourages others to use them, they won’t be followed. Reviews are an impor-\\ntant mechanism for giving programmers feedback about their code. The code, the \\nstandards, and the reasons for making the code meet the standards are good topics \\nfor review discussions.\\nIn addition to feedback about how well they follow standards, programmers need \\nfeedback about more subjective aspects of programming: formatting, comments, vari-\\nable names, local and global variable use, design approaches, the-way-we-do-things-\\naround-here, and so on. Programmers who are still wet behind the ears need guidance \\nfrom those who are more knowledgeable, and more knowledgeable programmers \\nwho tend to be busy need to be encouraged to spend time sharing what they know. \\nReviews create a venue for more experienced and less experienced programmers to \\ncommunicate about technical issues. As such, reviews are an opportunity for cultivat-\\ning quality improvements in the future as much as in the present.\\nOne team that used formal inspections reported that inspections quickly brought all \\nthe developers up to the level of the best developers (Tackett and Van Doren 1999).\\nCollective Ownership Applies to All Forms of \\nCollaborative Construction\\nCross-Reference A concept \\nthat spans all collaborative \\nconstruction techniques is \\nthe idea of collective owner-\\nship. In some development \\nmodels, programmers own \\nthe code they write and offi-\\ncial or unofficial restrictions \\non modifying someone else’s \\ncode exist. Collective owner-\\nship increases the need for \\nwork coordination, especially \\nconfiguration management. \\nFor details, see Section 28.2, \\n“Configuration Manage-\\nment.”\\nWith collective ownership, all code is owned by the group rather than by individuals \\nand can be accessed and modified by various members of the group. This produces \\nseveral valuable benefits:\\n■ Better code quality arises from multiple sets of eyes seeing the code and multiple \\nprogrammers working on the code.\\n■ The impact of someone leaving the project is lessened because multiple people \\nare familiar with each section of code.\\n■ Defect-correction cycles are shorter overall because any of several programmers \\ncan potentially be assigned to fix bugs on an as-available basis.\\nSome methodologies, such as Extreme Programming, recommend formally pairing \\nprogrammers and rotating their work assignments over time. At my company, we’ve \\nfound that programmers don’t need to pair up formally to achieve good code cover-\\nage. Over time we achieve cross-coverage through a combination of formal and infor-\\nmal technical reviews, pair programming when needed, and rotation of defect-\\ncorrection assignments.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 519}, page_content='21.2 Pair Programming 483\\nCollaboration Applies As Much Before Construction As After\\nThis book is about construction, so collaboration on detailed design and code are the \\nfocus of this chapter. However, most of the comments about collaborative construc-\\ntion in this chapter also apply to estimates, plans, requirements, architecture, testing, \\nand maintenance work. By studying the references at the end of the chapter, you can \\napply collaborative techniques to most software development activities.\\n21.2 Pair Programming\\nWhen pair programming, one programmer types in code at the keyboard and the \\nother programmer watches for mistakes and thinks strategically about whether the \\ncode is being written correctly and whether the right code is being written. Pair pro-\\ngramming was originally popularized by Extreme Programming (Beck 2000), but it is \\nnow being used more widely (Williams and Kessler 2002).\\nKeys to Success with Pair Programming\\nThe basic concept of pair programming is simple, but its use nonetheless benefits \\nfrom a few guidelines:\\nSupport pair programming with coding standards Pair programming will not be effec-\\ntive if the two people in the pair spend their time arguing about coding style. Try to stan-\\ndardize what Chapter 5, “Design in Construction,” refers to as the “accidental attributes” \\nof programming so that the programmers can focus on the “essential” task at hand.\\nDon’t let pair programming turn into watching The person without the keyboard \\nshould be an active participant in the programming. That person is analyzing the \\ncode, thinking ahead to what will be coded next, evaluating the design, and planning \\nhow to test the code.\\nDon’t force pair programming of the easy stuff One group that used pair program-\\nming for the most complicated code found it more expedient to do detailed design at \\nthe whiteboard for 15 minutes and then to program solo (Manzo 2002). Most organi-\\nzations that have tried pair programming eventually settle into using pairs for part of \\ntheir work but not all of it (Boehm and Turner 2004).\\nRotate pairs and work assignments regularly In pair programming, as with other \\ncollaborative development practices, benefit arises from different programmers learn-\\ning different parts of the system. Rotate pair assignments regularly to encourage cross-\\npollination—some experts recommend changing pairs as often as daily (Reifer 2002).\\nEncourage pairs to match each other’s pace One partner going too fast limits the \\nbenefit of having the other partner. The faster partner needs to slow down, or the pair \\nshould be broken up and reconfigured with different partners.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 520}, page_content='484 Chapter 21: Collaborative Construction\\nMake sure both partners can see the monitor Even seemingly mundane issues like \\nbeing able to see the monitor and using fonts that are too small can cause problems.\\nDon’t force people who don’t like each other to pair Sometimes personality conflicts \\nprevent people from pairing effectively. It’s pointless to force people who don’t get \\nalong to pair, so be sensitive to personality matches (Beck 2000, Reifer 2002).\\nAvoid pairing all newbies Pair programming works best when at least one of the \\npartners has paired before (Larman 2004).\\nAssign a team leaderIf your whole team wants to do 100 percent of its program-\\nming in pairs, you’ll still need to assign  one person to coordinate work assign-\\nments, be held accountable for results, and act as the point of contact for people \\noutside the project.\\nBenefits of Pair Programming\\nPair programming produces numerous benefits:\\n■ It holds up better under stress than solo development. Pairs encourage each \\nother to keep code quality high even when there’s pressure to write quick and \\ndirty code.\\n■ It improves code quality. The readability and understandability of the code \\ntends to rise to the level of the best programmer on the team.\\n■ It shortens schedules. Pairs tend to write code faster and with fewer errors. The \\nproject team spends less time at the end of the project correcting defects.\\n■ It produces all the other general benefits of collaborative construction, includ-\\ning disseminating corporate culture, mentoring junior programmers, and foster-\\ning collective ownership.\\ncc2e.com/2192 CHECKLIST: Effective Pair Programming\\n❑ Do you have a coding standard so that pair programmers stay focused on \\nprogramming rather than on philosophical coding-style discussions?\\n❑ Are both partners participating actively?\\n❑ Are you avoiding pair programming everything and, instead, selecting the \\nassignments that will really benefit from pair programming?\\n❑ Are you rotating pair assignments and work assignments regularly?\\n❑ Are the pairs well matched in terms of pace and personality?\\n❑ Is there a team leader to act as the focal point for management and other \\npeople outside the project?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 521}, page_content='21.3 Formal Inspections 485\\n21.3 Formal Inspections\\nFurther Reading If you want \\nto read the original article on \\ninspections, see “Design and \\nCode Inspections to Reduce \\nErrors in Program Develop-\\nment” (Fagan 1976).\\nAn inspection is a specific kind of review that has been shown to be extremely effec-\\ntive in detecting defects and to be relatively economical compared to testing. Inspec-\\ntions were developed by Michael Fagan and used at IBM for several years before Fagan \\npublished the paper that made them public. Although any review involves reading \\ndesigns or code, an inspection differs from a run-of-the-mill review in several key \\nways:\\n■ Checklists focus the reviewers’ attention on areas that have been problems in \\nthe past.\\n■ The inspection focuses on defect detection, not correction.\\n■ Reviewers prepare for the inspection meeting beforehand and arrive with a list \\nof the problems they’ve discovered.\\n■ Distinct roles are assigned to all participants.\\n■ The moderator of the inspection isn’t the author of the work product under \\ninspection.\\n■ The moderator has received specific training in moderating inspections.\\n■ The inspection meeting is held only if all participants have adequately prepared.\\n■ Data is collected at each inspection and is fed into future inspections to improve \\nthem.\\n■ General management doesn’t attend the inspection meeting unless you’re inspect-\\ning a project plan or other management materials. Technical leaders might attend.\\nWhat Results Can You Expect from Inspections?\\nIndividual inspections typically catch about 60 percent of defects, which is higher \\nthan other techniques except prototyping and high-volume beta testing. These results \\nhave been confirmed numerous times at various organizations, including Harris \\nBCSD, National Software Quality Experiment, Software Engineering Institute, Hewlett \\nPackard, and so on (Shull et al 2002).\\nThe combination of design and code inspections usually removes 70–85 percent or \\nmore of the defects in a product (Jones 1996). Inspections identify error-prone classes \\nearly, and Capers Jones reports that they result in 20–30 percent fewer defects per \\n1000 lines of code than less formal review practices. Designers and coders learn to \\nimprove their work through participating in inspections, and inspections increase \\nproductivity by about 20 percent (Fagan 1976, Humphrey 1989, Gilb and Graham \\n1993, Wiegers 2002). On a project that uses inspections for design and code, the \\ninspections will take up about 10–15 percent of project budget and will typically \\nreduce overall project cost.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 522}, page_content='486 Chapter 21: Collaborative Construction\\nInspections can also be used for assessing progress, but it’s the technical progress that \\nis assessed. That usually means answering two questions: Is the technical work being \\ndone? And is the technical work being done well? The answers to both questions are \\nbyproducts of formal inspections.\\nRoles During an Inspection\\nOne key characteristic of an inspection is that each person involved has a distinct role \\nto play. Here are the roles:\\nModerator The moderator is responsible for keeping the inspection moving at a rate \\nthat’s fast enough to be productive but slow enough to find the most errors possible. \\nThe moderator must be technically competent—not necessarily an expert in the partic-\\nular design or code under inspection, but capable of understanding relevant details. \\nThis person manages other aspects of the inspection, such as distributing the design \\nor code to be reviewed, distributing the inspection checklist, setting up a meeting \\nroom, reporting inspection results, and following up on the action items assigned at \\nthe inspection meeting.\\nAuthor The person who wrote the design or code plays a relatively minor role in the \\ninspection. Part of the goal of an inspection is to be sure that the design or code \\nspeaks for itself. If the design or code under inspection turns out to be unclear, the \\nauthor will be assigned the job of making it clearer. Otherwise, the author’s duties are \\nto explain parts of the design or code that are unclear and, occasionally, to explain \\nwhy things that seem like errors are actually acceptable. If the project is unfamiliar to \\nthe reviewers, the author might also present an overview of the project in preparation \\nfor the inspection meeting.\\nReviewer A reviewer is anyone who has a direct interest in the design or code but \\nwho is not the author. A reviewer of a design might be the programmer who will \\nimplement the design. A tester or higher-level architect might also be involved. The \\nrole of the reviewers is to find defects. They usually find defects during preparation, \\nand, as the design or code is discussed at the inspection meeting, the group should \\nfind considerably more defects.\\nScribe The scribe records errors that are detected and the assignments of action \\nitems during the inspection meeting. Neither the author nor the moderator should be \\nthe scribe.\\nManagement Including management in inspections is not usually a good idea. The \\npoint of a software inspection is that it is a purely technical review. Management’s \\npresence changes the interactions: people feel that they, instead of the review materi-\\nals, are under evaluation, which changes the focus from technical to political. How-\\never, management has a right to know the results of an inspection, and an inspection \\nreport is prepared to keep management informed.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 523}, page_content='21.3 Formal Inspections 487\\nSimilarly, under no circumstances should inspection results be used for performance \\nappraisals. Don’t kill the goose that lays the golden eggs. Code examined in an inspec-\\ntion is still under development. Evaluation of performance should be based on final \\nproducts, not on work that isn’t finished.\\nOverall, an inspection should have no fewer than three participants. It’s not possible \\nto have a separate moderator, author, and reviewer with fewer than three people, and \\nthose roles shouldn’t be combined. Traditional advice is to limit an inspection to \\nabout six people because, with any more, the group becomes too large to manage. \\nResearchers have generally found that having more than two to three reviewers \\ndoesn’t appear to increase the number of defects found (Bush and Kelly 1989, Porter \\nand Votta 1997). However, these general findings are not unanimous, and results \\nappear to vary depending on the kind of material being inspected (Wiegers 2002). \\nPay attention to your experience, and adjust your approach accordingly.\\nGeneral Procedure for an Inspection\\nAn inspection consists of several distinct stages:\\nPlanning The author gives the design or code to the moderator. The moderator \\ndecides who will review the material and when and where the inspection meeting will \\noccur; the moderator then distributes the design or code and a checklist that focuses \\nthe attention of the inspectors. Materials should be printed with line numbers to \\nspeed up error identification during the meeting.\\nOverview When the reviewers aren’t familiar with the project they are reviewing, the \\nauthor can spend up to an hour or so describing the technical environment within \\nwhich the design or code has been created. Having an overview tends to be a danger-\\nous practice because it can lead to a glossing over of unclear points in the design or \\ncode under inspection. The design or code should speak for itself; the overview \\nshouldn’t speak for it.\\nCross-Reference For a list of \\nchecklists you can use to \\nimprove code quality, see \\npage xxix.\\nPreparation Each reviewer works alone to scrutinize the design or code for errors. \\nThe reviewers use the checklist to stimulate and direct their examination of the review \\nmaterials.\\nFor a review of application code written in a high-level language, reviewers can pre-\\npare at about 500 lines of code per hour. For a review of system code written in a high-\\nlevel language, reviewers can prepare at only about 125 lines of code per hour (Hum-\\nphrey 1989). The most effective rate of review varies a great deal, so keep records of \\npreparation rates in your organization to determine the rate that’s most effective in \\nyour environment.\\nSome organizations have found that inspections are more effective when each \\nreviewer is assigned a specific perspective. A reviewer might be asked to prepare for \\nthe inspection from the point of view of the maintenance programmer, the customer,'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 524}, page_content='488 Chapter 21: Collaborative Construction\\nor the designer, for example. Research on perspective-based reviews has not been \\ncomprehensive, but it suggests that perspective-based reviews might uncover more \\nerrors than general reviews.\\nAn additional variation in inspection preparation is to assign each reviewer one or \\nmore scenarios to check. Scenarios can involve specific questions that a reviewer is \\nassigned to answer, such as “Are there any requirements that are not satisfied by this \\ndesign?” A scenario might also involve a specific task that a reviewer is assigned to per-\\nform, such as listing the specific requirements that a particular design element satis-\\nfies. You can also assign some reviewers to read the material front to back, back to \\nfront, or inside out.\\nInspection Meeting The moderator chooses someone other than the author to para-\\nphrase the design or read the code (Wiegers 2003). All logic is explained, including \\neach branch of each logical structure. During this presentation, the scribe records \\nerrors as they are detected, but discussion of an error stops as soon as it’s recognized \\nas an error. The scribe notes the type and the severity of the error, and the inspection \\nmoves on. If you have problems keeping the discussions focused, the moderator \\nmight ring a bell to get the group’s attention and put the discussion back on track.\\nThe rate at which the design or the code is considered should be neither too slow \\nnor too fast. If it’s too slow, attention ca n lag and the meeting won’t be productive. \\nIf it’s too fast, the group can overlook errors it would otherwise catch. Optimal \\ninspection rates vary from environment to environment, just as preparation rates \\ndo. Keep records so that over time you can determine the optimal rate for your envi-\\nronment. Other organizations have found that for system code, an inspection rate of \\n90 lines of code per hour is optimal. For applications code, the inspection rate can \\nbe as rapid as 500 lines of code per hour (Humphrey 1989). An average of about \\n150–200 nonblank, noncomment source statements per hour is a good place to \\nstart (Wiegers 2002).\\nDon’t discuss solutions during the meeting. The group should stay focused on identi-\\nfying defects. Some inspection groups don’t even allow discussion about whether a \\ndefect is really a defect. They assume that if someone is confused enough to think it’s \\na defect, the design, code, or documentation needs to be clarified.\\nThe meeting generally should not last more than two hours. This doesn’t mean that \\nyou have to fake a fire alarm to get everyone out at the two-hour mark, but experience \\nat IBM and other companies has been that reviewers can’t concentrate for much more \\nthan about two hours at a time. For the same reason, it’s unwise to schedule more \\nthan one inspection on the same day.\\nInspection Report Within a day of the inspection meeting, the moderator produces \\nan inspection report (e-mail or equivalent) that lists each defect, including its type and \\nseverity. The inspection report helps to ensure that all defects will be corrected, and'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 525}, page_content='21.3 Formal Inspections 489\\nit’s used to develop a checklist that emph asizes problems specific to the organiza-\\ntion. If you collect data on the time spen t and the number of errors found over time, \\nyou can respond to challenges about inspec tion’s efficacy with hard data. Other-\\nwise, you’ll be limited to saying that insp ections seem better. That won’t be as con-\\nvincing to someone who thinks testing seem s better. You’ll also be able to tell if \\ninspections aren’t working in your environment and mo dify or abandon them, as \\nappropriate. Data collection is also important because any new methodology needs \\nto justify its existence.\\nRework The moderator assigns defects to someone, usually the author, for repair. \\nThe assignee resolves each defect on the list.\\nFollow-UpThe moderator is responsible for seeing that all rework assigned during \\nthe inspection is carried out. Depending on the number of errors found and the sever-\\nity of those errors, you might follow up by having the reviewers reinspect the entire \\nwork product, having the reviewers reinspect only the fixes, or allowing the author to \\ncomplete the fixes without any follow-up.\\nThird-Hour Meeting Even though during the inspection participants aren’t allowed \\nto discuss solutions to the problems raised, some might still want to. You can hold an \\ninformal, third-hour meeting to allow interested parties to discuss solutions after the \\nofficial inspection is over.\\nFine-Tuning the Inspection\\nOnce you become skilled at performing inspections “by the book,” you can usually \\nfind several ways to improve them. Do n’t introduce changes willy-nilly, though. \\n“Instrument” the inspection process so that you know whether your changes are \\nbeneficial.\\nCompanies have often found that removing or combining any of the stages costs more \\nthan is saved (Fagan 1986). If you’re tempted to change the inspection process with-\\nout measuring the effect of the change, don’t. If you have measured the process and \\nyou know that your changed process works better than the one described here, go \\nright ahead.\\nAs you do inspections, you’ ll notice that certain kinds of errors occur more fre-\\nquently than other kinds. Create a checkl ist that calls attention to those kinds of \\nerrors so that reviewers will focus on them. Over time, you’ll find kinds of errors \\nthat aren’t on the checklist; add those to it. You might find that some errors on the \\ninitial checklist cease to occur; remove thos e. After a few inspections, your organiza-\\ntion will have a checklist for inspections customiz ed to its needs, and it might also \\nhave some clues about trouble areas in wh ich its programmers need more training \\nor support. Limit your checklist to one page or less. Longer ones are hard to use at \\nthe level of detail needed in an inspection.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 526}, page_content='490 Chapter 21: Collaborative Construction\\nEgos in Inspections\\nFurther Reading For a dis-\\ncussion of egoless program-\\nming, see The Psychology of \\nComputer Programming, 2d \\ned. (Weinberg 1998).\\nThe point of the inspection itself is to discover defects in the design or code. It is not \\nto explore alternatives or to debate about who is right and who is wrong. The point is \\nmost certainly not to criticize the author of the design or code. The experience should \\nbe a positive one for the author in which it’s obvious that group participation \\nimproves the program and is a learning experience for all involved. It should not con-\\nvince the author that some people in the group are jerks or that it’s time to look for a \\nnew job. Comments like “Anyone who knows Java knows that it’s more efficient to \\nloop from 0 to num-1, not 1 to num” are totally inappropriate, and if they occur, the \\nmoderator should make their inappropriateness unmistakably clear.\\nBecause the design or code is being criticized and the author probably feels somewhat \\nattached to it, the author will naturally feel some of the heat directed at the code. The \\nauthor should anticipate hearing criticisms of several defects that aren’t really defects \\nand several more that seem debatable. In spite of that, the author should acknowledge \\neach alleged defect and move on. Acknowledging a criticism doesn’t imply that the \\nauthor agrees with the content of the criticism. The author should not try to defend \\nthe work under review. After the review, the author can think about each point in pri-\\nvate and decide whether it’s valid.\\nReviewers must remember that the author has the ultimate responsibility for deciding \\nwhat to do about a defect. It’s fine to enjoy finding defects (and outside the review, to \\nenjoy proposing solutions), but each reviewer must respect the author’s ultimate right \\nto decide how to resolve an error.\\nInspections and Code Complete\\nI had a personal experience using inspections on the second edition of Code Complete. \\nFor the first edition of this book I initially wrote a rough draft. After letting the rough \\ndraft of each chapter sit in a drawer for a week or two, I reread the chapter cold and \\ncorrected the errors I found. I then circulated the revised chapter to about a dozen \\npeers for review, several of whom reviewed it quite thoroughly. I corrected the errors \\nthey found. After a few more weeks, I reviewed it again myself and corrected more \\nerrors. Finally, I submitted the manuscript to the publisher, where it was reviewed by \\na copy editor, technical editor, and proofreader. The book was in print for more than \\n10 years, and readers sent in about 200 corrections during that time.\\nYou might think there wouldn’t be many errors left in the book that had gone through \\nall that review activity. But that wasn’t the case. To create the second edition, I used \\nformal inspections of the first edition to identify issues that needed to be addressed in \\nthe second edition. Teams of three to four reviewers prepared according to the guide-\\nlines described in this chapter. Somewhat to my surprise, our formal inspections \\nfound several hundred errors in the first edition text that had not previously been \\ndetected through any of the numerous review activities.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 527}, page_content='21.3 Formal Inspections 491\\nIf I had any doubts about the value of formal inspections, my experience in creating \\nthe second edition of Code Complete eliminated them.\\nInspection Summary\\nInspection checklists encourage focused concentration. The inspection process is sys-\\ntematic because of its standard checklists and standard roles. It is also self-optimizing \\nbecause it uses a formal feedback loop to improve the checklists and to monitor prepa-\\nration and inspection rates. With this control over the process and continuing optimiza-\\ntion, inspection quickly becomes a powerful technique almost no matter how it begins.\\nFurther Reading For more \\ndetails on the SEI’s concept \\nof developmental maturity, \\nsee Managing the Software \\nProcess (Humphrey 1989).\\nThe Software Engineering Institute (SEI) has defined a Capability Maturity Model \\n(CMM) that measures the effectiveness of an organization’s software-development \\nprocess (SEI 1995). The inspection process demonstrates what the highest level is \\nlike. The process is systematic and repeatable and uses measured feedback to improve \\nitself. You can apply the same ideas to many of the techniques described in this book. \\nWhen generalized to an entire development organization, these ideas are, in a nut-\\nshell, what it takes to move the organization to the highest possible level of quality \\nand productivity.\\ncc2e.com/2199 CHECKLIST: Effective Inspections\\n❑ Do you have checklists that focus reviewer attention on areas that have \\nbeen problems in the past?\\n❑ Have you focused the inspection on defect detection rather than correc-\\ntion?\\n❑ Have you considered assigning perspectives or scenarios to help reviewers \\nfocus their preparation work?\\n❑ Are reviewersrs given enough time to prepare before the inspection meet-\\ning, and is each one prepared?\\n❑ Does each participant have a distinct role to play—moderator, reviewer, \\nscribe, and so on?\\n❑ Does the meeting move at a productive rate?\\n❑ Is the meeting limited to two hours?\\n❑ Have all inspection participants received specific training in conducting \\ninspections, and has the moderator received special training in moderation \\nskills?\\n❑ Is data about error types collected at each inspection so that you can tailor \\nfuture checklists to your organization?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 528}, page_content='492 Chapter 21: Collaborative Construction\\n❑ Is data about preparation and inspection rates collected so that you can \\noptimize future preparation and inspections?\\n❑ Are the action items assigned at each inspection followed up, either per-\\nsonally by the moderator or with a reinspection?\\n❑ Does management understand that it should not attend inspection meetings?\\n❑ Is there a follow-up plan to assure that fixes are made correctly?\\n21.4 Other Kinds of Collaborative Development Practices\\nOther kinds of collaboration haven’t accumulated the body of empirical support \\nthat inspections or pair pr ogramming have, so they’re covered in less depth here. \\nThe collaborations covered in this section includes walk-throughs, code reading, \\nand dog-and-pony shows.\\nWalk-Throughs\\nA walk-through is a popular kind of review. The term is loosely defined, and at least \\nsome of its popularity can be attributed to the fact that people can call virtually any \\nkind of review a “walk-through.”\\nBecause the term is so loosely defined, it’s hard to say exactly what a walk-through is. \\nCertainly, a walk-through involves two or more people discussing a design or code. It \\nmight be as informal as an impromptu bull session around a whiteboard; it might be \\nas formal as a scheduled meeting with an overhead presentation prepared by the art \\ndepartment and a formal summary sent to management. In one sense, “where two or \\nthree are gathered together,” there is a walk-through. Proponents of walk-throughs \\nlike the looseness of such a definition, so I’ll just point out a few things that all walk-\\nthroughs have in common and leave the rest of the details to you:\\n■ The walk-through is usually hosted and moderated by the author of the design \\nor code under review.\\n■ The walk-through focuses on technical issues—it’s a working meeting.\\n■ All participants prepare for the walk-through by reading the design or code and \\nlooking for errors.\\n■ The walk-through is a chance for senior programmers to pass on experience and \\ncorporate culture to junior programmers. It’s also a chance for junior program-\\nmers to present new methodologies and to challenge timeworn, possibly obso-\\nlete, assumptions.\\n■ A walk-through usually lasts 30 to 60 minutes.\\n■ The emphasis is on error detection, not correction.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 529}, page_content='21.4 Other Kinds of Collaborative Development Practices 493\\n■ Management doesn’t attend.\\n■ The walk-through concept is flexible and can be adapted to the specific needs of \\nthe organization using it.\\nWhat Results Can You Expect from a Walk-Through?\\nUsed intelligently and with discipline, a walk-through can produce results similar to \\nthose of an inspection—that is, it can typically find between 20 and 40 percent of the \\nerrors in a program (Myers 1979, Boehm 1987b, Yourdon 1989b, Jones 1996). But in \\ngeneral, walk-throughs have been found to be significantly less effective than inspec-\\ntions (Jones 1996).\\nUsed unintelligently, walk-throughs are more trouble than they’re worth. The low end \\nof their effectiveness, 20 percent, isn’t worth much, and at least one organization (Boe-\\ning Computer Services) found peer reviews of code to be “extremely expensive.” Boe-\\ning found it was difficult to motivate project personnel to apply walk-through \\ntechniques consistently, and when project pressures increased, walk-throughs \\nbecame nearly impossible (Glass 1982).\\nI’ve become more critical of walk-throughs during the past 10 years as a result of what \\nI’ve seen in my company’s consulting business. I’ve found that when people have bad \\nexperiences with technical reviews, it is nearly always with informal practices such as \\nwalk-throughs rather than with formal inspections. A review is basically a meeting, \\nand meetings are expensive. If you’re going to incur the overhead of holding a meet-\\ning, it’s worthwhile to structure the meeting as a formal inspection. If the work prod-\\nuct you’re reviewing doesn’t justify the overhead of a formal inspection, it doesn’t \\njustify the overhead of a meeting at all. In such a case you’re better off using document \\nreading or another less interactive approach.\\nInspections seem to be more effective than walk-throughs at removing errors. So why \\nwould anyone choose to use walk-throughs?\\nIf you have a large review group, a walk-through is a good review choice because it \\nbrings many diverse viewpoints to bear on the item under review. If everyone involved \\nin the walk-through can be convinced that the solution is all right, it probably doesn’t \\nhave any major flaws.\\nIf reviewers from other organizations are involved, a walk-through might also be pref-\\nerable. Roles in an inspection are more formalized and require some practice before \\npeople perform them effectively. Reviewers who haven’t participated in inspections \\nbefore are at a disadvantage. If you want to solicit their contributions, a walk-through \\nmight be the best choice.\\nInspections are more focused than walk-throughs and generally pay off better. Conse-\\nquently, if you’re choosing a review standard for your organization, choose inspec-\\ntions first unless you have good reason not to.\\n1\\n2\\n3\\nHARD DATA\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 530}, page_content='494 Chapter 21: Collaborative Construction\\nCode Reading\\nCode reading is an alternative to inspections and walk-throughs. In code reading, you \\nread source code and look for errors. You also comment on qualitative aspects of the \\ncode, such as its design, style, readability, maintainability, and efficiency.\\nA study at NASA’s Software Engineering Laboratory found that code reading detected \\nabout 3.3 defects per hour of effort. Testing detected about 1.8 errors per hour (Card \\n1987). Code reading also found 20 to 60 percent more errors over the life of the \\nproject than the various kinds of testing did.\\nLike the idea of a walk-through, the concept of code reading is loosely defined. A code \\nreading usually involves two or more people reading code independently and then \\nmeeting with the author of the code to discuss it. Here’s how code reading goes:\\n■ In preparation for the meeting, the author of the code hands out source listings \\nto the code readers. The listings are from 1000 to 10,000 lines of code; 4000 \\nlines is typical.\\n■ Two or more people read the code. Use at least two people to encourage compe-\\ntition between the reviewers. If you use more than two, measure everyone’s con-\\ntribution so that you know how much the extra people contribute.\\n■ Reviewers read the code independently. Estimate a rate of about 1000 lines a \\nday.\\n■ When the reviewers have finished reading the code, the code-reading meeting is \\nhosted by the author of the code. The meeting lasts one or two hours and \\nfocuses on problems discovered by the code readers. No one makes any attempt \\nto walk through the code line by line. The meeting is not even strictly necessary.\\n■ The author of the code fixes the problems identified by the reviewers.\\nThe difference between code reading on the one hand and inspections and walk-\\nthroughs on the other is that code reading focuses more on individual review of the \\ncode than on the meeting. The result is that each reviewer’s time is focused on finding \\nproblems in the code. Less time is spent in meetings in which each person contributes \\nonly part of the time and in which a substantial amount of the effort goes into moder-\\nating group dynamics. Less time is spent delaying meetings until each person in the \\ngroup can meet for two hours. Code readings are especially valuable in situations in \\nwhich reviewers are geographically dispersed.\\nA study of 13 reviews at AT&T found that the importance of the review meeting itself \\nwas overrated; 90 percent of the defects were found in preparation for the review \\nmeeting, and only about 10 percent were found during the review itself (Votta 1991, \\nGlass 1999).\\n1\\n2\\n3\\nHARD DATA\\nKEY POINT\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 531}, page_content='Comparison of Collaborative Construction Techniques 49521.4 Other Kinds of Collaborative Development Practices\\nDog-and-Pony Shows\\nDog-and-pony shows are reviews in which a software product is demonstrated to a \\ncustomer. Customer reviews are common in software developed for government con-\\ntracts, which often stipulate that reviews will be held for requirements, design, and \\ncode. The purpose of a dog-and-pony show is to demonstrate to the customer that the \\nproject is OK, so it’s a management review rather than a technical review.\\nDon’t rely on dog-and-pony shows to improve the technical quality of your products. \\nPreparing for them might have an indirect effect on technical quality, but usually more \\ntime is spent in making good-looking presentation slides than in improving the qual-\\nity of the software. Rely on inspections, walk-throughs, or code reading for technical \\nquality improvements.\\nComparison of Collaborative Construction Techniques\\nWhat are the differences among the various kinds of collaborative construction? Table \\n21-1 provides a summary of each technique’s major characteristics.\\nTable 21-1 Comparison of Collaborative Construction Techniques\\nProperty\\nPair \\nProgramming\\nFormal \\nInspection\\nInformal Review \\n(Walk-Throughs)\\nDefined participant roles Yes Yes No\\nFormal training in how to per-\\nform the roles\\nMaybe, through \\ncoaching\\nYes No\\nWho “drives” the collaboration Person with the \\nkeyboard\\nModerator Author, usually\\nFocus of collaboration Design, coding, \\ntesting, and defect \\ncorrection\\nDefect detec-\\ntion only\\nVaries\\nFocused review effort—looks \\nfor the most frequently found \\nkinds of errors\\nInformal, if at all Yes No\\nFollow-up to reduce bad fixes Yes Yes No\\nFewer future errors because of \\ndetailed error feedback to indi-\\nvidual programmers\\nIncidental Yes Incidental\\nImproved process efficiency \\nfrom analysis of results\\nNo Yes No\\nUseful for nonconstruction \\nactivities\\nPossibly Yes Yes\\nTypical percentage of defects \\nfound\\n40–60% 45–70% 20–40%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 532}, page_content='496 Chapter 21: Collaborative Construction\\nPair programming doesn’t have decades of data supporting its effectiveness like for-\\nmal inspection does, but the initial data suggests it’s on roughly equal footing with \\ninspections, and anecdotal reports have also been positive.\\nIf pair programming and formal inspections produce similar results for quality, cost, \\nand schedule, the choice between them becomes a matter of personal style rather \\nthan one of technical substance. Some people prefer to work solo, only occasionally \\nbreaking out of solo mode for inspection meetings. Others prefer to spend more of \\ntheir time directly working with others. The choice between the two techniques can \\nbe driven by the work-style preference of a team’s specific developers, and subgroups \\nwithin the team might be allowed to choose which way they would like to do most of \\ntheir work. You should also use different techniques with a project, as appropriate.\\nAdditional Resources\\ncc2e.com/2106 Here are more resources concerning collaborative contruction:\\nPair Programming\\nWilliams, Laurie and Robert Kessler. Pair Programming Illuminated. Boston, MA: Addi-\\nson Wesley, 2002. This book explains the detailed ins and outs of pair programming, \\nincluding how to handle various personality matches (for example, expert and inex-\\npert, introvert and extrovert) and other implementation issues.\\nBeck, Kent. Extreme Programming Explained: Embrace Change. Reading, MA: Addison \\nWesley, 2000. This book touches on pair programming briefly and shows how it can \\nbe used in conjunction with other mutually supportive techniques, including coding \\nstandards, frequent integration, and regression testing.\\nReifer, Donald. “How to Get the Most Out of Extreme Programming/Agile Methods,” \\nProceedings, XP/Agile Universe 2002. New York, NY: Springer; pp. 185–196. This paper \\nsummarizes industrial experience with Extreme Programming and agile methods and \\npresents keys to success for pair programming.\\nInspections\\nWiegers, Karl. Peer Reviews in Software: A Practical Guide. Boston, MA: Addison Wesley, \\n2002. This well-written book describes the ins and outs of various kinds of reviews, \\nincluding formal inspections and other, less formal practices. It’s well researched, has \\na practical focus, and is easy to read.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 533}, page_content='Key Points 497\\nGilb, Tom and Dorothy Graham. Software Inspection. Wokingham, England: Addison-\\nWesley, 1993. This contains a thorough discussion of inspections circa the early \\n1990s. It has a practical focus and includes case studies that describe experiences sev-\\neral organizations have had in setting up inspection programs.\\nFagan, Michael E. “Design and Code Inspections to Reduce Errors in Program Devel-\\nopment.” IBM Systems Journal 15, no. 3 (1976): 182–211.\\nFagan, Michael E. “Advances in Software Inspections.” IEEE Transactions on Software \\nEngineering, SE-12, no. 7 (July 1986): 744–51. These two articles were written by the \\ndeveloper of inspections. They contain the meat of what you need to know to run an \\ninspection, including all the standard inspection forms.\\nRelevant Standards\\nIEEE Std 1028-1997, Standard for Software Reviews\\nIEEE Std 730-2002, Standard for Software Quality Assurance Plans\\nKey Points\\n■ Collaborative development practices tend to find a higher percentage of defects \\nthan testing and to find them more efficiently.\\n■ Collaborative development practices tend to find different kinds of errors than \\ntesting does, implying that you need to use both reviews and testing to ensure \\nthe quality of your software.\\n■ Formal inspections use checklists, preparation, well-defined roles, and contin-\\nual process improvement to maximize error-detection efficiency. They tend to \\nfind more defects than walk-throughs.\\n■ Pair programming typically costs about the same as inspections and produces \\nsimilar quality code. Pair programming is especially valuable when schedule \\nreduction is desired. Some developers prefer working in pairs to working solo.\\n■ Formal inspections can be used on work products such as requirements, \\ndesigns, and test cases, as well as on code.\\n■ Walk-throughs and code reading are alternatives to inspections. Code reading \\noffers more flexibility in using each person’s time effectively.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 535}, page_content='499\\nChapter 22\\nDeveloper Testing\\ncc2e.com/2261 Contents\\n■ 22.1 Role of Developer Testing in Software Quality: page 500\\n■ 22.2 Recommended Approach to Developer Testing: page 503\\n■ 22.3 Bag of Testing Tricks: page 505\\n■ 22.4 Typical Errors: page 517\\n■ 22.5 Test-Support Tools: page 523\\n■ 22.6 Improving Your Testing: page 528\\n■ 22.7 Keeping Test Records: page 529\\nRelated Topics\\n■ The software-quality landscape: Chapter 20\\n■ Collaborative construction practices: Chapter 21\\n■ Debugging: Chapter 23\\n■ Integration: Chapter 29\\n■ Prerequisites to construction: Chapter 3\\nTesting is the most popular quality-improvement activity—a practice supported by a \\nwealth of industrial and academic research and by commercial experience. Software is \\ntested in numerous ways, some of which are typically performed by developers and \\nsome of which are more commonly performed by specialized test personnel:\\n■ Unit testing is the execution of a complete class, routine, or small program that \\nhas been written by a single programmer or team of programmers, which is \\ntested in isolation from the more complete system.\\n■ Component testing is the execution of a class, package, small program, or other \\nprogram element that involves the work of multiple programmers or program-\\nming teams, which is tested in isolation from the more complete system.\\n■ Integration testing is the combined execution of two or more classes, packages, \\ncomponents, or subsystems that have been created by multiple programmers or \\nprogramming teams. This kind of testing typically starts as soon as there are two \\nclasses to test and continues until the entire system is complete.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 536}, page_content='500 Chapter 22: Developer Testing\\n■ Regression testing is the repetition of previously executed test cases for the pur-\\npose of finding defects in software that previously passed the same set of tests.\\n■ System testing is the execution of the software in its final configuration, including \\nintegration with other software and hardware systems. It tests for security, per-\\nformance, resource loss, timing problems, and other issues that can’t be tested \\nat lower levels of integration.\\nIn this chapter, “testing” refers to testing by the developer, which typically consists of \\nunit tests, component tests, and integration tests but can sometimes include regres-\\nsion tests and system tests. Numerous additional kinds of testing are performed by \\nspecialized test personnel and are rarely performed by developers, including beta \\ntests, customer-acceptance tests, performance tests, configuration tests, platform \\ntests, stress tests, usability tests, and so on. These kinds of testing are not discussed \\nfurther in this chapter.\\nTesting is usually broken into two broad categories: black-box testing and white-box \\n(or glass-box) testing. “Black-box testing” refers to tests in which the tester cannot see \\nthe inner workings of the item being tested. This obviously does not apply when you \\ntest code that you have written! “White-box testing” refers to tests in which the tester \\nis aware of the inner workings of the item being tested. This is the kind of testing that \\nyou as a developer use to test your own code. Both black-box and white-box testing \\nhave strengths and weaknesses; this chapter focuses on white-box testing because \\nthat’s the kind of testing that developers perform.\\nSome programmers use the terms “testing” and “debugging” interchangeably, but \\ncareful programmers distinguish between the two activities. Testing is a means of \\ndetecting errors. Debugging is a means of diagnosing and correcting the root causes \\nof errors that have already been detected. This chapter deals exclusively with error \\ndetection. Error correction is discussed in detail in Chapter 23, “Debugging.”\\nThe whole topic of testing is much larger than the subject of testing during construc-\\ntion. System testing, stress testing, black-box testing, and other topics for test special-\\nists are discussed in the “Additional Resources” section at the end of the chapter.\\n22.1 Role of Developer Testing in Software Quality\\nCross-Reference For details \\non reviews, see Chapter 21, \\n“Collaborative Construction.”\\nTesting is an important part of any software-quality program, and in many cases it’s \\nthe only part. This is unfortunate, because collaborative development practices in \\ntheir various forms have been shown to find a higher percentage of errors than testing \\ndoes, and they cost less than half as much per error found as testing does (Card 1987, \\nRussell 1991, Kaplan 1995). Individual testing steps (unit test, component test, and \\nintegration test) typically find less than 50 percent of the errors present each. The \\ncombination of testing steps often finds less than 60 percent of the errors present \\n(Jones 1998).\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 537}, page_content='22.1 Role of Developer Testing in Software Quality 501\\nPrograms do not acquire \\nbugs as people acquire \\ngerms, by hanging around \\nother buggy programs. Pro-\\ngrammers must insert them. \\n—Harlan Mills\\nIf you were to list a set of software-development activities on “Sesame Street” and ask, \\n“Which of these things is not like the others?” the answer would be “Testing.” Testing \\nis a hard activity for most developers to swallow for several reasons:\\n■ Testing’s goal runs counter to the goals of other development activities. The goal \\nis to find errors. A successful test is one that breaks the software. The goal of \\nevery other development activity is to prevent errors and keep the software from \\nbreaking.\\n■ Testing can never completely prove the absence of errors. If you have tested \\nextensively and found thousands of errors, does it mean that you’ve found all \\nthe errors or that you have thousands more to find? An absence of errors could \\nmean ineffective or incomplete test cases as easily as it could mean perfect soft-\\nware.\\n■ Testing by itself does not improve software quality. Test results are an indicator \\nof quality, but in and of themselves they don’t improve it. Trying to improve soft-\\nware quality by increasing the amount of testing is like trying to lose weight by \\nweighing yourself more often. What you eat before you step onto the scale deter-\\nmines how much you will weigh, and the software-development techniques you \\nuse determine how many errors testing will find. If you want to lose weight, \\ndon’t buy a new scale; change your diet. If you want to improve your software, \\ndon’t just test more; develop better.\\n■ Testing requires you to assume that you’ll find errors in your code. If you assume \\nyou won’t, you probably won’t, but only because you’ll have set up a self-fulfill-\\ning prophecy. If you execute the program hoping that it won’t have any errors, it \\nwill be too easy to overlook the errors you find. In a study that has become a \\nclassic, Glenford Myers had a group of experienced programmers test a pro-\\ngram with 15 known defects. The average programmer found only 5 of the 15 \\nerrors. The best found only 9. The main source of undetected errors was that \\nerroneous output was not examined carefully enough. The errors were visible, \\nbut the programmers didn’t notice them (Myers 1978).\\nYou must hope to find errors in your code. Such a hope might seem like an \\nunnatural act, but you should hope that it’s you who finds the errors and not \\nsomeone else.\\nA key question is, How much time should be spent in developer testing on a typical \\nproject? A commonly cited figure for all testing is 50 percent of the time spent on the \\nproject, but that’s misleading. First, that particular figure combines testing and debug-\\nging; testing alone takes less time. Second, that figure represents the amount of time \\nthat’s typically spent rather than the time that should be spent. Third, the figure \\nincludes independent testing as well as developer testing.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 538}, page_content='502 Chapter 22: Developer Testing\\nAs Figure 22-1 shows, depending on the project’s size and complexity, developer test-\\ning should probably take 8 to 25 percent of the total project time. This is consistent \\nwith much of the data that has been reported.\\nFigure 22-1 As the size of the project increases, developer testing consumes a smaller per-\\ncentage of the total development time. The effects of program size are described in more \\ndetail in Chapter 27, “How Program Size Affects Construction.”\\nA second question is, What do you do with the results of developer testing? Most \\nimmediately, you can use the results to assess the reliability of the product under \\ndevelopment. Even if you never correct the defects that testing finds, testing describes \\nhow reliable the software is. Another use for the results is that they can and usually do \\nguide corrections to the software. Finally, over time, the record of defects found \\nthrough testing helps reveal the kinds of errors that are most common. You can use \\nthis information to select appropriate training classes, direct future technical review \\nactivities, and design future test cases.\\nTesting During Construction\\nThe big, wide world of testing sometimes ignores the subject of this chapter: “white-box” \\nor “glass-box” testing. You generally want to design a class to be a black box—a user of the \\nclass won’t have to look past the interface to know what the class does. In testing the \\nclass, however, it’s advantageous to treat it as a glass box, to look at the internal source \\ncode of the class as well as its inputs and outputs. If you know what’s inside the box, you \\ncan test the class more thoroughly. Of course, you also have the same blind spots in test-\\ning the class that you had in writing it, and so black-box testing has advantages too.\\nDuring construction, you generally write a routine or class, check it mentally, and \\nthen review it or test it. Regardless of your integration or system-testing strategy, you \\nshould test each unit thoroughly before you combine it with any others. If you’re writ-\\ning several routines, you should test them one at a time. Routines aren’t really any eas-\\nier to test individually, but they’re much easier to debug. If you throw several untested \\nroutines together at once and find an error, any of the several routines might be guilty. \\nIf you add one routine at a time to a collection of previously tested routines, you know \\nArchitecture\\n2K 8K 32K 128K 512K\\n0%\\n100%\\nDetailed design\\nCoding and debugging\\nDeveloper testing\\nIntegration\\nSystem testing\\nProject Size in Lines of Code\\nPercentage of \\nDevelopment Time Construction'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 539}, page_content='22.2 Recommended Approach to Developer Testing 503\\nthat any new errors are the result of the new routine or of interactions with the new \\nroutine. The debugging job is easier.\\nCollaborative construction practices have many strengths to offer that testing can’t \\nmatch. But part of the problem with testing is that testing often isn’t performed as well \\nas it could be. A developer can perform hundreds of tests and still achieve only partial \\ncode coverage. A feeling of good test coverage doesn’t mean that actual test coverage is \\nadequate. An understanding of basic test concepts can support better testing and raise \\ntesting’s effectiveness.\\n22.2 Recommended Approach to Developer Testing\\nA systematic approach to developer testing maximizes your ability to detect errors of \\nall kinds with a minimum of effort. Be sure to cover this ground:\\n■ Test for each relevant requirement to make sure that the requirements have been \\nimplemented. Plan the test cases for this step at the requirements stage or as \\nearly as possible—preferably before you begin writing the unit to be tested. Con-\\nsider testing for common omissions in requirements. The level of security, stor-\\nage, the installation procedure, and system reliability are all fair game for testing \\nand are often overlooked at requirements time.\\n■ Test for each relevant design concern to make sure that the design has been imple-\\nmented. Plan the test cases for this step at the design stage or as early as possible—\\nbefore you begin the detailed coding of the routine or class to be tested.\\n■ Use “basis testing” to add detailed test cases to those that test the requirements \\nand the design. Add data-flow tests, and then add the remaining test cases needed \\nto thoroughly exercise the code. At a minimum, you should test every line of code. \\nBasis testing and data-flow testing are described later in this chapter.\\n■ Use a checklist of the kinds of errors you’ve made on the project to date or have \\nmade on previous projects.\\nDesign the test cases along with the product. This can help avoid errors in require-\\nments and design, which tend to be more expensive than coding errors. Plan to test \\nand find defects as early as possible because it’s cheaper to fix defects early.\\nTest First or Test Last?\\nDevelopers sometimes wonder whether it’s better to write test cases after the code has \\nbeen written or beforehand (Beck 2003). The defect-cost increase graph—see Figure 3-1 \\non page 30—suggests that writing test cases first will minimize the amount of time \\nbetween when a defect is inserted into the code and when the defect is detected and \\nremoved. This turns out to be one of many reasons to write test cases first:\\n■ Writing test cases before writing the code doesn’t take any more effort than writ-\\ning test cases after the code; it simply resequences the test-case-writing activity.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 540}, page_content='504 Chapter 22: Developer Testing\\n■ When you write test cases first, you detect defects earlier and you can correct \\nthem more easily.\\n■ Writing test cases first forces you to think at least a little bit about the require-\\nments and design before writing code, which tends to produce better code.\\n■ Writing test cases first exposes requirements problems sooner, before the code \\nis written, because it’s hard to write a test case for a poor requirement.\\n■ If you save your test cases, which you should do, you can still test last, in addi-\\ntion to testing first.\\nAll in all, I think test-first programming is one of the most beneficial software practices \\nto emerge during the past decade and is a good general approach. But it isn’t a testing \\npanacea, because it’s subject to the general limitations of developer testing, which are \\ndescribed next.\\nLimitations of Developer Testing\\nWatch for the following limitations with developer testing:\\nDeveloper tests tend to be “clean tests” Developers tend to test for whether the code \\nworks (clean tests) rather than test for all the ways the code breaks (dirty tests). \\nImmature testing organizations tend to have about five clean tests for every dirty test. \\nMature testing organizations tend to have five dirty tests for every clean test. This ratio \\nis not reversed by reducing the clean tests; it’s done by creating 25 times as many dirty \\ntests (Boris Beizer in Johnson 1994).\\nDeveloper testing tends to have an optimistic view of test coverage Average program-\\nmers believe they are achieving 95 percent test coverage, but they’re typically achiev-\\ning more like 80 percent test coverage in the best case, 30 percent in the worst case, \\nand more like 50-60 percent in the average case (Boris Beizer in Johnson 1994).\\nDeveloper testing tends to skip more sophisticated kinds of test coverage Most devel-\\nopers view the kind of test coverage known as “100% statement coverage” as ade-\\nquate. This is a good start, but it’s hardly sufficient. A better coverage standard is to \\nmeet what’s called “100% branch coverage,” with every predicate term being tested \\nfor at least one true and one false value. Section 22.3, “Bag of Testing Tricks,” provides \\nmore details about how to accomplish this.\\nNone of these points reduce the value of developer testing, but they do help put \\ndeveloper testing into proper perspective. As  valuable as developer testing is, it isn’t \\nsufficient to provide adequate quality as surance on its own and should be supple-\\nmented with other practices, including independent testing and collaborative con-\\nstruction techniques.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 541}, page_content='22.3 Bag of Testing Tricks 505\\n22.3 Bag of Testing Tricks\\nWhy isn’t it possible to prove that a program is correct by testing it? To use testing to \\nprove that a program works, you’d have to test every conceivable input value to the \\nprogram and every conceivable combination of input values. Even for simple pro-\\ngrams, such an undertaking would become massively prohibitive. Suppose, for exam-\\nple, that you have a program that takes a name, an address, and a phone number and \\nstores them in a file. This is certainly a simple program, much simpler than any whose \\ncorrectness you’d really be worried about. Suppose further that each of the possible \\nnames and addresses is 20 characters long and that there are 26 possible characters to \\nbe used in them. This would be the number of possible inputs:\\nEven with this relatively small amount of input, you have one-with-66-zeros possible test \\ncases. To put this in perspective, if Noah had gotten off the ark and started testing this \\nprogram at the rate of a trillion test cases per second, he would be far less than 1 percent \\nof the way done today. Obviously, if you added a more realistic amount of data, the task \\nof exhaustively testing all possibilities would become even more impossible.\\nIncomplete Testing\\nCross-Reference One way of \\ntelling whether you’ve cov-\\nered all the code is to use a \\ncoverage monitor. For details, \\nsee “Coverage Monitors” in \\nSection 22.5, “Test-Support \\nTools,” later in this chapter.\\nSince exhaustive testing is impossible, practically speaking, the art of testing is that of \\npicking the test cases most likely to find errors. Of the 1066 possible test cases, only a \\nfew are likely to disclose errors that the others don’t. You need to concentrate on pick-\\ning a few that tell you different things rather than a set that tells you the same thing \\nover and over.\\nWhen you’re planning tests, eliminate those that don’t tell you anything new—that is, \\ntests on new data that probably won’t produce an error if other, similar data didn’t \\nproduce an error. Various people have proposed various methods of covering the \\nbases efficiently, and several of these methods are discussed in the following sections.\\nStructured Basis Testing\\nIn spite of the hairy name, structured basis testing is a fairly simple concept. The idea \\nis that you need to test each statement in a program at least once. If the statement is a \\nlogical statement—an if or a while, for example—you need to vary the testing according \\nName 2620 (20 characters, each with 26 possible choices)\\nAddress 26 20 (20 characters, each with 26 possible choices)\\nPhone Number 10 10 (10 digits, each with 10 possible choices)\\nTotal Possibilities = 26 20 * 2620 * 1010 ≈ 1066'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 542}, page_content='506 Chapter 22: Developer Testing\\nto how complicated the expression inside the if or while is to make sure that the state-\\nment is fully tested. The easiest way to make sure that you’ve gotten all the bases cov-\\nered is to calculate the number of paths through the program and then develop the \\nminimum number of test cases that will exercise every path through the program.\\nYou might have heard of “code coverage” testing or “logic coverage” testing. They are \\napproaches in which you test all the paths through a program. Since they cover all \\npaths, they’re similar to structured basis testing, but they don’t include the idea of cov-\\nering all paths with a minimal set of test cases. If you use code coverage or logic cover-\\nage testing, you might create many more test cases than you would need to cover the \\nsame logic with structured basis testing.\\nCross-Reference This proce-\\ndure is similar to the one for \\nmeasuring complexity in \\n“How to Measure Complex-\\nity” in Section 19.6.\\nYou can compute the minimum number of cases needed for basis testing in this \\nstraightforward way:\\n1. Start with 1 for the straight path through the routine.\\n2. Add 1 for each of the following keywords, or their equivalents: if, while, repeat, \\nfor, and, and or.\\n3. Add 1 for each case in a case statement. If the case statement doesn’t have a \\ndefault case, add 1 more.\\nHere’s an example:\\nSimple Example of Computing the Number of Paths Through a Java Program\\nCount “1” for the routine \\nitself.\\nCount “2” for the if.\\nStatement1;\\nStatement2;\\nif ( x < 10 ) {\\n   Statement3;\\n}\\nStatement4;\\nIn this instance, you start with one and count the if once to make a total of two. That \\nmeans that you need to have at least two test cases to cover all the paths through the \\nprogram. In this example, you’d need to have the following test cases:\\n■ Statements controlled by if are executed (x < 10).\\n■ Statements controlled by if aren’t executed (x >= 10).\\nThe sample code needs to be a little more realistic to give you an accurate idea of how \\nthis kind of testing works. Realism in this case includes code containing defects.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 543}, page_content='22.3 Bag of Testing Tricks 507\\nThe following listing is a slightly more complicated example. This piece of code is \\nused throughout the chapter and contains a few possible errors.\\nExample of Computing the Number of Cases Needed for Basis Testing \\nof a Java Program\\nCount “1” for the routine \\nitself.\\n1  // Compute Net Pay\\n2  totalWithholdings = 0;\\n3  \\nCount “2” for the for. 4  for ( id = 0; id < numEmployees; id++ ) {\\n5  \\n6     // compute social security withholding, if below the maximum\\nCount “3” for the if. 7     if ( m_employee[ id ].governmentRetirementWithheld < MAX_GOVT_RETIREMENT ) {\\n8        governmentRetirement = ComputeGovernmentRetirement( m_employee[ id ] );\\n9     }\\n10 \\n11    // set default to no retirement contribution\\n12    companyRetirement = 0;\\n13 \\n14    // determine discretionary employee retirement contribution\\nCount “4” for the if and “5” \\nfor the &&.\\n15    if ( m_employee[ id ].WantsRetirement &&\\n16       EligibleForRetirement( m_employee[ id ] ) ) {\\n17       companyRetirement = GetRetirement( m_employee[ id ] );\\n18    }\\n19 \\n20    grossPay = ComputeGrossPay ( m_employee[ id ] );\\n21 \\n22    // determine IRA contribution\\n23    personalRetirement = 0;\\nCount “6” for the if. 24    if ( EligibleForPersonalRetirement( m_employee[ id ] ) ) {\\n25       personalRetirement = PersonalRetirementContribution( m_employee[ id ],\\n26          companyRetirement, grossPay );\\n27    }\\n28 \\n29    // make weekly paycheck\\n30    withholding = ComputeWithholding( m_employee[ id ] );\\n31    netPay = grossPay - withholding - companyRetirement - governmentRetirement –\\n32       personalRetirement;\\n33    PayEmployee( m_employee[ id ], netPay );'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 544}, page_content=\"508 Chapter 22: Developer Testing\\n34 \\n35    // add this employee's paycheck to total for accounting\\n36    totalWithholdings = totalWithholdings + withholding;\\n37    totalGovernmentRetirement = totalGovernmentRetirement + governmentRetirement;\\n38    totalRetirement = totalRetirement + companyRetirement;\\n39 } \\n40 \\n41 SavePayRecords( totalWithholdings, totalGovernmentRetirement, totalRetirement );\\nIn this example, you’ll need one initial test case plus one for each of the five keywords, \\nfor a total of six. That doesn’t mean that any six test cases will cover all the bases. It \\nmeans that, at a minimum, six cases are required. Unless the cases are constructed \\ncarefully, they almost surely won’t cover all the bases. The trick is to pay attention to \\nthe same keywords you used when counting the number of cases needed. Each key-\\nword in the code represents something that can be either true or false; make sure you \\nhave at least one test case for each true and at least one for each false.\\nHere is a set of test cases that covers all the bases in this example:\\nIf the routine were much more complicated than this, the number of test cases you’d \\nhave to use just to cover all the paths would increase pretty quickly. Shorter routines \\ntend to have fewer paths to test. Boolean expressions without a lot of ands and ors \\nhave fewer variations to test. Ease of testing is another good reason to keep your rou-\\ntines short and your boolean expressions simple.\\nNow that you’ve created six test cases for the routine and satisfied the demands of \\nstructured basis testing, can you consider the routine to be fully tested? Probably not. \\nCase Test Description Test Data\\n1 Nominal case All boolean conditions are true\\n2 The initial for condi-\\ntion is false\\nnumEmployees < 1\\n3T he first if is false m_employee[ id ].governmentRetirementWith-\\nheld >=MAX_GOVT_RETIREMENT\\n4 The second if is false \\nbecause the first part \\nof the and is false\\nnot m_employee[ id ].WantsRetirement\\n5 The second if is false \\nbecause the second \\npart of the and is false\\nnot EligibleForRetirement( m_employee[id] )\\n6T he third if is false not EligibleForPersonalRetirement( m_employee[ \\nid ] )\\nNote: This table will be extended with additional test cases throughout the chapter.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 545}, page_content='22.3 Bag of Testing Tricks 509\\nThis kind of testing assures you only that all of the code will be executed. It does not \\naccount for variations in data.\\nData-Flow Testing\\nConsidering the last section and this one together gives you another example illustrat-\\ning that control flow and data flow are equally important in computer programming.\\nData-flow testing is based on the idea that data usage is at least as error-prone as con-\\ntrol flow. Boris Beizer claims that at least half of all code consists of data declarations \\nand initializations (Beizer 1990).\\nData can exist in one of three states:\\n■ Defined The data has been initialized, but it hasn’t been used yet.\\n■ Used The data has been used for computation, as an argument to a routine, or \\nfor something else.\\n■ Killed The data was once defined, but it has been undefined in some way. For \\nexample, if the data is a pointer, perhaps the pointer has been freed. If it’s a for-\\nloop index, perhaps the program is out of the loop and the programming lan-\\nguage doesn’t define the value of a for-loop index once it’s outside the loop. If \\nit’s a pointer to a record in a file, maybe the file has been closed and the record \\npointer is no longer valid.\\nIn addition to having the terms “defined,” “used,” and “killed,” it’s convenient to have \\nterms that describe entering or exiting a routine immediately before or after doing \\nsomething to a variable:\\n■ Entered The control flow enters the routine immediately before the variable is \\nacted upon. A working variable is initialized at the top of a routine, for example.\\n■ Exited The control flow leaves the routine immediately after the variable is \\nacted upon. A return value is assigned to a status variable at the end of a routine, \\nfor example.\\nCombinations of Data States\\nThe normal combination of data states is that a variable is defined, used one or more \\ntimes, and perhaps killed. View the following patterns suspiciously:\\n■ Defined-Defined If you have to define a variable twice before the value sticks, \\nyou don’t need a better program, you need a better computer! It’s wasteful and \\nerror-prone, even if not actually wrong.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 546}, page_content='510 Chapter 22: Developer Testing\\n■ Defined-Exited If the variable is a local variable, it doesn’t make sense to \\ndefine it and exit without using it. If it’s a routine parameter or a global variable, \\nit might be all right.\\n■ Defined-Killed Defining a variable and then killing it suggests that either the \\nvariable is extraneous or the code that was supposed to use the variable is miss-\\ning.\\n■ Entered-Killed This is a problem if the variable is a local variable. It wouldn’t \\nneed to be killed if it hasn’t been defined or used. If, on the other hand, it’s a rou-\\ntine parameter or a global variable, this pattern is all right as long as the variable \\nis defined somewhere else before it’s killed.\\n■ Entered-Used Again, this is a problem if the variable is a local variable. The \\nvariable needs to be defined before it’s used. If, on the other hand, it’s a routine \\nparameter or a global variable, the pattern is all right if the variable is defined \\nsomewhere else before it’s used.\\n■ Killed-Killed A variable shouldn’t need to be killed twice. Variables don’t \\ncome back to life. A resurrected variable indicates sloppy programming. Double \\nkills are also fatal for pointers—one of the best ways to hang your machine is to \\nkill (free) a pointer twice.\\n■ Killed-Used Using a variable after it has been killed is a logical error. If the \\ncode seems to work anyway (for example, a pointer that still points to memory \\nthat’s been freed), that’s an accident, and Murphy’s Law says that the code will \\nstop working at the time when it will cause the most mayhem.\\n■ Used-Defined Using and then defining a variable might or might not be a \\nproblem, depending on whether the variable was also defined before it was \\nused. Certainly if you see a used-defined pattern, it’s worthwhile to check for a \\nprevious definition.\\nCheck for these anomalous sequences of data states before testing begins. After you’ve \\nchecked for the anomalous sequences, the key to writing data-flow test cases is to \\nexercise all possible defined-used paths. You can do this to various degrees of thor-\\noughness, including\\n■ All definitions. Test every definition of every variable—that is, every place at \\nwhich any variable receives a value. This is a weak strategy because if you try to \\nexercise every line of code, you’ll do this by default.\\n■ All defined-used combinations. Test every combination of defining a variable in \\none place and using it in another. This is a stronger strategy than testing all def-\\ninitions because merely executing every line of code does not guarantee that \\nevery defined-used combination will be tested.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 547}, page_content='22.3 Bag of Testing Tricks 511\\nHere’s an example:\\nJava Example of a Program Whose Data Flow Is to Be Tested\\nif ( Condition 1 ) {\\n   x = a;\\n}\\nelse {\\n   x = b;\\n}\\nif ( Condition 2 ) {\\n   y = x + 1;\\n}\\nelse {\\n   y = x - 1;\\n}\\nTo cover every path in the program, you need one test case in which Condition 1 is true \\nand one in which it’s false. You also need a test case in which Condition 2 is true and \\none in which it’s false. This can be handled by two test cases: Case 1 (Condition 1=True, \\nCondition 2=True) and Case 2 (Condition 1=False, Condition 2=False). Those two cases \\nare all you need for structured basis testing. They’re also all you need to exercise every \\nline of code that defines a variable; they give you the weak form of data-flow testing \\nautomatically.\\nTo cover every defined-used combination, however, you need to add a few more cases. \\nRight now you have the cases created by having Condition 1 and Condition 2 true at the \\nsame time and Condition 1 and Condition 2 false at the same time:\\nx = a\\n...\\ny = x + 1\\nand\\nx = b\\n...\\ny = x - 1\\nBut you need two more cases to test every defined-used combination: (1) x = a and \\nthen y = x - 1 and (2) x = b and then y = x + 1. In this example, you can get these com-\\nbinations by adding two more cases: Case 3 (Condition 1=True, Condition 2=False) and \\nCase 4 (Condition 1=False, Condition 2=True).\\nA good way to develop test cases is to start with structured basis testing, which gives \\nyou some if not all of the defined-used data flows. Then add the cases you still need to \\nhave a complete set of defined-used data-flow test cases.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 548}, page_content='512 Chapter 22: Developer Testing\\nAs discussed in the previous section, structured basis testing provided six test cases \\nfor the routine beginning on page 507. Data-flow testing of each defined-used pair \\nrequires several more test cases, some of which are covered by existing test cases and \\nsome of which aren’t. Here are all the data-flow combinations that add test cases \\nbeyond the ones generated by structured basis testing:\\nOnce you run through the process of listing data-flow test cases a few times, you’ll get \\na sense of which cases are fruitful and which are already covered. When you get stuck, \\nlist all the defined-used combinations. That might seem like a lot of work, but it’s guar-\\nanteed to show you any cases that you didn’t test for free in the basis-testing approach.\\nEquivalence Partitioning\\nCross-Reference Equiva-\\nlence partitioning is dis-\\ncussed in far more depth in \\nthe books listed in the “Addi-\\ntional Resources” section at \\nthe end of this chapter.\\nA good test case covers a large part of the possible input data. If two test cases flush \\nout exactly the same errors, you need only one of them. The concept of “equivalence \\npartitioning” is a formalization of this idea and helps reduce the number of test cases \\nrequired.\\nIn the listing beginning on page 507, line 7 is a good place to use equivalence partition-\\ning. The condition to be tested is m_employee[ ID ].governmentRetirementWithheld < \\nMAX_GOVT_RETIREMENT. This case has two equivalence classes: the class in which \\nm_employee[ ID ].governmentRetirementWithheld is less than MAX_GOVT_RETIREMENT \\nand the class in which it’s greater than or equal to MAX_GOVT_RETIREMENT. \\nOther parts of the program might have other related equivalence classes that imply \\nthat you need to test more than two possible values of m_employee[ ID ].government-\\nRetirementWithheld, but as far as this part of the program is concerned, only two are \\nneeded.\\nThinking about equivalence partitioning won’t give you a lot of new insight into a pro-\\ngram when you have already covered the program with basis and data-flow testing. It’s \\nespecially helpful, however, when you’re looking at a program from the outside (from \\na specification rather than the source code) or when the data is complicated and the \\ncomplications aren’t all reflected in the program’s logic.\\nCase T est Description\\n7 Define companyRetirement in line 12, and use it first in line 26.\\nThis isn’t necessarily covered by any of the previous test cases.\\n8 Define companyRetirement in line 12, and use it first in line 31.\\nThis isn’t necessarily covered by any of the previous test cases.\\n9 Define companyRetirement in line 17, and use it first in line 31.\\nThis isn’t necessarily covered by any of the previous test cases.\\nC22619670.fm  Page 512  Tuesday, April 12, 2011  3:11 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 549}, page_content='22.3 Bag of Testing Tricks 513\\nError Guessing\\nCross-Reference For details \\non heuristics, see Section \\n2.2, “How to Use Software \\nMetaphors.”\\nIn addition to the formal test techniques, good programmers use a variety of less for-\\nmal, heuristic techniques to expose errors in their code. One heuristic is the technique \\nof error guessing. The term “error guessing” is a lowbrow name for a sensible concept. \\nIt means creating test cases based upon guesses about where the program might have \\nerrors, although it implies a certain amount of sophistication in the guessing.\\nYou can base guesses on intuition or on past experience. Chapter 21, “Collaborative \\nConstruction,” points out that one virtue of inspections is that they produce and \\nmaintain a list of common errors. The list is used to check new code. When you keep \\nrecords of the kinds of errors you’ve made before, you improve the likelihood that \\nyour “error guess” will discover an error.\\nThe next few sections describe specific kinds of errors that lend themselves to error \\nguessing.\\nBoundary Analysis\\nOne of the most fruitful areas for testing is boundary conditions—off-by-one errors. \\nSaying num – 1 when you mean num and saying >= when you mean > are common \\nmistakes.\\nThe idea of boundary analysis is to write test cases that exercise the boundary condi-\\ntions. Pictorially, if you’re testing for a range of values that are less than max, you have \\nthree possible conditions:\\nAs shown, there are three boundary cases: just less than max, max itself, and just \\ngreater than max. It takes three cases to ensure that none of the common mistakes has \\nbeen made.\\nThe code sample on page 507 contains a check for m_employee[ ID ].governmentRe-\\ntirementWithheld < MAX_GOVT_RETIREMENT. According to the principles of \\nboundary analysis, three cases should be examined:\\nCase Test Description\\n1 Case 1 is defined so that the true condition for m_employee[ ID ].govern-\\nmentRetirementWithheld < MAX_GOVT_RETIREMENT is the first case on the \\ntrue side of the boundary. Thus, the Case 1 test case sets m_employee[ ID \\n].governmentRetirementWithheld to MAX_GOVT_RETIREMENT – 1. This test \\ncase was already generated.\\nBoundary \\nbelow Max\\nBoundary \\nabove MaxMax'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 550}, page_content='514 Chapter 22: Developer Testing\\nCompound Boundaries\\nBoundary analysis also applies to minimum and maximum allowable values. In this \\nexample, it might be minimum or maximum grossPay, companyRetirement, or Personal-\\nRetirementContribution, but because calculations of those values are outside the scope \\nof the routine, test cases for them aren’t discussed further here.\\nA more subtle kind of boundary condition occurs when the boundary involves a com-\\nbination of variables. For example, if two variables are multiplied together, what hap-\\npens when both are large positive numbers? Large negative numbers? 0? What if all \\nthe strings passed to a routine are uncommonly long?\\nIn the running example, you might want to see what happens to the variables total-\\nWithholdings, totalGovernmentRetirement, and totalRetirement when every member of a \\nlarge group of employees has a large salary—say, a group of programmers at $250,000 \\neach. (We can always hope!) This calls for another test case:\\nA test case in the same vein but on the opposite side of the looking glass would be a \\nsmall group of employees, each of whom has a salary of $0.00:\\nClasses of Bad Data\\nAside from guessing that errors show up around boundary conditions, you can guess \\nabout and test for several other classes of bad data. Typical bad-data test cases include\\n■ Too little data (or no data)\\n■ Too much data\\n3 Case 3 is defined so that the false condition for m_employee[ ID ]. govern-\\nmentRetirementWithheld < MAX_GOVT_RETIREMENT is on the false side of \\nthe boundary. Thus, the Case 3 test case sets m_employee[ ID ].governmen-\\ntRetirementWithheld to MAX_GOVT_RETIREMENT + 1. This test case was \\nalso already generated.\\n10 An additional test case is added for the case directly on the boundary in \\nwhich m_employee [ ID ].governmentRetirementWithheld = \\nMAX_GOVT_RETIREMENT.\\nCase Test Description\\n11 A large group of employees, each of whom has a large salary (what consti-\\ntutes “large” depends on the specific system being developed)—for the \\nsake of example, we’ll say 1000 employees, each with a salary of $250,000, \\nnone of whom have had any social security tax withheld and all of whom \\nwant retirement withholding.\\nCase Test Description\\n12 A group of 10 employees, each of whom has a salary of $0.00.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 551}, page_content='22.3 Bag of Testing Tricks 515\\n■ The wrong kind of data (invalid data)\\n■ The wrong size of data\\n■ Uninitialized data\\nSome of the test cases you would think of if you followed these suggestions have \\nalready been covered. For example, “too little data” is covered by Cases 2 and 12, and \\nit’s hard to come up with anything for “wrong size of data.” Classes of bad data none-\\ntheless gives rise to a few more cases:\\nClasses of Good Data\\nWhen you try to find errors in a program, it’s easy to overlook the fact that the nomi-\\nnal case might contain an error. Usually the nominal cases described in the basis-test-\\ning section represent one kind of good data. Following are other kinds of good data \\nthat are worth checking. Checking each of these kinds of data can reveal errors, \\ndepending on the item being tested.\\n■ Nominal cases—middle-of-the-road, expected values\\n■ Minimum normal configuration\\n■ Maximum normal configuration\\n■ Compatibility with old data\\nThe minimum normal configuration is useful for testing not just one item, but a group \\nof items. It’s similar in spirit to the boundary condition of many minimal values, but \\nit’s different in that it creates the set of minimum values out of the set of what is nor-\\nmally expected. One example would be to save an empty spreadsheet when testing a \\nspreadsheet. For testing a word processor, it would be saving an empty document. In \\nthe case of the running example, testing the minimum normal configuration would \\nadd the following test case:\\nThe maximum normal configuration is the op posite of the minimum. It’s similar in \\nspirit to boundary testing, but again, it creates a set of maximum values out of the set \\nCase Test Description\\n13 An array of 100,000,000 employees. Tests for too much data. Of course, \\nhow much is too much would vary from system to system, but for the sake \\nof the example, assume that this is far too much.\\n14 A negative salary. Wrong kind of data.\\n15 A negative number of employees. Wrong kind of data.\\nCase Test Description\\n16 A group of one employee. To test the minimum normal configuration.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 552}, page_content='516 Chapter 22: Developer Testing\\nof expected values. An example of this would be saving a spreadsheet that’s as large as \\nthe “maximum spreadsheet size” advertised on the product’s packaging. Or printing \\nthe maximum-size spreadsheet. For a word processor, it would be saving a document \\nof the largest recommended size. In the case of the running example, testing the max-\\nimum normal configuration depends on the maximum normal number of employees. \\nAssuming it’s 500, you would add the following test case:\\nThe last kind of normal data testing—testing for compatibility with old data—comes \\ninto play when the program or routine is a replacement for an older program or rou-\\ntine. The new routine should produce the same results with old data that the old rou-\\ntine did, except in cases in which the old routine was defective. This kind of continuity \\nbetween versions is the basis for regression testing, the purpose of which is to ensure \\nthat corrections and enhancements maintain previous levels of quality without back-\\nsliding. In the case of the running example, the compatibility criterion wouldn’t add \\nany test cases.\\nUse Test Cases That Make Hand-Checks Convenient\\nLet’s suppose you’re writing a test case for a nominal salary; you need a nominal sal-\\nary, and the way you get one is to type in whatever numbers your hands land on. I’ll \\ntry it:\\n1239078382346\\nOK. That’s a pretty high salary, a little over a trillion dollars, in fact, but if I trim it so \\nthat it’s somewhat realistic, I get $90,783.82.\\nNow, further suppose that the test case succeeds—that is, it finds an error. How do you \\nknow that it’s found an error? Well, presumably, you know what the answer is and \\nwhat it should be because you calculated the correct answer by hand. When you try to \\ndo hand-calculations with an ugly number like $90,783.82, however, you’re as likely to \\nmake an error in the hand-calc as you are to discover one in your program. On the \\nother hand, a nice, even number like $20,000 makes number crunching a snap. The 0s \\nare easy to punch into the calculator, and multiplying by 2 is something most pro-\\ngrammers can do without using their fingers and toes.\\nYou might think that an ugly number like $90,783.82 would be more likely to reveal \\nerrors, but it’s no more likely to than any other number in its equivalence class.\\nCase Test Description\\n17 A group of 500 employees. To test the maximum normal configuration.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 553}, page_content='22.4 Typical Errors 517\\n22.4 Typical Errors\\nThis section is dedicated to the proposition that you can test best when you know as \\nmuch as possible about your enemy: errors.\\nWhich Classes Contain the Most Errors?\\nIt’s natural to assume that defects are distributed evenly throughout your source code. \\nIf you have an average of 10 defects per 1000 lines of code, you might assume that \\nyou’ll have one defect in a class that contains 100 lines of code. This is a natural \\nassumption, but it’s wrong.\\nCapers Jones reported that a focused quality-improvement program at IBM identified \\n31 of 425 classes in the IMS system as error-prone. The 31 classes were repaired or \\ncompletely redeveloped, and, in less than a year, customer-reported defects against \\nIMS were reduced ten to one. Total maintenance costs were reduced by about 45 per-\\ncent. Customer satisfaction improved from “unacceptable” to “good” (Jones 2000).\\nMost errors tend to be concentrated in a few highly defective routines. Here is the gen-\\neral relationship between errors and code:\\n■ Eighty percent of the errors are found in 20 percent of a project’s classes or rou-\\ntines (Endres 1975, Gremillion 1984, Boehm 1987b, Shull et al 2002).\\n■ Fifty percent of the errors are found in 5 percent of a project’s classes (Jones \\n2000).\\nThese relationships might not seem so important until you recognize a few corollaries. \\nFirst, 20% of a project’s routines contribute 80% of the cost of development (Boehm \\n1987b). That doesn’t necessarily mean that the 20% that cost the most are the same \\nas the 20% with the most defects, but it’s pretty suggestive.\\nSecond, regardless of the exact proportion of the cost contributed by highly defective \\nroutines, highly defective routines are extremely expensive. In a classic study in the \\n1960s, IBM performed an analysis of its OS/360 operating system and found that \\nerrors were not distributed evenly across all routines but were concentrated into a few. \\nThose error-prone routines were found to be “the most expensive entities in program-\\nming” (Jones 1986a). They contained as many as 50 defects per 1000 lines of code, \\nand fixing them often cost 10 times what it took to develop the whole system. (The \\ncosts included customer support and in-the-field maintenance.)\\nKEY POINT\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 554}, page_content='518 Chapter 22: Developer Testing\\nCross-Reference Another \\nclass of routines that tend to \\ncontain a lot of errors is the \\nclass of overly complex rou-\\ntines. For details on identify-\\ning and simplifying routines, \\nsee “General Guidelines for \\nReducing Complexity” in \\nSection 19.6.\\nThird, the implication of expensive routines for development is clear. As the old \\nexpression goes, “time is money.” The corollary is that “money is time,” and if you can \\ncut close to 80 percent of the cost by avoiding troublesome routines, you can cut a \\nsubstantial amount of the schedule as well. This is a clear illustration of the General \\nPrinciple of Software Quality: improving quality improves the development schedule \\nand reduces development costs.\\nFourth, the implication of avoiding troublesome routines for maintenance is equally \\nclear. Maintenance activities should be focused on identifying, redesigning, and \\nrewriting from the ground up those routines that have been identified as error-prone. \\nIn the IMS project mentioned earlier, productivity of IMS releases improved about 15 \\npercent after replacement of the error-prone classes (Jones 2000).\\nErrors by Classification\\nCross-Reference For a list of \\nall the checklists in the book, \\nsee the list following the \\nbook’s table of contents.\\nSeveral researchers have tried to classify errors by type and determine the extent to \\nwhich each kind of error occurs. Every programmer has a list of errors that have been \\nparticularly troublesome: off-by-one errors, forgetting to reinitialize a loop variable, \\nand so on. The checklists presented throughout the book provide more details.\\nBoris Beizer combined data from several studies, arriving at an exceptionally detailed \\nerror taxonomy (Beizer 1990). Following is a summary of his results:\\nBeizer reported his results to a precise two decimal places, but the research into error \\ntypes has generally been inconclusive. Different studies report wildly different kinds \\nof errors, and studies that report on similar kinds of errors arrive at wildly different \\nresults, results that differ by 50% rather than by hundredths of a percentage point.\\nGiven the wide variations in reports, combining results from multiple studies as \\nBeizer has done probably doesn’t produce meaningful data. But even if the data isn’t \\nconclusive, some of it is suggestive. Following are some of the suggestions that can be \\nderived from the data:\\n25.18% Structural\\n22.44% Data\\n16.19% Functionality as implemented\\n9.88% Construction\\n8.98% Integration\\n8.12% Functional requirements\\n2.76% Test definition or execution\\n1.74% System, software architecture\\n4.71% Unspecified'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 555}, page_content='22.4 Typical Errors 519\\nThe scope of most errors is fairly limited One study found that 85 percent of errors \\ncould be corrected without modifying more than one routine (Endres 1975).\\nMany errors are outside the domain of construction Researchers conducting a series \\nof 97 interviews found that the three most common sources of errors were thin appli-\\ncation-domain knowledge, fluctuating and conflicting requirements, and communica-\\ntion and coordination breakdown (Curtis, Krasner, and Iscoe 1988).\\nIf you see hoof prints, think \\nhorses—not zebras. The OS \\nis probably not broken. And \\nthe database is probably just \\nfine.\\n—Andy Hunt and \\nDave Thomas\\nMost construction errors are the programmers’ fault A pair of studies performed \\nmany years ago found that, of total errors reported, roughly 95% are caused by pro-\\ngrammers, 2% by systems software (the compiler and the operating system), 2% by \\nsome other software, and 1% by the hardware (Brown and Sampson 1973, Ostrand \\nand Weyuker 1984). Systems software and development tools are used by many more \\npeople today than they were in the 1970s and 1980s, and so my best guess is that, \\ntoday, an even higher percentage of errors are the programmers’ fault.\\nClerical errors (typos) are a surprisingly common source of problems One study \\nfound that 36% of all construction errors were clerical mistakes (Weiss 1975). A 1987 \\nstudy of almost 3 million lines of flight-dynamics software found that 18% of all errors \\nwere clerical (Card 1987). Another study found that 4% of all errors were spelling \\nerrors in messages (Endres 1975). In one of my programs, a colleague found several \\nspelling errors simply by running all the strings from the executable file through a \\nspelling checker. Attention to detail counts. If you doubt that, consider that three of \\nthe most expensive software errors of all time—costing $1.6 billion, $900 million, and \\n$245 million—involved the change of a single character in a previously correct program \\n(Weinberg 1983).\\nMisunderstanding the design is a recurring theme in studies of programmer errors\\nBeizer’s compilation study, for what it’s worth, found that 16% of the errors grew out \\nof misinterpretations of the design (Beizer 1990). Another study found that 19% of \\nthe errors resulted from misunderstood design (Weiss 1975). It’s worthwhile to take \\nthe time you need to understand the design thoroughly. Such time doesn’t produce \\nimmediate dividends—you don’t necessarily look like you’re working—but it pays off \\nover the life of the project.\\nMost errors are easy to fix About 85% of errors can be fixed in less than a few hours. \\nAbout 15% can be fixed in a few hours to a few days. And about 1% take longer (Weiss \\n1975, Ostrand and Weyuker 1984, Grady 1992). This result is supported by Barry \\nBoehm’s observation that about 20% of the errors take about 80% of the resources to \\nfix (Boehm 1987b). Avoid as many of the hard errors as you can by doing require-\\nments and design reviews upstream. Handle the numerous small errors as efficiently \\nas you can.\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 556}, page_content='520 Chapter 22: Developer Testing\\nIt’s a good idea to measure your own organization’s experiences with errors The \\ndiversity of results cited in this section indicates that people in different organizations \\nhave tremendously different experiences. That makes it hard to apply other organiza-\\ntions’ experiences to yours. Some results go against common intuition; you might \\nneed to supplement your intuition with other tools. A good first step is to start mea-\\nsuring your development process so that you know where the problems are.\\nProportion of Errors Resulting from Faulty Construction\\nIf the data that classifies errors is inconclu sive, so is much of the data that attributes \\nerrors to the various development activities. One certainty is that construction always \\nresults in a significant number of errors. Sometimes people argue that the errors \\ncaused by construction are cheaper to fix than the errors caused by requirements or \\ndesign. Fixing individual construction errors might be cheaper, but the evidence \\ndoesn’t support such a claim about the total cost.\\nHere are my conclusions:\\n■ On small projects, construction defects make up the vast bulk of all errors. In \\none study of coding errors on a small project (1000 lines of code), 75% of \\ndefects resulted from coding, compared to 10% from requirements and 15% \\nfrom design (Jones 1986a). This error breakdown appears to be representative \\nof many small projects.\\n■ Construction defects account for at least 35% of all defects regardless of project \\nsize. Although the proportion of construction defects is smaller on large \\nprojects, they still account for at least 35% of all defects (Beizer 1990, Jones \\n2000). Some researchers have reported proportions in the 75% range even on \\nvery large projects (Grady 1987). In general, the better the application area is \\nunderstood, the better the overall architecture is. Errors then tend to be concen-\\ntrated in detailed design and coding (Basili and Perricone 1984).\\n■ Construction errors, although cheaper to fix than requirements and design \\nerrors, are still expensive. A study of two very large projects at Hewlett-Packard \\nfound that the average construction defect cost 25–50% as much to fix as the \\naverage design error (Grady 1987). When the greater number of construction \\ndefects was figured into the overall equation, the total cost to fix construction \\ndefects was one to two times as much as the cost attributed to design defects.\\nFigure 22-2 provides a rough idea of the relationship between project size and the \\nsource of errors.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 557}, page_content='22.4 Typical Errors 521\\nFigure 22-2 As the size of the project increases, the proportion of errors committed during \\nconstruction decreases. Nevertheless, construction errors account for 45–75% of all errors \\non even the largest projects.\\nHow Many Errors Should You Expect to Find?\\nThe number of errors you should expect to find varies according to the quality of the \\ndevelopment process you use. Here’s the range of possibilities:\\n■ Industry average experience is about 1–25 errors per 1000 lines of code for \\ndelivered software. The software has usually been developed using a hodge-\\npodge of techniques (Boehm 1981, Gremillion 1984, Yourdon 1989a, Jones \\n1998, Jones 2000, Weber 2003). Cases that have one-tenth as many errors as \\nthis are rare; cases that have 10 times more tend not to be reported. (They prob-\\nably aren’t ever completed!)\\n■ The Applications Division at Microsoft experiences about 10–20 defects per \\n1000 lines of code during in-house testing and 0.5 defects per 1000 lines of code \\nin released product (Moore 1992). The technique used to achieve this level is a \\ncombination of the code-reading techniques described in Section 21.4, “Other \\nKinds of Collaborative Development Practices,” and independent testing.\\n■ Harlan Mills pioneered “cleanroom development,” a technique that has been \\nable to achieve rates as low as 3 defects per 1000 lines of code during in-house \\ntesting and 0.1 defects per 1000 lines of code in released product (Cobb and \\nMills 1990). A few projects—for example, the space-shuttle software—have \\nachieved a level of 0 defects in 500,000 lines of code by using a system of formal \\ndevelopment methods, peer reviews, and statistical testing (Fishman 1996).\\n■ Watts Humphrey reports that teams using the Team Software Process (TSP) have \\nachieved defect levels of about 0.06 defects per 1000 lines of code. TSP focuses on \\ntraining developers not to create defects in the first place (Weber 2003).\\nConstruction\\nRequirements\\nDesign\\n2K 8K 32K 128K 512K\\n0%\\n100%\\nProject Size in Lines of Code\\nErrors from \\nEach Activity\\nOn some projects, \\nthis percentage of \\nerrors may also be \\nfrom construction.\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 558}, page_content='522 Chapter 22: Developer Testing\\nThe results of the TSP and cleanroom projects confirm another version of the General \\nPrinciple of Software Quality: it’s cheaper to build high-quality software than it is to \\nbuild and fix low-quality software. Productivity for a fully checked-out, 80,000-line \\ncleanroom project was 740 lines of code per work-month. The industry average rate \\nfor fully checked-out code is closer to 250–300 lines per work-month, including all \\nnoncoding overhead (Cusumano et al 2003). The cost savings and productivity come \\nfrom the fact that virtually no time is devoted to debugging on TSP or cleanroom \\nprojects. No time spent on debugging? That is truly a worthy goal!\\nErrors in Testing Itself\\nYou may have had an experience like this: The software is found to be in error. You \\nhave a few immediate hunches about which part of the code might be wrong, but all \\nthat code seems to be correct. You run several more test cases to try to refine the error, \\nbut all the new test cases produce correct results. You spend several hours reading \\nand rereading the code and hand-calculating the results. They all check out. After a \\nfew more hours, something causes you to reexamine the test data. Eureka! The error’s \\nin the test data! How idiotic it feels to waste hours tracking down an error in the test \\ndata rather than in the code!\\nThis is a common experience. Test cases are often as likely or more likely to contain \\nerrors than the code being tested (Weiland 1983, Jones 1986a, Johnson 1994). The \\nreasons are easy to find—especially when the developer writes the test cases. Test cases \\ntend to be created on the fly rather than through a careful design and construction \\nprocess. They are often viewed as one-time tests and are developed with the care com-\\nmensurate with something to be thrown away.\\nYou can do several things to reduce the number of errors in your test cases:\\nCheck your workDevelop test cases as carefully as you develop code. Such care cer-\\ntainly includes double-checking your own testing. Step through test code in a debug-\\nger, line by line, just as you would production code. Walk-throughs and inspections of \\ntest data are appropriate.\\nPlan test cases as you develop your software Effective planning for testing should \\nstart at the requirements stage or as soon as you get the assignment for the program. \\nThis helps to avoid test cases based on mistaken assumptions.\\nKeep your test cases Spend a little quality time with your test cases. Save them for \\nregression testing and for work on version 2. It’s easy to justify the trouble if you know \\nyou’re going to keep them rather than throw them away.\\nPlug unit tests into a test frameworkWrite code for unit tests first, but integrate \\nthem into a systemwide test framework (like JUnit) as you complete each test. Having \\nan integrated test framework prevents the tendency, just mentioned, to throw away \\ntest cases.\\nKEY POINT\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 559}, page_content='22.5 Test-Support Tools 523\\n22.5 Test-Support Tools\\nThis section surveys the kinds of testing tools you can buy commercially or build \\nyourself. It won’t name specific products because they could easily be out of date by \\nthe time you read this. Refer to your favorite programmer’s magazine for the most \\nrecent specifics.\\nBuilding Scaffolding to Test Individual Classes\\nThe term “scaffolding” comes from building construction. Scaffolding is built so that \\nworkers can reach parts of a building they couldn’t reach otherwise. Software scaffold-\\ning is built for the sole purpose of making it easy to exercise code.\\nFurther Reading For several \\ngood examples of scaffold-\\ning, see Jon Bentley’s essay \\n“A Small Matter of Program-\\nming” in Programming \\nPearls, 2d ed. (2000).\\nOne kind of scaffolding is a class that’s dummied up so that it can be used by another \\nclass that’s being tested. Such a class is called a “mock object” or “stub object” \\n(Mackinnon, Freemand, and Craig 2000; Thomas and Hunt 2002). A similar \\napproach can be used with low-level routines, which are called “stub routines.” You \\ncan make a mock object or stub routines more or less realistic, depending on how \\nmuch veracity you need. In these cases, the scaffolding can\\n■ Return control immediately, having taken no action.\\n■ Test the data fed to it.\\n■ Print a diagnostic message, perhaps an echo of the input parameters, or log a \\nmessage to a file.\\n■ Get return values from interactive input.\\n■ Return a standard answer regardless of the input.\\n■ Burn up the number of clock cycles allocated to the real object or routine.\\n■ Function as a slow, fat, simple, or less accurate version of the real object or routine.\\nAnother kind of scaffolding is a fake routine that calls the real routine being tested. \\nThis is called a “driver” or, sometimes, a “test harness.” This scaffolding can\\n■ Call the object with a fixed set of inputs.\\n■ Prompt for input interactively and call the object with it.\\n■ Take arguments from the command line (in operating systems that support it) \\nand call the object.\\n■ Read arguments from a file and call the object.\\n■ Run through predefined sets of input data in multiple calls to the object.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 560}, page_content='524 Chapter 22: Developer Testing\\nCross-Reference The line \\nbetween testing tools and \\ndebugging tools is fuzzy. For \\ndetails on debugging tools, \\nsee Section 23.5, “Debug-\\nging Tools—Obvious and \\nNot-So-Obvious.”\\nA final kind of scaffolding is the dummy file, a small version of the real thing that has \\nthe same types of components that a full-size file has. A small dummy file offers a cou-\\nple of advantages. Because it’s small, you can know its exact contents and can be rea-\\nsonably sure that the file itself is error-free. And because you create it specifically for \\ntesting, you can design its contents so that any error in using it is conspicuous.\\ncc2e.com/2268 Obviously, building scaffolding requires some work, but if an error is ever detected in \\na class, you can reuse the scaffolding. And numerous tools exist to streamline creation \\nof mock objects and other scaffolding. If you use scaffolding, the class can also be \\ntested without the risk of its being affected by interactions with other classes. Scaffold-\\ning is particularly useful when subtle algorithms are involved. It’s easy to get stuck in \\na rut in which it takes several minutes to execute each test case because the code being \\nexercised is embedded in other code. Scaffolding allows you to exercise the code \\ndirectly. The few minutes that you spend building scaffolding to exercise the deeply \\nburied code can save hours of debugging time.\\nYou can use any of the numerous test frameworks available to provide scaffolding for \\nyour programs (JUnit, CppUnit, NUnit, and so on). If your environment isn’t sup-\\nported by one of the existing test frameworks, you can write a few routines in a class \\nand include a main() scaffolding routine in the file to test the class, even though the \\nroutines being tested aren’t intended to stand by themselves. The main() routine can \\nread arguments from the command line and pass them to the routine being tested so \\nthat you can exercise the routine on its own before integrating it with the rest of the \\nprogram. When you integrate the code, leave the routines and the scaffolding code \\nthat exercises them in the file and use preprocessor commands or comments to deac-\\ntivate the scaffolding code. Since it’s preprocessed out, it doesn’t affect the executable \\ncode, and since it’s at the bottom of the file, it’s not in the way visually. No harm is \\ndone by leaving it in. It’s there if you need it again, and it doesn’t burn up the time it \\nwould take to remove and archive it.\\nDiff Tools\\nCross-Reference For details \\non regression testing, see \\n“Retesting (Regression Test-\\ning)” in Section 22.6.\\nRegression testing, or retesting, is a lot easier if you have automated tools to check the \\nactual output against the expected output. One easy way to check printed output is to \\nredirect the output to a file and use a file-comparison tool such as diff to compare the \\nnew output against the expected output that was sent to a file previously. If the out-\\nputs aren’t the same, you have detected a regression error.\\nTest-Data Generators\\ncc2e.com/2275 You can also write code to exercise selected pieces of a program systematically. A few \\nyears ago, I developed a proprietary encryption algorithm and wrote a file-encryption \\nprogram to use it. The intent of the program was to encode a file so that it could be'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 561}, page_content='22.5 Test-Support Tools 525\\ndecoded only with the right password. The encryption didn’t just change the file \\nsuperficially; it altered the entire contents. It was critical that the program be able to \\ndecode a file properly, because the file would be ruined otherwise.\\nI set up a test-data generator that fully exercised the encryption and decryption parts \\nof the program. It generated files of random characters in random sizes, from 0K \\nthrough 500K. It generated passwords of random characters in random lengths from \\n1 through 255. For each random case, it generated two copies of the random file, \\nencrypted one copy, reinitialized itself, decrypted the copy, and then compared each \\nbyte in the decrypted copy to the unaltered copy. If any bytes were different, the gen-\\nerator printed all the information I needed to reproduce the error.\\nI weighted the test cases toward the average length of my files, 30K, which was consid-\\nerably shorter than the maximum length of 500K. If I had not weighted the test cases \\ntoward a shorter length, file lengths would have been uniformly distributed between \\n0K and 500K. The average tested file length would have been 250K. The shorter aver-\\nage length meant that I could test more files, passwords, end-of-file conditions, odd \\nfile lengths, and other circumstances that might produce errors than I could have \\nwith uniformly random lengths.\\nThe results were gratifying. After running only about 100 test cases, I found two errors \\nin the program. Both arose from special cases that might never have shown up in prac-\\ntice, but they were errors nonetheless and I was glad to find them. After fixing them, \\nI ran the program for weeks, encrypting and decrypting over 100,000 files without an \\nerror. Given the range in file contents, lengths, and passwords I tested, I could confi-\\ndently assert that the program was correct.\\nHere are some lessons from this story:\\n■ Properly designed random-data generators can generate unusual combinations \\nof test data that you wouldn’t think of.\\n■ Random-data generators can exercise your program more thoroughly than you \\ncan.\\n■ You can refine randomly generated test cases over time so that they emphasize a \\nrealistic range of input. This concentrates testing in the areas most likely to be \\nexercised by users, maximizing reliability in those areas.\\n■ Modular design pays off during testing. I was able to pull out the encryption and \\ndecryption code and use it independently of the user-interface code, making the \\njob of writing a test driver straightforward.\\n■ You can reuse a test driver if the code it tests ever has to be changed. Once I had \\ncorrected the two early errors, I was able to start retesting immediately.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 562}, page_content='526 Chapter 22: Developer Testing\\nCoverage Monitors\\ncc2e.com/2282 Karl Wiegers reports that testing done without measuring code coverage typically \\nexercises only about 50–60% of the code (Wiegers 2002). A coverage monitor is a tool \\nthat keeps track of the code that’s exercised and the code that isn’t. A coverage moni-\\ntor is especially useful for systematic testing because it tells you whether a set of test \\ncases fully exercises the code. If you run your full set of test cases and the coverage \\nmonitor indicates that some code still hasn’t been executed, you know that you need \\nmore tests.\\nData Recorder/Logging\\nSome tools can monitor your program and collect information on the program’s state \\nin the event of a failure—similar to the “black box” that airplanes use to diagnose crash \\nresults. Strong logging aids error diagnosis and supports effective service after the \\nsoftware has been released.\\nYou can build your own data recorder by logging significant events to a file. Record \\nthe system state prior to an error and details of the exact error conditions. This func-\\ntionality can be compiled into the development version of the code and compiled out \\nof the released version. Alternatively, if you implement logging with self-pruning stor-\\nage and thoughtful placement and content of error messages, you can include logging \\nfunctions in release versions. \\nSymbolic Debuggers\\nCross-Reference The avail-\\nability of debuggers varies \\naccording to the maturity of \\nthe technology environment. \\nFor more on this phenome-\\nnon, see Section 4.3, “Your \\nLocation on the Technology \\nWave.”\\nA symbolic debugger is a technological supplement to code walk-throughs and \\ninspections. A debugger has the capacity to step through code line by line, keep track \\nof variables’ values, and always interpret the code the same way the computer does. \\nThe process of stepping through a piece of code in a debugger and watching it work is \\nenormously valuable.\\nWalking through code in a debugger is in many respects the same process as having \\nother programmers step through your code in a review. Neither your peers nor the \\ndebugger has the same blind spots that yo u do. The additional benefit with a debug-\\nger is that it’s less labor-intensive than a team review. Watching your code execute \\nunder a variety of input-data sets is good  assurance that you’ve implemented the \\ncode you intended to.\\nA good debugger is even a good tool for learning about your language because you \\ncan see exactly how the code executes. You can toggle back and forth between a \\nview of your high-level language code and a view of the assembler code to see how \\nthe high-level code is translated into assembler. You can watch registers and the \\nstack to see how arguments are passed. You can look at code your compiler has \\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 563}, page_content='22.5 Test-Support Tools 527\\noptimized to see the kinds of optimizations that are performed. None of these ben-\\nefits has much to do with the debugger’s intended use—diagnosing errors that have \\nalready been detected—but imaginative use of a debugger produces benefits far \\nbeyond its initial charter.\\nSystem Perturbers\\ncc2e.com/2289 Another class of test-support tools are designed to perturb a system. Many people \\nhave stories of programs that work 99 times out of 100 but fail on the hundredth run-\\nthrough with the same data. The problem is nearly always a failure to initialize a vari-\\nable somewhere, and it’s usually hard to reproduce because 99 times out of 100 the \\nuninitialized variable happens to be 0.\\nTest-support tools in this class have a variety of capabilities:\\n■ Memory filling You want to be sure you don’t have any uninitialized variables. \\nSome tools fill memory with arbitrary values before you run your program so \\nthat uninitialized variables aren’t set to 0 accidentally. In some cases, the mem-\\nory might be set to a specific value. For example, on the x86 processor, the value \\n0xCC is the machine-language code for a breakpoint interrupt. If you fill mem-\\nory with 0xCC and have an error that causes you to execute something you \\nshouldn’t, you’ll hit a breakpoint in the debugger and detect the error.\\n■ Memory shaking In multitasking systems, some tools can rearrange memory \\nas your program operates so that you can be sure you haven’t written any code \\nthat depends on data being in absolute rather than relative locations.\\n■ Selective memory failing A memory driver can simulate low-memory condi-\\ntions in which a program might be running out of memory, fail on a memory \\nrequest, grant an arbitrary number of memory requests before failing, or fail on \\nan arbitrary number of requests before granting one. This is especially useful for \\ntesting complicated programs that work with dynamically allocated memory.\\n■ Memory-access checking (bounds checking) Bounds checkers watch \\npointer operations to make sure your pointers behave themselves. Such a tool is \\nuseful for detecting uninitialized or dangling pointers.\\nError Databases\\ncc2e.com/2296 One powerful test tool is a database of errors that have been reported. Such a database \\nis both a management and a technical tool. It allows you to check for recurring errors, \\ntrack the rate at which new errors are being detected and corrected, and track the sta-\\ntus of open and closed errors and their severity. For details on what information you \\nshould keep in an error database, see Section 22.7, “Keeping Test Records.”'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 564}, page_content='528 Chapter 22: Developer Testing\\n22.6 Improving Your Testing\\nThe steps for improving your testing are similar to the steps for improving any other \\nprocess. You have to know exactly what the process does so that you can vary it \\nslightly and observe the effects of the variation. When you observe a change that has \\na positive effect, you modify the process so that it becomes a little better. The following \\nsections describe how to do this with testing.\\nPlanning to Test\\nCross-Reference Part of \\nplanning to test is formalizing \\nyour plans in writing. To find \\nfurther information on test \\ndocumentation, refer to the \\n“Additional Resources” sec-\\ntion at the end of Chapter 32.\\nOne key to effective testing is planning from the beginning of the project to test. Put-\\nting testing on the same level of importance as design or coding means that time will \\nbe allocated to it, it will be viewed as important, and it will be a high-quality process. \\nTest planning is also an element of making the testing process repeatable. If you can’t \\nrepeat it, you can’t improve it.\\nRetesting (Regression Testing)\\nSuppose that you’ve tested a product thoroughly and found no errors. Suppose that \\nthe product is then changed in one area and you want to be sure that it still passes all \\nthe tests it did before the change—that the change didn’t introduce any new defects. \\nTesting designed to make sure the software hasn’t taken a step backward, or \\n“regressed,” is called “regression testing.”\\nIt’s nearly impossible to produce a high-quality software product unless you can sys-\\ntematically retest it after changes have been made. If you run different tests after each \\nchange, you have no way of knowing for sure that no new defects have been intro-\\nduced. Consequently, regression testing must run the same tests each time. Some-\\ntimes new tests are added as the product matures, but the old tests are kept too.\\nAutomated Testing\\nThe only practical way to manage regression testing is to automate it. People become \\nnumbed from running the same tests many times and seeing the same test results \\nmany times. It becomes too easy to overlook errors, which defeats the purpose of \\nregression testing. Test guru Boriz Beizer reports that the error rate in manual testing \\nis comparable to the bug rate in the code being tested. He estimates that in manual \\ntesting, only about half of all the tests are executed properly (Johnson 1994).\\nBenefits of test automation include the following:\\n■ An automated test has a lower chance of being wrong than a manual test.\\n■ Once you automate a test, it’s readily available for the rest of the project with lit-\\ntle incremental effort on your part.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 565}, page_content='22.7 Keeping Test Records 529\\n■ If tests are automated, they can be run frequently to see whether any code check-\\nins have broken the code. Test automation is part of the foundation of test-inten-\\nsive practices, such as the daily build and smoke test and Extreme Programming.\\n■ Automated tests improve your chances of detecting any given problem at the \\nearliest possible moment, which tends to minimize the work needed to diag-\\nnose and correct the problem.\\n■ Automated tests provide a safety net for large-scale code changes because they \\nincrease your chance of quickly detecting defects inserted during the modifications.\\nCross-Reference For more \\non the relationship between \\ntechnology maturity and \\ndevelopment practices, see \\nSection 4.3, “Your Location \\non the Technology Wave.”\\n■ Automated tests are especially useful in new, volatile technology environments \\nbecause they flush out changes in the environments sooner rather than later.\\nThe main tools used to support automated testing provide test scaffolding, generate \\ninput, capture output, and compare actual output with expected output. The variety \\nof tools discussed in the preceding section will perform some or all of these functions.\\n22.7 Keeping Test Records\\nAside from making the testing process repeatable, you need to measure the project so \\nthat you can tell for sure whether changes improve or degrade  it. Here are a few kinds \\nof data you can collect to measure your project:\\n■ Administrative description of the defect (the date reported, the person who \\nreported it, a title or description, the build number, the date fixed)\\n■ Full description of the problem\\n■ Steps to take to repeat the problem\\n■ Suggested workaround for the problem\\n■ Related defects\\n■ Severity of the problem—for example, fatal, bothersome, or cosmetic\\n■ Origin of the defect: requirements, design, coding, or testing\\n■ Subclassification of a coding defect: off-by-one, bad assignment, bad array \\nindex, bad routine call, and so on\\n■ Classes and routines changed by the fix\\n■ Number of lines of code affected by the defect\\n■ Hours to find the defect\\n■ Hours to fix the defect\\nOnce you collect the data, you can crunch a few numbers to determine whether your \\nproject is getting sicker or healthier:\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 566}, page_content='530 Chapter 22: Developer Testing\\n■ Number of defects in each class, sorted from worst class to best, possibly nor-\\nmalized by class size\\n■ Number of defects in each routine, sorted from worst routine to best, possibly \\nnormalized by routine size\\n■ Average number of testing hours per defect found\\n■ Average number of defects found per test case\\n■ Average number of programming hours per defect fixed\\n■ Percentage of code covered by test cases\\n■ Number of outstanding defects in each severity classification\\nPersonal Test Records\\nIn addition to project-level test records, you might find it useful to keep track of your \\npersonal test records. These records can include both a checklist of the errors you \\nmost commonly make as well as a record of the amount of time you spend writing \\ncode, testing code, and correcting errors.\\nAdditional Resources\\ncc2e.com/2203 Federal truth-in-advising statutes compel me to disclose that several other books cover \\ntesting in more depth than this chapter does. Books that are devoted to testing discuss \\nsystem and black-box testing, which haven’t been discussed in this chapter. They also \\ngo into more depth on developer topics. They discuss formal approaches such as cause-\\neffect graphing and the ins and outs of establishing an independent test organization.\\nTesting\\nKaner, Cem, Jack Falk, and Hung Q. Nguyen. Testing Computer Software, 2d ed. New \\nYork, NY: John Wiley & Sons, 1999. This is probably the best current book on soft-\\nware testing. It is most applicable to testing applications that will be distributed to a \\nwidespread customer base, such as high-volume websites and shrink-wrap applica-\\ntions, but it is also generally useful.\\nKaner, Cem, James Bach, and Bret Pettichord. Lessons Learned in Software Testing. New \\nYork, NY: John Wiley & Sons, 2002. This book is a good supplement to Testing Com-\\nputer Software, 2d ed. It’s organized into 11 chapters that enumerate 250 lessons \\nlearned by the authors.\\nTamre, Louise. Introducing Software Testing. Boston, MA: Addison-Wesley, 2002. This is \\nan accessible testing book targeted at developers who need to understand testing. \\nBelying the title, the book goes into some depth on testing details that are useful even \\nto experienced testers.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 567}, page_content='Additional Resources 531\\nWhittaker, James A. How to Break Software: A Practical Guide to Testing. Boston, MA: \\nAddison-Wesley, 2002. This book lists 23 attacks testers can use to make software fail \\nand presents examples for each attack using popular software packages. You can use \\nthis book as a primary source of information about testing or, because its approach is \\ndistinctive, you can use it to supplement other testing books.\\nWhittaker, James A. “What Is Software Testing? And Why Is It So Hard?” IEEE Soft-\\nware, January 2000, pp. 70–79. This article is a good introduction to software testing \\nissues and explains some of the challenges associated with effectively testing software.\\nMyers, Glenford J. The Art of Software Testing. New York, NY: John Wiley, 1979. This is \\nthe classic book on software testing and is still in print (though quite expensive). The \\ncontents of the book are straightforward: A Self-Assessment Test; The Psychology and \\nEconomics of Program Testing; Program Inspections, Walkthroughs, and Reviews; \\nTest-Case Design; Class Testing; Higher-Order Testing; Debugging; Test Tools and \\nOther Techniques. It’s short (177 pages) and readable. The quiz at the beginning gets \\nyou started thinking like a tester and demonstrates how many ways a piece of code \\ncan be broken.\\nTest Scaffolding\\nBentley, Jon. “A Small Matter of Programming” in Programming Pearls, 2d ed. Boston, MA: \\nAddison-Wesley, 2000. This essay includes several good examples of test scaffolding.\\nMackinnon, Tim, Steve Freeman, and Philip Craig. “Endo-Testing: Unit Testing with \\nMock Objects,” eXtreme Programming and Flexible Processes Software Engineering - \\nXP2000” Conference, 2000. This is the original paper to discuss the use of mock \\nobjects to support developer testing.\\nThomas, Dave and Andy Hunt. “Mock Objects,” IEEE Software, May/June 2002. This is \\na highly readable introduction to using mock objects to support developer testing.\\ncc2e.com/2217 www.junit.org. This site provides support for developers using JUnit. Similar resources \\nare provided at cppunit.sourceforge.net and nunit.sourceforge.net.\\nTest First Development\\nBeck, Kent. Test-Driven Development: By Example. Boston, MA: Addison-Wesley, 2003. \\nBeck describes the ins and outs of “test-driven development,” a development \\napproach that’s characterized by writing test cases first and then writing the code to \\nsatisfy the test cases. Despite Beck’s sometimes-evangelical tone, the advice is sound, \\nand the book is short and to the point. The book has an extensive running example \\nwith real code.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 568}, page_content='532 Chapter 22: Developer Testing\\nRelevant Standards\\nIEEE Std 1008-1987 (R1993), Standard for Software Unit Testing\\nIEEE Std 829-1998, Standard for Software Test Documentation\\nIEEE Std 730-2002, Standard for Software Quality Assurance Plans\\ncc2e.com/2210 CHECKLIST: Test Cases\\n❑ Does each requirement that applies to the class or routine have its own test \\ncase?\\n❑ Does each element from the design that applies to the class or routine \\nhave its own test case?\\n❑ Has each line of code been tested with at least one test case? Has this been \\nverified by computing the minimum number of tests necessary to exercise \\neach line of code?\\n❑ Have all defined-used data-flow paths been tested with at least one test \\ncase?\\n❑ Has the code been checked for data-flow patterns that are unlikely to be \\ncorrect, such as defined-defined, defined-exited, and defined-killed?\\n❑ Has a list of common errors been used to write test cases to detect errors \\nthat have occurred frequently in the past?\\n❑ Have all simple boundaries been tested: maximum, minimum, and off-by-\\none boundaries?\\n❑ Have compound boundaries been tested—that is, combinations of input \\ndata that might result in a computed variable that’s too small or too large?\\n❑ Do test cases check for the wrong kind of data—for example, a negative \\nnumber of employees in a payroll program?\\n❑ Are representative, middle-of-the-road values tested?\\n❑ Is the minimum normal configuration tested?\\n❑ Is the maximum normal configuration tested?\\n❑ Is compatibility with old data tested? And are old hardware, old versions \\nof the operating system, and interfaces with old versions of other software \\ntested?\\n❑ Do the test cases make hand-checks easy?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 569}, page_content='Key Points 533\\nKey Points\\n■ Testing by the developer is a key part of a full testing strategy. Independent test-\\ning is also important but is outside the scope of this book.\\n■ Writing test cases before the code takes the same amount of time and effort as \\nwriting the test cases after the code, but it shortens defect-detection-debug-cor-\\nrection cycles.\\n■ Even considering the numerous kinds of testing available, testing is only one \\npart of a good software-quality program. High-quality development methods, \\nincluding minimizing defects in requirements and design, are at least as impor-\\ntant. Collaborative development practices are also at least as effective at detect-\\ning errors as testing, and these practices detect different kinds of errors.\\n■ You can generate many test cases deterministically by using basis testing, data-\\nflow analysis, boundary analysis, classes of bad data, and classes of good data. \\nYou can generate additional test cases with error guessing.\\n■ Errors tend to cluster in a few error-prone classes and routines. Find that error-\\nprone code, redesign it, and rewrite it.\\n■ Test data tends to have a higher error density than the code being tested. \\nBecause hunting for such errors wastes time without improving the code, test-\\ndata errors are more aggravating than programming errors. Avoid them by \\ndeveloping your tests as carefully as your code.\\n■ Automated testing is useful in general and is essential for regression testing.\\n■ In the long run, the best way to improve your testing process is to make it regu-\\nlar, measure it, and use what you learn to improve it.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 571}, page_content='535\\nChapter 23\\nDebugging\\ncc2e.com/2361 Contents\\n■ 23.1 Overview of Debugging Issues: page 535\\n■ 23.2 Finding a Defect: page 540\\n■ 23.3 Fixing a Defect: page 550\\n■ 23.4 Psychological Considerations in Debugging: page 554\\n■ 23.5 Debugging Tools—Obvious and Not-So-Obvious: page 556\\nRelated Topics\\n■ The software-quality landscape: Chapter 20\\n■ Developer testing: Chapter 22\\n■ Refactoring: Chapter 24\\nDebugging is twice as hard \\nas writing the code in the \\nfirst place. Therefore, if you \\nwrite the code as cleverly as \\npossible, you are, by defini-\\ntion, not smart enough to \\ndebug it.\\n—Brian W. Kernighan\\nDebugging is the process of identifying the root cause of an error and correcting it. It \\ncontrasts with testing, which is the process of detecting the error initially. On some \\nprojects, debugging occupies as much as 50 percent of the total development time. \\nFor many programmers, debugging is the hardest part of programming.\\nDebugging doesn’t have to be the hardest part. If you follow the advice in this book, \\nyou’ll have fewer errors to debug. Most of the defects you’ll have will be minor over-\\nsights and typos, easily found by looking at a source-code listing or stepping through \\nthe code in a debugger. For the remaining harder bugs, this chapter describes how to \\nmake debugging much easier than it usually is.\\n23.1 Overview of Debugging Issues\\nThe late Rear Admiral Grace Hopper, co-inventor of COBOL, always said that the \\nword “bug” in software dated back to the first large-scale digital computer, the Mark I \\n(IEEE 1992). Programmers traced a circuit malfunction to the presence of a large \\nmoth that had found its way into the computer, and from that time on, computer \\nproblems were blamed on “bugs.” Outside software, the word “bug” dates back at \\nleast to Thomas Edison, who is quoted as using it as early as 1878 (Tenner 1997). \\nThe word “bug” is a cute word and conjures up images like this one:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 572}, page_content='536 Chapter 23: Debugging\\nThe reality of software defects, however, is that bugs aren’t organisms that sneak into \\nyour code when you forget to spray it with pesticide. They are errors. A bug in software \\nmeans that a programmer made a mistake. The result of the mistake isn’t like the cute \\npicture shown above. It’s more likely a note like this one:\\nIn the context of this book, technical accuracy requires that mistakes in the code be \\ncalled “errors,” “defects,” or “faults.”\\nRole of Debugging in Software Quality\\nLike testing, debugging isn’t a way to improve the quality of your software per se; it’s \\na way to diagnose defects. Software quality must be built in from the start. The best \\nway to build a quality product is to develop requirements carefully, design well, and \\nuse high-quality coding practices. Debugging is a last resort.\\nVariations in Debugging Performance\\nWhy talk about debugging? Doesn’t everyone know how to debug?\\nNo, not everyone knows how to debug. Studies of experienced programmers have \\nfound roughly a 20-to-1 difference in the time it takes experienced programmers to \\nfind the same set of defects found by by inexperienced programmers. Moreover, some \\nprogrammers find more defects and make corrections more accurately. Here are the \\nFrom:\\nTo:\\nRe:\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 573}, page_content='23.1 Overview of Debugging Issues 537\\nresults of a classic study that examined how effectively professional programmers \\nwith at least four years of experience debugged a program with 12 defects:\\nThe three programmers who were best at debugging were able to find the defects in \\nabout one-third the time and inserted only about two-fifths as many new defects as \\nthe three who were the worst. The best programmer found all the defects and didn’t \\ninsert any new defects in correcting them. The worst missed 4 of the 12 defects and \\ninserted 11 new defects in correcting the 8 defects he found. \\nBut this study doesn’t really tell the whole story. After the first round of debugging, the \\nfastest three programmers still have 3.7 defects left in their code and the slowest still \\nhave 9.4 defects. Neither group is done debugging yet. I wondered what would happen \\nif I applied the same find-and-bad-fix ratios to additional debugging cycles. My results \\naren’t statistically valid, but they’re still interesting. When I applied the same find-and-\\nbad-fix ratios to successive debugging cycles until each group had less than half a defect \\nremaining, the fastest group required a total of three debugging cycles, whereas the \\nslowest group required 14 debugging cycles. Bearing in mind that each cycle of the \\nslower group takes almost three times as long as each cycle of the fastest group, the \\nslowest group would take about 13 times as long to fully debug its programs as the fast-\\nest group, according to my nonscientific extrapolation of this study. This wide variation \\nhas been confirmed by other studies (Gilb 1977, Curtis 1981).\\nCross-Reference For details \\non the relationship between \\nquality and cost, see Section \\n20.5, “The General Principle \\nof Software Quality.”\\nIn addition to providing insight into debugging, the evidence supports the General \\nPrinciple of Software Quality: improving quality reduces development costs. The best \\nprogrammers found the most defects, found the defects most quickly, and made cor-\\nrect modifications most often. You don’t have to choose between quality, cost, and \\ntime—they all go hand in hand.\\nDefects as Opportunities\\nWhat does having a defect mean? Assuming that you don’t want the program to have \\na defect, it means that you don’t fully understand what the program does. The idea of \\nnot understanding what the program does is unsettling. After all, if you created the \\nprogram, it should do your bidding. If you don’t know exactly what you’re telling the \\ncomputer to do, you’re only a small step away from merely trying different things until \\nFastest Three \\nProgrammers\\nSlowest Three \\nProgrammers\\nAverage debug time (minutes) 5.0 14.1\\nAverage number of defects not found 0.7 1.7\\nAverage number of defects made correcting \\ndefects\\n3.0 7.7\\nSource: “Some Psychological Evidence on How People Debug Computer Programs” (Gould 1975)\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 574}, page_content='538 Chapter 23: Debugging\\nsomething seems to work—that is, programming by trial and error. And if you’re pro-\\ngramming by trial and error, defects are guaranteed. You don’t need to learn how to fix \\ndefects; you need to learn how to avoid them in the first place.\\nMost people are somewhat fallible, however, and you might be an excellent program-\\nmer who has simply made a modest oversight. If this is the case, an error in your pro-\\ngram provides a powerful opportunity for you to learn many things. You can:\\nLearn about the program you’re working on You have something to learn about the \\nprogram because if you already knew it perfectly, it wouldn’t have a defect. You would \\nhave corrected it already.\\nFurther Reading For details \\non practices that will help \\nyou learn about the kinds of \\nerrors you are personally \\nprone to, see A Discipline \\nfor Software Engineering \\n(Humphrey 1995).\\nLearn about the kinds of mistakes you make If you wrote the program, you inserted \\nthe defect. It’s not every day that a spotlight exposes a weakness with glaring clarity, \\nbut such a day is an opportunity, so take advantage of it. Once you find the mistake, \\nask yourself how and why you made it. How could you have found it more quickly? \\nHow could you have prevented it? Does the code have other mistakes just like it? Can \\nyou correct them before they cause problems of their own?\\nLearn about the quality of your code from the point of view of someone who has to read \\nit You’ll have to read your code to find the defect. This is an opportunity to look crit-\\nically at the quality of your code. Is it easy to read? How could it be better? Use your \\ndiscoveries to refactor your current code or to improve the code you write next.\\nLearn about how you solve problems Does your approach to solving debugging prob-\\nlems give you confidence? Does your approach work? Do you find defects quickly? Or is \\nyour approach to debugging weak? Do you feel anguish and frustration? Do you guess \\nrandomly? Do you need to improve? Considering the amount of time many projects \\nspend on debugging, you definitely won’t waste time if you observe how you debug. \\nTaking time to analyze and change the way you debug might be the quickest way to \\ndecrease the total amount of time it takes you to develop a program.\\nLearn about how you fix defects In addition to learning how you find defects, you \\ncan learn about how you fix them. Do you make the easiest possible correction by \\napplying goto bandages and special-case makeup that changes the symptom but not \\nthe problem? Or do you make systemic corrections, demanding an accurate diagnosis \\nand prescribing treatment for the heart of the problem?\\nAll things considered, debugging is an extraordinarily rich soil in which to plant the \\nseeds of your own improvement. It’s where all construction roads cross: readability, \\ndesign, code quality—you name it. This is where building good code pays off, espe-\\ncially if you do it well enough that you don’t have to debug very often.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 575}, page_content=\"23.1 Overview of Debugging Issues 539\\nAn Ineffective Approach\\nUnfortunately, programming classes in colleges and universities hardly ever offer \\ninstruction in debugging. If you studied programming in college, you might have had \\na lecture devoted to debugging. Although my computer-science education was excel-\\nlent, the extent of the debugging advice I received was to “put print statements in the \\nprogram to find the defect.” This is not adequate. If other programmers’ educational \\nexperiences are like mine, a great many programmers are being forced to reinvent \\ndebugging concepts on their own. What a waste!\\nThe Devil’s Guide to Debugging\\nProgrammers do not always \\nuse available data to con-\\nstrain their reasoning. They \\ncarry out minor and irratio-\\nnal repairs, and they often \\ndon’t undo the incorrect \\nrepairs.\\n—Iris Vessey\\nIn Dante’s vision of hell, the lowest circle is reserved for Satan himself. In modern \\ntimes, Old Scratch has agreed to share the lowest circle with programmers who don’t \\nlearn to debug effectively. He tortures programmers by making them use these com-\\nmon debugging approaches:\\nFind the defect by guessing To find the defect, scatter print statements randomly \\nthroughout a program. Examine the output to see where the defect is. If you can’t find \\nthe defect with print statements, try changing things in the program until something \\nseems to work. Don’t back up the original version of the program, and don’t keep a \\nrecord of the changes you’ve made. Programming is more exciting when you’re not \\nquite sure what the program is doing. Stock up on cola and candy because you’re in \\nfor a long night in front of the terminal.\\nDon’t waste time trying to understand the problem It’s likely that the problem is \\ntrivial, and you don’t need to understand it completely to fix it. Simply finding it is \\nenough.\\nFix the error with the most obvious fix It’s usually good just to fix the specific prob-\\nlem you see, rather than wasting a lot of time making some big, ambitious correction \\nthat’s going to affect the whole program. This is a perfect example:\\nx = Compute( y )\\nif ( y = 17 )\\n   x = $25.15      -- Compute() doesn't work for y = 17, so fix it\\nWho needs to dig all the way into Compute() for an obscure problem with the value of \\n17 when you can just write a special case for it in the obvious place? \\nDebugging by Superstition\\nSatan has leased part of hell to programmers who debug by superstition. Every group \\nhas one programmer who has endless problems with demon machines, mysterious \\ncompiler defects, hidden language defects that appear when the moon is full, bad\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 576}, page_content='540 Chapter 23: Debugging\\ndata, losing important changes, a possessed editor that saves programs incorrectly—\\nyou name it. This is “programming by superstition.”\\nIf you have a problem with a program you’ve written, it’s your fault. It’s not the com-\\nputer’s fault, and it’s not the compiler’s fault. The program doesn’t do something dif-\\nferent every time. It didn’t write itself; you wrote it, so take responsibility for it.\\nEven if an error at first appears not to be your fault, it’s strongly in your interest to \\nassume that it is. That assumption helps you debug. It’s hard enough to find a defect \\nin your code when you’re looking for it; it’s even harder when you assume your code \\nis error-free. Assuming the error is your fault also improves your credibility. If you \\nclaim that an error arose from someone else’s code, other programmers will believe \\nthat you have checked out the problem carefully. If you assume the error is yours, you \\navoid the embarrassment of having to recant publicly later when you find out that it \\nwas your defect after all.\\n23.2 Finding a Defect\\nDebugging consists of finding the defect and fixing it. Finding the defect—and under-\\nstanding it—is usually 90 percent of the work.\\nFortunately, you don’t have to make a pact with Satan to find an approach to debug-\\nging that’s better than random guessing. Debugging by thinking about the problem is \\nmuch more effective and interesting than debugging with an eye of a newt and the \\ndust of a frog’s ear.\\nSuppose you were asked to solve a murder mystery. Which would be more interesting: \\ngoing door to door throughout the county, checking every person’s alibi for the night of \\nOctober 17, or finding a few clues and deducing the murderer’s identity? Most people \\nwould rather deduce the person’s identity, and most programmers find the intellectual \\napproach to debugging more satisfying. Even better, the effective programmers who \\ndebug in one-twentieth the time used by the ineffective programmers aren’t randomly \\nguessing about how to fix the program. They’re using the scientific method—that is, the \\nprocess of discovery and demonstration necessary for scientific investigation.\\nThe Scientific Method of Debugging\\nHere are the steps you go through when you use the classic scientific method:\\n1. Gather data through repeatable experiments.\\n2. Form a hypothesis that accounts for the relevant data.\\n3. Design an experiment to prove or disprove the hypothesis.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 577}, page_content='23.2 Finding a Defect 541\\n4. Prove or disprove the hypothesis.\\n5. Repeat as needed.\\nThe scientific method has many parallels in debugging. Here’s an effective approach \\nfor finding a defect:\\n1. Stabilize the error.\\n2. Locate the source of the error (the “fault”).\\na. Gather the data that produces the defect.\\nb. Analyze the data that has been gathered, and form a hypothesis about the \\ndefect.\\nc. Determine how to prove or disprove the hypothesis, either by testing the \\nprogram or by examining the code. \\nd. Prove or disprove the hypothesis by using the procedure identified in 2(c). \\n3. Fix the defect.\\n4. Test the fix.\\n5. Look for similar errors.\\nThe first step is similar to the scientific meth od’s first step in that it relies on repeat-\\nability. The defect is easier to diagnose if you can stabilize it—that is, make it occur reli-\\nably. The second step uses the steps of the scientific method. You gather the test data \\nthat divulged the defect, analyze the data that has been produced, and form a hypoth-\\nesis about the source of the error. You then design a test case or an inspection to eval-\\nuate the hypothesis, and you either declare success (regarding proving your \\nhypothesis) or renew your efforts, as appropriate. When you have proven your \\nhypothesis, you fix the defect, test the fix, and search your code for similar errors.\\nLet’s look at each of the steps in conjunction with an example. Assume that you have \\nan employee database program that has an intermittent error. The program is sup-\\nposed to print a list of employees and their income-tax withholdings in alphabetical \\norder. Here’s part of the output:\\nFormatting, Fred Freeform     $5,877\\nGlobal, Gary                  $1,666\\nModula, Mildred              $10,788\\nMany-Loop, Mavis              $8,889\\nStatement, Sue Switch         $4,000\\nWhileloop, Wendy              $7,860\\nThe error is that Many-Loop, Mavis and Modula, Mildred are out of order.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 578}, page_content='542 Chapter 23: Debugging\\nStabilize the Error\\nIf a defect doesn’t occur reliably, it’s almost impossible to diagnose. Making an inter-\\nmittent defect occur predictably is one of the most challenging tasks in debugging.\\nCross-Reference For details \\non using pointers safely, see \\nSection 13.2, “Pointers.”\\nAn error that doesn’t occur predictably is usually an initialization error, a timing issue, \\nor a dangling-pointer problem. If the calculation of a sum is right sometimes and \\nwrong sometimes, a variable involved in the calculation probably isn’t being initial-\\nized properly—most of the time it just happens to start at 0. If the problem is a strange \\nand unpredictable phenomenon and you’re using pointers, you almost certainly have \\nan uninitialized pointer or are using a pointer after the memory that it points to has \\nbeen deallocated.\\nStabilizing an error usually requires more than finding a test case that produces the \\nerror. It includes narrowing the test case to the simplest one that still produces the \\nerror. The goal of simplifying the test case is to make it so simple that changing any \\naspect of it changes the behavior of the error. Then, by changing the test case carefully \\nand watching the program’s behavior under controlled conditions, you can diagnose \\nthe problem. If you work in an organization that has an independent test team, some-\\ntimes it’s the team’s job to make the test cases simple. Most of the time, it’s your job.\\nTo simplify the test case, you bring the scientific method into play again. Suppose you \\nhave 10 factors that, used in combination, produce the error. Form a hypothesis about \\nwhich factors were irrelevant to producing the error. Change the supposedly irrele-\\nvant factors, and rerun the test case. If you still get the error, you can eliminate those \\nfactors and you’ve simplified the test. Then you can try to simplify the test further. If \\nyou don’t get the error, you’ve disproved that specific hypothesis and you know more \\nthan you did before. It might be that some subtly different change would still produce \\nthe error, but you know at least one specific change that does not.\\nIn the employee withholdings example, when the program is run initially, Many-Loop, \\nMavis is listed after Modula, Mildred. When the program is run a second time, how-\\never, the list is fine:\\nFormatting, Fred Freeform     $5,877\\nGlobal, Gary                  $1,666\\nMany-Loop, Mavis              $8,889\\nModula, Mildred              $10,788\\nStatement, Sue Switch         $4,000\\nWhileloop, Wendy              $7,860\\nIt isn’t until Fruit-Loop, Frita is entered and shows up in an incorrect position that you \\nremember that Modula, Mildred had been entered just prior to showing up in the \\nwrong spot too. What’s odd about both cases is that they were entered singly. Usually, \\nemployees are entered in groups.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 579}, page_content='23.2 Finding a Defect 543\\nYou hypothesize: the problem has something to do with entering a single new \\nemployee. If this is true, running the program again should put Fruit-Loop, Frita in the \\nright position. Here’s the result of a second run:\\nFormatting, Fred Freeform     $5,877\\nFruit-Loop, Frita             $5,771\\nGlobal, Gary                  $1,666\\nMany-Loop, Mavis              $8,889\\nModula, Mildred              $10,788\\nStatement, Sue Switch         $4,000\\nWhileloop, Wendy              $7,860\\nThis successful run supports the hypothesis . To confirm it, you want to try adding a \\nfew new employees, one at a time, to see whether they show up in the wrong order \\nand whether the order changes on the second run.\\nLocate the Source of the Error\\nLocating the source of the error also calls for using the scientific method. You might \\nsuspect that the defect is a result of a specific problem, say an off-by-one error. You \\ncould then vary the parameter you suspect is causing the problem—one below the \\nboundary, on the boundary, and one above the boundary—and determine whether \\nyour hypothesis is correct.\\nIn the running example, the source of the problem could be an off-by-one defect that \\noccurs when you add one new employee but not when you add two or more. Examin-\\ning the code, you don’t find an obvious off-by-one defect. Resorting to Plan B, you run \\na test case with a single new employee to see whether that’s the problem. You add \\nHardcase, Henry as a single employee and hypothesize that his record will be out of \\norder. Here’s what you find:\\nFormatting, Fred Freeform     $5,877\\nFruit-Loop, Frita             $5,771\\nGlobal, Gary                  $1,666\\nHardcase, Henry                 $493\\nMany-Loop, Mavis              $8,889\\nModula, Mildred              $10,788\\nStatement, Sue Switch         $4,000\\nWhileloop, Wendy              $7,860\\nThe line for Hardcase, Henry is exactly where it should be, which means that your first \\nhypothesis is false. The problem isn’t caused simply by adding one employee at a time. \\nIt’s either a more complicated problem or something completely different.\\nExamining the test-run output again, you notice that Fruit-Loop, Frita and Many-Loop, \\nMavis are the only names containing hyphens. Fruit-Loop was out of order when she was \\nfirst entered, but Many-Loop wasn’t, was she? Although you don’t have a printout from \\nthe original entry, in the original error Modula, Mildred appeared to be out of order, but \\nshe was next to Many-Loop. Maybe Many-Loop was out of order and Modula was all right.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 580}, page_content='544 Chapter 23: Debugging\\nYou hypothesize again: the problem arises from names with hyphens, not names that \\nare entered singly.\\nBut how does that account for the fact that the problem shows up only the first time \\nan employee is entered? You look at the code and find that two different sorting rou-\\ntines are used. One is used when an employee is entered, and another is used when \\nthe data is saved. A closer look at the routine used when an employee is first entered \\nshows that it isn’t supposed to sort the data completely. It only puts the data in \\napproximate order to speed up the save routine’s sorting. Thus, the problem is that \\nthe data is printed before it’s sorted. The problem with hyphenated names arises \\nbecause the rough-sort routine doesn’t handle niceties such as punctuation charac-\\nters. Now, you can refine the hypothesis even further.\\nYou hypothesize one last time: names with punctuation characters aren’t sorted cor-\\nrectly until they’re saved.\\nYou later confirm this hypothesis with additional test cases.\\nTips for Finding Defects\\nOnce you’ve stabilized an error and refined the test case that produces it, finding its \\nsource can be either trivial or challenging, depending on how well you’ve written your \\ncode. If you’re having a hard time finding a defect, it could be because the code isn’t \\nwell written. You might not want to hear that, but it’s true. If you’re having trouble, \\nconsider these tips:\\nUse all the data available to make your hypothesis When creating a hypothesis \\nabout the source of a defect, account for as much of the data as you can in your \\nhypothesis. In the example, you might have noticed that Fruit-Loop, Frita was out of \\norder and created a hypothesis that names beginning with an “F” are sorted incor-\\nrectly. That’s a poor hypothesis because it doesn’t account for the fact that Modula, \\nMildred was out of order or that names are sorted correctly the second time around. If \\nthe data doesn’t fit the hypothesis, don’t discard the data—ask why it doesn’t fit, and \\ncreate a new hypothesis.\\nThe second hypothesis in the example—that the problem arises from names with \\nhyphens, not names that are entered singly—didn’t seem initially to account for the \\nfact that names were sorted correctly the second time around either. In this case, how-\\never, the second hypothesis led to a more refined hypothesis that proved to be correct. \\nIt’s all right that the hypothesis doesn’t account for all of the data at first as long as you \\nkeep refining the hypothesis so that it does eventually.\\nRefine the test cases that produce the error If you can’t find the source of an error, \\ntry to refine the test cases further than you already have. You might be able to vary one \\nparameter more than you had assumed, and focusing on one of the parameters might \\nprovide the crucial breakthrough.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 581}, page_content='23.2 Finding a Defect 545\\nCross-Reference For more \\non unit test frameworks, see \\n“Plug unit tests into a test \\nframework” in Section 22.4.\\nExercise the code in your unit test suite Defects tend to be easier to find in small \\nfragments of code than in large integrated programs. Use your unit tests to test the \\ncode in isolation. \\nUse available tools Numerous tools are available to support debugging sessions: \\ninteractive debuggers, picky compilers, memory checkers, syntax-directed editors, \\nand so on. The right tool can make a difficult job easy. With one tough-to-find error, \\nfor example, one part of the program was overwriting another part’s memory. This \\nerror was difficult to diagnose using conventional debugging practices because the \\nprogrammer couldn’t determine the specific point at which the program was incor-\\nrectly overwriting memory. The programmer used a memory breakpoint to set a \\nwatch on a specific memory address. When the program wrote to that memory loca-\\ntion, the debugger stopped the code and the guilty code was exposed. \\nThis is an example of a problem that’s difficult to diagnose analytically but that \\nbecomes quite simple when the right tool is applied.\\nReproduce the error several different waysSometimes trying cases that are similar to \\nthe error-producing case but not exactly the same is instructive. Think of this \\napproach as triangulating the defect. If you can get a fix on it from one point and a fix \\non it from another, you can better determine exactly where it is.\\nAs illustrated by Figure 23-1, reproducing an error several different ways helps diag-\\nnose the cause of the error. Once you think you’ve identified the defect, run a case \\nthat’s close to the cases that produce errors but that should not produce an error \\nitself. If it does produce an error, you don’t completely understand the problem yet. \\nErrors often arise from combinations of factors, and trying to diagnose the problem \\nwith only one test case often doesn’t diagnose the root problem.\\nFigure 23-1 Try to reproduce an error several different ways to determine its exact cause.\\nProgram First test\\nDefect\\nProgram\\nSecond test\\nDefect\\nProgram\\nThird test\\nDefect\\nProgram\\nSubsequent tests\\nDefect'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 582}, page_content='546 Chapter 23: Debugging\\nGenerate more data to generate more hypotheses Choose test cases that are different \\nfrom the test cases you already know to be erroneous or correct. Run them to generate \\nmore data, and use the new data to add to your list of possible hypotheses.\\nUse the results of negative tests Suppose you create a hypothesis and run a test case \\nto prove it. Suppose further that the test case disproves the hypothesis, so you still \\ndon’t know the source of the error. You do know something you didn’t before—\\nnamely, that the defect is not in the area you thought it was. That narrows your search \\nfield and the set of remaining possible hypotheses.\\nBrainstorm for possible hypotheses Rather than limiting yourself to the first hypothe-\\nsis you think of, try to come up with several. Don’t analyze them at first—just come up \\nwith as many as you can in a few minutes. Then look at each hypothesis and think about \\ntest cases that would prove or disprove it. This mental exercise is helpful in breaking the \\ndebugging logjam that results from concentrating too hard on a single line of reasoning.\\nKeep a notepad by your desk, and make a list of things to try One reason program-\\nmers get stuck during debugging sessions is that they go too far down dead-end \\npaths. Make a list of things to try, and if one approach isn’t working, move on to the \\nnext approach. \\nNarrow the suspicious region of the code If you’ve been testing the whole program \\nor a whole class or routine, test a smaller part instead. Use print statements, logging, \\nor tracing to identify which section of code is producing the error. \\nIf you need a more powerful technique to narrow the suspicious region of the code, \\nsystematically remove parts of the program and see whether the error still occurs. If it \\ndoesn’t, you know it’s in the part you took away. If it does, you know it’s in the part \\nyou’ve kept.\\nRather than removing regions haphazardly, divide and conquer. Use a binary search \\nalgorithm to focus your search. Try to remove about half the code the first time. Deter-\\nmine the half the defect is in, and then divide that section. Again, determine which \\nhalf contains the defect, and again, chop that section in half. Continue until you find \\nthe defect.\\nIf you use many small routines, you’ll be able to chop out sections of code simply by \\ncommenting out calls to the routines. Otherwise, you can use comments or preproces-\\nsor commands to remove code.\\nIf you’re using a debugger, you don’t necessarily have to remove pieces of code. You \\ncan set a breakpoint partway through the program and check for the defect that way \\ninstead. If your debugger allows you to skip calls to routines, eliminate suspects by \\nskipping the execution of certain routines and seeing whether the error still occurs. \\nThe process with a debugger is otherwise similar to the one in which pieces of a pro-\\ngram are physically removed.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 583}, page_content='23.2 Finding a Defect 547\\nCross-Reference For more \\ndetails on error-prone code, \\nsee “Target error-prone \\nmodules” in Section 24.5.\\nBe suspicious of classes and routines that have had defects before Classes that have \\nhad defects before are likely to continue to have defects. A class that has been trouble-\\nsome in the past is more likely to contain a new defect than a class that has been \\ndefect-free. Reexamine error-prone classes and routines. \\nCheck code that’s changed recently If you have a new error that’s hard to diagnose, \\nit’s usually related to code that’s changed recently. It could be in completely new code \\nor in changes to old code. If you can’t find a defect, run an old version of the program \\nto see whether the error occurs. If it doesn’t, you know the error’s in the new version \\nor is caused by an interaction with the new version. Scrutinize the differences between \\nthe old and new versions. Check the version control log to see what code has changed \\nrecently. If that’s not possible, use a diff tool to compare changes in the old, working \\nsource code to the new, broken source code. \\nExpand the suspicious region of the code It’s easy to focus on a small section of code, \\nsure that “the defect must be in this section.” If you don’t find it in the section, con-\\nsider the possibility that the defect isn’t in the section. Expand the area of code you \\nsuspect, and then focus on pieces of it by using the binary search technique described \\nearlier.\\nCross-Reference For a full \\ndiscussion of integration, see \\nChapter 29, “Integration.”\\nIntegrate incrementally Debugging is easy if you add pieces to a system one at a \\ntime. If you add a piece to a system and encounter a new error, remove the piece and \\ntest it separately. \\nCheck for common defects Use code-quality checklists to stimulate your thinking \\nabout possible defects. If you’re following  the inspection practi ces described in Sec-\\ntion 21.3, “Formal Inspections,” you’ll have your own fine-tuned checklist of the \\ncommon problems in your environment. You can also use the checklists that \\nappear throughout this book. See the “L ist of Checklists” following the book’s \\ntable of contents.\\nCross-Reference For details \\non how involving other \\ndevelopers can put a benefi-\\ncial distance between you \\nand the problem, see Section \\n21.1, “Overview of Collabora-\\ntive Development Practices.”\\nTalk to someone else about the problem Some people call this “confessional debug-\\nging.” You often discover your own defect in the act of explaining it to another person. \\nFor example, if you were explaining the problem in the salary example, you might \\nsound like this:\\nHey, Jennifer, have you got a minute? I’m having a problem. I’ve got this list of \\nemployee salaries that’s supposed to be sorted, but some names are out of order. \\nThey’re sorted all right the second time I print them out but not the first. I \\nchecked to see if it was new names, but I tried some that worked. I know they \\nshould be sorted the first time I print them because the program sorts all the \\nnames as they’re entered and again when they’re saved—wait a minute—no, it \\ndoesn’t sort them when they’re entered. That’s right. It only orders them \\nroughly. Thanks, Jennifer. You’ve been a big help.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 584}, page_content='548 Chapter 23: Debugging\\nJennifer didn’t say a word, and you solved your problem. This result is typical, and this \\napproach is a potent tool for solving difficult defects.\\nTake a break from the problem Sometimes you concentrate so hard you can’t think. \\nHow many times have you paused for a cup of coffee and figured out the problem on \\nyour way to the coffee machine? Or in the middle of lunch? Or on the way home? Or \\nin the shower the next morning? If you’re debugging and making no progress, once \\nyou’ve tried all the options, let it rest. Go for a walk. Work on something else. Go \\nhome for the day. Let your subconscious mind tease a solution out of the problem.\\nThe auxiliary benefit of giving up temporarily is that it reduces the anxiety associated \\nwith debugging. The onset of anxiety is a clear sign that it’s time to take a break.\\nBrute-Force Debugging\\nBrute force is an often-overlooked approa ch to debugging software problems. By \\n“brute force,” I’m referring to a technique that might be tedious, arduous, and time-\\nconsuming but that is guaranteed to solve the problem. Which specific techniques \\nare guaranteed to solve a problem are context-dependent, but here are some general \\ncandidates:\\n■ Perform a full design and/or code review on the broken code.\\n■ Throw away the section of code and redesign/recode it from scratch.\\n■ Throw away the whole program and redesign/recode it from scratch.\\n■ Compile code with full debugging information.\\n■ Compile code at pickiest warning level and fix all the picky compiler warnings.\\n■ Strap on a unit test harness and test the new code in isolation.\\n■ Create an automated test suite and run it all night.\\n■ Step through a big loop in the debugger manually until you get to the error \\ncondition.\\n■ Instrument the code with print, display, or other logging statements.\\n■ Compile the code with a different compiler.\\n■ Compile and run the program in a different environment.\\n■ Link or run the code against special libraries or execution environments that \\nproduce warnings when code is used incorrectly.\\n■ Replicate the end-user’s full machine configuration.\\n■ Integrate new code in small pieces, fully testing each piece as it’s integrated.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 585}, page_content='23.2 Finding a Defect 549\\nSet a maximum time for quick and dirty debugging For each brute-force technique, \\nyour reaction might well be, “I can’t do that—it’s too much work!” The point is that it’s \\nonly too much work if it takes more time than what I call “quick and dirty debugging.” \\nIt’s always tempting to try for a quick guess rather than systematically instrumenting \\nthe code and giving the defect no place to hide. The gambler in each of us would \\nrather use a risky approach that might find the defect in five minutes than the sure-fire \\napproach that will find the defect in half an hour. The risk is that if the five-minute \\napproach doesn’t work, you get stubborn. Finding the defect the “easy” way becomes \\na matter of principle, and hours pass unproductively, as do days, weeks, months.... \\nHow often have you spent two hours debugging code that took only 30 minutes to \\nwrite? That’s a bad distribution of labor, and you would have been better off to rewrite \\nthe code than to debug bad code. \\nWhen you decide to go for the quick victory, set a maximum time limit for trying the \\nquick way. If you go past the time limit, resign yourself to the idea that the defect is \\ngoing to be harder to diagnose than you originally thought, and flush it out the hard \\nway. This approach allows you to get the easy defects right away and the hard defects \\nafter a bit longer.\\nMake a list of brute-force techniques Before you begin debugging a difficult error, \\nask yourself, “If I get stuck debugging this problem, is there some way that I am guar-\\nanteed to be able to fix the problem?” If you can identify at least one brute-force tech-\\nnique that will fix the problem—including rewriting the code in question—it’s less \\nlikely that you’ll waste hours or days when there’s a quicker alternative. \\nSyntax Errors\\nSyntax-error problems are going the way of the woolly mammoth and the saber-\\ntoothed tiger. Compilers are getting better at diagnostic messages, and the days when \\nyou had to spend two hours finding a misplaced semicolon in a Pascal listing are \\nalmost gone. Here’s a list of guidelines you can use to hasten the extinction of this \\nendangered species:\\nDon’t trust line numbers in compiler messages When your compiler reports a myste-\\nrious syntax error, look immediately before and immediately after the error—the com-\\npiler could have misunderstood the problem or could simply have poor diagnostics. \\nOnce you find the real defect, try to determine the reason the compiler put the mes-\\nsage on the wrong statement. Understanding your compiler better can help you find \\nfuture defects.\\nDon’t trust compiler messages Compilers try to tell you exactly what’s wrong, but \\ncompilers are dissembling little rascals, and you often have to read between the lines \\nto know what one really means. For example, in UNIX C, you can get a message that \\nsays “floating exception” for an integer divide-by-0. With C++’s Standard Template'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 586}, page_content='550 Chapter 23: Debugging\\nLibrary, you can get a pair of error messages: the first message is the real error in the \\nuse of the STL; the second message is a message from the compiler saying, “Error mes-\\nsage too long for printer to print; message truncated.” You can probably come up with \\nmany examples of your own.\\nDon’t trust the compiler’s second message Some compilers are better than others at \\ndetecting multiple errors. Some compilers get so excited after detecting the first error \\nthat they become giddy and overconfident; they prattle on with dozens of error mes-\\nsages that don’t mean anything. Other compilers are more levelheaded, and although \\nthey must feel a sense of accomplishment when they detect an error, they refrain from \\nspewing out inaccurate messages. When your compiler generates a series of cascading \\nerror messages, don’t worry if you can’t quickly find the source of the second or third \\nerror message. Fix the first one and recompile.\\nDivide and conquer The idea of dividing the program into sections to help detect \\ndefects works especially well for syntax errors. If you have a troublesome syntax error, \\nremove part of the code and compile again. You’ll either get no error (because the \\nerror’s in the part you removed), get the same error (meaning you need to remove a \\ndifferent part), or get a different error (because you’ll have tricked the compiler into \\nproducing a message that makes more sense).\\nCross-Reference The avail-\\nability of syntax-directed \\neditors is one characteristic \\nof early-wave vs. mature-\\nwave programming environ-\\nments. For details, see Sec-\\ntion 4.3, “Your Location on \\nthe Technology Wave.”\\nFind misplaced comments and quotation marks Many programming text editors \\nautomatically format comments, string literals, and other syntactical elements. In \\nmore primitive environments, a misplaced comment or quotation mark can trip up \\nthe compiler. To find the extra comment or quotation mark, insert the following \\nsequence into your code in C, C++, and Java:\\n/*\"/**/\\nThis code phrase will terminate either a comment or string, which is useful in narrow-\\ning the space in which the unterminated comment or string is hiding.\\n23.3 Fixing a Defect\\nThe hard part of debugging is finding the defect. Fixing the defect is the easy part. But as \\nwith many easy tasks, the fact that it\\'s easy makes it especially error-prone. At least one \\nstudy found that defect corrections have more than a 50 percent chance of being wrong \\nthe first time (Yourdon 1986b). Here are a few guidelines for reducing the chance of error:\\nUnderstand the problem before you fix it “The Devil’s Guide to Debugging” is right: \\nthe best way to make your life difficult and corrode the quality of your program is to fix \\nproblems without really understanding them. Before you fix a problem, make sure you \\nunderstand it to the core. Triangulate the defect both with cases that should reproduce \\nthe error and with cases that shouldn’t reproduce the error. Keep at it until you under-\\nstand the problem well enough to predict its occurrence correctly every time.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 587}, page_content='23.3 Fixing a Defect 551\\nUnderstand the program, not just the problem If you understand the context in \\nwhich a problem occurs, you’re more likely to solve the problem completely rather \\nthan only one aspect of it. A study done with short programs found that programmers \\nwho achieve a global understanding of program behavior have a better chance of \\nmodifying it successfully than programmers who focus on local behavior, learning \\nabout the program only as they need to (Littman et al. 1986). Because the program in \\nthis study was small (280 lines), it doesn’t prove that you should try to understand a \\n50,000-line program completely before you fix a defect. It does suggest that you \\nshould understand at least the code in the vicinity of the defect correction—the “vicin-\\nity” being not a few lines but a few hundred.\\nConfirm the defect diagnosis Before you rush to fix a defect, make sure that you’ve \\ndiagnosed the problem correctly. Take the time to run test cases that prove your \\nhypothesis and disprove competing hypotheses. If you’ve proven only that the error \\ncould be the result of one of several causes, you don’t yet have enough evidence to \\nwork on the one cause; rule out the others first.\\nNever debug standing up. \\n—Gerald Weinberg\\nRelax A programmer was ready for a ski trip. His product was ready to ship, he was \\nalready late, and he had only one more defect to correct. He changed the source file \\nand checked it into version control. He didn’t recompile the program and didn’t verify \\nthat the change was correct.\\nIn fact, the change was not correct, and his manager was outraged. How could he \\nchange code in a product that was ready to ship without checking it? What could be \\nworse? Isn’t this the pinnacle of professional recklessness?\\nIf this isn’t the height of recklessness, it’s close and it’s common. Hurrying to solve a \\nproblem is one of the most time-ineffective things you can do. It leads to rushed judg-\\nments, incomplete defect diagnosis, and incomplete corrections. Wishful thinking \\ncan lead you to see solutions where there are none. The pressure—often self-imposed—\\nencourages haphazard trial-and-error solutions and the assumption that a solution \\nworks without verification that it does.\\nIn striking contrast, during the final days of Microsoft Windows 2000 development, a \\ndeveloper needed to fix a defect that was the last remaining defect before a Release \\nCandidate could be created. The developer changed the code, checked his fix, and \\ntested his fix on his local build. But he didn’t check the fix into version control at that \\npoint. Instead, he went to play basketball. He said, “I’m feeling too stressed right now \\nto be sure that I’ve considered everything I should consider. I’m going to clear my \\nmind for an hour, and then I’ll come back and check in the code—once I’ve convinced \\nmyself that the fix is really correct.” \\nRelax long enough to make sure your solution is right. Don’t be tempted to take short-\\ncuts. It might take more time, but it’ll probably take less. If nothing else, you’ll fix the \\nproblem correctly and your manager won’t call you back from your ski trip.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 588}, page_content='552 Chapter 23: Debugging\\nCross-Reference General \\nissues involved in changing \\ncode are discussed in depth \\nin Chapter 24, “Refactoring.”\\nSave the original source code Before you begin fixing the defect, be sure to archive a \\nversion of the code that you can return to later. It’s easy to forget which change in a \\ngroup of changes is the significant one. If you have the original source code, at least \\nyou can compare the old and the new files and see where the changes are. \\nFix the problem, not the symptom You should fix the symptom too, but the focus \\nshould be on fixing the underlying problem rather than wrapping it in programming \\nduct tape. If you don’t thoroughly understand the problem, you’re not fixing the code. \\nYou’re fixing the symptom and making the code worse. Suppose you have this code:\\nJava Example of Code That Needs to Be Fixed\\nfor ( claimNumber = 0; claimNumber < numClaims[ client ]; claimNumber++ ) {\\n   sum[ client ] = sum[ client ] + claimAmount[ claimNumber ];\\n}\\nFurther suppose that when client equals 45, sum turns out to be wrong by $3.45. \\nHere’s the wrong way to fix the problem:\\nJava Example of Making the Code Worse by “Fixing” It\\nfor ( claimNumber = 0; claimNumber < numClaims[ client ]; claimNumber++ ) {\\n   sum[ client ] = sum[ client ] + claimAmount[ claimNumber ];\\n}\\nHere’s the “fix.” \\nif ( client == 45 ) {\\n   sum[ 45 ] = sum[ 45 ] + 3.45;\\n}\\nNow suppose that when client equals 37 and the number of claims for the client is 0, \\nyou’re not getting 0. Here’s the wrong way to fix the problem:\\nJava Example of Making the Code Worse by “Fixing” It (continued)\\nfor ( claimNumber = 0; claimNumber < numClaims[ client ]; claimNumber++ ) {\\n   sum[ client ] = sum[ client ] + claimAmount[ claimNumber ];\\n}\\nif ( client == 45 ) {\\n   sum[ 45 ] = sum[ 45 ] + 3.45;\\n}\\nHere’s the second “fix.” else if ( ( client == 37 ) && ( numClaims[ client ] == 0 ) ) {\\n   sum[ 37 ] = 0.0;\\n}\\nIf this doesn’t send a cold chill down your spine, you won’t be affected by anything \\nelse in this book either. It’s impossible to list all the problems with this approach in a \\nbook that’s only around 1000 pages long, but here are the top three:\\nCODING \\nHORROR\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 589}, page_content='23.3 Fixing a Defect 553\\n■ The fixes won’t work most of the time. The problems look as though they’re the \\nresult of initialization defects. Initialization defects are, by definition, unpredict-\\nable, so the fact that the sum for client 45 is off by $3.45 today doesn’t tell you \\nanything about tomorrow. It could be off by $10,000.02, or it could be correct. \\nThat’s the nature of initialization defects.\\n■ It’s unmaintainable. When code is special-cased to work around errors, the spe-\\ncial cases become the code’s most prominent feature. The $3.45 won’t always be \\n$3.45, and another error will show up later. The code will be modified again to \\nhandle the new special case, and the special case for $3.45 won’t be removed. \\nThe code will become increasingly barnacled with special cases. Eventually the \\nbarnacles will be too heavy for the code to support, and the code will sink to the \\nbottom of the ocean—a fitting place for it.\\n■ It uses the computer for something that’s better done by hand. Computers are \\ngood at predictable, systematic calculations, but humans are better at fudging \\ndata creatively. You’d be wiser to treat the output with whiteout and a typewriter \\nthan to monkey with the code.\\nChange the code only for good reason Related to fixing symptoms is the technique \\nof changing code at random until it seems to work. The typical line of reasoning goes \\nlike this: “This loop seems to contain a defect. It’s probably an off-by-one error, so I’ll \\njust put a -1 here and try it. OK. That didn’t work, so I’ll just put a +1 in instead. OK. \\nThat seems to work. I’ll say it’s fixed.”\\nAs popular as this practice is, it isn’t effective. Making changes to code randomly is like \\nrotating a Pontiac Aztek’s tires to fix an engine problem. You’re not learning anything; \\nyou’re just goofing around. By changing the program randomly, you say in effect, “I \\ndon’t know what’s happening here, but I’ll try this change and hope it works.” Don’t \\nchange code randomly. That’s voodoo programming. The more different you make it \\nwithout understanding it, the less confidence you’ll have that it works correctly.\\nBefore you make a change, be confident that it will work. Being wrong about a change \\nshould leave you astonished. It should cause self-doubt, personal reevaluation, and \\ndeep soul-searching. It should happen rarely.\\nMake one change at a time Changes are tricky enough when they’re done one at a \\ntime. When done two at a time, they can introduce subtle errors that look like the orig-\\ninal errors. Then you’re in the awkward position of not knowing whether you didn’t \\ncorrect the error, whether you corrected the error but introduced a new one that looks \\nsimilar, or whether you didn’t correct the error and you introduced a similar new \\nerror. Keep it simple: make just one change at a time.\\nCross-Reference For details \\non automated regression \\ntesting, see “Retesting \\n(Regression Testing)” in Sec-\\ntion 22.6.\\nCheck your fix Check the program yourself, have someone else check it for you, or \\nwalk through it with someone else. Run the same triangulation test cases you used to \\ndiagnose the problem to make sure that all aspects of the problem have been resolved. \\nIf you’ve solved only part of the problem, you’ll find out that you still have work to do.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 590}, page_content='554 Chapter 23: Debugging\\nRerun the whole program to check for side effects of your changes. The easiest and \\nmost effective way to check for side effects is to run the program through an auto-\\nmated suite of regression tests in JUnit, CppUnit, or equivalent. \\nAdd a unit test that exposes the defect When you encounter an error that wasn’t \\nexposed by your test suite, add a test case to expose the error so that it won’t be rein-\\ntroduced later.  \\nLook for similar defects When you find one defect, look for others that are similar. \\nDefects tend to occur in groups, and one of the values of paying attention to the kinds \\nof defects you make is that you can correct all the defects of that kind. Looking for sim-\\nilar defects requires you to have a thorough understanding of the problem. Watch for \\nthe warning sign: if you can’t figure out how to look for similar defects, that’s a sign \\nthat you don’t yet completely understand the problem.\\n23.4 Psychological Considerations in Debugging\\nFurther Reading For an \\nexcellent discussion of psy-\\nchological issues in debug-\\nging, as well as many other \\nareas of software develop-\\nment, see The Psychology of \\nComputer Programming \\n(Weinberg 1998).\\nDebugging is as intellectually demanding as any other software-development activity. \\nYour ego tells you that your code is good and doesn’t have a defect even when you’ve \\nseen that it has one. You have to think precisely—forming hypotheses, collecting data, \\nanalyzing hypotheses, and methodically rejecting them—with a formality that’s unnat-\\nural to many people. If you’re both building code and debugging it, you have to switch \\nquickly between the fluid, creative thinking that goes with design and the rigidly crit-\\nical thinking that goes with debugging. As you read your code, you have to battle the \\ncode’s familiarity and guard against seeing what you expect to see.\\nHow “Psychological Set” Contributes to Debugging Blindness\\nWhen you see a token in a program that says Num, what do you see? Do you see a mis-\\nspelling of the word “Numb”? Or do you see the abbreviation for “Number”? Most \\nlikely, you see the abbreviation for “Number.” This is the phenomenon of “psycholog-\\nical set”—seeing what you expect to see. What does this sign say?\\nIn this classic puzzle, people often see only one “the.” People see what they expect to \\nsee. Consider the following:\\n■ Students learning while loops often expect a loop to be continuously evaluated; \\nthat is, they expect the loop to terminate as soon as the while condition becomes \\nParis in the \\nthe Spring'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 591}, page_content='23.4 Psychological Considerations in Debugging 555\\nfalse, rather than only at the top or bottom (Curtis et al. 1986). They expect a \\nwhile loop to act as “while” does in natural language.\\n■ A programmer who unintentionally used both the variable SYSTSTS and the \\nvariable SYSSTSTS thought he was using a single variable. He didn’t discover the \\nproblem until the program had been run hundreds of times and a book was \\nwritten containing the erroneous results (Weinberg 1998).\\n■ A programmer looking at code like this code:\\nif ( x < y ) \\n   swap = x;\\n   x = y;\\n   y = swap;\\nsometimes sees code like this code:\\nif ( x < y ) {\\n   swap = x;\\n   x = y;\\n   y = swap;\\n}\\nPeople expect a new phenomenon to resemble similar phenomena they’ve seen \\nbefore. They expect a new control construct to work the same as old constructs; pro-\\ngramming-langauge while statements to work the same as real-life “while” statements; \\nand variable names to be the same as they’ve been before. You see what you expect to \\nsee and thus overlook differences, like the misspelling of the word “language” in the \\nprevious sentence.\\nWhat does psychological set have to do with debugging? First, it speaks to the impor-\\ntance of good programming practices. Good formatting, commenting, variable names, \\nroutine names, and other elements of programming style help structure the program-\\nming background so that likely defects appear as variations and stand out.\\nThe second impact of psychological set is in selecting parts of the program to examine \\nwhen an error is found. Research has shown that the programmers who debug most \\neffectively mentally slice away parts of the program that aren’t relevant during debug-\\nging (Basili, Selby, and Hutchens 1986). In general, the practice allows excellent pro-\\ngrammers to narrow their search fields and find defects more quickly. Sometimes, \\nhowever, the part of the program that contains the defect is mistakenly sliced away. \\nYou spend time scouring a section of code for a defect, and you ignore the section that \\ncontains the defect. You took a wrong turn at the fork in the road and need to back up \\nbefore you can go forward again. Some of the suggestions in Section 23.2’s discussion \\nof tips for finding defects are designed to overcome this “debugging blindness.”\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 592}, page_content='556 Chapter 23: Debugging\\nHow “Psychological Distance” Can Help\\nCross-Reference For details \\non creating variable names \\nthat won’t be confusing, see \\nSection 11.7, “Kinds of \\nNames to Avoid.”\\nPsychological distance can be defined as the ease with which two items can be differ-\\nentiated. If you are looking at a long list of words and have been told that they’re all \\nabout ducks, you could easily mistake “Queck” for “Quack” because the two words \\nlook similar. The psychological distance between the words is small. You would be \\nmuch less likely to mistake “Tuack” for “Quack” even though the difference is only \\none letter again. “Tuack” is less like “Quack” than “Queck” is because the first letter in \\na word is more prominent than the one in the middle.\\nTable 23-1 lists examples of psychological distances between variable names:\\nAs you debug, be ready for the problems caused by insufficient psychological distance \\nbetween similar variable names and between similar routine names. As you construct \\ncode, choose names with large differences so that you avoid the problem.\\n23.5 Debugging Tools—Obvious and Not-So-Obvious \\nCross-Reference The line \\nbetween testing and debug-\\nging tools is fuzzy. See Section \\n22.5 for more on testing tools \\nand Chapter 30 for more on \\nsoftware-development tools. \\nYou can do much of the detailed, brain-busting work of debugging with debugging \\ntools that are readily available. The tool that will drive the final stake through the heart \\nof the defect vampire isn’t yet available, but each year brings an incremental improve-\\nment in available capabilities.\\nSource-Code Comparators\\nA source-code comparator such as Diff is useful when you’re modifying a program in \\nresponse to errors. If you make several changes and need to remove some that you \\ncan’t quite remember, a comparator can pinpoint the differences and jog your mem-\\nory. If you discover a defect in a new version that you don’t remember in an older ver-\\nsion, you can compare the files to determine what changed.\\nTable 23-1 Examples of Psychological Distance Between Variable Names\\nFirst Variable Second Variable Psychological Distance\\nstoppt stcppt Almost invisible\\nshiftrn shiftrm Almost none\\ndcount bcount Small\\nclaims1 claims2 Small\\nproduct sum Large'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 593}, page_content='23.5 Debugging Tools—Obvious and Not-So-Obvious 557\\nCompiler Warning Messages\\nOne of the simplest and most effective debugging tools is your own compiler.\\nSet your compiler’s warning level to the highest, pickiest level possible, and fix the \\nerrors it reports It’s sloppy to ignore compiler errors. It’s even sloppier to turn off \\nthe warnings so that you can’t even see them. Children sometimes think that if they \\nclose their eyes and can’t see you, they’ve made you go away. Setting a switch on the \\ncompiler to turn off warnings just means you can’t see the errors. It doesn’t make \\nthem go away any more than closing your eyes makes an adult go away.\\nAssume that the people who wrote the compiler know a great deal more about your \\nlanguage than you do. If they’re warning you about something, it usually means you \\nhave an opportunity to learn something new about your language. Make the effort to \\nunderstand what the warning really means.\\nTreat warnings as errors Some compilers let you treat warnings as errors. One rea-\\nson to use the feature is that it elevates the apparent importance of a warning. Just as \\nsetting your watch five minutes fast tricks you into thinking it’s five minutes later than \\nit is, setting your compiler to treat warnings as errors tricks you into taking them more \\nseriously. Another reason to treat warnings as errors is that they often affect how your \\nprogram compiles. When you compile and link a program, warnings typically won’t \\nstop the program from linking, but errors typically will. If you want to check warnings \\nbefore you link, set the compiler switch that treats warnings as errors.\\nInitiate projectwide standards for compile-time settings Set a standard that requires \\neveryone on your team to compile code using the same compiler settings. Otherwise, \\nwhen you try to integrate code compiled by different people with different settings, \\nyou’ll get a flood of error messages and an integration nightmare. This is easy to \\nenforce if you use a project-standard make file or build script. \\nExtended Syntax and Logic Checking\\nYou can use additional tools to check your code more thoroughly than your compiler \\ndoes. For example, for C programmers, the lint utility painstakingly checks for use of \\nuninitialized variables (writing = when you mean = =) and similarly subtle problems.\\nExecution Profilers\\nYou might not think of an execution profiler as a debugging tool, but a few minutes \\nspent studying a program profile can uncover some surprising (and hidden) defects.\\nFor example, I had suspected that a memory-management routine in one of my pro-\\ngrams was a performance bottleneck. Memory management had originally been a \\nsmall component using a linearly ordered array of pointers to memory. I replaced the \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 594}, page_content='558 Chapter 23: Debugging\\nlinearly ordered array with a hash table in the expectation that execution time would \\ndrop by at least half. But after profiling the code, I found no change in performance at \\nall. I examined the code more closely and found a defect that was wasting a huge \\namount of time in the allocation algorithm. The bottleneck hadn’t been the linear-\\nsearch technique; it was the defect. I hadn’t needed to optimize the search after all. \\nExamine the output of an execution profiler to satisfy yourself that your program \\nspends a reasonable amount of time in each area.\\nTest Frameworks/Scaffolding\\nCross-Reference For details \\non scaffolding, see “Building \\nScaffolding to Test Individual \\nClasses” in Section 22.5.\\nAs mentioned in Section 23.2 on finding defects, pulling out a troublesome piece of \\ncode, writing code to test it, and executing it by itself is often the most effective way to \\nexorcise the demons from an error-prone program.\\nDebuggers\\nCommercially available debuggers have advanced steadily over the years, and the capa-\\nbilities available today can change the way you program. Good debuggers allow you to \\nset breakpoints to break when execution reaches a specific line, or the nth time it \\nreaches a specific line, or when a global variable changes, or when a variable is assigned \\na specific value. They allow you to step through code line by line, stepping through or \\nover routines. They allow the program to be executed backwards, stepping back to the \\npoint where a defect originated. They allow you to log the execution of specific state-\\nments—similar to scattering “I’m here!” print statements throughout a program.\\nGood debuggers allow full examination of data, including structured and dynamically \\nallocated data. They make it easy to view the contents of a linked list of pointers or a \\ndynamically allocated array. They’re intelligent about user-defined data types. They \\nallow you to make ad hoc queries about data, assign new values, and continue pro-\\ngram execution.\\nYou can look at the high-level language or the assembly language generated by your \\ncompiler. If you’re using several languages, the debugger automatically displays the \\ncorrect language for each section of code. You can look at a chain of calls to routines \\nand quickly view the source code of any routine. You can change parameters to a pro-\\ngram within the debugger environment. \\nThe best of today’s debuggers also remember debugging parameters (breakpoints, \\nvariables being watched, and so on) for each individual program so that you don’t \\nhave to re-create them for each program you debug.\\nSystem debuggers operate at the systems level rather than the applications level so \\nthat they don’t interfere with the execution of the program being debugged. They’re'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 595}, page_content='23.5 Debugging Tools—Obvious and Not-So-Obvious 559\\nessential when you are debugging programs that are sensitive to timing or the amount \\nof memory available.\\nAn interactive debugger is an \\noutstanding example of what \\nis not needed—it encour-\\nages trial-and-error hacking \\nrather than systematic \\ndesign, and also hides mar-\\nginal people barely qualified \\nfor precision programming.\\n—Harlan Mills\\nGiven the enormous power offered by modern debuggers, you might be surprised \\nthat anyone would criticize them. But some of the most respected people in computer \\nscience recommend not using them. They recommend using your brain and avoiding \\ndebugging tools altogether. Their argument is that debugging tools are a crutch and \\nthat you find problems faster and more accurately by thinking about them than by \\nrelying on tools. They argue that you, rather than the debugger, should mentally exe-\\ncute the program to flush out defects.\\nRegardless of the empirical evidence, the basic argument against debuggers isn’t valid. \\nThe fact that a tool can be misused doesn’t imply that it should be rejected. You \\nwouldn’t avoid taking aspirin merely because it’s possible to overdose. You wouldn’t \\navoid mowing your lawn with a power mower just because it’s possible to cut yourself. \\nAny other powerful tool can be used or abused, and so can a debugger.\\nThe debugger isn’t a substitute for good thinking. But, in some cases, thinking isn’t a \\nsubstitute for a good debugger either. The most effective combination is good think-\\ning and a good debugger.\\ncc2e.com/2368 CHECKLISTS: Debugging Reminders\\nTechniques for Finding Defects\\n❑ Use all the data available to make your hypothesis.\\n❑ Refine the test cases that produce the error.\\n❑ Exercise the code in your unit test suite.\\n❑ Use available tools.\\n❑ Reproduce the error several different ways.\\n❑ Generate more data to generate more hypotheses.\\n❑ Use the results of negative tests.\\n❑ Brainstorm for possible hypotheses.\\n❑ Keep a notepad by your desk, and make a list of things to try.\\n❑ Narrow the suspicious region of the code.\\n❑ Be suspicious of classes and routines that have had defects before.\\n❑ Check code that’s changed recently.\\n❑ Expand the suspicious region of the code.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 596}, page_content='560 Chapter 23: Debugging\\n❑ Integrate incrementally.\\n❑ Check for common defects.\\n❑ Talk to someone else about the problem.\\n❑ Take a break from the problem.\\n❑ Set a maximum time for quick and dirty debugging.\\n❑ Make a list of brute-force techniques, and use them.\\nTechniques for Syntax Errors\\n❑ Don’t trust line numbers in compiler messages.\\n❑ Don’t trust compiler messages.\\n❑ Don’t trust the compiler’s second message.\\n❑ Divide and conquer.\\n❑ Use a syntax-directed editor to find misplaced comments and quotation \\nmarks.\\nTechniques for Fixing Defects\\n❑ Understand the problem before you fix it.\\n❑ Understand the program, not just the problem.\\n❑ Confirm the defect diagnosis.\\n❑ Relax.\\n❑ Save the original source code.\\n❑ Fix the problem, not the symptom.\\n❑ Change the code only for good reason.\\n❑ Make one change at a time.\\n❑ Check your fix.\\n❑ Add a unit test that exposes the defect.\\n❑ Look for similar defects.\\nGeneral Approach to Debugging\\n❑ Do you use debugging as an opportunity to learn more about your pro-\\ngram, mistakes, code quality, and problem-solving approach?\\n❑ Do you avoid the trial-and-error, superstitious approach to debugging?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 597}, page_content='Additional Resources 561\\n❑ Do you assume that errors are your fault?\\n❑ Do you use the scientific method to stabilize intermittent errors?\\n❑ Do you use the scientific method to find defects?\\n❑ Rather than using the same approach every time, do you use several differ-\\nent techniques to find defects?\\n❑ Do you verify that the fix is correct?\\n❑ Do you use compiler warning messages, execution profiling, a test frame-\\nwork, scaffolding, and interactive debugging?\\nAdditional Resources\\ncc2e.com/2375 The following resources also address debugging:\\nAgans, David J. Debugging: The Nine Indispensable Rules for Finding Even the Most Elu-\\nsive Software and Hardware Problems. Amacom, 2003. This book provides general \\ndebugging principles that can be applied in any language or environment. \\nMyers, Glenford J. The Art of Software Testing. New York, NY: John Wiley & Sons, 1979. \\nChapter 7 of this classic book is devoted to debugging.\\nAllen, Eric. Bug Patterns In Java. Berkeley, CA: Apress, 2002. This book lays out an \\napproach to debugging Java programs that is conceptually very similar to what is \\ndescribed in this chapter, including “The Scientific Method of Debugging,” distin-\\nguishing between debugging and testing, and identifying common bug patterns. \\nThe following two books are similar in that their titles suggest they are applicable only \\nto Microsoft Windows and .NET programs, but they both contain discussions of \\ndebugging in general, use of assertions, and coding practices that help to avoid bugs \\nin the first place:\\nRobbins, John. Debugging Applications for Microsoft .NET and Microsoft Windows. Red-\\nmond, WA: Microsoft Press, 2003. \\nMcKay, Everett N. and Mike Woodring. Debugging Windows Programs: Strategies, Tools, \\nand Techniques for Visual C++ Programmers. Boston, MA: Addison-Wesley, 2000.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 598}, page_content='562 Chapter 23: Debugging\\nKey Points\\n■ Debugging is a make-or-break aspect of software development. The best \\napproach is to use other techniques described in this book to avoid defects in \\nthe first place. It’s still worth your time to improve your debugging skills, how-\\never, because the difference between good and poor debugging performance is \\nat least 10 to 1.\\n■ A systematic approach to finding and fixing errors is critical to success. Focus \\nyour debugging so that each test moves you a step forward. Use the Scientific \\nMethod of Debugging. \\n■ Understand the root problem before you fix the program. Random guesses \\nabout the sources of errors and random corrections will leave the program in \\nworse condition than when you started.\\n■ Set your compiler warning to the pickiest level possible, and fix the errors it \\nreports. It’s hard to fix subtle errors if you ignore the obvious ones.\\n■ Debugging tools are powerful aids to software development. Find them and use \\nthem, and remember to use your brain at the same time.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 599}, page_content='563\\nChapter 24\\nRefactoring\\ncc2e.com/2436 Contents\\n■ 24.1 Kinds of Software Evolution: page 564\\n■ 24.2 Introduction to Refactoring: page 565\\n■ 24.3 Specific Refactorings: page 571\\n■ 24.4 Refactoring Safely: page 579\\n■ 24.5 Refactoring Strategies: page 582\\nRelated Topics\\n■ Tips for fixing defects: Section 23.3\\n■ Code-tuning approach: Section 25.6\\n■ Design in construction: Chapter 5\\n■ Working classes: Chapter 6\\n■ High-quality routines: Chapter 7\\n■ Collaborative construction: Chapter 21\\n■ Developer testing: Chapter 22\\n■ Areas likely to change: “Identify Areas Likely to Change” in Section 5.3\\nAll successful software gets \\nchanged.\\n—Fred Brooks\\nMyth: a well-managed software project conducts methodical requirements development \\nand defines a stable list of the program’s responsibilities. Design follows requirements, \\nand it is done carefully so that coding can proceed linearly, from start to finish, implying \\nthat most of the code can be written once, tested, and forgotten. According to the myth, \\nthe only time that the code is significantly modified is during the software-maintenance \\nphase, something that happens only after the initial version of a system has been delivered.\\nReality: code evolves substantially during its initial development. Many of the changes \\nseen during initial coding are at least as dramatic as changes seen during mainte-\\nnance. Coding, debugging, and unit testing consume between 30 to 65 percent of the \\neffort on a typical project, depending on the project’s size. (See Chapter 27, “How Pro-\\ngram Size Affects Construction,” for details.) If coding and unit testing were straight-\\nforward processes, they would consume no more than 20–30 percent of the total \\neffort on a project. Even on well-managed projects, however, requirements change by \\nabout one to four percent per month (Jones 2000). Requirements changes invariably \\ncause corresponding code changes—sometimes substantial code changes.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 600}, page_content='564 Chapter 24: Refactoring\\nAnother reality: modern development practices increase the potential for code \\nchanges during construction. In older life cycles, the focus—successful or not—was on \\navoiding code changes. More modern approaches move away from coding predictabil-\\nity. Current approaches are more code-centered, and over the life of a project, you can \\nexpect code to evolve more than ever.\\n24.1 Kinds of Software Evolution\\nSoftware evolution is like biological evolution in that some mutations are beneficial \\nand many mutations are not. Good software evolution produces code whose develop-\\nment mimics the ascent from monkeys to Neanderthals to our current exalted state as \\nsoftware developers. Evolutionary forces sometimes beat on a program the other way, \\nhowever, knocking the program into a deevolutionary spiral.\\nThe key distinction between kinds of software evolution is whether the program’s \\nquality improves or degrades under modification. If you fix errors with logical duct \\ntape and superstition, quality degrades. If you treat modifications as opportunities to \\ntighten up the original design of the program, quality improves. If you see that pro-\\ngram quality is degrading, that’s like that silent canary in a mine shaft I’ve mentioned \\nbefore. It’s a warning that the program is evolving in the wrong direction.\\nA second distinction in the kinds of software evolution is the one between changes \\nmade during construction and those made during maintenance. These two kinds of \\nevolution differ in several ways. Construction changes are usually made by the origi-\\nnal developers, usually before the program has been completely forgotten. The system \\nisn’t yet on line, so the pressure to finish changes is only schedule pressure—it’s not \\n500 angry users wondering why their system is down. For the same reason, changes \\nduring construction can be more freewheeling—the system is in a more dynamic state, \\nand the penalty for making mistakes is low. These circumstances imply a style of soft-\\nware evolution that’s different from what you’d find during software maintenance.\\nPhilosophy of Software Evolution\\nThere is no code so big, \\ntwisted, or complex that \\nmaintenance can’t make it \\nworse.\\n—Gerald Weinberg\\nA common weakness in programmers’ approaches to software evolution is that it goes \\non as an unselfconscious process. If you recognize that evolution during development \\nis an inevitable and important phenomenon and plan for it, you can use it to your \\nadvantage.\\nEvolution is at once hazardous and an opportunity to approach perfection. When you \\nhave to make a change, strive to improve the code so that future changes are easier. \\nYou never know as much when you begin writing a program as you do afterward. \\nWhen you have a chance to revise a program, use what you’ve learned to improve it. \\nMake both your initial code and your changes with further change in mind.\\nKEY POINT\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 601}, page_content='24.2 Introduction to Refactoring 565\\nThe Cardinal Rule of Software Evolution is that evolution should improve the internal \\nquality of the program. The following sections describe how to accomplish this. \\n24.2 Introduction to Refactoring\\nThe key strategy in achieving The Cardinal Rule of Software Evolution is refactoring, \\nwhich Martin Fowler defines as “a change made to the internal structure of the soft-\\nware to make it easier to understand and cheaper to modify without changing its \\nobservable behavior” (Fowler 1999). The word “refactoring” in modern programming \\ngrew out of Larry Constantine’s original use of the word “factoring” in structured pro-\\ngramming, which referred to decomposing a program into its constituent parts as \\nmuch as possible (Yourdon and Constantine 1979). \\nReasons to Refactor\\nSometimes code degenerates under maintenance, and sometimes the code just wasn’t \\nvery good in the first place. In either case, here are some warning signs —sometimes \\ncalled “smells” (Fowler 1999)—that indicate where refactorings are needed: \\nCode is duplicated Duplicated code almost always represents a failure to fully factor \\nthe design in the first place. Duplicate code sets you up to make parallel modifica-\\ntions—whenever you make changes in one place, you have to make parallel changes in \\nanother place. It also violates what Andrew Hunt and Dave Thomas refer to as the \\n“DRY principle”: Don’t Repeat Yourself (2000). I think David Parnas says it best: \\n“Copy and paste is a design error” (McConnell 1998b). \\nA routine is too long In object-oriented programming, routines longer than a screen \\nare rarely needed and usually represent the attempt to force-fit a structured program-\\nming foot into an object-oriented shoe. \\nOne of my clients was assigned the task of breaking up a legacy system’s longest rou-\\ntine, which was more than 12,000 lines long. With effort, he was able to reduce the \\nsize of the largest routine to only about 4,000 lines. \\nOne way to improve a system is to increase its modularity—increase the number of \\nwell-defined, well-named routines that do one thing and do it well. When changes \\nlead you to revisit a section of code, take the opportunity to check the modularity of \\nthe routines in that section. If a routine would be cleaner if part of it were made into a \\nseparate routine, create a separate routine. \\nA loop is too long or too deeply nested Loop innards tend to be good candidates for \\nbeing converted into routines, which helps to better factor the code and to reduce the \\nloop’s complexity. \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 602}, page_content='566 Chapter 24: Refactoring\\nA class has poor cohesion If you find a class that takes ownership for a hodgepodge \\nof unrelated responsibilities, that class should be broken up into multiple classes, \\neach of which has responsibility for a cohesive set of responsibilities. \\nA class interface does not provide a consistent level of abstraction Even classes that \\nbegin life with a cohesive interface can lose their original consistency. Class interfaces \\ntend to morph over time as a result of modifications that are made in the heat of the \\nmoment and that favor expediency to interface integrity. Eventually the class interface \\nbecomes a Frankensteinian maintenance monster that does little to improve the intel-\\nlectual manageability of the program. \\nA parameter list has too many parameters Well-factored programs tend to have \\nmany small, well-defined routines that don’t need large parameter lists. A long param-\\neter list is a warning that the abstraction of the routine interface has not been well \\nthought out. \\nChanges within a class tend to be compartmentalized Sometimes a class has two or \\nmore distinct responsibilities. When that happens you find yourself changing either \\none part of the class or another part of the class—but few changes affect both parts of \\nthe class. That’s a sign that the class should be cleaved into multiple classes along the \\nlines of the separate responsibilities. \\nChanges require parallel modifications to multiple classes I saw one project that had \\na checklist of about 15 classes that had to be modified whenever a new kind of output \\nwas added. When you find yourself routinely making changes to the same set of \\nclasses, that suggests the code in those classes could be rearranged so that changes \\naffect only one class. In my experience, this is a hard ideal to accomplish, but it’s none-\\ntheless a good goal. \\nInheritance hierarchies have to be modified in parallel Finding yourself making a \\nsubclass of one class every time you make a subclass of another class is a special kind \\nof parallel modification and should be addressed. \\ncase statements have to be modified in parallel Although case statements are not \\ninherently bad, if you find yourself making parallel modifications to similar case state-\\nments in multiple parts of the program, you should ask whether inheritance might be \\na better approach. \\nRelated data items that are used together are not organized into classes If you find \\nyourself repeatedly manipulating the same set of data items, you should ask whether \\nthose manipulations should be combined into a class of their own. \\nA routine uses more features of another class than of its own class This suggests that \\nthe routine should be moved into the other class and then invoked by its old class.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 603}, page_content='24.2 Introduction to Refactoring 567\\nA primitive data type is overloaded Primitive data types can be used to represent an \\ninfinite number of real-world entities. If your program uses a primitive data type like \\nan integer to represent a common entity such as money, consider creating a simple \\nMoney class so that the compiler can perform type checking on Money variables, so \\nthat you can add safety checks on the values assigned to money, and so on. If both \\nMoney and Temperature are integers, the compiler won’t warn you about erroneous \\nassignments like bankBalance = recordLowTemperature. \\nA class doesn’t do very much Sometimes the result of refactoring code is that an old \\nclass doesn’t have much to do. If a class doesn’t seem to be carrying its weight, ask if \\nyou should assign all of that class’s responsibilities to other classes and eliminate the \\nclass altogether. \\nA chain of routines passes tramp data Finding yourself passing data to one routine \\njust so that routine can pass it to another routine is called “tramp data” (Page-Jones \\n1988). This might be OK, but ask yourself whether passing the specific data in ques-\\ntion is consistent with the abstraction presented by each of the routine interfaces. If \\nthe abstraction for each routine is OK, passing the data is OK. If not, find some way to \\nmake each routine’s interface more consistent. \\nA middleman object isn’t doing anything If you find that most of the code in a class \\nis just passing off calls to routines in other classes, consider whether you should elim-\\ninate the middleman and call those other classes directly. \\nOne class is overly intimate with anotherEncapsulation (information hiding) is \\nprobably the strongest tool you have to make your program intellectually manageable \\nand to minimize ripple effects of code changes. Anytime you see one class that knows \\nmore about another class than it should—including derived classes knowing too much \\nabout their parents—err on the side of stronger encapsulation rather than weaker. \\nA routine has a poor name If a routine has a poor name, change the name of the \\nroutine where it’s defined, change the name in all places it’s called, and then recom-\\npile. As hard as it might be to do this now, it will be even harder later, so do it as soon \\nas you notice it’s a problem. \\nData members are public Public data members are, in my view, always a bad idea. \\nThey blur the line between interface and implementation, and they inherently violate \\nencapsulation and limit future flexibility. Strongly consider hiding public data mem-\\nbers behind access routines. \\nA subclass uses only a small percentage of its parents’ routinesTypically this indi-\\ncates that that subclass has been created because a parent class happened to contain \\nthe routines it needed, not because the subclass is logically a descendent of the super-\\nclass. Consider achieving better encapsulation by switching the subclass’s relation-\\nship to its superclass from an is-a relationship to a has-a relationship; convert the'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 604}, page_content='568 Chapter 24: Refactoring\\nsuperclass to member data of the former subclass, and expose only the routines in the \\nformer subclass that are really needed. \\nComments are used to explain difficult code Comments have an important role to \\nplay, but they should not be used as a crutch to explain bad code. The age-old wisdom \\nis dead-on: “Don’t document bad code—rewrite it” (Kernighan and Plauger 1978).\\nCross-Reference For guide-\\nlines on the use of global \\nvariables, see Section 13.3, \\n“Global Data.” For an expla-\\nnation of the differences \\nbetween global data and \\nclass data, see “Class data \\nmistaken for global data” in \\nSection 5.3.\\nGlobal variables are used When you revisit a section of code that uses global vari-\\nables, take time to reexamine them. You might have thought of a way to avoid using \\nglobal variables since the last time you visited that part of the code. Because you’re \\nless familiar with the code than when you first wrote it, you might now find the global \\nvariables sufficiently confusing that you’re willing to develop a cleaner approach. You \\nmight also have a better sense of how to isolate global variables in access routines and \\na keener sense of the pain caused by not doing so. Bite the bullet and make the bene-\\nficial modifications. The initial coding will be far enough in the past that you can be \\nobjective about your work yet close enough that you will remember most of what you \\nneed to make the revisions correctly. The time during early revisions is the perfect \\ntime to improve the code.\\nA routine uses setup code before a routine call or takedown code after a routine call \\nCode like this should be a warning to you:\\nBad C+ + Example of Setup and Takedown Code for a Routine Call\\nThis setup code is a \\nwarning.\\nWithdrawalTransaction withdrawal;\\nwithdrawal.SetCustomerId( customerId );\\nwithdrawal.SetBalance( balance );\\nwithdrawal.SetWithdrawalAmount( withdrawalAmount );\\nwithdrawal.SetWithdrawalDate( withdrawalDate );\\nProcessWithdrawal( withdrawal );\\nThis takedown code is \\nanother warning.\\ncustomerId = withdrawal.GetCustomerId();\\nbalance = withdrawal.GetBalance();\\nwithdrawalAmount = withdrawal.GetWithdrawalAmount();\\nwithdrawalDate = withdrawal.GetWithdrawalDate();\\nA similar warning sign is when you find yourself creating a special constructor for the \\nWithdrawalTransaction class that takes a subset of its normal initialization data so that \\nyou can write code like this:\\nBad C+ + Example of Setup and Takedown Code for a Method Call\\nwithdrawal = new WithdrawalTransaction( customerId, balance, \\n   withdrawalAmount, withdrawalDate );\\nwithdrawal.ProcessWithdrawal();\\ndelete withdrawal;'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 605}, page_content='24.2 Introduction to Refactoring 569\\nAnytime you see code that sets up for a call to a routine or takes down after a call to a \\nroutine, ask whether the routine interface is presenting the right abstraction. In this \\ncase, perhaps the parameter list of ProcessWithdrawal should be modified to support \\ncode like this:\\nGood C+ + Example of a Routine That Doesn’t Require Setup or Takedown Code\\nProcessWithdrawal( customerId, balance, withdrawalAmount, withdrawalDate );\\nNote that the converse of this example presents a similar problem. If you find yourself \\nusually having a WithdrawalTransaction object in hand but needing to pass several of \\nits values to a routine like the one shown here, you should also consider refactoring \\nthe ProcessWithdrawal interface so that it requires the WithdrawalTransaction object \\nrather than its individual fields:\\nC+ + Example of Code That Requires Several Method Calls\\nProcessWithdrawal( withdrawal.GetCustomerId(), withdrawal.GetBalance(), \\n   withdrawal.GetWithdrawalAmount(), withdrawal.GetWithdrawalDate() );\\nAny of these approaches can be right, and any can be wrong—it depends on whether \\nthe ProcessWithdrawal() interface’s abstraction is that it expects to have four distinct \\npieces of data or expects to have a WithdrawalTransaction object. \\nA program contains code that seems like it might be needed someday Programmers \\nare notoriously bad at guessing what functionality might be needed someday. \\n“Designing ahead” is subject to numerous predictable problems:\\n■ Requirements for the “design ahead” code haven’t been fully developed, which \\nmeans the programmer will likely guess wrong about those future require-\\nments. The “code ahead” work will ultimately be thrown away. \\n■ If the programmer’s guess about the future requirement is pretty close, the pro-\\ngrammer still will not generally anticipate all the intricacies of the future require-\\nment. These intricacies undermine the programmer’s basic design assumptions, \\nwhich means the “design ahead” work will have to be thrown away. \\n■ Future programmers who use the “design ahead” code don’t know that it was \\n“design ahead” code, or they assume the code works better than it does. They \\nassume that the code has been coded, tested, and reviewed to the same level as \\nthe other code. They waste a lot of time building code that uses the “design \\nahead” code, only to discover ultimately that the “design ahead” code doesn’t \\nactually work. \\n■ The additional “design ahead” code creates additional complexity, which calls \\nfor additional testing, additional defect correction, and so on. The overall effect \\nis to slow down the project.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 606}, page_content='570 Chapter 24: Refactoring\\nExperts agree that the best way to prepare for future requirements is not to write spec-\\nulative code; it’s to make the currently required code as clear and straightforward as \\npossible so that future programmers will know what it does and does not do and will \\nmake their changes accordingly (Fowler 1999, Beck 2000). \\ncc2e.com/2443 CHECKLIST: Reasons to Refactor\\n❑ Code is duplicated.\\n❑ A routine is too long.\\n❑ A loop is too long or too deeply nested. \\n❑ A class has poor cohesion.\\n❑ A class interface does not provide a consistent level of abstraction. \\n❑ A parameter list has too many parameters. \\n❑ Changes within a class tend to be compartmentalized.\\n❑ Changes require parallel modifications to multiple classes.\\n❑ Inheritance hierarchies have to be modified in parallel. \\n❑ case statements have to be modified in parallel. \\n❑ Related data items that are used together are not organized into classes.\\n❑ A routine uses more features of another class than of its own class.\\n❑ A primitive data type is overloaded.\\n❑ A class doesn’t do very much.\\n❑ A chain of routines passes tramp data.\\n❑ A middleman object isn’t doing anything.\\n❑ One class is overly intimate with another.\\n❑ A routine has a poor name. \\n❑ Data members are public. \\n❑ A subclass uses only a small percentage of its parents’ routines.\\n❑ Comments are used to explain difficult code. \\n❑ Global variables are used.\\n❑ A routine uses setup code before a routine call or takedown code after a \\nroutine call.\\n❑ A program contains code that seems like it might be needed someday.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 607}, page_content='24.3 Specific Refactorings 571\\nReasons Not to Refactor\\nIn common parlance, “refactoring” is used loosely to refer to fixing defects, adding \\nfunctionality, modifying the design—essentially as a synonym for making any change to \\nthe code whatsoever. This common dilution of the term’s meaning is unfortunate. \\nChange in itself is not a virtue, but purposeful change, applied with a teaspoonful of dis-\\ncipline, can be the key strategy that supports steady improvement in a program’s quality \\nunder maintenance and prevents the all-too-familiar software-entropy death spiral.\\n24.3 Specific Refactorings\\nIn this section, I present a catalog of refactorings, many of which I describe by summa-\\nrizing the more detailed descriptions presented in Refactoring (Fowler 1999). I have \\nnot, however, attempted to make this catalog exhaustive. In a sense, every case in this \\nbook that shows a “bad code” example and a “good code” example is a candidate for \\nbecoming a refactoring. In the interest of space, I’ve focused on the refactorings I per-\\nsonally have found most useful. \\nData-Level Refactorings\\nHere are refactorings that improve the use of variables and other kinds of data.\\nReplace a magic number with a named constant If you’re using a numeric or string \\nliteral like 3.14, replace that literal with a named constant like PI. \\nRename a variable with a clearer or more informative name If a variable’s name \\nisn’t clear, change it to a better name. The same advice applies to renaming constants, \\nclasses, and routines, of course. \\nMove an expression inline Replace an intermediate variable that was assigned the \\nresult of an expression with the expression itself. \\nReplace an expression with a routine Replace an expression with a routine (usually \\nso that the expression isn’t duplicated in the code). \\nIntroduce an intermediate variable Assign an expression to an intermediate vari-\\nable whose name summarizes the purpose of the expression. \\nConvert a multiuse variable to multiple single-use variables If a variable is used for \\nmore than one purpose—common culprits are i, j, temp, and x—create separate vari-\\nables for each usage, each of which has a more specific name. \\nUse a local variable for local purposes rather than a parameter If an input-only \\nroutine parameter is being used as a local variable, create a local variable and use that \\ninstead.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 608}, page_content='572 Chapter 24: Refactoring\\nConvert a data primitive to a class If a data primitive needs additional behavior \\n(including stricter type checking) or additional data, convert the data to an object and \\nadd the behavior you need. This can apply to simple numeric types like Money and Tem-\\nperature. It can also apply to enumerated types like Color, Shape, Country, or OutputType.\\nConvert a set of type codes to a class or an enumeration In older programs, it’s com-\\nmon to see associations like\\nconst int SCREEN = 0;\\nconst int PRINTER = 1;\\nconst int FILE = 2;\\nRather than defining standalone constants, create a class so that you can receive the \\nbenefits of stricter type checking and set yourself up to provide richer semantics for \\nOutputType if you ever need to. Creating an enumeration is sometimes a good alterna-\\ntive to creating a class. \\nConvert a set of type codes to a class with subclasses If the different elements asso-\\nciated with different types might have different behavior, consider creating a base class \\nfor the type with subclasses for each type code. For the OutputType base class, you \\nmight create subclasses like Screen, Printer, and File. \\nChange an array to an object If you’re using an array in which different elements are \\ndifferent types, create an object that has a field for each former element of the array.\\nEncapsulate a collection If a class returns a collection, having multiple instances of \\nthe collection floating around can create synchronization difficulties. Consider having \\nthe class return a read-only collection, and provide routines to add and remove ele-\\nments from the collection. \\nReplace a traditional record with a data class Create a class that contains the mem-\\nbers of the record. Creating a class allows you to centralize error checking, persis-\\ntence, and other operations that concern the record. \\nStatement-Level Refactorings\\nHere are refactorings that improve the use of individual statements.\\nDecompose a boolean expression Simplify a boolean expression by introducing well-\\nnamed intermediate variables that help document the meaning of the expression. \\nMove a complex boolean expression into a well-named boolean function If the \\nexpression is complicated enough, this refactoring can improve readability. If the \\nexpression is used more than once, it eliminates the need for parallel modifications \\nand reduces the chance of error in using the expression.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 609}, page_content='24.3 Specific Refactorings 573\\nConsolidate fragments that are duplicated within different parts of a conditional If \\nyou have the same lines of code repeated at the end of an else block that you have at \\nthe end of the if block, move those lines of code so that they occur after the entire if-\\nthen-else block. \\nUse break or return instead of a loop control variable If you have a variable within a \\nloop like done that’s used to control the loop, use break or return to exit the loop instead.\\nReturn as soon as you know the answer instead of assigning a return value within \\nnested if-then-else statements Code is often easiest to read and least error-prone if \\nyou exit a routine as soon as you know the return value. The alternative of setting a \\nreturn value and then unwinding your way through a lot of logic can be harder to follow. \\nReplace conditionals (especially repeated case statements) with polymorphism\\nMuch of the logic that used to be contained in case statements in structured programs \\ncan instead be baked into the inheritance hierarchy and accomplished through poly-\\nmorphic routine calls.\\nCreate and use null objects instead of testing for null values Sometimes a null object \\nwill have generic behavior or data associated with it, such as referring to a resident \\nwhose name is not known as “occupant.” In this case, consider moving the responsi-\\nbility for handling null values out of the client code and into the class—that is, have the \\nCustomer class define the unknown resident as “occupant” instead of having Cus-\\ntomer’s client code repeatedly test for whether the customer’s name is known and sub-\\nstitute “occupant” if not. \\nRoutine-Level Refactorings\\nHere are refactorings that improve code at the individual-routine level.\\nExtract routine/extract method Remove inline code from one routine, and turn it into \\nits own routine.\\nMove a routine’s code inlineTake code from a routine whose body is simple and \\nself-explanatory, and move that routine’s code inline where it is used. \\nConvert a long routine to a class If a routine is too long, sometimes turning it into a \\nclass and then further factoring the former routine into multiple routines will improve \\nreadability. \\nSubstitute a simple algorithm for a complex algorithm Replace a complicated algo-\\nrithm with a simpler algorithm. \\nAdd a parameter If a routine needs more information from its caller, add a parame-\\nter so that that information can be provided. \\nRemove a parameter If a routine no longer uses a parameter, remove it.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 610}, page_content='574 Chapter 24: Refactoring\\nSeparate query operations from modification operations Normally, query opera-\\ntions don’t change an object’s state. If an operation like GetTotals() changes an object’s \\nstate, separate the query functionality from the state-changing functionality and pro-\\nvide two separate routines. \\nCombine similar routines by parameterizing them Two similar routines might differ \\nonly with respect to a constant value that’s used within the routine. Combine the rou-\\ntines into one routine, and pass in the value to be used as a parameter. \\nSeparate routines whose behavior depends on parameters passed in If a routine exe-\\ncutes different code depending on the value of an input parameter, consider breaking \\nthe routine into separate routines that can be called separately, without passing in that \\nparticular input parameter. \\nPass a whole object rather than specific fields If you find yourself passing several \\nvalues from the same object into a routine, consider changing the routine’s interface \\nso that it takes the whole object instead. \\nPass specific fields rather than a whole object If you find yourself creating an object \\njust so that you can pass it to a routine, consider modifying the routine so that it takes \\nspecific fields rather than a whole object. \\nEncapsulate downcasting If a routine returns an object, it normally should return \\nthe most specific type of object it knows about. This is particularly applicable to rou-\\ntines that return iterators, collections, elements of collections, and so on. \\nClass Implementation Refactorings\\nHere are refactorings that improve at the class level.\\nChange value objects to reference objects If you find yourself creating and maintain-\\ning numerous copies of large or complex objects, change your usage of those objects \\nso that only one master copy exists (the value object) and the rest of the code uses ref-\\nerences to that object (reference objects). \\nChange reference objects to value objects If you find yourself performing a lot of ref-\\nerence housekeeping for small or simple objects, change your usage of those objects \\nso that all objects are value objects. \\nReplace virtual routines with data initialization If you have a set of subclasses that \\nvary only according to constant values they return, rather than overriding member \\nroutines in the derived classes, have the derived classes initialize the class with appro-\\npriate constant values, and then have generic code in the base class that works with \\nthose values.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 611}, page_content='24.3 Specific Refactorings 575\\nChange member routine or data placement Consider making several general \\nchanges in an inheritance hierarchy. These changes are normally performed to elimi-\\nnate duplication in derived classes:\\n■ Pull a routine up into its superclass. \\n■ Pull a field up into its superclass.\\n■ Pull a constructor body up into its superclass.\\nSeveral other changes are normally made to support specialization in derived \\nclasses:\\n■ Push a routine down into its derived classes.\\n■ Push a field down into its derived classes.\\n■ Push a constructor body down into its derived classes.\\nExtract specialized code into a subclass If a class has code that’s used by only a sub-\\nset of its instances, move that specialized code into its own subclass. \\nCombine similar code into a superclass If two subclasses have similar code, com-\\nbine that code and move it into the superclass. \\nClass Interface Refactorings\\nHere are refactorings that make for better class interfaces.\\nMove a routine to another class Create a new routine in the target class, and move \\nthe body of the routine from the source class into the target class. You can then call \\nthe new routine from the old routine. \\nConvert one class to two If a class has two or more distinct areas of responsibility, \\nbreak the class into multiple classes, each of which has a clearly defined responsibility. \\nEliminate a class If a class isn’t doing much, move its code into other classes that \\nare more cohesive and eliminate the class. \\nHide a delegateSometimes Class A calls Class B and Class C, when really Class A \\nshould call only Class B and Class B should  call Class C. Ask yourself what the right \\nabstraction is for A’s interaction with B. If B should be responsible for calling C, have \\nB call C.\\nRemove a middleman If Class A calls Class B and Class B calls Class C, sometimes it \\nworks better to have Class A call Class C directly. The question of whether you should \\ndelegate to Class B depends on what will best maintain the integrity of Class B’s interface.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 612}, page_content='576 Chapter 24: Refactoring\\nReplace inheritance with delegation If a class needs to use another class but wants \\nmore control over its interface, make the superclass a field of the former subclass and \\nthen expose a set of routines that will provide a cohesive abstraction. \\nReplace delegation with inheritance If a class exposes every public routine of a dele-\\ngate class (member class), inherit from the delegate class instead of just using the class.\\nIntroduce a foreign routine If a class needs an additional routine and you can’t mod-\\nify the class to provide it, you can create a new routine within the client class that pro-\\nvides that functionality. \\nIntroduce an extension class If a class needs several additional routines and you \\ncan’t modify the class, you can create a new class that combines the unmodifiable \\nclass’s functionality with the additional functionality. You can do that either by sub-\\nclassing the original class and adding new routines or by wrapping the class and \\nexposing the routines you need. \\nEncapsulate an exposed member variable If member data is public, change the \\nmember data to private and expose the member data’s value through a routine instead.\\nRemove Set() routines for fields that cannot be changed If a field is supposed to be \\nset at object creation time and not changed afterward, initialize that field in the \\nobject’s constructor rather than providing a misleading Set() routine. \\nHide routines that are not intended to be used outside the class If the class interface \\nwould be more coherent without a routine, hide the routine. \\nEncapsulate unused routines If you find yourself routinely using only a portion of a \\nclass’s interface, create a new interface to the class that exposes only those necessary \\nroutines. Be sure that the new interface provides a coherent abstraction. \\nCollapse a superclass and subclass if their implementations are very similar If the \\nsubclass doesn’t provide much specialization, combine it into its superclass. \\nSystem-Level Refactorings\\nHere are refactorings that improve code at the whole-system level.\\nCreate a definitive reference source for data you can’t control Sometimes you have \\ndata maintained by the system that you can’t conveniently or consistently access from \\nother objects that need to know about that data. A common example is data main-\\ntained in a GUI control. In such a case, you can create a class that mirrors the data in \\nthe GUI control, and then have both the GUI control and the other code treat that \\nclass as the definitive source of that data.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 613}, page_content='24.3 Specific Refactorings 577\\nChange unidirectional class association to bidirectional class association If you \\nhave two classes that need to use each other’s features but only one class can know \\nabout the other class, change the classes so that they both know about each other. \\nChange bidirectional class association to unidirectional class association If you have \\ntwo classes that know about each other’s features but only one class that really needs \\nto know about the other, change the classes so that one knows about the other but not \\nvice versa.\\nProvide a factory method rather than a simple constructor Use a factory method \\n(routine) when you need to create objects based on a type code or when you want to \\nwork with reference objects rather than value objects. \\nReplace error codes with exceptions or vice versa Depending on your error-han-\\ndling strategy, make sure the code is using the standard approach. \\ncc2e.com/2450 CHECKLIST: Summary of Refactorings\\nData-Level Refactorings\\n❑ Replace a magic number with a named constant. \\n❑ Rename a variable with a clearer or more informative name. \\n❑ Move an expression inline. \\n❑ Replace an expression with a routine. \\n❑ Introduce an intermediate variable. \\n❑ Convert a multiuse variable to a multiple single-use variables. \\n❑ Use a local variable for local purposes rather than a parameter. \\n❑ Convert a data primitive to a class. \\n❑ Convert a set of type codes to a class or an enumeration. \\n❑ Convert a set of type codes to a class with subclasses. \\n❑ Change an array to an object. \\n❑ Encapsulate a collection. \\n❑ Replace a traditional record with a  data class. \\nStatement-Level Refactorings\\n❑ Decompose a boolean expression. \\n❑ Move a complex boolean expression into a well-named boolean function.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 614}, page_content='578 Chapter 24: Refactoring\\n❑ Consolidate fragments that are duplicated within different parts of a \\nconditional.\\n❑ Use break or return instead of a loop control variable.\\n❑ Return as soon as you know the answer instead of assigning a return value \\nwithin nested if-then-else statements.\\n❑ Replace conditionals (especially repeated case statements) with polymor-\\nphism. \\n❑ Create and use null objects instead of testing for null values. \\nRoutine-Level Refactorings\\n❑ Extract a routine. \\n❑ Move a routine’s code inline.\\n❑ Convert a long routine to a class. \\n❑ Substitute a simple algorithm for a complex algorithm. \\n❑ Add a parameter. \\n❑ Remove a parameter. \\n❑ Separate query operations from modification operations. \\n❑ Combine similar routines by parameterizing them. \\n❑ Separate routines whose behavior depends on parameters passed in. \\n❑ Pass a whole object rather than specific fields. \\n❑ Pass specific fields rather than a whole object. \\n❑ Encapsulate downcasting. \\nClass Implementation Refactorings\\n❑ Change value objects to reference objects. \\n❑ Change reference objects to value objects. \\n❑ Replace virtual routines with data initialization. \\n❑ Change member routine or data placement. \\n❑ Extract specialized code into a subclass. \\n❑ Combine similar code into a superclass.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 615}, page_content='24.4 Refactoring Safely 579\\nClass Interface Refactorings\\n❑ Move a routine to another class. \\n❑ Convert one class to two. \\n❑ Eliminate a class. \\n❑ Hide a delegate.\\n❑ Remove a middleman.\\n❑ Replace inheritance with delegation.\\n❑ Replace delegation with inheritance.\\n❑ Introduce a foreign routine. \\n❑ Introduce an extension class.\\n❑ Encapsulate an exposed member variable.\\n❑ Remove Set() routines for fields that cannot be changed. \\n❑ Hide routines that are not intended to be used outside the class. \\n❑ Encapsulate unused routines.\\n❑ Collapse a superclass and subclass if their implementations are very \\nsimilar. \\nSystem-Level Refactorings\\n❑ Create a definitive reference source for data you can’t control. \\n❑ Change unidirectional class association to bidirectional class association. \\n❑ Change bidirectional class association to unidirectional class association.\\n❑ Provide a factory routine rather than a simple constructor. \\n❑ Replace error codes with exceptions or vice versa. \\n24.4 Refactoring Safely\\nOpening up a working sys-\\ntem is more like opening up \\na human brain and replacing \\na nerve than opening up a \\nsink and replacing a washer. \\nWould maintenance be eas-\\nier if it was called “Software \\nBrain Surgery?” \\n—Gerald Weinberg\\nRefactoring is a powerful technique for improving code quality. Like all powerful \\ntools, refactoring can cause more harm than good if misused. A few simple guidelines \\ncan prevent refactoring missteps. \\nSave the code you start with Before you begin refactoring, make sure you can get \\nback to the code you started with. Save a version in your revision control system, or \\ncopy the correct files to a backup directory.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 616}, page_content='580 Chapter 24: Refactoring\\nKeep refactorings small Some refactorings are larger than others, and exactly what \\nconstitutes “one refactoring” can be a little fuzzy. Keep the refactorings small so that you \\nfully understand all the impacts of the changes you make. The detailed refactorings \\ndescribed in Refactoring (Fowler 1999) provide many good examples of how to do this.\\nDo refactorings one at a time Some refactorings are more complicated than others. \\nFor all but the simplest refactorings, do the refactorings one at a time, recompiling and \\nretesting after a refactoring before doing the next one. \\nMake a list of steps you intend to take A natural extension of the Pseudocode Pro-\\ngramming Process is to make a list of the refactorings that will get you from Point A to \\nPoint B. Making a list helps you keep each change in context. \\nMake a parking lot When you’re midway through one refactoring, you’ll some-\\ntimes find that you need another refactoring. Midway through that refactoring, you \\nfind a third refactoring that would be beneficial. For changes that aren’t needed imme-\\ndiately, make a “parking lot,” a list of the changes that you’d like to make at some point \\nbut that don’t need to be made right now. \\nMake frequent checkpoints It’s easy to find the code suddenly going sideways while \\nyou’re refactoring. In addition to saving the code you started with, save checkpoints at \\nvarious steps in a refactoring session so that you can get back to a working program if \\nyou code yourself into a dead end. \\nUse your compiler warnings It’s easy to make small errors that slip past the com-\\npiler. Setting your compiler to the pickiest warning level possible will help catch many \\nerrors almost as soon as you type them. \\nRetestReviews of changed code should be complemented by retests. Of course, this \\nis dependent on having a good set of test cases in the first place. Regression testing \\nand other test topics are described in more detail in Chapter 22, “Developer Testing.” \\nAdd test cases In addition to retesting with your old tests, add new unit tests to \\nexercise the new code. Remove any test cases that have been made obsolete by the \\nrefactorings. \\nCross-Reference For details \\non reviews, see Chapter 21, \\n“Collaborative Construction.”\\nReview the changes If reviews are important the first time through, they are even \\nmore important during subsequent modifications. Ed Yourdon reports that program-\\nmers typically have more than a 50 percent chance of making an error on their first \\nattempt to make a change (Yourdon 1986b). Interestingly, if programmers work with \\na substantial portion of the code, rather than  just a few lines, the chance of making a'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 617}, page_content='24.4 Refactoring Safely 581\\ncorrect modification improves, as shown in Figure 24-1. Specifically, as the number of \\nlines changed increases from one to five lines, the chance of making a bad change \\nincreases. After that, the chance of making a bad change decreases.\\nFigure 24-1 Small changes tend to be more error-prone than larger changes \\n(Weinberg 1983).\\nProgrammers treat small changes casually. They don’t desk-check them, they don’t \\nhave others review them, and they sometimes don’t even run the code to verify that \\nthe fix works properly.\\nThe moral is simple: treat simple changes as if they were complicated. One organiza-\\ntion that introduced reviews for one-line changes found that its error rate went from \\n55 percent before reviews to 2 percent afterward (Freedman and Weinberg 1982). A \\ntelecommunications organization went from 86 percent correct before reviewing code \\nchanges to 99.6 percent afterward (Perrott 2004). \\nAdjust your approach depending on the risk level of the refactoring Some refactor-\\nings are riskier than others. A refactoring like “Replace a magic number with a named \\nconstant” is relatively risk-free. Refactorings that involve class or routine interface \\nchanges, database schema changes, or changes to boolean tests, among others, tend to \\nbe more risky. For easier refactorings, you might streamline your refactoring process \\nto do more than one refactoring at a time and to simply retest, without going through \\nan official review.\\nFor riskier refactorings, err on the side of caution. Do the refactorings one at a time. \\nHave someone else review the refactoring or use pair programming for that refactor-\\ning, in addition to the normal compiler checking and unit tests. \\nChance\\nof Error\\n0 51 0 1 5 2 0\\n0%\\n100%\\nLines Changed\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 618}, page_content='582 Chapter 24: Refactoring\\nBad Times to Refactor\\nRefactoring is a powerful technique, but it isn’t a panacea and it’s subject to a few spe-\\ncific kinds of abuse. \\nDo not partially write a fea-\\nture with the intent of refac-\\ntoring to get it complete \\nlater.\\n—John Manzo\\nDon’t use refactoring as a cover for code and fix The worst problem with refactor-\\ning is how it’s misused. Programmers will sometimes say they’re refactoring, when \\nall they’re really doing is tweaking the code, hoping to find a way to make it work. \\nRefactoring refers to changes in working code that do not affect the program’s behavior. \\nProgrammers who are tweaking broken code aren’t refactoring; they’re hacking. \\nA big refactoring is a recipe \\nfor disaster.\\n—Kent Beck\\nAvoid refactoring instead of rewriting Sometimes code doesn’t need small \\nchanges—it needs to be tossed out so that you can start over. If you find yourself in a \\nmajor refactoring session, ask yourself whether instead you should be redesigning \\nand reimplementing that section of code from the ground up. \\n24.5 Refactoring Strategies\\nThe number of refactorings that would be beneficial to any specific program is essen-\\ntially infinite. Refactoring is subject to the same law of diminishing returns as other \\nprogramming activities, and the 80/20 rule applies. Spend your time on the 20 per-\\ncent of the refactorings that provide 80 percent of the benefit. Consider the following \\nguidelines when deciding which refactorings are most important: \\nRefactor when you add a routine When you add a routine, check whether related \\nroutines are well organized. If not, refactor them. \\nRefactor when you add a class Adding a class often brings issues with existing code \\nto the fore. Use this time as an opportunity to refactor other classes that are closely \\nrelated to the class you’re adding. \\nRefactor when you fix a defect Use the understanding you gain from fixing a bug to \\nimprove other code that might be prone to similar defects. \\nCross-Reference For more \\non error-prone code, see \\n\"Which Classes Contain the \\nMost Errors?\" in Section 22.4.\\nTarget error-prone modules Some modules are more error-prone and brittle than \\nothers. Is there a section of code that you and everyone else on your team is afraid of? \\nThat’s probably an error-prone module. Although most people’s natural tendency is \\nto avoid these  challenging sections of code, targeting these sections for refactoring \\ncan be one of the more effective strategies (Jones 2000).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 619}, page_content='24.5 Refactoring Strategies 583\\nTarget high-complexity modules Another approach is to focus on modules that have \\nthe highest complexity ratings. (See “How to Measure Complexity” in Section 19.6 for \\ndetails on these metrics.) One classic study found that program quality improved dra-\\nmatically when maintenance programmers focused their improvement efforts on the \\nmodules that had the highest complexity (Henry and Kafura 1984). \\nIn a maintenance environment, improve the parts you touch Code that is never \\nmodified doesn’t need to be refactored. But when you do touch a section of code, be \\nsure you leave it better than you found it. \\nDefine an interface between clean code and ugly code, and then move code across the \\ninterface The “real world” is often messier than you’d like. The messiness might \\ncome from complicated business rules, hardware interfaces, or software interfaces. A \\ncommon problem with geriatric systems is poorly written production code that must \\nremain operational at all times. \\nAn effective strategy for rejuvenating geriatric production systems is to designate some \\ncode as being in the messy real world, some code as being in an idealized new world, \\nand some code as being the interface between the two. Figure 24-2 illustrates this idea. \\nFigure 24-2 Your code doesn’t have to be messy just because the real world is messy. \\nConceive your system as a combination of ideal code, interfaces from the ideal code to the \\nmessy real world, and the messy real world. \\nInterface to Messy Real World\\nNice Tidy Ideal World\\nMessy Real World'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 620}, page_content='584 Chapter 24: Refactoring\\nAs you work with the system, you can begin moving code across the “real world inter-\\nface” into a more organized ideal world. When you begin working with a legacy sys-\\ntem, the poorly written legacy code might make up nearly all the system. One policy \\nthat works well is that anytime you touch a section of messy code, you are required to \\nbring it up to current coding standards, give it clear variable names, and so on—effec-\\ntively moving it into the ideal world. Over time this can provide for a rapid improve-\\nment in a code base, as shown in Figure 24-3. \\nFigure 24-3 One strategy for improving production code is to refactor poorly written leg-\\nacy code as you touch it, so as to move it to the other side of the “interface to the messy real \\nworld.” \\ncc2e.com/2457 CHECKLIST: Refactoring Safely\\n❑ Is each change part of a systematic change strategy?\\n❑ Did you save the code you started with before beginning refactoring?\\n❑ Are you keeping each refactoring small? \\n❑ Are you doing refactorings one at a time?\\n❑ Have you made a list of steps you intend to take during your refactoring?\\n❑ Do you have a parking lot so that you can remember ideas that occur to \\nyou mid-refactoring?\\n❑ Have you retested after each refactoring?\\n❑ Have changes been reviewed if they are complicated or if they affect mis-\\nsion-critical code? \\n❑ Have you considered the riskiness of the specific refactoring and adjusted \\nyour approach accordingly? \\n❑ Does the change enhance the program’s internal quality rather than \\ndegrade it?\\n❑ Have you avoided using refactoring as a cover for code and fix or as an \\nexcuse for not rewriting bad code? \\nInitial State \\nMostly Poorly-Written Legacy Code\\n Target State\\nMostly Well-Written Refactored Code'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 621}, page_content='Additional Resources 585\\nAdditional Resources\\ncc2e.com/2464 The process of refactoring has a lot in common with the process of fixing defects. For \\nmore on fixing defects, see Section 23.3, “Fixing a Defect.” The risks associated with \\nrefactoring are similar to the risks associated with code tuning. For more on managing \\ncode-tuning risks, see Section 25.6, “Summary of the Approach to Code Tuning.” \\nFowler, Martin. Refactoring: Improving the Design of Existing Code. Reading, MA: Addi-\\nson Wesley, 1999. This is the definitive guide to refactoring. It contains detailed dis-\\ncussions of many of the specific refactorings summarized in this chapter, as well as a \\nhandful of other refactorings not summarized here. Fowler provides numerous code \\nsamples to illustrate how each refactoring is performed step by step. \\nKey Points\\n■ Program changes are a fact of life both during initial development and after ini-\\ntial release. \\n■ Software can either improve or degrade as it’s changed. The Cardinal Rule of \\nSoftware Evolution is that internal quality should improve with code evolution. \\n■ One key to success in refactoring is learning to pay attention to the numerous \\nwarning signs or smells that indicate a need to refactor. \\n■ Another key to refactoring success is learning numerous specific refactorings. \\n■ A final key to success is having a strategy for refactoring safely. Some refactoring \\napproaches are better than others. \\n■ Refactoring during development is the best chance you’ll get to improve your \\nprogram, to make all the changes you’ll wish you’d made the first time. Take \\nadvantage of these opportunities during development!'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 623}, page_content='587\\nChapter 25\\nCode-Tuning Strategies\\ncc2e.com/2578 Contents\\n■ 25.1 Performance Overview: page 588\\n■ 25.2 Introduction to Code Tuning: page 591\\n■ 25.3 Kinds of Fat and Molasses: page 597\\n■ 25.4 Measurement: page 603\\n■ 25.5 Iteration: page 605\\n■ 25.6 Summary of the Approach to Code Tuning: page 606\\nRelated Topics\\n■ Code-tuning techniques: Chapter 26\\n■ Software architecture: Section 3.5\\nThis chapter discusses the question of performance tuning—historically, a controver-\\nsial issue. Computer resources were severely limited in the 1960s, and efficiency was \\na paramount concern. As computers became more powerful in the 1970s, program-\\nmers realized how much their focus on performance had hurt readability and main-\\ntainability and code tuning received less attention. The return of performance \\nlimitations with the microcomputer revolution of the 1980s again brought efficiency \\nto the fore, which then waned throughout the 1990s. In the 2000s, memory limita-\\ntions in embedded software for devices such as telephones and PDAs and the execu-\\ntion time of interpreted code have once again made efficiency a key topic.\\nYou can address performance concerns at two levels: strategic and tactical. This chap-\\nter addresses strategic performance issues: what performance is, how important it is, \\nand the general approach to achieving it. If you already have a good grip on perfor-\\nmance strategies and are looking for specific code-level techniques that improve per-\\nformance, move on to Chapter 26, “Code-Tuning Techniques.” Before you begin any \\nmajor performance work, however, at least skim the information in this chapter so \\nthat you don’t waste time optimizing when you should be doing other kinds of work.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 624}, page_content='588 Chapter 25: Code-Tuning Strategies\\n25.1 Performance Overview\\nCode tuning is one way of improving a program’s performance. You can often find \\nother ways to improve performance more—and in less time and with less harm to the \\ncode—than by code tuning. This section describes the options.\\nQuality Characteristics and Performance\\nMore computing sins are \\ncommitted in the name of \\nefficiency (without necessarily \\nachieving it) than for any \\nother single reason—\\nincluding blind stupidity. \\n—W. A. Wulf\\nSome people look at the world through rose-colored glasses. Programmers like you \\nand me tend to look at the world through code-colored glasses. We assume that the \\nbetter we make the code, the more our clients and customers will like our software.\\nThis point of view might have a mailing address somewhere in reality, but it doesn’t \\nhave a street number and it certainly doesn’t own any real estate. Users are more inter-\\nested in tangible program characteristics than they are in code quality. Sometimes \\nusers are interested in raw performance, but only when it affects their work. Users \\ntend to be more interested in program throughput than raw performance. Delivering \\nsoftware on time, providing a clean user interface, and avoiding downtime are often \\nmore significant.\\nHere’s an illustration. I take at least 50 pictures a week on my digital camera. To \\nupload the pictures to my computer, the software that came with the camera requires \\nme to select each picture one by one, viewing them in a window that shows only six \\npictures at a time. Uploading 50 pictures is a tedious process that requires dozens of \\nmouse clicks and lots of navigation through the six-picture window. After putting up \\nwith this for a few months, I bought a memory-card reader that plugs directly into my \\ncomputer and that my computer thinks is a disk drive. Now I can use Windows \\nExplorer to copy the pictures to my computer. What used to take dozens of mouse \\nclicks and lots of waiting now requires about two mouse clicks, a Ctrl+A, and a drag \\nand drop. I really don’t care whether the memory card reader transfers each file in half \\nthe time or twice the time as the other software, because my throughput is faster. \\nRegardless of whether the memory card reader’s code is faster or slower, its perfor-\\nmance is better.\\nPerformance is only loosely related to code speed. To the extent that you work on your \\ncode’s speed, you’re not working on other quality characteristics. Be wary of sacrific-\\ning other characteristics to make your code faster. Your work on speed might hurt \\noverall performance rather than help it.\\nPerformance and Code Tuning\\nOnce you’ve chosen efficiency as a priority, whether its emphasis is on speed or on \\nsize, you should consider several options before choosing to improve either speed or \\nsize at the code level. Think about efficiency from each of these viewpoints:\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 625}, page_content='25.1 Performance Overview 589\\n■ Program requirements\\n■ Program design\\n■ Class and routine design\\n■ Operating-system interactions\\n■ Code compilation\\n■ Hardware\\n■ Code tuning\\nProgram Requirements\\nPerformance is stated as a requirement far more often than it actually is a requirement. \\nBarry Boehm tells the story of a system at TRW that initially required subsecond \\nresponse time. This requirement led to a highly complex design and an estimated cost \\nof $100 million. Further analysis determined that users would be satisfied with four-\\nsecond responses 90 percent of the time. Modifying the response-time requirement \\nreduced overall system cost by about $70 million. (Boehm 2000b).\\nBefore you invest time solving a performance problem, make sure that you’re solving \\na problem that needs to be solved. \\nProgram Design\\nCross-Reference For details \\non designing performance \\ninto a program, see the \\n“Additional Resources” sec-\\ntion at the end of this chapter.\\nProgram design includes the major strokes of the design for a single program, mainly \\nthe way in which a program is divided into classes. Some program designs make it dif-\\nficult to write a high-performance system. Others make it hard not to.\\nConsider the example of a real-world data-acquisition program for which the high-\\nlevel design had identified measurement throughput as a key product attribute. Each \\nmeasurement included time to make an electrical measurement, calibrate the value, \\nscale the value, and convert it from sensor data units (such as millivolts) into engi-\\nneering data units (such as degrees Celsius).\\nIn this case, without addressing the risk in the high-level design, the programmers \\nwould have found themselves trying to optimize the math to evaluate a 13th-order \\npolynomial in software—that is, a polynomial with 14 terms, including variables raised \\nto the 13th power. Instead, they addressed the problem with different hardware and a \\nhigh-level design that used dozens of 3rd-order polynomials. This change could not \\nhave been effected through code tuning, and it’s unlikely that any amount of code \\ntuning would have solved the problem. This is an example of a problem that had to be \\naddressed at the program-design level.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 626}, page_content='590 Chapter 25: Code-Tuning Strategies\\nCross-Reference For details \\non the way programmers \\nwork toward objectives, see \\n“Setting Objectives” in Sec-\\ntion 20.2.\\nIf you know that a program’s size and speed are important, design the program’s \\narchitecture so that you can reasonably meet your size and speed goals. Design a per-\\nformance-oriented architecture, and then set resource goals for individual sub-\\nsystems, features, and classes. This will help in several ways:\\n■ Setting individual resource goals makes the system’s ultimate performance pre-\\ndictable. If each feature meets its resource goals, the whole system will meet its \\ngoals. You can identify subsystems that have trouble meeting their goals early \\nand target them for redesign or code tuning.\\n■ The mere act of making goals explicit improves the likelihood that they’ll be \\nachieved. Programmers work to objectives when they know what they are; the \\nmore explicit the objectives, the easier they are to work to.\\n■ You can set goals that don’t achieve efficiency directly but promote efficiency in \\nthe long run. Efficiency is often best treated in the context of other issues. For \\nexample, achieving a high degree of modifiability can provide a better basis for \\nmeeting efficiency goals than explicitly setting an efficiency target. With a highly \\nmodular, modifiable design, you can easily swap less-efficient components for \\nmore-efficient ones.\\nClass and Routine Design\\nCross-Reference For more \\ninformation about data \\ntypes and algorithms, see \\nthe “Additional Resources” \\nsection at the end of the \\nchapter.\\nDesigning the internals of classes and routines presents another opportunity to \\ndesign for performance. One performance key that comes into play at this level is the \\nchoice of data types and algorithms, which usually affect both the program’s memory \\nuse and execution speed. This is the level at which you can choose quicksort rather \\nthan bubblesort or a binary search instead of a linear search. \\nOperating-System Interactions\\nCross-Reference For code-\\nlevel strategies that address \\nslow or fat operating-system \\nroutines, see Chapter 26, \\n“Code-Tuning Techniques.”\\nIf your program works with external files, dynamic memory, or output devices, it’s prob-\\nably interacting with the operating system. If performance isn’t good, it might be because \\nthe operating-system routines are slow or fat. You might not be aware that the program is \\ninteracting with the operating system; sometimes your compiler generates system calls or \\nyour libraries invoke system calls you would never dream of. More on this later. \\nCode Compilation\\nGood compilers turn clear, high-level language code into optimized machine code. If \\nyou choose the right compiler, you might not need to think about optimizing speed \\nany further. \\nThe optimization results reported in Chapter 26 provide numerous examples of com-\\npiler optimizations that produce more efficient code than manual code tuning does.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 627}, page_content='25.2 Introduction to Code Tuning 591\\nHardware\\nSometimes the cheapest and best way to improve a program’s performance is to buy \\nnew hardware. If you’re distributing a program for nationwide use by hundreds of \\nthousands of customers, buying new hardware isn’t a realistic option. But if you’re \\ndeveloping custom software for a few in-house users, a hardware upgrade might be \\nthe cheapest option. It saves the cost of initial performance work. It saves the cost of \\nfuture maintenance problems caused by performance work. It improves the perfor-\\nmance of every other program that runs on that hardware, too. \\nCode Tuning\\nCode tuning is the practice of modifying correct code in ways that make it run more \\nefficiently, and it’s the subject of the rest of this chapter. “Tuning” refers to small-scale \\nchanges that affect a single class, a single routine, or, more commonly, a few lines of \\ncode. “Tuning” does not refer to large-scale design changes or other higher-level \\nmeans of improving performance.\\nYou can make dramatic improvements at each level from system design through code \\ntuning. Jon Bentley cites an argument that in some systems the improvements at each \\nlevel can be multiplied (1982). Because you can achieve a 10-fold improvement in each \\nof six levels, that implies a potential performance improvement of a million fold. \\nAlthough such a multiplication of improvements requires a program in which gains at \\none level are independent of gains at other levels, which is rare, the potential is inspiring.\\n25.2 Introduction to Code Tuning\\nWhat is code tuning’s appeal? It’s not the most effective way to improve performance—\\nprogram architecture, class design, and algorithm selection usually produce more dra-\\nmatic improvements. Nor is it the easiest way to improve performance—buying new \\nhardware or a compiler with a better optimizer is easier. And it’s not the cheapest way \\nto improve performance either—it takes more time to hand-tune code initially, and \\nhand-tuned code is harder to maintain later.\\nCode tuning is appealing for several reasons. One attraction is that it seems to defy the \\nlaws of nature. It’s incredibly satisfying to take a routine that executes in 20 microsec-\\nonds, tweak a few lines, and reduce the execution speed to 2 microseconds.\\nIt’s also appealing because mastering the art of writing efficient code is a rite of pas-\\nsage to becoming a serious programmer. In tennis, you don’t get any game points for \\nthe way you pick up a tennis ball, but you still need to learn the right way to do it. You \\ncan’t just lean over and pick it up with your hand. If you’re good, you whack it with \\nthe head of your racket until it bounces waist high and then you catch it. Whacking it'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 628}, page_content='592 Chapter 25: Code-Tuning Strategies\\nmore than three times, even not bouncing it the first time, is a serious failing. Despite \\nits seeming unimportance, the way you pick up the ball carries a certain cachet within \\ntennis culture. Similarly, no one but you and other programmers usually cares how \\ntight your code is. Nonetheless, within the programming culture, writing microeffi-\\ncient code proves you’re cool.\\nThe problem with code tuning is that efficient code isn’t necessarily “better” code. \\nThat’s the subject of the next few sections.\\nThe Pareto Principle\\nThe Pareto Principle, also known as the 80/20 rule, states that you can get 80 percent \\nof the result with 20 percent of the effort. The principle applies to a lot of areas other \\nthan programming, but it definitely applies to program optimization.\\nBarry Boehm reports that 20 percent of a program’s routines consume 80 percent of \\nits execution time (1987b). In his classic paper “An Empirical Study of Fortran Pro-\\ngrams,” Donald Knuth found that less than four percent of a program usually \\naccounts for more than 50 percent of its run time (1971).\\nKnuth used a line-count profiler to discover this surprising relationship, and the \\nimplications for optimization are clear. You should measure the code to find the hot \\nspots and then put your resources into optimizing the few percent that are used the \\nmost. Knuth profiled his line-count program and found that it was spending half its \\nexecution time in two loops. He changed a few lines of code and doubled the speed of \\nthe profiler in less than an hour.\\nJon Bentley describes a case in which a 1000-line program spent 80 percent of its time \\nin a five-line square-root routine. By tripling the speed of the square-root routine, he \\ndoubled the speed of the program (1988). The Pareto Principle is also the source of \\nthe advice to write most of the code in an interpreted language like Python and then \\nrewrite the hot spots in a faster compiled language like C.\\nBentley also reports the case of a team that discovered half an operating system’s time \\nbeing spent in a small loop. They rewrote the loop in microcode and made the loop 10 \\ntimes faster, but it didn’t change the system’s performance—they had rewritten the sys-\\ntem’s idle loop!\\nThe team who designed the ALGOL language—the granddaddy of most modern lan-\\nguages and one of the most influential languages ever—received the following advice: \\n“The best is the enemy of the good.” Working toward perfection might prevent com-\\npletion. Complete it first, and then perfect it. The part that needs to be perfect is usu-\\nally small.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 629}, page_content='25.2 Introduction to Code Tuning 593\\nOld Wives’ Tales\\nMuch of what you’ve heard about code tuning is false, including the following com-\\nmon misapprehensions:\\nReducing the lines of code in a high-level language improves the speed or size of the \\nresulting machine code—false! Many programmers cling tenaciously to the belief \\nthat if they can write code in one or two lines, it will be the most efficient possible. \\nConsider the following code that initializes a 10-element array:\\nfor i = 1 to 10 \\n   a[ i ] = i\\nend for \\nWould you guess that these lines are faster or slower than the following 10 lines that \\ndo the same job?\\na[ 1 ] = 1\\na[ 2 ] = 2\\na[ 3 ] = 3\\na[ 4 ] = 4\\na[ 5 ] = 5\\na[ 6 ] = 6\\na[ 7 ] = 7\\na[ 8 ] = 8\\na[ 9 ] = 9\\na[ 10 ] = 10\\nIf you follow the old “fewer lines are faster” dogma, you’ll guess that the first code is \\nfaster. But tests in Microsoft Visual Basic and Java have shown that the second frag-\\nment is at least 60 percent faster than the first. Here are the numbers:\\nNote (1) Times in this and the following tables in this chapter are given in seconds \\nand are meaningful only for comparisons across rows in each table. Actual times will \\nvary according to the compiler, compiler options used, and the environment in which \\neach test is run. (2) Benchmark results are typically made up of several thousand to many \\nmillion executions of the code fragments to smooth out sample-to-sample fluctuations \\nin the results. (3) Specific brands and versions of compilers aren’t indicated. Performance \\ncharacteristics vary significantly from brand to brand and from version to version. \\n(4) Comparisons among results from different languages aren’t always meaningful \\nbecause compilers for different languages don’t always offer comparable code-genera-\\ntion options. (5) The results shown for interpreted languages (PHP and Python) are \\ntypically based on less than 1% of the test runs used for the other languages. (6) Some of \\nthe “time savings” percentages might not be exactly reproducible from the data in these \\ntables due to rounding of the “straight time” and “code-tuned time” entries.\\nLanguage\\nfor-Loop \\nTime\\nStraight-Code \\nTimeTime Savings Performance Ratio\\nVisual Basic 8.47 3.16 63% 2.5:1\\nJava 12.6 3.23 74% 4:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 630}, page_content='594 Chapter 25: Code-Tuning Strategies\\nThis certainly doesn’t imply that increasing the number of lines of high-level language \\ncode always improves speed or reduces size. It does imply that regardless of the aes-\\nthetic appeal of writing something with the fewest lines of code, no predictable rela-\\ntionship exists between the number of lines of code in a high-level language and a \\nprogram’s ultimate size and speed.\\nCertain operations are probably faster or smaller than others—false! There’s no \\nroom for “probably” when you’re talking about performance. You must always mea-\\nsure performance to know whether your changes helped or hurt your program. The \\nrules of the game change every time you change languages, compilers, versions of \\ncompilers, libraries, versions of libraries, processor, amount of memory on the \\nmachine, color of shirt you’re wearing (OK, not this one), and so on. What was true \\non one machine with one set of tools can easily be false on another machine with a dif-\\nferent set of tools.\\nThis phenomenon suggests several reasons not to improve performance by code tuning. \\nIf you want your program to be portable, techniques that improve performance in one \\nenvironment can degrade it in others. If you change compilers or upgrade, the new com-\\npiler might automatically optimize code the way you were hand-tuning it and your work \\nwill have been wasted. Even worse, your code tuning might defeat more powerful com-\\npiler optimizations that have been designed to work with straightforward code.\\nWhen you tune code, you’re implicitly si gning up to reprofile each optimization \\nevery time you change your compiler brand, compiler version, library version, and \\nso on. If you don’t reprofile, an optimization that improves performance under one \\nversion of a compiler or library might well degrade performance when you change \\nthe build environment.\\nWe should forget about small \\nefficiencies, say about 97% of \\nthe time: premature optimi-\\nzation is the root of all evil.\\n—Donald Knuth\\nYou should optimize as you go—false! One theory is that if you strive to write the fast-\\nest and smallest possible code as you write each routine, your program will be fast and \\nsmall. This approach creates a forest-for-the-trees situation in which programmers \\nignore significant global optimizations because they’re too busy with micro-optimiza-\\ntions. Here are the main problems with optimizing as you go along:\\n■ It’s almost impossible to identify performance bottlenecks before a program is \\nworking completely. Programmers are very bad at guessing which four percent \\nof the code accounts for 50 percent of the execution time, and so programmers \\nwho optimize as they go will, on average, spend 96 percent of their time optimiz-\\ning code that doesn’t need to be optimized. That leaves little time to optimize \\nthe four percent that really counts. \\n■ In the rare case in which developers identify the bottlenecks correctly, they over-\\nkill the bottlenecks they’ve identified and allow others to become critical. Again, \\nthe ultimate effect is a reduction in performance. Optimizations done after a sys-\\ntem is complete can identify each problem area and its relative importance so \\nthat optimization time is allocated effectively.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 631}, page_content='25.2 Introduction to Code Tuning 595\\n■ Focusing on optimization during initial development detracts from achieving \\nother program objectives. Developers immerse themselves in algorithm analysis \\nand arcane debates that in the end don’t contribute much value to the user. Con-\\ncerns such as correctness, information hiding, and readability become second-\\nary goals, even though performance is easier to improve later than these other \\nconcerns are. Post hoc performance work typically affects less than five percent \\nof a program’s code. Would you rather go back and do performance work on \\nfive percent of the code or readability work on 100 percent?\\nIn short, premature optimization’s primary drawback is its lack of perspective. Its vic-\\ntims include final code speed, performance attributes that are more important than \\ncode speed, program quality, and ultimately the software’s users. If the development \\ntime saved by implementing the simplest program is devoted to optimizing the run-\\nning program, the result will always be a program that runs faster than one developed \\nwith indiscriminate optimization efforts (Stevens 1981).\\nOccasionally, post hoc optimization won’t be sufficient to meet performance goals \\nand you’ll have to make major changes in the completed code. In those cases, small, \\nlocalized optimizations wouldn’t have provided the gains needed anyway. The prob-\\nlem in such cases isn’t inadequate code quality—it’s inadequate software architecture.\\nIf you need to optimize before a program is complete, minimize the risks by building \\nperspective into your process. One way is to specify size and speed goals for features and \\nthen optimize to meet the goals as you go along. Setting such goals in a specification is \\na way to keep one eye on the forest while you figure out how big your particular tree is.\\nFurther Reading For many \\nother entertaining and \\nenlightening anecdotes, see \\nGerald Weinberg’s Psychol-\\nogy of Computer Program-\\nming (1998).\\nA fast program is just as important as a correct one—false! It’s hardly ever true that \\nprograms need to be fast or small before they need to be correct. Gerald Weinberg \\ntells the story of a programmer who was flown to Detroit to help debug a troubled \\nprogram. The programmer worked with the team who had developed the program \\nand concluded after several days that the situation was hopeless.\\nOn the flight home, he mulled over the situation and realized what the problem was. By \\nthe end of the flight, he had an outline for the new code. He tested the code for several \\ndays and was about to return to Detroit when he got a telegram saying that the project \\nhad been cancelled because the program was impossible to write. He headed back to \\nDetroit anyway and convinced the executives that the project could be completed.\\nThen he had to convince the project’s original programmers. They listened to his pre-\\nsentation, and when he’d finished, the creator of the old system asked, “And how long \\ndoes your program take?”\\n“That varies, but about ten seconds per input.”'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 632}, page_content='596 Chapter 25: Code-Tuning Strategies\\n“Aha! But my program takes only one second per input.” The veteran leaned back, sat-\\nisfied that he’d stumped the upstart. The other programmers seemed to agree, but the \\nnew programmer wasn’t intimidated.\\n“Yes, but your program doesn’t work. If mine doesn’t have to work, I can make it run \\ninstantly.”\\nFor a certain class of projects, speed or size is a major concern. This class is the minor-\\nity, is much smaller than most people think, and is getting smaller all the time. For \\nthese projects, the performance risks must be addressed by up-front design. For other \\nprojects, early optimization poses a significant threat to overall software quality, \\nincluding performance.\\nWhen to Tune\\nJackson’s Rules of Optimiza-\\ntion: Rule 1. Don’t do it. Rule \\n2 (for experts only). Don’t do \\nit yet—that is, not until you \\nhave a perfectly clear and \\nunoptimized solution. \\n—M. A. Jackson\\nUse a high-quality design. Make the program right. Make it modular and easily modi-\\nfiable so that it’s easy to work on later. When it’s complete and correct, check the per-\\nformance. If the program lumbers, make it fast and small. Don’t optimize until you \\nknow you need to.\\nA few years ago I worked on a C++ project that produced graphical outputs to analyze \\ninvestment data. After my team got the first graph working, testing reported that the \\nprogram took about 45 minutes to draw the graph, which was clearly not acceptable. \\nWe held a team meeting to decide what to do about it. One of the developers became \\nirate and shouted, “If we want to have any chance of releasing an acceptable product, \\nwe’ve got to start rewriting the whole code base in assembler right now.” I responded \\nthat I didn’t think so—that four percent of the code probably accounted for 50 percent \\nor more of the performance bottleneck. It would be best to address that four percent \\ntoward the end of the project. After a bit more shouting, our manager assigned me to \\ndo some initial performance work (which was really a case of “Oh no! Please don’t \\nthrow me into that briar patch!”).\\nAs is often the case, a day’s work identified a couple of glaring bottlenecks in the code. \\nA small number of code-tuning changes reduced the drawing time from 45 minutes to \\nless than 30 seconds. Far less than one percent of the code accounted for 90 percent \\nof the run time. By the time we released the software months later, several additional \\ncode-tuning changes reduced that drawing time to a little more than 1 second. \\nCompiler Optimizations\\nModern compiler optimizations might be more powerful than you expect. In the case \\nI described earlier, my compiler did as good a job of optimizing a nested loop as I was \\nable to do by rewriting the code in a supposedly more efficient style. When shopping \\nfor a compiler, compare the performance of each compiler on your program. Each'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 633}, page_content='25.3 Kinds of Fat and Molasses 597\\ncompiler has different strengths and weaknesses, and some will be better suited to \\nyour program than others.\\nOptimizing compilers are better at optimizing straightforward code than they are at \\noptimizing tricky code. If you do “clever” things like fooling around with loop \\nindexes, your compiler has a harder time doing its job and your program suffers. See \\n“Using Only One Statement Per Line” in Section 31.5 for an example in which a \\nstraightforward approach resulted in compiler-optimized code that was 11 percent \\nfaster than comparable “tricky” code.\\nWith a good optimizing compiler, your code speed can improve 40 percent or more \\nacross the board. Many of the techniques described in the next chapter produce gains \\nof only 15–30 percent. Why not just write clear code and let the compiler do the \\nwork? Here are the results of a few tests to check how much an optimizer speeded up \\nan insertion-sort routine:\\nThe only difference between versions of the routine was that compiler optimizations \\nwere turned off for the first compile and turned on for the second. Clearly, some com-\\npilers optimize better than others, and some are better without optimizations in the \\nfirst place. Some Java Virtual Machines (JVMs) are also clearly better than others. \\nYou’ll have to check your own compiler, JVM, or both to measure the effect. \\n25.3 Kinds of Fat and Molasses\\nIn code tuning you find the parts of a program that are as slow as molasses in winter \\nand as big as Godzilla and change them so that they are as fast as greased lightning \\nand so skinny they can hide in the cracks between the other bytes in RAM. You always \\nhave to profile the program to know with any confidence which parts are slow and fat, \\nbut some operations have a long history of laziness and obesity, and you can start by \\ninvestigating them.\\nLanguage\\nTime Without \\nCompiler \\nOptimizations\\nTime with \\nCompiler \\nOptimizations Time Savings\\nPerformance\\nRatio\\nC+ + compiler 1 2.21 1.05 52% 2:1\\nC+ + compiler 2 2.78 1.15 59% 2.5:1\\nC+ + compiler 3 2.43 1.25 49% 2:1\\nC# compiler 1.55 1.55 0% 1:1\\nVisual Basic 1.78 1.78 0% 1:1\\nJava VM 1 2.77 2.77 0% 1:1\\nJava VM 2 1.39 1.38 <1% 1:1\\nJava VM 3 2.63 2.63 0% 1:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 634}, page_content='598 Chapter 25: Code-Tuning Strategies\\nCommon Sources of Inefficiency\\nHere are several common sources of inefficiency:\\nInput/output operations One of the most significant sources of inefficiency is unnec-\\nessary input/output (I/O). If you have a choice of working with a file in memory vs. on \\ndisk, in a database, or across a network, use an in-memory data structure unless space \\nis critical.\\nHere’s a performance comparison between code that accesses random elements in a \\n100-element in-memory array and code that accesses random elements of the same \\nsize in a 100-record disk file:\\nAccording to this data, in-memory access is on the order of 1000 times faster than \\naccessing data in an external file. Indeed  with the C++ compiler I used, the time \\nrequired for in-memory access wasn’t measurable.\\nThe performance comparison for a similar test of sequential access times is similar:\\nIf the test had used a slower medium for external access—for example, a hard disk \\nacross a network connection—the difference would have been even greater. The perfor-\\nmance looks like this when a similar random-access test is performed on a network \\nlocation instead of on the local machine:\\nOf course, these results can vary dramatically depending on the speed of your net-\\nwork, network loading, distance of the local machine from the networked disk drive, \\nspeed of the networked disk drive compared to the speed of the local drive, current \\nphase of the moon, and other factors.\\nLanguage External File \\nTime\\nIn-Memory \\nData Time\\nTime Savings Performance \\nRatio\\nC++ 6.04 0.000 100% n/a\\nC# 12.8 0.010 100% 1000:1\\nLanguage External File \\nTime\\nIn-Memory \\nData Time\\nTime Savings Performance \\nRatio\\nC++ 3.29 0.021 99% 150:1\\nC# 2.60 0.030 99% 85:1\\nNote: The tests for sequential access were run with 13 times the data volume of the tests for random access, \\nso the results are not comparable across the two types of tests.\\nLanguage Local File Time Netw ork File Time Time Savings\\nC++ 6.04 6.64 -10%\\nC# 12.8 14.1 -10%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 635}, page_content='25.3 Kinds of Fat and Molasses 599\\nOverall, the effect of in-memory access is significant enough to make you think twice \\nabout having I/O in a speed-critical part of a program.\\nPaging An operation that causes the operating system to swap pages of memory is \\nmuch slower than an operation that works on only one page of memory. Sometimes a \\nsimple change makes a huge difference. In the next example, one programmer wrote \\nan initialization loop that produced many page faults on a system that used 4K pages.\\nJava Example of an Initialization Loop That Causes Many Page Faults\\nfor ( column = 0; column < MAX_COLUMNS; column++ ) {\\n   for ( row = 0; row < MAX_ROWS; row++ ) {\\n      table[ row ][ column ] = BlankTableElement();\\n   }\\n}\\nThis is a nicely formatted loop with good variable names, so what’s the problem? The \\nproblem is that each element of table is about 4000 bytes long. If table has too many \\nrows, every time the program accesses a different row, the operating system will have \\nto switch memory pages. The way the loop is structured, every single array access \\nswitches rows, which means that every single array access causes paging to disk.\\nThe programmer restructured the loop this way:\\nJava Example of an Initialization Loop That Causes Few Page Faults\\nfor ( row = 0; row < MAX_ROWS; row++ ) {\\n   for ( column = 0; column < MAX_COLUMNS; column++ ) {\\n      table[ row ][ column ] = BlankTableElement();\\n   }\\n}\\nThis code still causes a page fault every time it switches rows, but it switches rows only \\nMAX_ROWS times instead of MAX_ROWS * MAX_COLUMNS times.\\nThe specific performance penalty varies significantly. On a machine with limited \\nmemory, I measured the second code sample to be about 1000 times faster than the \\nfirst code sample. On machines with more memory, I’ve measured the difference to be \\nas small as a factor of 2, and it doesn’t show up at all except for very large values of \\nMAX_ROWS  and MAX_COLUMNS. \\nSystem calls Calls to system routines are often expensive. They often involve a con-\\ntext switch—saving the program’s state, recovering the kernel’s state, and the reverse. \\nSystem routines include input/output operations to disk, keyboard, screen, printer, or \\nother device; memory-management routines; and certain utility routines. If perfor-'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 636}, page_content='600 Chapter 25: Code-Tuning Strategies\\nmance is an issue, find out how expensive your system calls are. If they’re expensive, \\nconsider these options:\\n■ Write your own services. Sometimes you need only a small part of the function-\\nality offered by a system routine and can build your own from lower-level system \\nroutines. Writing your own replacement gives you something that’s faster, \\nsmaller, and better suited to your needs.\\n■ Avoid going to the system.\\n■ Work with the system vendor to make the call faster. Most vendors want to \\nimprove their products and are glad to learn about parts of their systems with \\nweak performance. (They might seem a little grouchy about it at first, but they \\nreally are interested.)\\nIn the code-tuning effort I described in “When to Tune” in Section 25.2, the program \\nused an AppTime class that was derived from a commercially available BaseTime class. \\n(These names have been changed to protect the guilty.) The AppTime object was the \\nmost common object in this application, and we instantiated tens of thousands of \\nAppTime objects. After several months, we discovered that BaseTime was initializing \\nitself to the system time in its constructor. For our purposes, the system time was irrel-\\nevant, which meant we were needlessly generating thousands of system-level calls. \\nSimply overriding BaseTime’s constructor and initializing the time field to 0 instead of \\nto the system time gave us about as much performance improvement as all the other \\nchanges we made put together.\\nInterpreted languages Interpreted languages tend to exact significant performance \\npenalties because they must process each programming-language instruction before \\ncreating and executing machine code. In the performance benchmarking I performed \\nfor this chapter and Chapter 26, I observed the approximate relationships in perfor-\\nmance among different languages that are described in Table 25-1.\\nAs you can see, C++, Visual Basic, and C# are all comparable. Java is close but tends to \\nbe slower than the other languages. PHP and Python are interpreted languages, and \\ncode in those languages tended to run a factor of 100 or more slower than code in \\nC++, Visual Basic, C#, and Java. The general numbers presented in this table must be \\nviewed cautiously. For any particular piece of code, C++, Visual Basic, C#, or Java \\nTable 25-1 Relative Execution Time of Programming Languages \\nLanguage Type of Language Execution Time Relative to C++\\nC++ Compiled 1:1\\nVisual Basic Compiled 1:1\\nC# Compiled 1:1\\nJava Byte code 1.5:1\\nPHP Interpreted >100:1\\nPython Interpreted >100:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 637}, page_content='25.3 Kinds of Fat and Molasses 601\\nmight be twice as fast or half as fast as the other languages. (You can see this for your-\\nself in the detailed examples in Chapter 26.)\\nErrors A final source of performance problems is errors in the code. Errors can \\ninclude leaving debugging code turned on (such as logging trace information to a \\nfile), forgetting to deallocate memory, improperly designing database tables, polling \\nnonexistent devices until they time out, and so on.\\nA version 1.0 application I worked on had a particular operation that was much \\nslower than other similar operations. A great deal of project mythology grew up to \\nexplain the slowness of this operation. We released version 1.0 without ever fully \\nunderstanding why this particular operation was so slow. While working on the ver-\\nsion 1.1 release, however, I discovered that the database table used by the operation \\nwasn’t indexed! Simply indexing the table improved performance by a factor of 30 for \\nsome operations. Defining an index on a commonly used table is not optimization; it’s \\njust good programming practice. \\nRelative Performance Costs of Common Operations\\nAlthough you can’t count on some operations being more expensive than others with-\\nout measuring them, certain operations tend to be more expensive. When you look \\nfor the molasses in your program, use Table 25-2 to help make some initial guesses \\nabout the sticky parts of your program.\\nTable 25-2 Costs of Common Operations\\nRelative Time Consumed\\nOperation Example C++ Java\\nBaseline (integer assignment) i = j 1 1\\nRoutine Calls\\nCall routine with no parameters foo() 1n /a\\nCall private routine with no \\nparameters\\nthis.foo() 10 .5\\nCall private routine with 1 \\nparameter\\nthis.foo( i ) 1.5 0.5\\nCall private routine with 2 \\nparameters\\nthis.foo( i, j ) 20 .5\\nObject routine call bar.foo() 21\\nDerived routine call derivedBar.foo() 21\\nPolymorphic routine call abstractBar.foo() 2.5 2\\nObject References\\nLevel 1 object dereference i = obj.num 11\\nLevel 2 object dereference i = obj1.obj2. num 11\\nEach additional dereference i = obj1.obj2.obj3... not \\nmeasurable\\nnot \\nmeasurable'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 638}, page_content='602 Chapter 25: Code-Tuning Strategies\\nInteger Operations\\nInteger assignment (local) i = j 11\\nInteger assignment (inherited) i = j 11\\nInteger addition i = j + k 11\\nInteger subtraction i = j - k 11\\nInteger multiplication i = j * k 11\\nInteger division i = j \\\\ k 51 . 5\\nFloating-Point Operations\\nFloating-point assignment x = y 11\\nFloating-point addition x = y + z 11\\nFloating-point subtraction x = y - z 11\\nFloating-point multiplication x = y * z 11\\nFloating-point division x = y / z 41\\nTranscendental Functions\\nFloating-point square rootx = sqrt( y ) 15 4\\nFloating-point sine x = sin( y ) 25 20\\nFloating-point logarithm x = log( y ) 25 20\\nFloating-point ey x = exp( y ) 50 20\\nArrays\\nAccess integer array with con-\\nstant subscript\\ni = a[ 5 ] 11\\nAccess integer array with variable \\nsubscript\\ni = a[ j ] 11\\nAccess two-dimensional integer \\narray with constant subscripts\\ni = a[ 3, 5 ] 11\\nAccess two-dimensional integer \\narray with variable subscripts\\ni = a[ j, k ] 11\\nAccess floating-point array with \\nconstant subscript\\nx = z[ 5 ] 11\\nAccess floating-point array with \\ninteger-variable subscript\\nx = z[ j ] 11\\nAccess two-dimensional, float-\\ning-point array with constant \\nsubscripts\\nx = z[ 3, 5 ] 11\\nAccess two-dimensional, float-\\ning-point array with integer-vari-\\nable subscripts\\nx = z[ j, k ] 11\\nNote: Measurements in this table are highly sensitive to local machine environment, compiler optimizations, \\nand code generated by specific compilers. Measurements between C++ and Java are not directly \\ncomparable.\\nTable 25-2 Costs of Common Operations\\nRelative Time Consumed\\nOperation Example C++ Java'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 639}, page_content='25.4 Measurement 603\\nThe relative performance of these operations has changed significantly since the first \\nedition of Code Complete, so if you’re approaching code tuning with 10-year-old ideas \\nabout performance, you might need to update your thinking.\\nMost of the common operations are about the same price—routine calls, assignments, \\ninteger arithmetic, and floating-point arithmetic are all roughly equal. Transcendental \\nmath functions are extremely expensive. Polymorphic routine calls are a bit more \\nexpensive than other kinds of routine calls.\\nTable 25-2, or a similar one that you make, is the key that unlocks all the speed \\nimprovements described in Chapter 26. In every case, improving speed comes from \\nreplacing an expensive operation with a cheaper one. Chapter 26 provides examples \\nof how to do so.\\n25.4 Measurement\\nBecause small parts of a program usually consume a disproportionate share of the run \\ntime, measure your code to find the hot spots. Once you’ve found the hot spots and \\noptimized them, measure the code again to assess how much you’ve improved it. \\nMany aspects of performance are counterintuitive. The earlier case in this chapter, in \\nwhich 10 lines of code were significantly faster and smaller than one line, is one exam-\\nple of the ways that code can surprise you.\\nExperience doesn’t help much with optimization either. A person’s experience might \\nhave come from an old machine, language, or compiler—when any of those things \\nchanges, all bets are off. You can never be sure about the effect of an optimization until \\nyou measure the effect.\\nMany years ago now I wrote a program that summed the elements in a matrix. The \\noriginal code looked like this:\\nC++ Example of Straightforward Code to Sum the Elements in a Matrix\\nsum = 0;\\nfor ( row = 0; row < rowCount; row++ ) {\\n   for ( column = 0; column < columnCount; column++ ) {\\n      sum = sum + matrix[ row ][ column ];\\n   }\\n}\\nThis code was straightforward, but performance of the matrix-summation routine was \\ncritical, and I knew that all the array accesses and loop tests had to be expensive. I \\nknew from computer-science classes that every time the code accessed a two-dimen-\\nsional array, it performed expensive multiplications and additions. For a 100-by-100 \\nmatrix, that totaled 10,000 multiplications and additions, plus the loop overhead. By \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 640}, page_content='604 Chapter 25: Code-Tuning Strategies\\nconverting to pointer notation, I reasoned, I could increment a pointer and replace \\n10,000 expensive multiplications with 10,000 relatively cheap increment operations. I \\ncarefully converted the code to pointer notation and got this:\\nFurther Reading Jon Bentley \\nreported a similar experience \\nin which converting to point-\\ners hurt performance by \\nabout 10 percent. The same \\nconversion had—in another \\nsetting—improved perfor-\\nmance more than 50 percent. \\nSee “Software Exploratorium: \\nWriting Efficient C Programs” \\n(Bentley 1991).\\nC+ + Example of an Attempt to Tune Code to Sum the Elements in a Matrix\\nsum = 0;\\nelementPointer = matrix;\\nlastElementPointer = matrix[ rowCount - 1 ][ columnCount - 1 ] + 1;\\nwhile ( elementPointer < lastElementPointer ) {\\n   sum = sum + *elementPointer++;\\n}\\nEven though the code wasn’t as readable as the first code, especially to programmers \\nwho aren’t C++ experts, I was magnificently pleased with myself. For a 100-by-100 \\nmatrix, I calculated that I had saved 10,000 multiplications and a lot of loop overhead. \\nI was so pleased that I decided to measure the speed improvement, something I didn’t \\nalways do back then, so that I could pat myself on the back more quantitatively.\\nNo programmer has ever \\nbeen able to predict or ana-\\nlyze where performance bot-\\ntlenecks are without data. \\nNo matter where you think \\nit’s going, you will be sur-\\nprised to discover that it is \\ngoing somewhere else.\\n—Joseph M. Newcomer\\nDo you know what I found? No improvement whatsoever. Not with a 100-by-100 \\nmatrix. Not with a 10-by-10 matrix. Not with any size matrix. I was so disappointed \\nthat I dug into the assembly code generated by the compiler to see why my optimiza-\\ntion hadn’t worked. To my surprise, it turned out that I was not the first programmer \\nwho ever needed to iterate through the elements of an array—the compiler’s optimizer \\nwas already converting the array accesses to pointers. I learned that the only result of \\noptimization you can usually be sure of without measuring performance is that you’ve \\nmade your code harder to read. If it’s not worth measuring to know that it’s more effi-\\ncient, it’s not worth sacrificing clarity for a performance gamble.\\nMeasurements Need to Be Precise\\nCross-Reference For a dis-\\ncussion of profiling tools, see \\n“Code Tuning” in Section \\n30.3.\\nPerformance measurements need to be precise. Timing your program with a stop-\\nwatch or by counting “one elephant, two elephant, three elephant” isn’t precise. Pro-\\nfiling tools are useful, or you can use your system’s clock and routines that record the \\nelapsed times for computing operations.\\nWhether you use someone else’s tool or write your own code to make the measure-\\nments, make sure that you’re measuring only the execution time of the code you’re tun-\\ning. Use the number of CPU clock ticks allocated to your program rather than the time \\nof day. Otherwise, when the system switches from your program to another program, \\none of your routines will be penalized for the time spent executing another program. \\nLikewise, try to factor out measurement overhead and program-startup overhead so that \\nneither the original code nor the tuning attempt is unfairly penalized.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 641}, page_content='25.5 Iteration 605\\n25.5 Iteration\\nOnce you’ve identified a performance bottleneck, you’ll be amazed at how much you \\ncan improve performance by code tuning. You’ll rarely get a 10-fold improvement \\nfrom one technique, but you can effectively combine techniques; so keep trying, even \\nafter you find one that works.\\nI once wrote a software implementation of the Data Encryption Standard (DES). Actu-\\nally, I didn’t write it once—I wrote it about 30 times. Encryption according to DES \\nencodes digital data so that it can’t be unscrambled without a password. The encryp-\\ntion algorithm is so convoluted that it seems like it’s been used on itself. The perfor-\\nmance goal for my DES implementation was to encrypt an 18K file in 37 seconds on \\nan original IBM PC. My first implementation executed in 21 minutes and 40 seconds, \\nso I had a long row to hoe.\\nEven though most individual optimizations were small, cumulatively they were signifi-\\ncant. To judge from the percentage improvements, no three or even four optimizations \\nwould have met my performance goal. But the final combination was effective. The \\nmoral of the story is that if you dig deep enough, you can make some surprising gains.\\nCross-Reference The tech-\\nniques listed in this table are \\ndescribed in Chapter 26, \\n“Code-Tuning Techniques.”\\nThe code tuning I did in this case is the most aggressive code tuning I’ve ever done. At \\nthe same time, the final code is the most unreadable, unmaintainable code I’ve ever \\nwritten. The initial algorithm is complicated. The code resulting from the high-level \\nlanguage transformation was barely readable. The translation to assembler produced \\na single 500-line routine that I’m afraid to look at. In general, this relationship between \\ncode tuning and code quality holds true. Here’s a table that shows a history of the \\noptimizations:\\nOptimization Benchmark Time Improvement\\nImplement initially—straightforward 21:40 —\\nConvert from bit fields to arrays 7:30 65%\\nUnroll innermost for loop 6:00 20%\\nRemove final permutation 5:24 10%\\nCombine two variables 5:06 5%\\nUse a logical identity to combine the \\nfirst two steps of the DES algorithm\\n4:30 12%\\nMake two variables share the same \\nmemory to reduce data shuttling in \\ninner loop\\n3:36 20%\\nMake two variables share the same \\nmemory to reduce data shuttling in \\nouter loop\\n3:09 13%\\nUnfold all loops and use literal array \\nsubscripts\\n1:36 49%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 642}, page_content='606 Chapter 25: Code-Tuning Strategies\\n25.6 Summary of the Approach to Code Tuning\\nYou should take the following steps as you consider whether code tuning can help \\nyou improve the performance of a program:\\n1. Develop the software by using well-designed code that’s easy to understand and \\nmodify.\\n2. If performance is poor, \\na. Save a working version of the code so that you can get back to the “last \\nknown good state.” \\nb. Measure the system to find hot spots.\\nc. Determine whether the weak performance comes from inadequate design, \\ndata types, or algorithms and whether code tuning is appropriate. If code \\ntuning isn’t appropriate, go back to step 1.\\nd. Tune the bottleneck identified in step (c). \\ne. Measure each improvement one at a time. \\nf. If an improvement doesn’t improve the code, revert to the code saved in \\nstep (a). (Typically, more than half the attempted tunings will produce \\nonly a negligible improvement in performance or degrade performance.)\\n3. Repeat from step 2.\\nAdditional Resources\\ncc2e.com/2585 This section contains resources releated to performance improvement in general. For \\nadditional resources that discuss specific code-tuning techniques, see the “Additional \\nResources” section at the end of Chapter 26.\\nPerformance\\nSmith, Connie U. and Lloyd G. Williams. Performance Solutions: A Practical Guide to \\nCreating Responsive, Scalable Software. Boston, MA: Addison-Wesley, 2002. This book \\ncovers software performance engineering, an approach for building performance into \\nRemove routine calls and put all the \\ncode in line\\n0:45 53%\\nRewrite the whole routine in assem-\\nbler\\n0:22 51%\\nFinal 0:22 98%\\nNote: The steady progress of optimizations in this table doesn’t imply that all optimizations work. I haven’t \\nshown all the things I tried that doubled the run time. At least two-thirds of the optimizations I tried didn’t \\nwork.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 643}, page_content='Additional Resources 607\\nsoftware systems at all stages of development. It makes extensive use of examples and \\ncase studies for several kinds of programs. It includes specific recommendations for \\nWeb applications and pays special attention to scalability.\\ncc2e.com/2592 Newcomer, Joseph M. “Optimization: Your Worst Enemy.” May 2000, www.floun-\\nder.com/optimization.htm. Newcomer is an experienced systems programmer who \\ndescribes the various pitfalls of ineffective optimization strategies in graphic detail. \\nAlgorithms and Data Types\\ncc2e.com/2599 Knuth, Donald. The Art of Computer Programming, vol. 1, Fundamental Algorithms, 3d \\ned. Reading, MA: Addison-Wesley, 1997.\\nKnuth, Donald. The Art of Computer Programming, vol. 2, Seminumerical Algorithms, 3d \\ned. Reading, MA: Addison-Wesley, 1997.\\nKnuth, Donald. The Art of Computer Programming, vol. 3, Sorting and Searching, 2d ed. \\nReading, MA: Addison-Wesley, 1998.\\nThese are the first three volumes of a series that was originally intended to grow to \\nseven volumes. They can be somewhat intimidating. In addition to the English \\ndescription of the algorithms, they’re described in mathematical notation or MIX, an \\nassembly language for the imaginary MIX computer. The books contain exhaustive \\ndetails on a huge number of topics, and if you have an intense interest in a particular \\nalgorithm, you won’t find a better reference.\\nSedgewick, Robert. Algorithms in Java, Parts 1-4, 3d ed. Boston, MA: Addison-Wesley, \\n2002. This book’s four parts contain a survey of the best methods of solving a wide \\nvariety of problems. Its subject areas include fundamentals, sorting, searching, \\nabstract data type implementation, and advanced topics. Sedgewick’s Algorithms in \\nJava, Part 5, 3d ed. (2003) covers graph algorithms. Sedgewick’s Algorithms in C++, \\nParts 1-4, 3d ed. (1998), Algorithms in C++, Part 5, 3d ed. (2002), Algorithms in C, Parts \\n1-4, 3d ed. (1997), and Algorithms in C, Part 5, 3d ed. (2001) are similarly organized. \\nSedgewick was a Ph.D. student of Knuth’s.\\ncc2e.com/2506 CHECKLIST: Code-Tuning Strategies\\nOverall Program Performance\\n❑ Have you considered improving performance by changing the program \\nrequirements? \\n❑ Have you considered improving performance by modifying the program’s \\ndesign? \\n❑ Have you considered improving performance by modifying the class \\ndesign?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 644}, page_content='608 Chapter 25: Code-Tuning Strategies\\n❑ Have you considered improving performance by avoiding operating sys-\\ntem interactions? \\n❑ Have you considered improving performance by avoiding I/O? \\n❑ Have you considered improving performance by using a compiled \\nlanguage instead of an interpreted language? \\n❑ Have you considered improving performance by using compiler \\noptimizations? \\n❑ Have you considered improving performance by switching to different \\nhardware? \\n❑ Have you considered code tuning only as a last resort? \\nCode-Tuning Approach\\n❑ Is your program fully correct before you begin code tuning?\\n❑ Have you measured performance bottlenecks before beginning code tuning? \\n❑ Have you measured the effect of each code-tuning change?\\n❑ Have you backed out the code-tuning changes that didn’t produce the \\nintended improvement? \\n❑ Have you tried more than one change to improve performance of each bot-\\ntleneck—that is, iterated? \\nKey Points\\n■ Performance is only one aspect of overall software quality, and it’s usually not \\nthe most important. Finely tuned code is only one aspect of overall perfor-\\nmance, and it’s usually not the most significant. Program architecture, detailed \\ndesign, and data-structure and algorithm selection usually have more influence \\non a program’s execution speed and size than the efficiency of its code does.\\n■ Quantitative measurement is a key to maximizing performance. It’s needed to find \\nthe areas in which performance improvements will really count, and it’s needed \\nagain to verify that optimizations improve rather than degrade the software.\\n■ Most programs spend most of their time in a small fraction of their code. You \\nwon’t know which code that is until you measure it.\\n■ Multiple iterations are usually needed to achieve desired performance improve-\\nments through code tuning.\\n■ The best way to prepare for performance work during initial coding is to write \\nclean code that’s easy to understand and modify.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 645}, page_content='609\\nChapter 26\\nCode-Tuning Techniques\\ncc2e.com/2665 Contents\\n■ 26.1 Logic: page 610\\n■ 26.2 Loops: page 616\\n■ 26.3 Data Transformations: page 624\\n■ 26.4 Expressions: page 630\\n■ 26.5 Routines: page 639\\n■ 26.6 Recoding in a Low-Level Language: page 640\\n■ 26.7 The More Things Change, the More They Stay the Same: page 643\\nRelated Topics\\n■ Code-tuning strategies: Chapter 25\\n■ Refactoring: Chapter 24\\nCode tuning has been a popular topic during most of the history of computer program-\\nming. Consequently, once you’ve decided that you need to improve performance and \\nthat you want to do it at the code level (bearing in mind the warnings from Chapter 25, \\n“Code-Tuning Strategies”), you have a rich set of techniques at your disposal.\\nThis chapter focuses on improving speed and includes a few tips for making code \\nsmaller. Performance usually refers to both speed and size, but size reductions tend to \\ncome more from redesigning classes and data than from tuning code. Code tuning \\nrefers to small-scale changes rather than changes in larger-scale designs.\\nFew of the techniques in this chapter are so generally applicable that you’ll be able to \\ncopy the example code directly into your programs. The main purpose of the discus-\\nsion here is to illustrate a handful of code tunings that you can adapt to your situation.\\nThe code-tuning changes described in this chapter might seem cosmetically similar to \\nthe refactorings described in Chapter 24, but refactorings are changes that improve a \\nprogram’s internal structure (Fowler 1999). The changes in this chapter might better \\nbe called “anti-refactorings.” Far from “improving the internal structure,” these \\nchanges degrade the internal structure in exchange for gains in performance. This is'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 646}, page_content='610 Chapter 26: Code-Tuning Techniques\\ntrue by definition. If the changes didn’t degrade the internal structure, we wouldn’t \\nconsider them to be optimizations; we would use them by default and consider them \\nto be standard coding practice.\\nCross-Reference Code tun-\\nings are heuristics. For more \\non heuristics, see Section \\n5.3, “Design Building Blocks: \\nHeuristics.”\\nSome books present code-tuning techniques as “rules of thumb” or cite research that \\nsuggests that a specific tuning will produce the desired effect. As you’ll soon see, the \\n“rules of thumb” concept applies poorly to code tuning. The only reliable rule of \\nthumb is to measure the effect of each tuning in your environment. Thus, this chapter \\npresents a catalog of “things to try,” many of which won’t work in your environment \\nbut some of which will work very well indeed.\\n26.1 Logic\\nCross-Reference For other \\ndetails on using statement \\nlogic, see Chapters 14–19.\\nMuch of programming consists of manipulating logic. This section describes how to \\nmanipulate logical expressions to your advantage.\\nStop T esting When You Know the Answer\\nSuppose you have a statement like\\nif ( 5 < x ) and ( x < 10 ) then ...\\nOnce you’ve determined that x is not greater than 5, you don’t need to perform the \\nsecond half of the test.\\nCross-Reference For more \\non short-circuit evaluation, \\nsee “Knowing How Boolean \\nExpressions Are Evaluated” \\nin Section 19.1.\\nSome languages provide a form of expression evaluation known as “short-circuit eval-\\nuation,” which means that the compiler generates code that automatically stops test-\\ning as soon as it knows the answer. Short-circuit evaluation is part of C++’s standard \\noperators and Java’s “conditional” operators.\\nIf your language doesn’t support short-circuit evaluation natively, you have to avoid \\nusing and and or, adding logic instead. With short-circuit evaluation, the code above \\nchanges to this:\\nif ( 5 < x ) then\\n   if ( x < 10 ) then ...\\nThe principle of not testing after you know the answer is a good one for many other \\nkinds of cases as well. A search loop is a common case. If you’re scanning an array of \\ninput numbers for a negative value and you simply need to know whether a negative \\nvalue is present, one approach is to check every value, setting a negativeFound variable \\nwhen you find one. Here’s how the search loop would look:\\nC26619670.fm  Page 610  Tuesday, April 12, 2011  3:15 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 647}, page_content='26.1 Logic 611\\nC+ + Example of Not Stopping After You Know the Answer\\nnegativeInputFound = false;\\nfor ( i = 0; i < count; i++ ) {\\n   if ( input[ i ] < 0 ) {\\n      negativeInputFound = true;\\n   }\\n}\\nA better approach would be to stop scanning as soon as you find a negative value. Any \\nof these approaches would solve the problem:\\n■ Add a break statement after the negativeInputFound = true line.\\n■ If your language doesn’t have break, emulate a break with a goto that goes to the \\nfirst statement after the loop.\\n■ Change the for loop to a while loop, and check for negativeInputFound as well as \\nfor incrementing the loop counter past count.\\n■ Change the for loop to a while loop, put a sentinel value in the first array element \\nafter the last value entry, and simply check for a negative value in the while test. \\nAfter the loop terminates, see whether the position of the first found value is in the \\narray or one past the end. Sentinels are discussed in more detail later in the chapter.\\nHere are the results of using the break keyword in C++ and Java:\\nNote  (1) Times in this and the following tables in this chapter are given in seconds \\nand are meaningful only for comparisons across rows of each table. Actual times will \\nvary according to the compiler, compiler options used, and the environment in which \\neach test is run. (2) Benchmark results are typically made up of several thousand to \\nmany million executions of the code fragments to smooth out the sample-to-sample \\nfluctuations in the results. (3) Specific brands and versions of compilers aren’t indi-\\ncated. Performance characteristics vary significantly from brand to brand and version \\nto version. (4) Comparisons among results from different languages aren’t always \\nmeaningful because compilers for different languages don’t always offer comparable \\ncode-generation options. (5) The results shown for interpreted languages (PHP and \\nPython) are typically based on less than 1% of the test runs used for the other lan-\\nguages. (6) Some of the “time savings” percentages  might not be exactly reproducible \\nfrom the data in these tables due to rounding of the “straight time” and “code-tuned \\ntime” entries.\\nThe impact of this change varies a great deal depending on how many values you have \\nand how often you expect to find a negative value. This test assumed an average of 100 \\nvalues and assumed that a negative value would be found 50 percent of the time.\\nLanguage Straight Time Code -Tuned Time Time Savings\\nC+ + 4.27 3.68 14%\\nJava 4.85 3.46 29%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 648}, page_content='612 Chapter 26: Code-Tuning Techniques\\nOrder Tests by Frequency\\nArrange tests so that the one that’s fastest and most likely to be true is performed first. \\nIt should be easy to drop through the normal case, and if there are inefficiencies, they \\nshould be in processing the uncommon cases. This principle applies to case state-\\nments and to chains of if-then-elses.\\nHere’s a Select-Case statement that responds to keyboard input in a word processor:\\nVisual Basic Example of a Poorly Ordered Logical Test\\nSelect inputCharacter\\n   Case \"+\", \"=\"\\n      ProcessMathSymbol( inputCharacter )\\n   Case \"0\" To \"9\"\\n      ProcessDigit( inputCharacter )\\n   Case \",\", \".\", \":\", \";\", \"!\", \"?\"\\n      ProcessPunctuation( inputCharacter )\\n   Case \" \"\\n      ProcessSpace( inputCharacter )\\n   Case \"A\" To \"Z\", \"a\" To \"z\"\\n      ProcessAlpha( inputCharacter )\\n   Case Else\\n      ProcessError( inputCharacter )\\nEnd Select\\nThe cases in this case statement are ordered in something close to the ASCII sort order. In \\na case statement, however, the effect is often the same as if you had written a big set of if-\\nthen-elses, so if you get an \"a\" as an input character, the program tests whether it’s a math \\nsymbol, a punctuation mark, a digit, or a space before determining that it’s an alphabetic \\ncharacter. If you know the likely frequency of your input characters, you can put the most \\ncommon cases first. Here’s the reordered case statement:\\nVisual Basic Example of a Well-Ordered Logical Test\\nSelect inputCharacter\\n   Case \"A\" To \"Z\", \"a\" To \"z\"\\n      ProcessAlpha( inputCharacter )\\n   Case \" \"\\n      ProcessSpace( inputCharacter )\\n   Case \",\", \".\", \":\", \";\", \"!\", \"?\"\\n      ProcessPunctuation( inputCharacter )\\n   Case \"0\" To \"9\"\\n      ProcessDigit( inputCharacter )\\n   Case \"+\", \"=\"\\n      ProcessMathSymbol( inputCharacter )\\n   Case Else\\n      ProcessError( inputCharacter )\\nEnd Select'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 649}, page_content='26.1 Logic 613\\nBecause the most common case is usually found sooner in the optimized code, the net \\neffect will be the performance of fewer tests. Following are the results of this optimi-\\nzation with a typical mix of characters:\\nThe Microsoft Visual Basic results are as expected, but the Java and C# results are not as \\nexpected. Apparently that’s because of the way switch-case statements are structured in \\nC# and Java—because each value must be enumerated individually rather than in ranges, \\nthe C# and Java code doesn’t benefit from the optimization as the Visual Basic code does. \\nThis result underscores the importance of not following any optimization advice \\nblindly—specific compiler implementations will significantly affect the results.\\nYou might assume that the code generated by the Visual Basic compiler for a set of if-\\nthen-elses that perform the same test as the case statement would be similar. Take a \\nlook at those results:\\nThe results are quite different. For the same number of tests, the Visual Basic compiler \\ntakes about five times as long in the unoptimized case, four times in the optimized \\ncase. This suggests that the compiler is generating different code for the case approach \\nthan for the if-then-else approach.\\nThe improvement with if-then-elses is more consistent than it was with the case state-\\nments, but that’s a mixed blessing. In C# and Visual Basic, both versions of the case \\nstatement approach are faster than both versions of the if-then-else approach, whereas \\nin Java both versions are slower. This variation in results suggests a third possible opti-\\nmization, described in the next section.\\nLanguage Straight Time Code-Tuned Time Time Savings\\nC# 0.220 0.260 -18%\\nJava 2.56 2.56 0%\\nVisual Basic 0.280 0.260 7%\\nNote: Benchmarked with an input mix of 78 percent alphabetic characters, 17 percent spaces, and 5 percent \\npunctuation symbols.\\nLanguage Straight Time Code-Tuned Time Time Savings\\nC# 0.630 0.330 48%\\nJava 0.922 0.460 50%\\nVisual Basic 1.36 1.00 26%\\nC26619670.fm  Page 613  Tuesday, April 12, 2011  3:17 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 650}, page_content='614 Chapter 26: Code-Tuning Techniques\\nCompare Performance of Similar Logic Structures\\nThe test described above could be performed using either a case statement or if-then-\\nelses. Depending on the environment, either approach might work better. Here is the \\ndata from the preceding two tables reformatted to present the “code-tuned” times \\ncomparing if-then-else and case performance:\\nThese results defy any logical explanation. In one of the languages, case is dramatically \\nsuperior to if-then-else, and in another, if-then-else is dramatically superior to case. In \\nthe third language, the difference is relatively small. You might think that because C# \\nand Java share similar syntax for case statements, their results would be similar, but in \\nfact their results are opposite each other.\\nThis example clearly illustrates the difficulty of performing any sort of “rule of thumb” \\nor “logic” to code tuning—there is simply no reliable substitute for measuring results.\\nSubstitute T able Lookups for Complicated Expressions\\nCross-Reference For details \\non using table lookups to \\nreplace complicated logic, \\nsee Chapter 18, “Table-\\nDriven Methods.”\\nIn some circumstances, a table lookup might be quicker than traversing a complicated \\nchain of logic. The point of a complicated chain is usually to categorize something and \\nthen to take an action based on its category. As an abstract example, suppose you \\nwant to assign a category number to something based on which of three groups—\\nGroups A, B, and C—it falls into:\\nLanguage case if-then-else Time Savings Performance Ratio\\nC# 0.260 0.330 -27% 1:1\\nJava 2.56 0.460 82% 6:1\\nVisual Basic 0.260 1.00 -258% 1:4\\nA\\n1\\n211\\n22\\nB\\nC\\n0 3\\nC26619670.fm  Page 614  Tuesday, April 12, 2011  3:19 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 651}, page_content='26.1 Logic 615\\nThis complicated logic chain assigns the category numbers:\\nC+ + Example of a Complicated Chain of Logic\\nif ( ( a && !c ) || ( a && b && c ) ) {\\n   category = 1;\\n}\\nelse if ( ( b && !a ) || ( a && c && !b ) ) {\\n   category = 2;\\n}\\nelse if ( c && !a && !b ) {\\n   category = 3;\\n}\\nelse {\\n   category = 0;\\n}\\nYou can replace this test with a more modifiable and higher-performance lookup table:\\nC+ + Example of Using a Table Lookup to Replace Complicated Logic\\n// define categoryTable\\nThis table definition is \\nsomewhat difficult to \\nunderstand. Any comment-\\ning you can do to make \\ntable definitions readable \\nhelps.\\nstatic int categoryTable[ 2 ][ 2 ][ 2 ] = {\\n   // !b!c  !bc  b!c  bc\\n       0,   3,   2,   2,   //   !a\\n       1,   2,   1,   1    //    a\\n};\\n...\\ncategory = categoryTable[ a ][ b ][ c ];\\nAlthough the definition of the table is hard to read, if it’s well documented it won’t be \\nany harder to read than the code for the complicated chain of logic was. If the defini-\\ntion changes, the table will be much easier to maintain than the earlier logic would \\nhave been. Here are the performance results:\\nUse Lazy Evaluation\\nOne of my former roommates was a great procrastinator. He justified his laziness by \\nsaying that many of the things people feel rushed to do simply don’t need to be done. \\nIf he waited long enough, he claimed, the things that weren’t important would be pro-\\ncrastinated into oblivion and he wouldn’t waste his time doing them.\\nLazy evaluation is based on the principle my roommate used. If a program uses lazy \\nevaluation, it avoids doing any work until the work is needed. Lazy evaluation is sim-\\nilar to just-in-time strategies that do the work closest to when it’s needed.\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nC+ + 5.04 3.39 33% 1.5:1\\nVisual Basic 5.21 2.60 50% 2:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 652}, page_content='616 Chapter 26: Code-Tuning Techniques\\nSuppose, for example, that your program contains a table of 5000 values, generates \\nthe whole table at startup time, and then us es it as the program executes. If the pro-\\ngram uses only a small percentage of the entries in the table, it might make more sense \\nto compute them as they’re needed rather than all at once. Once an entry is com-\\nputed, it can still be stored for future reference (otherwise known as “cached”).\\n26.2 Loops\\nCross-Reference For other \\ndetails on loops, see Chapter \\n16, “Controlling Loops.”\\nBecause loops are executed many times, the hot spots in a program are often inside \\nloops. The techniques in this section make the loop itself faster.\\nUnswitching\\nSwitching refers to making a decision inside a loop every time it’s executed. If the deci-\\nsion doesn’t change while the loop is executing, you can unswitch the loop by making \\nthe decision outside the loop. Usually this requires turning the loop inside out, put-\\nting loops inside the conditional rather than putting the conditional inside the loop. \\nHere’s an example of a loop before unswitching:\\nC+ + Example of a Switched Loop\\nfor ( i = 0; i < count; i++ ) {\\n   if ( sumType == SUMTYPE_NET ) {\\n      netSum = netSum + amount[ i ];\\n   }\\n   else { \\n      grossSum = grossSum + amount[ i ];\\n   }\\n}\\nIn this code, the test if ( sumType == SUMTYPE_NET ) is repeated through each itera-\\ntion, even though it’ll be the same each time through the loop. You can rewrite the \\ncode for a speed gain this way:\\nC+ + Example of an Unswitched Loop\\nif ( sumType == SUMTYPE_NET ) {\\n   for ( i = 0; i < count; i++ ) {\\n      netSum = netSum + amount[ i ];\\n   }\\n}\\nelse { \\n   for ( i = 0; i < count; i++ ) {\\n      grossSum = grossSum + amount[ i ];\\n   }\\n}\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 653}, page_content='26.2 Loops 617\\nNote This code fragment violates several rules of good programming. Readability \\nand maintenance are usually more important than execution speed or size, but in this \\nchapter the topic is performance, and that implies a tradeoff with the other objectives. \\nAs in the last chapter, you’ll see examples of coding practices here that aren’t recom-\\nmended in other parts of this book.\\nThis is good for about a 20 percent time savings:\\nA hazard distinct to this case is that the two loops have to be maintained in parallel. If \\ncount changes to clientCount, you have to remember to change it in both places, which \\nis an annoyance for you and a maintenance headache for anyone else who has to work \\nwith the code.\\nThis example also illustrates a key challenge in code tuning: the effect of any specific \\ncode tuning is not predictable. The code tuning produced significant improvements \\nin three of the four languages but not in Visual Basic. To perform this specific optimi-\\nzation in this specific version of Visual Basic would produce less maintainable code \\nwithout any offsetting gain in performance. The general lesson is that you must mea-\\nsure the effect of each specific optimization to be sure of its effect—no exceptions.\\nJamming\\nJamming, or “fusion,” is the result of combining two loops that operate on the same \\nset of elements. The gain lies in cutting the loop overhead from two loops to one. \\nHere’s a candidate for loop jamming:\\nVisual Basic Example of Separate Loops That Could Be Jammed\\nFor i = 0 to employeeCount - 1\\n   employeeName( i ) = \"\"\\nNext\\n...\\nFor i = 0 to employeeCount - 1\\n   employeeEarnings( i ) = 0\\nNext\\nWhen you jam loops, you find code in two loops that you can combine into one. Usu-\\nally, that means the loop counters have to be the same. In this example, both loops \\nrun from 0 to employeeCount - 1, so you can jam them:\\nLanguage Straight Time Code -Tuned Time Time Savings\\nC+ + 2.81 2.27 19%\\nJava 3.97 3.12 21%\\nVisual Basic 2.78 2.77 <1%\\nPython 8.14 5.87 28%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 654}, page_content='618 Chapter 26: Code-Tuning Techniques\\nVisual Basic Example of a Jammed Loop\\nFor i = 0 to employeeCount - 1\\n   employeeName( i ) = \"\" \\n   employeeEarnings( i ) = 0\\nNext\\nHere are the savings:\\nAs before, the results vary significantly among languages.\\nLoop jamming has two main hazards. First, the indexes for the two parts that have \\nbeen jammed might change so that they’re no longer compatible. Second, you might \\nnot be able to combine the loops easily. Before you combine the loops, make sure \\nthey’ll still be in the right order with respect to the rest of the code.\\nUnrolling\\nThe goal of loop unrolling is to reduce the amount of loop housekeeping. In Chapter \\n25, a loop was completely unrolled and 10 lines of code were shown to be faster than \\n3. In that case, the loop that went from 3 to 10 lines was unrolled so that all 10 array \\naccesses were done individually.\\nAlthough completely unrolling a loop is a fast solution and works well when you’re \\ndealing with a small number of elements, it’s not practical when you have a large num-\\nber of elements or when you don’t know in advance how many elements you’ll have. \\nHere’s an example of a general loop:\\nJava Example of a Loop That Can Be Unrolled\\nNormally, you’d probably use \\na for loop for a job like this, \\nbut to optimize, you’d have \\nto convert to a while loop. \\nFor clarity, a while loop is \\nshown here.\\ni = 0;\\nwhile ( i < count ) {\\n   a[ i ] = i;\\n   i = i + 1;\\n}\\nTo unroll the loop partially, you handle two or more cases in each pass through the \\nloop instead of one. This unrolling hurts readability but doesn’t hurt the generality of \\nthe loop. Here’s the loop unrolled once:\\nLanguage Straight Time Code -Tuned Time Time Savings\\nC++ 3.68 2.65 28%\\nPHP 3.97 2.42 32%\\nVisual Basic 3.75 3.56 4%\\nNote: Benchmarked for the case in which employeeCount equals 100.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 655}, page_content='26.2 Loops 619\\nJava Example of a Loop That’s Been Unrolled Once\\nThese lines pick up the case \\nthat might fall through the \\ncracks if the loop went by \\ntwos instead of by ones.\\ni = 0;\\nwhile ( i < count - 1 ) {\\n   a[ i ] = i;\\n   a[ i + 1 ] = i + 1;\\n   i = i + 2;\\n}\\nif ( i == count - 1) {\\n   a[ count - 1 ] = count - 1;\\n}\\nThe technique replaced the original a[ i ] = i line with two lines, and i is incremented \\nby 2 rather than by 1. The extra code after the while loop is needed when count is odd \\nand the loop has one iteration left after the loop terminates.\\nWhen five lines of straightforward code expand to nine lines of tricky code, the code \\nbecomes harder to read and maintain. Except for the gain in speed, its quality is poor. \\nPart of any design discipline, however, is making necessary tradeoffs. So, even though \\na particular technique generally represents poor coding practice, specific circum-\\nstances might make it the best one to use.\\nHere are the results of unrolling the loop:\\nA gain of 16 to 43 percent is respectable, although again you have to watch out for \\nhurting performance, as the Python benchmark shows. The main hazard of loop \\nunrolling is an off-by-one error in the code after the loop that picks up the last case.\\nWhat if you unroll the loop even further, going for two or more unrollings? Do you get \\nmore benefit if you unroll a loop twice?\\nJava Example of a Loop That’s Been Unrolled Twice\\ni = 0;\\nwhile ( i < count - 2 ) {\\n   a[ i ] = i;\\n   a[ i + 1 ] = i+1;\\n   a[ i + 2 ] = i+2;\\n   i = i + 3;\\n}\\nCODING \\nHORROR\\nLanguage Straight Time Code-Tuned Time Time Savings\\nC+ + 1.75 1.15 34%\\nJava 1.01 0.581 43%\\nPHP 5.33 4.49 16%\\nPython 2.51 3.21 -27%\\nNote: Benchmarked for the case in which count equals 100.\\nCODING \\nHORROR\\nC26619670.fm  Page 619  Tuesday, April 12, 2011  3:20 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 656}, page_content='620 Chapter 26: Code-Tuning Techniques\\nif ( i <= count - 1 ) {\\n    a[ count - 1 ] = count - 1;\\n}\\nif ( i == count - 2 ) {\\n    a[ count -2 ] = count - 2;\\n}\\nHere are the results of unrolling the loop the second time:\\nThe results indicate that further loop unrolling can result in further time savings, but \\nnot necessarily so, as the Java measurement shows. The main concern is how Byzantine \\nyour code becomes. When you look at the previous code, you might not think it looks \\nincredibly complicated, but when you realize that it started life a couple of pages ago as \\na five-line loop, you can appreciate the tradeoff between performance and readability.\\nMinimizing the Work Inside Loops\\nOne key to writing effective loops is to minimize the work done inside a loop. If you \\ncan evaluate a statement or part of a statement outside a loop so that only the result is \\nused inside the loop, do so. It’s good programming practice, and in some cases it \\nimproves readability.\\nSuppose you have a complicated pointer expression inside a hot loop that looks like this:\\nC+ + Example of a Complicated Pointer Expression Inside a Loop\\nfor ( i = 0; i < rateCount; i++ ) {\\n   netRate[ i ] = baseRate[ i ] * rates->discounts->factors->net;\\n}\\nIn this case, assigning the complicated pointer expression to a well-named variable \\nimproves readability and often improves performance.\\nC+ + Example of Simplifying a Complicated Pointer Expression\\nquantityDiscount = rates->discounts->factors->net;\\nfor ( i = 0; i < rateCount; i++ ) {\\n   netRate[ i ] = baseRate[ i ] * quantityDiscount;\\n}\\nLanguage Straight Time\\nDouble Unrolled \\nTime Time Savings\\nC++ 1.75 1.01 42%\\nJava 1.01 0.581 43%\\nPHP 5.33 3.70 31%\\nPython 2.51 2.79 -12%\\nNote: Benchmarked for the case in which count equals 100.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 657}, page_content='26.2 Loops 621\\nThe extra variable, quantityDiscount, makes it clear that the baseRate array is being \\nmultiplied by a quantity-discount factor to compute the net rate. That wasn’t at all \\nclear from the original expression in the loop. Putting the complicated pointer expres-\\nsion into a variable outside the loop also saves the pointer from being dereferenced \\nthree times for each pass through the loop, resulting in the following savings:\\nExcept for the Java compiler, the savings aren’t anything to crow about, implying that \\nduring initial coding you can use whichever technique is more readable without wor-\\nrying about the speed of the code until later.\\nSentinel Values\\nWhen you have a loop with a compound test, you can often save time by simplifying \\nthe test. If the loop is a search loop, one way to simplify the test is to use a sentinel \\nvalue, a value that you put just past the end of the search range and that’s guaranteed \\nto terminate the search.\\nThe classic example of a compound test that can be improved by use of a sentinel is \\nthe search loop that checks both whether it has found the value it’s seeking and \\nwhether it has run out of values. Here’s the code:\\nC# Example of Compound Tests in a Search Loop\\nfound = FALSE;\\ni = 0;\\nHere’s the compound test. while ( ( !found ) && ( i < count ) ) {\\n   if ( item[ i ] == testValue ) {\\n      found = TRUE;\\n   } \\n   else {\\n      i++;\\n   }\\n}\\nif ( found ) {\\n   ...\\nIn this code, each iteration of the loop tests for !found and for i < count. The purpose of \\nthe !found test is to determine when the desired element has been found. The purpose \\nLanguage Straight Time Code -Tuned Time Time Savings\\nC+ + 3.69 2.97 19%\\nC# 2.27 1.97 13%\\nJava 4.13 2.35 43%\\nNote: Benchmarked for the case in which rateCount equals 100.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 658}, page_content='622 Chapter 26: Code-Tuning Techniques\\nof the i < count test is to avoid running past the end of the array. Inside the loop, each \\nvalue of item[] is tested individually, so the loop really has three tests for each iteration.\\nIn this kind of search loop, you can combine the three tests so that you test only once \\nper iteration by putting a “sentinel” at the end of the search range to stop the loop. In \\nthis case, you can simply assign the value you’re looking for to the element just \\nbeyond the end of the search range. (Remember to leave space for that element when \\nyou declare the array.) You then check each element, and if you don’t find the element \\nuntil you find the one you stuck at the end, you know that the value you’re looking for \\nisn’t really there. Here’s the code:\\nC# Example of Using a Sentinel Value to Speed Up a Loop\\n// set sentinel value, preserving the original value\\ninitialValue = item[ count ];\\nRemember to allow space \\nfor the sentinel value at the \\nend of the array.\\nitem[ count ] = testValue;\\ni = 0;\\nwhile ( item[ i ] != testValue ) {\\n   i++;\\n}\\n// check if value was found\\nif ( i < count ) {\\n   ...\\nWhen item is an array of integers, the savings can be dramatic:\\nThe Visual Basic results are particularly dramatic, but all the results are good. When \\nthe kind of array changes, however, the results also change. When item is an array of \\nsingle-precision floating-point numbers, the results are as follows:\\nAs usual, the results vary significantly.\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nC# 0.771 0.590 23% 1.3:1\\nJava 1.63 0.912 44% 2:1\\nVisual Basic 1.34 0.470 65% 3:1\\nNote: Search is of a 100-element array of integers.\\nLanguage Straight Time Code -Tuned Time Time Savings\\nC# 1.351 1.021 24%\\nJava 1.923 1.282 33%\\nVisual Basic 1.752 1.011 42%\\nNote: Search is of a 100-element array of 4-byte floating-point numbers.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 659}, page_content='26.2 Loops 623\\nThe sentinel technique can be applied to virtually any situation in which you use a lin-\\near search—to linked lists as well as arrays. The only caveats are that you must choose \\nthe sentinel value carefully and that you must be careful about how you put the senti-\\nnel value into the data structure.\\nPutting the Busiest Loop on the Inside\\nWhen you have nested loops, think about which loop you want on the outside and \\nwhich you want on the inside. Following is an example of a nested loop that can be \\nimproved:\\nJava Example of a Nested Loop That Can Be Improved\\nfor ( column = 0; column < 100; column++ ) {\\n   for ( row = 0; row < 5; row++ ) {\\n      sum = sum + table[ row ][ column ];\\n   }\\n}\\nThe key to improving the loop is that the outer loop executes much more often than the \\ninner loop. Each time the loop executes, it has to initialize the loop index, increment it \\non each pass through the loop, and check it after each pass. The total number of loop \\nexecutions is 100 for the outer loop and 100 * 5 = 500 for the inner loop, for a total of \\n600 iterations. By merely switching the inner and outer loops, you can change the total \\nnumber of iterations to 5 for the outer loop and 5 * 100 = 500 for the inner loop, for a \\ntotal of 505 iterations. Analytically, you’d expect to save about (600 – 505) / 600 = 16 \\npercent by switching the loops. Here’s the measured difference in performance:\\nThe results vary significantly, which shows once again that you have to measure the \\neffect in your particular environment before you can be sure your optimization will help.\\nStrength Reduction\\nReducing strength means replacing an expensive operation such as multiplication \\nwith a cheaper operation such as addition. Sometimes you’ll have an expression \\ninside a loop that depends on multiplying the loop index by a factor. Addition is usu-\\nally faster than multiplication, and if you can compute the same number by adding \\nthe amount on each iteration of the loop rather than by multiplying, the code will typ-\\nically run faster. Here’s an example of code that uses multiplication:\\nLanguage Straight Time Code -Tuned Time Time Savings\\nC++ 4.75 3.19 33%\\nJava 5.39 3.56 34%\\nPHP 4.16 3.65 12%\\nPython 3.48 3.33 4%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 660}, page_content='624 Chapter 26: Code-Tuning Techniques\\nVisual Basic Example of Multiplying a Loop Index\\nFor i = 0 to saleCount - 1\\n   commission( i ) = (i + 1) * revenue * baseCommission * discount\\nNext\\nThis code is straightforward but expensive. You can rewrite the loop so that you accu-\\nmulate multiples rather than computing them each time. This reduces the strength of \\nthe operations from multiplication to addition.\\nVisual Basic Example of Adding Rather Than Multiplying\\nincrementalCommission = revenue * baseCommission * discount\\ncumulativeCommission = incrementalCommission\\nFor i = 0 to saleCount - 1\\n   commission( i ) = cumulativeCommission\\n   cumulativeCommission = cumulativeCommission + incrementalCommission\\nNext\\nMultiplication is expensive, and this kind of change is like a manufacturer’s coupon \\nthat gives you a discount on the cost of the loop. The original code incremented i each \\ntime and multiplied it by revenue * baseCommission * discount—first by 1, then by 2, \\nthen by 3, and so on. The optimized code sets incrementalCommission equal to revenue \\n* baseCommission * discount. It then adds incrementalCommission to cumulativeCommis-\\nsion on each pass through the loop. On the first pass, it’s been added once; on the sec-\\nond pass, it’s been added twice; on the third pass, it’s been added three times; and so \\non. The effect is the same as multiplying incrementalCommission by 1, then by 2, then \\nby 3, and so on, but it’s cheaper.\\nThe key is that the original multiplication has to depend on the loop index. In this \\ncase, the loop index was the only part of the expression that varied, so the expression \\ncould be recoded more economically. Here’s how much the rewrite helped in some \\ntest cases:\\n26.3 Data Transformations\\nChanges in data types can be a powerful aid in reducing program size and improving \\nexecution speed. Data-structure design is outside the scope of this book, but modest \\nchanges in the implementation of a specific data type can also improve performance. \\nHere are a few ways to tune your data types.\\nLanguage Straight Time Code -Tuned Time Time Savings\\nC+ + 4.33 3.80 12%\\nVisual Basic 3.54 1.80 49%\\nNote: Benchmark performed with saleCount equals 20. All computed variables are floating point.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 661}, page_content='26.3 Data Transformations 625\\nUse Integers Rather Than Floating-Point Numbers\\nCross-Reference For details \\non using integers and float-\\ning point, see Chapter 12, \\n“Fundamental Data Types.”\\nInteger addition and multiplication tend to be faster than floating point. Changing a \\nloop index from a floating point to an integer, for example, can save time:\\nVisual Basic Example of a Loop That Uses a Time-Consuming Floating-Point \\nLoop Index\\nDim x As Single\\nFor x = 0 to 99\\n   a( x ) = 0\\nNext\\nContrast this with a similar Visual Basic loop that explicitly uses the integer type:\\nVisual Basic Example of a Loop That Uses a Timesaving Integer Loop Index\\nDim i As Integer\\nFor i = 0 to 99\\n   a( i ) = 0\\nNext\\nHow much difference does it make? Here are the results for this Visual Basic code and \\nfor similar code in C++ and PHP:\\nUse the Fewest Array Dimensions Possible\\nCross-Reference For details \\non arrays, see Section 12.8, \\n“Arrays.”\\nConventional wisdom maintains that multiple dimensions on arrays are expensive. If \\nyou can structure your data so that it’s in a one-dimensional array rather than a two-\\ndimensional or three-dimensional array, you might be able to save some time. Sup-\\npose you have initialization code like this:\\nJava Example of a Standard, Two-Dimensional Array Initialization\\nfor ( row = 0; row < numRows; row++ ) {\\n   for ( column = 0; column < numColumns; column++ ) {\\n      matrix[ row ][ column ] = 0;\\n   }\\n}\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nC+ + 2.80 0.801 71% 3.5:1\\nPHP 5.01 4.65 7% 1:1\\nVisual Basic 6.84 0.280 96% 25:1\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 662}, page_content='626 Chapter 26: Code-Tuning Techniques\\nWhen this code is run with 50 rows and 20 columns, it takes twice as long with my \\ncurrent Java compiler as when the array is restructured so that it’s one-dimensional. \\nHere’s how the revised code would look:\\nJava Example of a One-Dimensional Representation of an Array\\nfor ( entry = 0; entry < numRows * numColumns; entry++ ) {\\n   matrix[ entry ] = 0;\\n}\\nAnd here’s a summary of the results, with the addition of comparable results in sev-\\neral other languages:\\nThe results of this optimization are excellent in Visual Basic and Java, good in PHP \\nand Python, but mediocre in C++ and C#. Of course, the C# compiler’s unoptimized \\ntime was easily the best of the group, so you can’t be too hard on it.\\nThis wide range of results again shows the hazard of following any code-tuning advice \\nblindly. You can never be sure until you try the advice in your specific circumstances.\\nMinimize Array References\\nIn addition to minimizing accesses to doubly or triply dimensioned arrays, it’s often \\nadvantageous to minimize array accesses, period. A loop that repeatedly uses one ele-\\nment of an array is a good candidate for the application of this technique. Here’s an \\nexample of an unnecessary array access:\\nC+ + Example of Unnecessarily Referencing an Array Inside a Loop\\nfor ( discountType = 0; discountType < typeCount; discountType++ ) {\\n   for ( discountLevel = 0; discountLevel < levelCount; discountLevel++ ) {\\n      rate[ discountLevel ] = rate[ discountLevel ] * discount[ discountType ];\\n   }\\n}\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nC+ + 8.75 7.82 11% 1:1\\nC# 3.28 2.99 9% 1:1\\nJava 7.78 4.14 47% 2:1\\nPHP 6.24 4.10 34% 1.5:1\\nPython 3.31 2.23 32% 1.5:1\\nVisual Basic 9.43 3.22 66% 3:1\\nNote: Times for Python and PHP aren’t directly comparable to times for the other languages because they \\nwere run <1% as many iterations as the other languages.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 663}, page_content='26.3 Data Transformations 627\\nThe reference to discount[ discountType ] doesn’t change when discountLevel changes in \\nthe inner loop. Consequently, you can move it out of the inner loop so that you’ll have \\nonly one array access per execution of the outer loop rather than one for each execu-\\ntion of the inner loop. The next example shows the revised code.\\nC+ + Example of Moving an Array Reference Outside a Loop\\nfor ( discountType = 0; discountType < typeCount; discountType++ ) {\\n   thisDiscount = discount[ discountType ];\\n   for ( discountLevel = 0; discountLevel < levelCount; discountLevel++ ) {\\n      rate[ discountLevel ] = rate[ discountLevel ] * thisDiscount;\\n   }\\n}\\nHere are the results:\\nAs usual, the results vary significantly from compiler to compiler.\\nUse Supplementary Indexes\\nUsing a supplementary index means adding related data that makes accessing a data \\ntype more efficient. You can add the related data to the main data type, or you can \\nstore it in a parallel structure.\\nString-Length Index\\nOne example of using a supplementary index can be found in the different string-stor-\\nage strategies. In C, strings are terminated by a byte that’s set to 0. In Visual Basic \\nstring format, a length byte hidden at the beginning of each string indicates how long \\nthe string is. To determine the length of a string in C, a program has to start at the \\nbeginning of the string and count each byte until it finds the byte that’s set to 0. To \\ndetermine the length of a Visual Basic stri ng, the program just looks at the length \\nbyte. Visual Basic length byte is an example of augmenting a data type with an index \\nto make certain operations—like computing the length of a string—faster.\\nYou can apply the idea of indexing for length to any variable-length data type. It’s \\noften more efficient to keep track of the length of the structure rather than computing \\nthe length each time you need it.\\nLanguage Straight Time Code-Tuned Time Time Savings\\nC+ + 32.1 34.5 -7%\\nC# 18.3 17.0 7%\\nVisual Basic 23.2 18.4 20%\\nNote: Benchmark times were computed for the case in which typeCount equals 10 and levelCount equals 100.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 664}, page_content='628 Chapter 26: Code-Tuning Techniques\\nIndependent, Parallel Index Structure\\nSometimes it’s more efficient to manipulate an index to a data type than it is to manip-\\nulate the data type itself. If the items in the data type are big or hard to move (on disk, \\nperhaps), sorting and searching index references is faster than working with the data \\ndirectly. If each data item is large, you can create an auxiliary structure that consists of \\nkey values and pointers to the detailed information. If the difference in size between \\nthe data-structure item and the auxiliary-structure item is great enough, sometimes \\nyou can store the key item in memory even when the data item has to be stored exter-\\nnally. All searching and sorting is done in memory, and you have to access the disk \\nonly once, when you know the exact location of the item you want.\\nUse Caching\\nCaching means saving a few values in such a way that you can retrieve the most com-\\nmonly used values more easily than the less commonly used values. If a program ran-\\ndomly reads records from a disk, for example, a routine might use a cache to save the \\nrecords read most frequently. When the routine receives a request for a record, it \\nchecks the cache to see whether it has the record. If it does, the record is returned \\ndirectly from memory rather than from disk.\\nIn addition to caching records on disk, you can apply caching in other areas. In a \\nMicrosoft Windows font-proofing program, the performance bottleneck was in \\nretrieving the width of each character as it was displayed. Caching the most recently \\nused character width roughly doubled the display speed.\\nYou can cache the results of time-consuming computations too—especially if the \\nparameters to the calculation are simple. Suppose, for example, that you need to com-\\npute the length of the hypotenuse of a right triangle, given the lengths of the other two \\nsides. The straightforward implementation of the routine would look like this:\\nJava Example of a Routine That’s Conducive to Caching\\ndouble Hypotenuse(\\n   double sideA,\\n   double sideB\\n   ) {\\n   return Math.sqrt( ( sideA * sideA ) + ( sideB * sideB ) );\\n}\\nIf you know that the same values tend to be requested repeatedly, you can cache val-\\nues this way:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 665}, page_content='26.3 Data Transformations 629\\nJava Example of Caching to Avoid an Expensive Computation\\nprivate double cachedHypotenuse = 0;\\nprivate double cachedSideA = 0;\\nprivate double cachedSideB = 0;\\npublic double Hypotenuse(\\n   double sideA,\\n   double sideB\\n   ) {\\n   // check to see if the triangle is already in the cache\\n   if ( ( sideA == cachedSideA ) && ( sideB == cachedSideB ) ) {\\n      return cachedHypotenuse;\\n   }\\n   // compute new hypotenuse and cache it\\n   cachedHypotenuse = Math.sqrt( ( sideA * sideA ) + ( sideB * sideB ) );\\n   cachedSideA = sideA;\\n   cachedSideB = sideB;\\n   return cachedHypotenuse;\\n}\\nThe second version of the routine is more complicated than the first and takes up \\nmore space, so speed has to be at a premium to justify it. Many caching schemes cache \\nmore than one element, so they have even more overhead. Here’s the speed difference \\nbetween these two versions:\\nThe success of the cache depends on the relative costs of accessing a cached element, \\ncreating an uncached element, and saving a new element in the cache. Success also \\ndepends on how often the cached information is requested. In some cases, success \\nmight also depend on caching done by the hardware. Generally, the more it costs to \\ngenerate a new element and the more times the same information is requested, the \\nmore valuable a cache is. The cheaper it is to access a cached element and save new \\nelements in the cache, the more valuable a cache is. As with other optimization tech-\\nniques, caching adds complexity and tends to be error-prone.\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nC+ + 4.06 1.05 74% 4:1\\nJava 2.54 1.40 45% 2:1\\nPython 8.16 4.17 49% 2:1\\nVisual Basic 24.0 12.9 47% 2:1\\nNote: The results shown assume that the cache is hit twice for each time it’s set.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 666}, page_content='630 Chapter 26: Code-Tuning Techniques\\n26.4 Expressions\\nCross-Reference For more \\ninformation on expressions, \\nsee Section 19.1, “Boolean \\nExpressions.”\\nMuch of the work in a program is done inside mathematical or logical expressions. \\nComplicated expressions tend to be expensive, so this section looks at ways to make \\nthem cheaper.\\nExploit Algebraic Identities\\nYou can use algebraic identities to replace costly operations with cheaper ones. For \\nexample, the following expressions are logically equivalent:\\nnot a and not b\\nnot (a or b)\\nIf you choose the second expression instead of the first, you can save a not operation.\\nAlthough the savings from avoiding a single not operation are probably inconsequen-\\ntial, the general principle is powerful. Jon Bentley describes a program that tested \\nwhether sqrt(x) < sqrt(y) (1982). Since sqrt(x) is less than sqrt(y) only when x is less \\nthan y, you can replace the first test with x < y. Given the cost of the sqrt() routine, \\nyou’d expect the savings to be dramatic, and they are. Here are the results:\\nUse Strength Reduction\\nAs mentioned earlier, strength reduction means replacing an expensive operation \\nwith a cheaper one. Here are some possible substitutions:\\n■ Replace multiplication with addition.\\n■ Replace exponentiation with multiplication.\\n■ Replace trigonometric routines with their trigonometric identities.\\n■ Replace longlong integers with longs or ints (but watch for performance issues \\nassociated with using native-length vs. non-native-length integers)\\n■ Replace floating-point numbers with fixed-point numbers or integers.\\n■ Replace double-precision floating points with single-precision numbers.\\n■ Replace integer multiplication-by-two and division-by-two with shift operations.\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nC+ + 7.43 0.010 99.9% 750:1\\nVisual Basic 4.59 0.220 95% 20:1\\nPython 4.21 0.401 90% 10:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 667}, page_content='26.4 Expressions 631\\nSuppose you have to evaluate a polynomial. If you’re rusty on polynomials, they’re the \\nthings that look like Ax2 + Bx + C. The letters A, B, and C are coefficients, and x is a \\nvariable. General code to evaluate an nth-order polynomial looks like this:\\nVisual Basic Example of Evaluating a Polynomial\\nvalue = coefficient( 0 )\\nFor power = 1 To order\\n   value = value + coefficient( power ) * x^power\\nNext \\nIf you’re thinking about strength reduction, you’ll look at the exponentiation operator \\nwith a jaundiced eye. One solution would be to replace the exponentiation with a mul-\\ntiplication on each pass through the loop, which is analogous to the strength-reduc-\\ntion case a few sections ago in which a multiplication was replaced with an addition. \\nHere’s how the reduced-strength polynomial evaluation would look:\\nVisual Basic Example of a Reduced-Strength Method of Evaluating a Polynomial\\nvalue = coefficient( 0 )\\npowerOfX = x\\nFor power = 1 to order\\n   value = value + coefficient( power ) * powerOfX\\n   powerOfX = powerOfX * x\\nNext \\nThis produces a noticeable advantage if you’re working with second-order polynomi-\\nals—that is, polynomials in which the highest-power term is squared—or higher-order \\npolynomials:\\nIf you’re serious about strength reduction, you still won’t care for those two floating-\\npoint multiplications. The strength-reduction principle suggests that you can further \\nreduce the strength of the operations in the loop by accumulating powers rather than \\nmultiplying them each time:\\nVisual Basic Example of Further Reducing the Strength Required to Evaluate \\na Polynomial\\nvalue = 0\\nFor power = order to 1 Step -1\\n   value = ( value + coefficient( power ) ) * x\\nNext \\nvalue = value + coefficient( 0 )\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nPython 3.24 2.60 20% 1:1\\nVisual Basic 6.26 0.160 97% 40:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 668}, page_content='632 Chapter 26: Code-Tuning Techniques\\nThis method eliminates the extra powerOfX variable and replaces the two multiplica-\\ntions in each pass through the loop with one. The results: \\nThis is a good example of theory not holding up very well to practice. The code with \\nreduced strength seems like it should be faster, but it isn’t. One possibility is that dec-\\nrementing a loop by 1 instead of incrementing it by 1 in Visual Basic hurts perfor-\\nmance, but you’d have to measure that hypothesis to be sure.\\nInitialize at Compile Time\\nIf you’re using a named constant or a magic number in a routine call and it’s the only \\nargument, that’s a clue that you could precompute the number, put it into a constant, \\nand avoid the routine call. The same principle applies to multiplications, divisions, \\nadditions, and other operations.\\nI once needed to compute the base-two logarithm of an integer, truncated to the near-\\nest integer. The system didn’t have a log-base-two routine, so I wrote my own. The \\nquick and easy approach was to use this fact:\\nlog(x)base = log(x) / log(base)\\nGiven this identity, I could write a routine like this one:\\nCross-Reference For details \\non binding variables to their \\nvalues, see Section 10.6, \\n“Binding Time.”\\nC+ + Example of a Log-Base-Two Routine Based on System Routines\\nunsigned int Log2( unsigned int x ) {\\n   return (unsigned int) ( log( x ) / log( 2 ) );\\n}\\nThis routine was really slow, and because the value of log(2) never changed, I replaced \\nlog(2) with its computed value, 0.69314718, like this:\\nC+ + Example of a Log-Base-Two Routine Based on a System Routine and a Constant\\nconst double LOG2 = 0.69314718;\\n...\\nunsigned int Log2( unsigned int x ) {\\n   return (unsigned int) ( log( x ) / LOG2 );\\n}\\nLanguage Straight Time\\nFirst \\nOptimization \\nSecond \\nOptimization\\nSavings \\nover First \\nOptimization\\nPython 3.24 2.60 2.53 3%\\nVisual Basic 6.26 0.16 0.31 -94%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 669}, page_content='26.4 Expressions 633\\nSince log() tends to be an expensive routine—much more expensive than type conver-\\nsions or division—you’d expect that cutting the calls to the log() function by half \\nwould cut the time required for the routine by about half. Here are the measured \\nresults:\\nIn this case, the educated guess about the relative importance of the division and type \\nconversions and the estimate of 50 percent were pretty close. Considering the predict-\\nability of the results described in this chapter, the accuracy of my prediction in this \\ncase proves only that even a blind squirrel finds a nut occasionally.\\nBe Wary of System Routines\\nSystem routines are expensive and provide accuracy that’s often wasted. Typical sys-\\ntem math routines, for example, are designed to put an astronaut on the moon within \\n±2 feet of the target. If you don’t need that degree of accuracy, you don’t need to spend \\nthe time to compute it either.\\nIn the previous example, the Log2() routine returned an integer value but used a float-\\ning-point log() routine to compute it. That was overkill for an integer result, so after my \\nfirst attempt, I wrote a series of integer tests that were perfectly accurate for calculating \\nan integer log2. Here’s the code:\\nC+ + Example of a Log-Base-Two Routine Based on Integers\\nunsigned int Log2( unsigned int x ) {\\n   if ( x < 2 ) return 0 ;\\n   if ( x < 4 ) return 1 ;\\n   if ( x < 8 ) return 2 ;\\n   if ( x < 16 ) return 3 ;\\n   if ( x < 32 ) return 4 ;\\n   if ( x < 64 ) return 5 ;\\n   if ( x < 128 ) return 6 ;\\n   if ( x < 256 ) return 7 ;\\n   if ( x < 512 ) return 8 ;\\n   if ( x < 1024 ) return 9 ;\\n   ...\\n   if ( x < 2147483648 ) return 30;\\n   return 31 ;\\n}\\nLanguage Straight Time Code-Tuned Time Time Savings\\nC+ + 9.66 5.97 38%\\nJava 17.0 12.3 28%\\nPHP 2.45 1.50 39%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 670}, page_content='634 Chapter 26: Code-Tuning Techniques\\nThis routine uses integer operations, never converts to floating point, and blows the \\ndoors off both floating-point versions:\\nMost of the so-called “transcendental” functions are designed for the worst case—that \\nis, they convert to double-precision floating point internally even if you give them an \\ninteger argument. If you find one in a tight section of code and don’t need that much \\naccuracy, give it your immediate attention.\\nAnother option is to take advantage of the fact that a right-shift operation is the same \\nas dividing by two. The number of times you can divide a number by two and still have \\na nonzero value is the same as the log2 of that number. Here’s how code based on that \\nobservation looks:\\nC+ + Example of an Alternative Log-Base-Two Routine Based on the \\nRight-Shift Operator\\nunsigned int Log2( unsigned int x ) {\\n   unsigned int i = 0;\\n   while ( ( x = ( x >> 1 ) ) != 0 ) {\\n      i++;\\n   }\\n   return i ;\\n}\\nTo non-C++ programmers, this code is particularly hard to read. The complicated \\nexpression in the while condition is an example of a coding practice you should avoid \\nunless you have a good reason to use it.\\nThis routine takes about 350 percent longer than the longer version above, executing \\nin 2.4 seconds rather than 0.66 seconds. But it’s faster than the first approach, and it \\nadapts easily to 32-bit, 64-bit, and other environments.\\nThis example highlights the value of not stopping after one successful optimization. \\nThe first optimization earned a respectable 30–40 percent savings but had nowhere \\nnear the impact of the second or third optimizations.\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nC+ + 9.66 0.662 93% 15:1\\nJava 17.0 0.882 95% 20:1\\nPHP 2.45 3.45 -41% 2:3\\nCODING \\nHORROR\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 671}, page_content='26.4 Expressions 635\\nUse the Correct Type of Constants\\nUse named constants and literals that are the same type as the variables they’re assigned \\nto. When a constant and its related variable are different types, the compiler has to do a \\ntype conversion to assign the constant to the variable. A good compiler does the type \\nconversion at compile time so that it doesn’t affect run-time performance.\\nA less advanced compiler or an interpreter generates code for a run-time conversion, \\nso you might be stuck. Here are some differences in performance between the initial-\\nizations of a floating-point variable x and an integer variable i in two cases. In the first \\ncase, the initializations look like this:\\nx = 5\\ni = 3.14\\nand require type conversions, assuming x is a floating point variable and i is an inte-\\nger. In the second case, they look like this:\\nx = 3.14\\ni = 5\\nand don’t require type conversions. Here are the results, and the variation among \\ncompilers is once again notable:\\nPrecompute Results\\nA common low-level design decision is the choice of whether to compute results on \\nthe fly or compute them once, save them, and look them up as needed. If the results \\nare used many times, it’s often cheaper to compute them once and look them up the \\nrest of the time.\\nThis choice manifests itself in several ways. At the simplest level, you might compute \\npart of an expression outside a loop rather than inside. An example of this appeared \\nearlier in the chapter. At a more complicated level, you might compute a lookup table \\nonce when program execution begins, using it every time thereafter, or you might \\nstore results in a data file or embed them in a program.\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nC+ + 1.11 0.000 100% not measurable\\nC# 1.49 1.48 <1% 1:1\\nJava 1.66 1.11 33% 1.5:1\\nVisual Basic 0.721 0. 000 100% not measurable\\nPHP 0.872 0.847 3% 1:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 672}, page_content='636 Chapter 26: Code-Tuning Techniques\\nCross-Reference For more \\non using data in tables \\ninstead of complex logic, see \\nChapter 18, “Table-Driven \\nMethods.”\\nIn a space-wars video game, for example, the programmers initially computed gravity \\ncoefficients for different distances from the sun. The computation for the gravity coef-\\nficients was expensive and affected performance. The program recognized relatively \\nfew distinct distances from the sun, however, so the programmers were able to pre-\\ncompute the gravity coefficients and store them in a 10-element array. The array \\nlookup was much faster than the expensive computation.\\nSuppose you have a routine that computes payment amounts on automobile loans. \\nThe code for such a routine would look like this:\\nJava Example of a Complex Computation That Could Be Precomputed\\ndouble ComputePayment(\\n   long loanAmount,\\n   int months,\\n   double interestRate\\n   ) {\\n   return loanAmount /\\n      (\\n      ( 1.0 - Math.pow( ( 1.0 + ( interestRate / 12.0 ) ), -months ) ) /\\n      ( interestRate / 12.0 )\\n      );\\n}\\nThe formula for computing loan payments is complicated and fairly expensive. Put-\\nting the information into a table instead of computing it each time would probably be \\ncheaper.\\nHow big would the table be? The widest-ranging variable is loanAmount. The variable \\ninterestRate might range from 5 percent through 20 percent by quarter points, but that’s \\nonly 61 distinct rates. months might range from 12 through 72, but that’s only 61 dis-\\ntinct periods. loanAmount could conceivably range from $1000 through $100,000, \\nwhich is more entries than you’d generally want to handle in a lookup table.\\nMost of the computation doesn’t depend on loanAmount, however, so you can put the \\nreally ugly part of the computation (the denominator of the larger expression) into a \\ntable that’s indexed by interestRate and months. You recompute the loanAmount part \\neach time:\\nJava Example of Precomputing a Complex Computation\\ndouble ComputePayment(\\n   long loanAmount,\\n   int months,\\n   double interestRate\\n   ) {\\nThe new variable interest-\\nIndex is created to provide a \\nsubscript into the \\nloanDivisor array.\\n   int interestIndex =\\n      Math.round( ( interestRate - LOWEST_RATE ) * GRANULARITY * 100.00 );\\n   return loanAmount / loanDivisor[ interestIndex ][ months ];\\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 673}, page_content='26.4 Expressions 637\\nIn this code, the hairy calculation has been replaced with the computation of an array \\nindex and a single array access. Here are the results of that change:\\nDepending on your circumstances, you would need to precompute the loanDivisor array \\nat program initialization time or read it from a disk file. Alternatively, you could initialize \\nit to 0, compute each element the first time it’s requested, store it, and look it up each \\ntime it’s requested subsequently. That would be a form of caching, discussed earlier.\\nYou don’t have to create a table to take advantage of the performance gains you can \\nachieve by precomputing an expression. Code similar to the code in the previous \\nexamples raises the possibility of a different kind of precomputation. Suppose you \\nhave code that computes payments for many loan amounts, as shown here:\\nJava Example of a Second Complex Computation That Could Be Precomputed\\ndouble ComputePayments(\\n   int months,\\n   double interestRate\\n   ) {\\n   for ( long loanAmount = MIN_LOAN_AMOUNT; loanAmount < MAX_LOAN_AMOUNT;     \\n      loanAmount++ ) {\\n      payment = loanAmount / (\\n         ( 1.0 – Math.pow( 1.0+(interestRate/12.0), - months ) ) /\\n         ( interestRate/12.0 )\\n         );\\nThe following code would do \\nsomething with payment \\nhere; for this example’s \\npoint, it doesn’t matter what.\\n      ...\\n   }\\n}\\nEven without precomputing a table, you can precompute the complicated part of the \\nexpression outside the loop and use it inside the loop. Here’s how it would look:\\nJava Example of Precomputing the Second Complex Computation\\ndouble ComputePayments(\\n   int months,\\n   double interestRate\\n   ) {\\nHere’s the part that’s \\nprecomputed.\\n   long loanAmount;\\n   double divisor = ( 1.0 – Math.pow( 1.0+(interestRate/12.0). - months ) ) /\\n      ( interestRate/12.0 );\\n   for ( long loanAmount = MIN_LOAN_AMOUNT; loanAmount <= MAX_LOAN_AMOUNT;\\n      loanAmount++ ) {\\n      payment = loanAmount / divisor;\\n      ...\\n   }\\n}\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nJava 2.97 0.251 92% 10:1\\nPython 3.86 4.63 -20% 1:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 674}, page_content='638 Chapter 26: Code-Tuning Techniques\\nThis is similar to the techniques suggested earlier of putting array references and \\npointer dereferences outside a loop. The results for Java in this case are comparable to \\nthe results of using the precomputed table in the first optimization:\\nPython improved here, but not in the first optimization attempt. Many times when \\none optimization does not produce the desired results, a seemingly similar optimiza-\\ntion will work as expected.\\nOptimizing a program by precomputation can take several forms:\\n■ Computing results before the program executes, and wiring them into constants \\nthat are assigned at compile time\\n■ Computing results before the program executes, and hard-coding them into \\nvariables used at run time\\n■ Computing results before the program executes, and putting them into a file \\nthat’s loaded at run time\\n■ Computing results once, at program startup, and then referencing them each \\ntime they’re needed\\n■ Computing as much as possible before a loop begins, minimizing the work done \\ninside the loop\\n■ Computing results the first time they’re needed, and storing them so that you \\ncan retrieve them when they’re needed again\\nEliminate Common Subexpressions\\nIf you find an expression that’s repeated several times, assign it to a variable and refer \\nto the variable rather than recomputing the expression in several places. The loan-cal-\\nculation example has a common subexpression that you could eliminate. This is the \\noriginal code:\\nJava Example of a Common Subexpression\\npayment = loanAmount / (\\n      ( 1.0 – Math.pow( 1.0 + ( interestRate / 12.0 ), -months ) ) /\\n      ( interestRate / 12.0 )\\n   );\\nLanguage Straight Time\\nCode-Tuned \\nTime\\nTime \\nSavings Performance Ratio\\nJava 7.43 0.24 97% 30:1\\nPython 5.00 1.69 66% 3:1'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 675}, page_content='26.5 Routines 639\\nIn this sample, you can assign interestRate/12.0 to a variable that is then referenced \\ntwice rather than computing the expression twice. If you have chosen the variable \\nname well, this optimization can improve the code’s readability at the same time that \\nit improves performance. This is the revised code:\\nJava Example of Eliminating a Common Subexpression\\nmonthlyInterest = interestRate / 12.0;\\npayment = loanAmount / (\\n      ( 1.0 – Math.pow( 1.0 + monthlyInterest, -months ) ) /\\n      monthlyInterest\\n   );\\nThe savings in this case don’t seem impressive:\\nIt appears that the Math.pow() routine is so costly that it overshadows the savings \\nfrom subexpression elimination. Or possibly the subexpression is already being elim-\\ninated by the compiler. If the subexpression were a bigger part of the cost of the whole \\nexpression or if the compiler optimizer were less effective, the optimization might \\nhave more impact.\\n26.5 Routines\\nCross-Reference For details \\non working with routines, \\nsee Chapter 7, “High-Quality \\nRoutines.”\\nOne of the most powerful tools in code tuning is a good routine decomposition. \\nSmall, well-defined routines save space because they take the place of doing jobs sep-\\narately in multiple places. They make a program easy to optimize because you can \\nrefactor code in one routine and thus improve every routine that calls it. Small rou-\\ntines are relatively easy to rewrite in a low-level language. Long, tortuous routines are \\nhard enough to understand on their own; in a low-level language like assembler, \\nthey’re impossible.\\nRewrite Routines Inline\\nIn the early days of computer programming, some machines imposed prohibitive per-\\nformance penalties for calling a routine. A call to a routine meant that the operating \\nsystem had to swap out the program, swap in a directory of routines, swap in the par-\\nticular routine, execute the routine, swap out the routine, and swap the calling routine \\nback in. All this swapping chewed up resources and made the program slow.\\nLanguage Straight Time Code-Tuned Time Time Savings\\nJava 2.94 2.83 4%\\nPython 3.91 3.94 -1%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 676}, page_content='640 Chapter 26: Code-Tuning Techniques\\nModern computers collect a far smaller toll for calling a routine. Here are the results of \\nputting a string-copy routine inline:\\nIn some cases, you might be able to save a few nanoseconds by putting the code from a \\nroutine into the program directly where it’s needed via a language feature like C++’s inline \\nkeyword. If you’re working in a language that doesn’t support inline directly but that does \\nhave a macro preprocessor, you can use a macro to put the code in, switching it in and \\nout as needed. But modern machines—and “modern” means any machine you’re ever \\nlikely to work on—impose virtually no penalty for calling a routine. As the example \\nshows, you’re as likely to degrade performance by keeping code inline as to optimize it.\\n26.6 Recoding in a Low-Level Language\\nOne long-standing piece of conventional wisdom that shouldn’t be left unmentioned \\nis the advice that when you run into a performance bottleneck, you should recode in \\na low-level language. If you’re coding in C++, the low-level language might be assem-\\nbler. If you’re coding in Python, the low-level language might be C. Recoding in a low-\\nlevel language tends to improve both speed and code size. Here is a typical approach \\nto optimizing with a low-level language:\\n1. Write 100 percent of an application in a high-level language.\\n2. Fully test the application, and verify that it’s correct.\\nCross-Reference For details \\non the phenomenon of a \\nsmall percentage of a pro-\\ngram accounting for most of \\nits run time, see “The Pareto \\nPrinciple” in Section 25.2.\\n3. If performance improvements are needed after that, profile the application to \\nidentify hot spots. Since about 5 percent of a program usually accounts for \\nabout 50 percent of the running time, you can usually identify small pieces of \\nthe program as hot spots.\\n4. Recode a few small pieces in a low-level language to improve overall performance.\\nWhether you follow this well-beaten path depends on how comfortable you are with \\nlow-level languages, how well-suited the problem is to low-level languages, and on your \\nlevel of desperation. I got my first exposure to this technique on the Data Encryption \\nStandard program I mentioned in the previous chapter. I had tried every optimization \\nI’d ever heard of, and the program was still twice as slow as the speed goal. Recoding \\npart of the program in assembler was the only remaining option. As an assembler nov-\\nice, about all I could do was make a straight translation from a high-level language to \\nassembler, but I got a 50 percent improvement even at that rudimentary level.\\nSuppose you have a routine that converts binary data to uppercase ASCII characters. \\nThe next example shows the Delphi code to do it:\\nLanguage Routine Time Inline -Code Time Time Savings\\nC++ 0.471 0.431 8%\\nJava 13.1 14.4 -10%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 677}, page_content='26.6 Recoding in a Low-Level Language 641\\nDelphi Example of Code That’s Better Suited to Assembler\\nprocedure HexExpand(\\n   var source: ByteArray;\\n   var target: WordArray;\\n   byteCount: word\\n);\\nvar\\n   index: integer;\\n   targetIndex: integer;\\nbegin\\n   targetIndex := 1;\\n   for index := 1 to byteCount do begin\\n      target[ targetIndex ] := ( (source[ index ] and $F0) shr 4 ) + $41;\\n      target[ targetIndex+1 ] := (source[ index ] and $0f) + $41;\\n      targetIndex := targetIndex + 2;\\n   end;\\nend;\\nAlthough it’s hard to see where the fat is in this code, it contains a lot of bit manipula-\\ntion, which isn’t exactly Delphi’s forte. Bit manipulation is assembler’s forte, however, \\nso this code is a good candidate for recoding. Here’s the assembler code:\\nExample of a Routine Recoded in Assembler\\nprocedure HexExpand(\\n   var source;\\n   var target;\\n   byteCount : Integer\\n);\\n    label\\n    EXPAND;\\n    asm\\n          MOV   ECX,byteCount      // load number of bytes to expand\\n          MOV   ESI,source         // source offset\\n          MOV   EDI,target         // target offset\\n          XOR   EAX,EAX            // zero out array offset\\n    EXPAND:\\n          MOV   EBX,EAX            // array offset\\n          MOV   DL,[ESI+EBX]       // get source byte\\n          MOV   DH,DL              // copy source byte\\n          AND   DH,$F              // get msbs\\n          ADD   DH,$41             // add 65 to make upper case\\n          SHR   DL,4               // move lsbs into position\\n          AND   DL,$F              // get lsbs\\n          ADD   DL,$41             // add 65 to make upper case\\nC26619670.fm  Page 641  Tuesday, April 12, 2011  3:22 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 678}, page_content='642 Chapter 26: Code-Tuning Techniques\\n          SHL   BX,1               // double offset for target array offset\\n          MOV   [EDI+EBX],DX       // put target word\\n          INC   EAX                // increment array offset\\n          LOOP  EXPAND             // repeat until finished\\n    end;\\nRewriting in assembler in this case was profitable, resulting in a time savings of 41 per-\\ncent. It’s logical to assume that code in a language that’s more suited to bit manipulation—\\nC++, for instance—would have less to gain than Delphi code would. Here are the results:\\nThe “before” picture in these measurements reflects the two languages’ strengths at bit \\nmanipulation. The “after” picture looks virtually identical, and it appears that the assem-\\nbler code has minimized the initial performance differences between Delphi and C++.\\nThe assembler routine shows that rewriting in assembler doesn’t have to produce a \\nhuge, ugly routine. Such routines are often quite modest, as this one is. Sometimes \\nassembler code is almost as compact as its high-level-language equivalent.\\nA relatively easy and effective strategy for recoding in assembler is to start with a com-\\npiler that generates assembler listings as a byproduct of compilation. Extract the \\nassembler code for the routine you need to tune, and save it in a separate source file. \\nUsing the compiler’s assembler code as a base, hand-optimize the code, checking for \\ncorrectness and measuring improvements at each step. Some compilers intersperse \\nthe high-level-language statements as comments in the assembler code. If yours does, \\nyou might keep them in the assembler code as documentation.\\ncc2e.com/2672 CHECKLIST: Code-Tuning Techniques\\nImprove Both Speed and Size\\n❑ Substitute table lookups for complicated logic.\\n❑ Jam loops.\\n❑ Use integer instead of floating-point variables.\\n❑ Initialize data at compile time.\\n❑ Use constants of the correct type.\\n❑ Precompute results.\\n❑ Eliminate common subexpressions.\\n❑ Translate key routines to a low-level language.\\nLanguage High-Level Time Assembler Time Time Savings\\nC++ 4.25 3.02 29%\\nDelphi 5.18 3.04 41%'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 679}, page_content='26.7 The More Things Change, the More They Stay the Same 643\\nImprove Speed Only\\n❑ Stop testing when you know the answer.\\n❑ Order tests in case statements and if-then-else chains by frequency.\\n❑ Compare performance of similar logic structures.\\n❑ Use lazy evaluation.\\n❑ Unswitch loops that contain if tests.\\n❑ Unroll loops.\\n❑ Minimize work performed inside loops.\\n❑ Use sentinels in search loops.\\n❑ Put the busiest loop on the inside of nested loops.\\n❑ Reduce the strength of operations performed inside loops.\\n❑ Change multiple-dimension arrays to a single dimension.\\n❑ Minimize array references.\\n❑ Augment data types with indexes.\\n❑ Cache frequently used values.\\n❑ Exploit algebraic identities.\\n❑ Reduce strength in logical and mathematical expressions.\\n❑ Be wary of system routines.\\n❑ Rewrite routines inline.\\n26.7 The More Things Change, the More They Stay the Same\\nYou might expect that performance attributes of systems would have changed some-\\nwhat in the 10 years since I wrote the first edition of Code Complete, and in some ways \\nthey have. Computers are dramatically faster and memory is more plentiful. In the \\nfirst edition, I ran most of the tests in this chapter 10,000 to 50,000 times to get mean-\\ningful, measurable results. For this edition I had to run most tests 1 million to 100 mil-\\nlion times. When you have to run a test 100 million times to get measurable results, \\nyou have to ask whether anyone will ever notice the impact in a real program. Com-\\nputers have become so powerful that for many common kinds of programs, the level \\nof performance optimization discussed in this chapter has become irrelevant.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 680}, page_content='644 Chapter 26: Code-Tuning Techniques\\nIn other ways, performance issues have hardly changed at all. People writing desktop \\napplications may not need this information, but people writing software for embed-\\nded systems, real-time systems, and other systems with strict speed or space restric-\\ntions can still benefit from it.\\nThe need to measure the impact of each and every attempt at code tuning has been a \\nconstant since Donald Knuth published his study of Fortran programs in 1971. \\nAccording to the measurements in this chapter, the effect of any specific optimization \\nis actually less predictable than it was 10 years ago. The effect of each code tuning is \\naffected by the programming language, compiler, compiler version, code libraries, \\nlibrary versions, and compiler settings, among other things.\\nCode tuning invariably involves tradeoffs among complexity, readability, simplicity, \\nand maintainability on the one hand and a desire to improve performance on the \\nother. It introduces a high degree of maintenance overhead because of all the reprofil-\\ning that’s required.\\nI have found that insisting on measurable improvement is a good way to resist the temp-\\ntation to optimize prematurely and a good way to enforce a bias toward clear, straight-\\nforward code. If an optimization is important enough to haul out the profiler and \\nmeasure the optimization’s effect, then it’s probably important enough to allow—as \\nlong as it works. But if an optimization isn’t important enough to haul out the profil-\\ning machinery, it isn’t important enough to degrade readability, maintainability, and \\nother code characteristics. The impact of unmeasured code tuning on performance is \\nspeculative at best, whereas the impact on readability is as certain as it is detrimental.\\nAdditional Resources\\ncc2e.com/2679 My favorite reference on code tuning is Writing Efficient Programs (Bentley, Englewood \\nCliffs, NJ: Prentice Hall, 1982). The book is out of print but worth reading if you can \\nfind it. It’s an expert treatment of code tuning, broadly considered. Bentley describes \\ntechniques that trade time for space and space for time. He provides several examples \\nof redesigning data types to reduce both space and time. His approach is a little more \\nanecdotal than the one taken here, and his anecdotes are interesting. He takes a few \\nroutines through several optimization steps so that you can see the effects of first, sec-\\nond, and third attempts on a single problem. Bentley strolls through the primary con-\\ntents of the book in 135 pages. The book has an unusually high signal-to-noise ratio—\\nit’s one of the rare gems that every practicing programmer should own.\\nAppendix 4 of Bentley’s Programming Pearls, 2d ed. (Boston, MA: Addison-Wesley, \\n2000) contains a summary of the code-tuning rules from his earlier book.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 681}, page_content='Key Points 645\\ncc2e.com/2686 You can also find a full array of technology-specific optimization books. Several are \\nlisted below, and the Web link to the left contains an up-to-date list.  \\nBooth, Rick. Inner Loops: A Sourcebook for Fast 32-bit Software Development. Boston, \\nMA: Addison-Wesley, 1997.\\nGerber, Richard. Software Optimization Cookbook: High-Performance Recipes for the Intel \\nArchitecture. Intel Press, 2002.\\nHasan, Jeffrey and Kenneth Tu. Performance Tuning and Optimizing ASP.NET Applica-\\ntions. Berkeley, CA: Apress, 2003.\\nKillelea, Patrick. Web Performance Tuning, 2d ed. Sebastopol, CA: O’Reilly & Associ-\\nates, 2002.\\nLarman, Craig and Rhett Guthrie. Java 2 Performance and Idiom Guide. Englewood \\nCliffs, NJ: Prentice Hall, 2000.\\nShirazi, Jack. Java Performance Tuning. Sebastopol, CA: O’Reilly & Associates, 2000.\\nWilson, Steve and Jeff Kesselman. Java Platform Performance: Strategies and Tactics. Bos-\\nton, MA: Addison-Wesley, 2000.\\nKey Points\\n■ Results of optimizations vary widely with different languages, compilers, and \\nenvironments. Without measuring each specific optimization, you’ll have no \\nidea whether it will help or hurt your program.\\n■ The first optimization is often not the best. Even after you find a good one, keep \\nlooking for one that’s better.\\n■ Code tuning is a little like nuclear energy. It’s a controversial, emotional topic. \\nSome people think it’s so detrimental to reliability and maintainability that they \\nwon’t do it at all. Others think that with proper safeguards, it’s beneficial. If you \\ndecide to use the techniques in this chapter, apply them with care.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 683}, page_content='Part VI\\nSystem Considerations\\nIn this part:\\nChapter 27: How Program Size Affects Construction . . . . . . . . . . . . . . . .649\\nChapter 28: Managing Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .661\\nChapter 29: Integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .689\\nChapter 30: Programming Tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .709'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 685}, page_content='649\\nChapter 27\\nHow Program Size Affects \\nConstruction\\ncc2e.com/2761 Contents\\n■ 27.1 Communication and Size: page 650\\n■ 27.2 Range of Project Sizes: page 651\\n■ 27.3 Effect of Project Size on Errors: page 651\\n■ 27.4 Effect of Project Size on Productivity: page 653\\n■ 27.5 Effect of Project Size on Development Activities: page 654\\nRelated Topics\\n■ Prerequisites to construction: Chapter 3\\n■ Determining the kind of software you’re working on: Section 3.2\\n■ Managing construction: Chapter 28\\nScaling up in software development isn’t a simple matter of taking a small project and \\nmaking each part of it bigger. Suppose you wrote the 25,000-line Gigatron software \\npackage in 20 staff-months and found 500 errors in field testing. Suppose Gigatron \\n1.0 is successful, as is Gigatron 2.0, and you start work on the Gigatron Deluxe, a \\ngreatly enhanced version of the program that’s expected to be 250,000 lines of code.\\nEven though it’s 10 times as large as the original Gigatron, the Gigatron Deluxe won’t \\ntake 10 times the effort to develop; it’ll take 30 times the effort. Moreover, 30 times the \\ntotal effort doesn’t imply 30 times as much construction. It probably implies 25 times \\nas much construction and 40 times as much architecture and system testing. You \\nwon’t have 10 times as many errors either; you’ll have 15 times as many—or more.\\nIf you’ve been accustomed to working on small projects, your first medium-to-large \\nproject can rage riotously out of control, becoming an uncontrollable beast instead of \\nthe pleasant success you had envisioned. This chapter tells you what kind of beast to \\nexpect and where to find the whip and chair to tame it. In contrast, if you’re accus-\\ntomed to working on large projects, you might use approaches that are too formal on \\na small project. This chapter describes how you can economize to keep a small project \\nfrom toppling under the weight of its own overhead.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 686}, page_content='650 Chapter 27: How Program Size Affects Construction\\n27.1 Communication and Size\\nIf you’re the only person on a project, the only communication path is between you and \\nthe customer, unless you count the path across your corpus callosum, the path that con-\\nnects the left side of your brain to the right. As the number of people on a project \\nincreases, the number of communication paths increases, too. The number doesn’t \\nincrease additively as the number of people increases. It increases multiplicatively, pro-\\nportionally to the square of the number of people, as illustrated in Figure 27-1.\\nFigure 27-1 The number of communication paths increases proportionate to the square of \\nthe number of people on the team.\\nAs you can see, a two-person project has only one path of communication. A five-per-\\nson project has 10 paths. A ten-person project has 45 paths, assuming that every per-\\nson talks to every other person. The 10 percent of projects that have 50 or more \\nprogrammers have at least 1,200 potential paths. The more communication paths you \\nhave, the more time you spend communicating and the more opportunities are cre-\\nated for communication mistakes. Larger-size projects demand organizational tech-\\nniques that streamline communication or limit it in a sensible way.\\nThe typical approach taken to streamlining communication is to formalize it in docu-\\nments. Instead of having 50 people talk to each other in every conceivable combina-\\ntion, 50 people read and write documents. Some are text documents; some are \\ngraphic. Some are printed on paper; others are kept in electronic form.\\n45\\nCommunication paths \\nwith ten programmers\\n10\\nCommunication path \\nwith two programmers\\n1\\nCommunication paths \\nwith three programmers\\n3\\nCommunication paths \\nwith four programmers\\n6\\n10\\nCommunication paths \\nwith five programmers\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 687}, page_content='27.2 Range of Project Sizes 651\\n27.2 Range of Project Sizes\\nIs the size of the project you’re working on typical? The wide range of project sizes \\nmeans that you can’t consider any single size to be typical. One way of thinking about \\nproject size is to think about the size of a project team. Here’s a crude estimate of the \\npercentages of all projects that are done by teams of various sizes:\\nOne aspect of project size data that might not be immediately apparent is the differ-\\nence between the percentages of projects of various sizes and the number of pro-\\ngrammers who work on projects of each size. Because larger projects use more \\nprogrammers on each project than do sma ll ones, they employ a large percentage of \\nall programmers. Here’s a rough estimate  of the percentage of all programmers who \\nwork on projects of various sizes:\\n27.3 Effect of Project Size on Errors\\nCross-Reference For more \\ndetails on errors, see Section \\n22.4, “Typical Errors.”\\nBoth quantity and type of errors are affected by project size. You might not think that \\nerror type would be affected, but as project size increases, a larger percentage of errors can \\nusually be attributed to mistakes in requirements and design, as shown in Figure 27-2.\\nTeam Size Approximate Percentage of Projects\\n1–3 25%\\n4–10 30%\\n11–25 20%\\n26–50 15%\\n50+ 10%\\nSource: Adapted from “A Survey of Software Engineering Practice: Tools, Methods, and Results” (Beck and \\nPerkins 1983), Agile Software Development Ecosystems (Highsmith 2002), and Balancing Agility and \\nDiscipline (Boehm and Turner 2003).\\nTeam Size Approximate Percentage of Programmers \\n1–3 5%\\n4–10 10%\\n11–25 15%\\n26–50 20%\\n50+ 50%\\nSource: Derived from data in “A Survey of Software Engineering Practice: Tools, Methods, and Results” (Beck \\nand Perkins 1983), Agile Software Development Ecosystems (Highsmith 2002), and Balancing Agility and \\nDiscipline (Boehm and Turner 2003).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 688}, page_content='652 Chapter 27: How Program Size Affects Construction\\nFigure 27-2 As project size increases, errors usually come more from requirements and \\ndesign.  Sometimes they still come primarily from construction (Boehm 1981, Grady 1987, \\nJones 1998).\\nOn small projects, construction errors make up about 75 percent of all the errors \\nfound. Methodology has less influence on code quality, and the biggest influence on \\nprogram quality is often the skill of the individual writing the program (Jones 1998).\\nOn larger projects, construction errors can taper off to about 50 percent of the total \\nerrors; requirements and architecture errors make up the difference. Presumably this \\nis related to the fact that more requirements development and architectural design are \\nrequired on large projects, so the opportunity for errors arising out of those activities \\nis proportionally larger. In some very large projects, however, the proportion of con-\\nstruction errors remains high; sometimes even with 500,000 lines of code, up to 75 \\npercent of the errors can be attributed to construction (Grady 1987).\\nAs the kinds of defects change with size, so do the numbers of defects. You would nat-\\nurally expect a project that’s twice as large as another to have twice as many errors. But \\nthe density of defects—the number of defects per 1000 lines of code—increases. The \\nproduct that’s twice as large is likely to have more than twice as many errors. Table 27-1 \\nshows the range of defect densities you can expect on projects of various sizes.\\nTable 27-1 Project Size and Typical Error Density\\nProject Size (in Lines \\nof Code) Typical Error Density\\nSmaller than 2K 0–25 errors per thousand lines of code (KLOC)\\n2K–16K 0–40 errors per KLOC\\n16K–64K 0.5–50 errors per KLOC\\n64K–512K 2–70 errors per KLOC\\n512K or more 4–100 errors per KLOC\\nSources: “Program Quality and Programmer Productivity” (Jones 1977), Estimating Software Costs (Jones \\n1998).\\nConstruction\\nRequirements\\nDesign\\n2K 8K 32K 128K 512K\\n0%\\n100%\\nProject Size in Lines of Code\\nErrors from \\nEach Activity\\nOn some projects, \\nthis percentage of \\nerrors may also be \\nfrom construction.\\n1\\n2\\n3\\nHARD DATA\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 689}, page_content='27.4 Effect of Project Size on Productivity 653\\nCross-Reference The data in \\nthis table represents average \\nperformance. A handful of \\norganizations have reported \\nbetter error rates than the \\nminimums shown here. For \\nexamples, see “How Many \\nErrors Should You Expect to \\nFind?” in Section 22.4.\\nThe data in this table was derived from specific projects, and the numbers might bear \\nlittle resemblance to those for the projects you’ve worked on. As a snapshot of the \\nindustry, however, the data is illuminating. It indicates that the number of errors \\nincreases dramatically as project size increases, with very large projects having up to \\nfour times as many errors per thousand lines of code as small projects.  A large project \\nwill need to work harder than a small project to achieve the same error rate.\\n27.4 Effect of Project Size on Productivity\\nProductivity has a lot in common with software quality when it comes to project size. \\nAt small sizes (2000 lines of code or smaller), the single biggest influence on produc-\\ntivity is the skill of the individual programmer (Jones 1998). As project size increases, \\nteam size and organization become greater influences on productivity.\\nHow big does a project need to be before team size begins to affect productivity? In \\n“Prototyping Versus Specifying: a Multiproject Experiment,” Boehm, Gray, and See-\\nwaldt reported that smaller teams completed their projects with 39 percent higher \\nproductivity than larger teams. The size of the teams? Two people for the small \\nprojects and three for the large (1984). Table 27-2 gives the inside scoop on the gen-\\neral relationship between project size and productivity.\\nProductivity is substantially determined by the kind of software you’re working on, \\npersonnel quality, programming language, methodology, product complexity, pro-\\ngramming environment, tool support, how “lines of code” are counted, how nonpro-\\ngrammer support effort is factored into the “lines of code per staff-year” figure, and \\nmany other factors, so the specific figures in Table 27-2 vary dramatically.\\nRealize, however, that the general trend the numbers show is significant. Productivity \\non small projects can be 2–3 times as high as productivity on large projects, and pro-\\nductivity can vary by a factor of 5–10 from the smallest projects to the largest.\\nTable 27-2 Project Size and Productivity\\nProject Size (in Lines \\nof Code)\\nLines of Code per Staff-Year (Cocomo II Nominal in \\nParentheses)\\n1K 2,500–25,000 (4,000)\\n10K 2,000–25,000 (3,200)\\n100K 1,000–20,000 (2,600)\\n1,000K 700–10,000 (2,000)\\n10,000K 300–5,000 (1,600)\\nSource: Derived from data in Measures for Excellence (Putnam and Meyers 1992), Industrial Strength Software \\n(Putnam and Meyers 1997), Software Cost Estimation with Cocomo II (Boehm et al. 2000), and “Software \\nDevelopment Worldwide: The State of the Practice” (Cusumano et al. 2003).\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 690}, page_content='654 Chapter 27: How Program Size Affects Construction\\n27.5 Effect of Project Size on Development Activities\\nIf you are working on a one-person project, the biggest influence on the project’s suc-\\ncess or failure is you. If you’re working on a 25-person project, it’s conceivable that \\nyou’re still the biggest influence, but it’s more likely that no one person will wear the \\nmedal for that distinction; your organization will be a stronger influence on the \\nproject’s success or failure.\\nActivity Proportions and Size\\nAs project size increases and the need for formal communications increases, the kinds \\nof activities a project needs change dramatically. Figure 27-3 shows the proportions of \\ndevelopment activities for projects of different sizes.\\nFigure 27-3 Construction activities dominate small projects. Larger projects require more \\narchitecture, integration work, and system testing to succeed. Requirements work is not \\nshown on this diagram because requirements effort is not as directly a function of program \\nsize as other activities are (Albrecht 1979; Glass 1982; Boehm, Gray, and Seewaldt 1984; \\nBoddie 1987; Card 1987; McGarry, Waligora, and McDermott 1989; Brooks 1995; Jones 1998; \\nJones 2000; Boehm et al. 2000).\\nOn a small project, construction is the most prominent activity by far, taking up as \\nmuch as 65 percent of the total development time. On a medium-size project, con-\\nstruction is still the dominant activity but its share of the total effort falls to about 50 \\npercent. On very large projects, architecture, integration, and system testing take up \\nmore time and construction becomes less dominant. In short, as project size \\nincreases, construction becomes a smaller part of the total effort. The chart looks as \\nthough you could extend it to the right and make construction disappear altogether, \\nso in the interest of protecting my job, I’ve cut it off at 512K.\\nConstruction becomes less predominant because as project size increases, the construc-\\ntion activities—detailed design, coding, debugging, and unit testing—scale up propor-\\ntionately but many other activities scale up faster. Figure 27-4 provides an illustration.\\nArchitecture\\n2K 8K 32K 128K 512K\\n0%\\n100%\\nDetailed design\\nCoding and debugging\\nDeveloper testing\\nIntegration\\nSystem testing\\nProject Size in Lines of Code\\nPercentage of \\nDevelopment Time Construction\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 691}, page_content='27.5 Effect of Project Size on Development Activities 655\\nFigure 27-4 The amount of software construction work is a near-linear function of project \\nsize. Other kinds of work increase nonlinearly as project size increases.\\nProjects that are close in size will perform similar activities, but as sizes diverge, the \\nkinds of activities will diverge, too. As the introduction to this chapter described, \\nwhen the Gigatron Deluxe comes out at 10 times the size of the original Gigatron, it \\nwill need 25 times more construction effort, 25–50 times the planning effort, 30 times \\nthe integration effort, and 40 times the architecture and system testing.\\nProportions of activities vary because different activities become critical at different \\nproject sizes. Barry Boehm and Richard Turner found that spending about five per-\\ncent of total project costs on architecture and requirements produced the lowest cost \\nfor projects in the 10,000-lines-of-code range. But for projects in the 100,000-lines-of-\\ncode range, spending 15–20 percent of project effort on architecture and require-\\nments produced the best results (Boehm and Turner 2004).\\nHere’s a list of activities that grow at a more-than-linear rate as project size increases:\\nI Communication\\nI Planning\\nI Management\\nI Requirements development\\nI System functional design\\nI Interface design and specification\\nI Architecture\\nI Integration\\nI Defect removal\\nI System testing\\nI Document production\\nRegardless of the size of a project, a few techniques are always valuable: disciplined \\ncoding practices, design and code inspections by other developers, good tool support, \\nand use of high-level languages. These techniques are valuable on small projects and \\ninvaluable on large projects.\\nOther \\nactivities\\nConstruction\\nSize\\nEffort\\n1\\n2\\n3\\nHARD DATA\\nC27619670.fm  Page 655  Tuesday, April 12, 2011  3:26 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 692}, page_content='656 Chapter 27: How Program Size Affects Construction\\nPrograms, Products, Systems, and System Products\\nFurther Reading For \\nanother explanation of this \\npoint, see Chapter 1 in The \\nMythical Man-Month \\n(Brooks 1995).\\nLines of code and team size aren’t the only influences on a project’s size. A more subtle \\ninfluence is the quality and the complexity of the final software. The original Gigatron, \\nthe Gigatron Jr., might have taken only a month to write and debug. It was a single pro-\\ngram written, tested, and documented by a single person. If the 2,500-line Gigatron Jr. \\ntook one month, why did the full-fledged 25,000-line Gigatron take 20 months?\\nThe simplest kind of software is a single “program” that’s used by itself by the person \\nwho developed it or, informally, by a few others.\\nA more sophisticated kind of program is a software “product,” a program that’s \\nintended for use by people other than the original developer. A software product is \\nused in environments that differ from the environment in which the product was cre-\\nated. It’s extensively tested before it’s released, it’s documented, and it’s capable of \\nbeing maintained by others. A software product costs about three times as much to \\ndevelop as a software program.\\nAnother level of sophistication is required to develop a group of programs that work \\ntogether. Such a group is called a software “system.” Development of a system is more \\ncomplicated than development of a simple program because of the complexity of \\ndeveloping interfaces among the pieces and the care needed to integrate the pieces. \\nOn the whole, a system also costs about three times as much as a simple program.\\nWhen a “system product” is developed, it has the polish of a product and the multiple \\nparts of a system. System products cost about nine times as much as simple programs \\n(Brooks 1995, Shull et al. 2002).\\nA failure to appreciate the differences in polish and complexity among programs, \\nproducts, systems, and system products is a common cause of estimation errors. Pro-\\ngrammers who use their experience in building a program to estimate the schedule \\nfor building a system product can underestimate by a factor of almost 10. As you con-\\nsider the following example, refer to the chart in Figure 27-3 (on page 654). If you \\nused your experience in writing 2K lines of code to estimate the time it would take you \\nto develop a 2K program, your estimate would be only 65 percent of the total time \\nyou’d actually need to perform all the activities that go into developing a program. \\nWriting 2K lines of code doesn’t take as long as creating a whole program that con-\\ntains 2K lines of code. If you don’t consider the time it takes to do nonconstruction \\nactivities, development will take 50 percent more time than you estimate.\\nAs you scale up, construction becomes a smaller part of the total effort in a project. If you \\nbase your estimates solely on construction experience, the estimation error increases. If \\nyou used your own 2K construction experience to estimate the time it would take to \\ndevelop a 32K program, your estimate would be only 50 percent of the total time \\nrequired; development would take 100 percent more time than you would estimate.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 693}, page_content='27.5 Effect of Project Size on Development Activities 657\\nThe estimation error here would be completely attributable to your not understand-\\ning the effect of size on developing larger programs. If in addition you failed to con-\\nsider the extra degree of polish required for a product rather than a mere program, the \\nerror could easily increase by a factor of three or more.\\nMethodology and Size\\nMethodologies are used on projects of all sizes. On small projects, methodologies \\ntend to be casual and instinctive. On large projects, they tend to be rigorous and care-\\nfully planned.\\nSome methodologies can be so loose that programmers aren’t even aware that they’re \\nusing them. A few programmers argue that methodologies are too rigid and say that \\nthey won’t touch them. While it may be true that a programmer hasn’t selected a \\nmethodology consciously, any approach to programming constitutes a methodology, \\nno matter how unconscious or primitive the approach is. Merely getting out of bed \\nand going to work in the morning is a rudimentary methodology although not a very \\ncreative one. The programmer who insists on avoiding methodologies is really only \\navoiding choosing one explicitly—no one can avoid using them altogether.\\nFormal approaches aren’t always fun, and if they are misapplied, their overhead gob-\\nbles up their other savings. The greater complexity of larger projects, however, \\nrequires a greater conscious attention to methodology. Building a skyscraper requires \\na different approach than building a doghouse. Different sizes of software projects \\nwork the same way. On large projects, unconscious choices are inadequate to the task. \\nSuccessful project planners choose their strategies for large projects explicitly.\\nIn social settings, the more formal the event, the more uncomfortable your clothes \\nhave to be (high heels, neckties, and so on). In software development, the more formal \\nthe project, the more paper you have to generate to make sure you’ve done your home-\\nwork. Capers Jones points out that a project of 1,000 lines of code will average about \\n7 percent of its effort on paperwork, whereas a 100,000-lines-of-code project will aver-\\nage about 26 percent of its effort on paperwork (Jones 1998).\\nThis paperwork isn’t created for the sheer joy of writing documents. It’s created as a \\ndirect result of the phenomenon illustrated in Figure 27-1: the more people’s brains \\nyou have to coordinate, the more formal documentation you need to coordinate them.\\nYou don’t create any of this documentation for its own sake. The point of writing a \\nconfiguration-management plan, for example, isn’t to exercise your writing muscles. \\nThe point of your writing the plan is to force you to think carefully about configura-\\ntion management and to explain your plan to everyone else. The documentation is a \\ntangible side effect of the real work you do as you plan and construct a software sys-\\ntem. If you feel as though you’re going through the motions and writing generic doc-\\numents, something is wrong.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 694}, page_content='658 Chapter 27: How Program Size Affects Construction\\n “More” is not better, as far as methodologies are concerned. In their review of agile vs. \\nplan-driven methodologies, Barry Boehm and Richard Turner caution that you’ll usu-\\nally do better if you start your methods small and scale up for a large project than if \\nyou start with an all-inclusive method and pare it down for a small project (Boehm \\nand Turner 2004). Some software pundits talk about “lightweight” and “heavyweight” \\nmethodologies, but in practice the key is to consider your project’s specific size and \\ntype and then find the methodology that’s “right-weight.” \\nAdditional Resources\\ncc2e.com/2768 Use the following resources to investigate this chapter’s subject further: \\nBoehm, Barry and Richard Turner. Balancing Agility and Discipline: A Guide for the Per-\\nplexed. Boston, MA: Addison-Wesley, 2004. Boehm and Turner describe how project \\nsize affects the use of agile and plan-driven methods, along with other agile and plan-\\ndriven issues.\\nCockburn, Alistair. Agile Software Development. Boston, MA: Addison-Wesley, 2002.  \\nChapter 4 discusses issues involved in selecting appropriate project methodologies, \\nincluding project size. Chapter 6 introduces Cockburn’s Crystal Methodologies, which \\nare defined approaches for developing projects of various sizes and degrees of criticality.\\nBoehm, Barry W. Software Engineering Economics. Englewood Cliffs, NJ: Prentice Hall, \\n1981. Boehm’s book is an extensive treatment of the cost, productivity, and quality \\nramifications of project size and other variables in the software-development process. \\nIt includes discussions of the effect of size on construction and other activities. Chap-\\nter 11 is an excellent explanation of software’s diseconomies of scale. Other informa-\\ntion on project size is spread throughout the book. Boehm’s 2000 book Software Cost \\nEstimation with Cocomo II contains much more up-to-date information on Boehm’s \\nCocomo estimating model, but the earlier book provides more in-depth background \\ndiscussions that are still relevant.\\nJones, Capers. Estimating Software Costs. New York, NY: McGraw-Hill, 1998. This book \\nis packed with tables and graphs that di ssect the sources of software development \\nproductivity. For the impact of project size specifically, Jones’s 1986 book, Program-\\nming Productivity, contains an excellent discussion in the section titled “The Impact of \\nProgram Size” in Chapter 3.\\nBrooks, Frederick P., Jr. The Mythical Man-Month: Essays on Software Engineering, Anni-\\nversary Edition (2d ed.). Reading, MA: Addison-Wesley, 1995. Brooks was the manager \\nof IBM’s OS/360 development, a mammoth project that took 5000 staff-years. He dis-\\ncusses management issues pertaining to small and large teams and presents a partic-\\nularly vivid account of chief-programmer teams in this engaging collection of essays.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 695}, page_content='Key Points 659\\nDeGrace, Peter, and Leslie Stahl. Wicked Problems, Righteous Solutions: A Catalogue of \\nModern Software Engineering Paradigms. Englewood Cliffs, NJ: Yourdon Press, 1990. As \\nthe title suggests, this book catalogs approaches to developing software. As noted \\nthroughout this chapter, your approach needs to vary as the size of the project varies, \\nand DeGrace and Stahl make that point clearly. The section titled “Attenuating and \\nTruncating” in Chapter 5 discusses customizing software-development processes based \\non project size and formality. The book includes descriptions of models from NASA and \\nthe Department of Defense and a remarkable number of edifying illustrations.\\nJones, T. Capers. “Program Quality and Programmer Productivity.” IBM Technical \\nReport TR 02.764 (January 1977): 42–78. Also available in Jones’s Tutorial: Program-\\nming Productivity: Issues for the Eighties, 2d ed. Los Angeles, CA: IEEE Computer Soci-\\nety Press, 1986. This paper contains the first in-depth analysis of the reasons large \\nprojects have different spending patterns than small ones. It’s a thorough discussion \\nof the differences between large and small projects, including requirements and qual-\\nity-assurance measures. It’s dated but still interesting.\\nKey Points\\n■ As project size increases, communication needs to be supported. The point of \\nmost methodologies is to reduce communications problems, and a methodol-\\nogy should live or die on its merits as a communication facilitator.\\n■ All other things being equal, productivity will be lower on a large project than on \\na small one.\\n■ All other things being equal, a large project will have more errors per thousand \\nlines of code than a small one.\\n■ Activities that are taken for granted on small projects must be carefully planned \\non larger ones. Construction becomes less predominant as project size \\nincreases.\\n■ Scaling up a lightweight methodology tends to work better than scaling down a \\nheavyweight methodology. The most effective approach of all is using a “right-\\nweight” methodology.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 697}, page_content='661\\nChapter 28\\nManaging Construction\\ncc2e.com/2836 Contents\\n■ 28.1 Encouraging Good Coding: page 662\\n■ 28.2 Configuration Management: page 664\\n■ 28.3 Estimating a Construction Schedule: page 671\\n■ 28.4 Measurement: page 677\\n■ 28.5 Treating Programmers as People: page 680\\n■ 28.6 Managing Your Manager: page 686\\nRelated Topics\\n■ Prerequisites to construction: Chapter 3\\n■ Determining the kind of software you’re working on: Section 3.2\\n■ Program size: Chapter 27\\n■ Software quality: Chapter 20\\nManaging software development has been a formidable challenge for the past several \\ndecades. As Figure 28-1 suggests, the general topic of software-project management \\nextends beyond the scope of this book, but this chapter discusses a few specific man-\\nagement topics that apply directly to construction. If you’re a developer, this chapter \\nwill help you understand the issues that managers need to consider. If you’re a man-\\nager, this chapter will help you understand how management looks to developers as \\nwell as how to manage construction effectively. Because the chapter covers a broad \\ncollection of topics, several of its sections also describe where you can go for more \\ninformation.\\nFigure 28-1 This chapter covers the software-management topics related to construction.\\nSoftware \\nmanagement\\nGeneral \\nmanagement\\nManagement of\\nconstruction'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 698}, page_content='662 Chapter 28: Managing Construction\\nIf you’re interested in software management, be sure to read Section 3.2, “Determine \\nthe Kind of Software You’re Working On,” to understand the difference between tra-\\nditional sequential approaches to development and modern iterative approaches. Be \\nsure also to read Chapter 20, “The Software-Quality Landscape,” and Chapter 27, \\n“How Program Size Affects Construction.” Quality goals and the size of the project \\nboth significantly affect how a specific software project should be managed.\\n28.1 Encouraging Good Coding\\nBecause code is the primary output of cons truction, a key question in managing con-\\nstruction is “How do you encourage good coding practices?” In general, mandating a \\nstrict set of technical standards from the management position isn’t a good idea. Pro-\\ngrammers tend to view managers as being at a lower level of technical evolution, \\nsomewhere between single-celled organisms and the woolly mammoths that died out \\nduring the Ice Age, and if there are going to be programming standards, programmers \\nneed to buy into them.\\nIf someone on a project is going to define standards, have a respected architect define \\nthe standards rather than the manager. Software projects operate as much on an “exper-\\ntise hierarchy” as on an “authority hierarchy.” If the architect is regarded as the project’s \\nthought leader, the project team will generally follow standards set by that person.\\nIf you choose this approach, be sure the architect really is respected. Sometimes a \\nproject architect is just a senior person who has been around too long and is out of \\ntouch with production coding issues. Programmers will resent that kind of “architect” \\ndefining standards that are out of touch with the work they’re doing.\\nConsiderations in Setting Standards\\nStandards are more useful in some organizations than in others. Some developers wel-\\ncome standards because they reduce arbitrary variance in the project. If your group \\nresists adopting strict standards, consider a few alternatives: flexible guidelines, a col-\\nlection of suggestions rather than guidelines, or a set of examples that embody the \\nbest practices.\\nTechniques for Encouraging Good Coding\\nThis section describes several techniques for achieving good coding practices that are \\nless heavy-handed than laying down rigid coding standards:\\nCross-Reference For more \\ndetails on pair program-\\nming, see Section 21.2, “Pair \\nProgramming.”\\nAssign two people to every part of the project If two people have to work on each \\nline of code, you’ll guarantee that at least two people think it works and is readable. \\nThe mechanisms for teaming two people can range from pair programming to mentor-\\ntrainee pairs to buddy-system reviews.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 699}, page_content='28.1 Encouraging Good Coding 663\\nCross-Reference For details \\non reviews, see Section 21.3, \\n“Formal Inspections,” and \\nSection 21.4, “Other Kinds of \\nCollaborative Development \\nPractices.”\\nReview every line of code A code review typically involves the programmer and at \\nleast two reviewers. That means that at least three people read every line of code. \\nAnother name for peer review is “peer pressure.” In addition to providing a safety net \\nin case the original programmer leaves the project, reviews improve code quality \\nbecause the programmer knows that the code will be read by others. Even if your \\nshop hasn’t created explicit coding standards, reviews provide a subtle way of moving \\ntoward a group coding standard—decisions are made by the group during reviews, \\nand over time the group derives its own standards.\\nRequire code sign-offs In other fields, technical drawings are approved and signed \\nby the managing engineer. The signature means that to the best of the engineer’s \\nknowledge, the drawings are technically competent and error-free. Some companies \\ntreat code the same way. Before code is considered to be complete, senior technical \\npersonnel must sign the code listing.\\nRoute good code examples for review A big part of good management is communi-\\ncating your objectives clearly. One way to communicate your objectives is to circulate \\ngood code to your programmers or post it for public display. In doing so, you provide \\na clear example of the quality you’re aiming for. Similarly, a coding-standards manual \\ncan consist mainly of a set of “best code listings.” Identifying certain listings as “best” \\nsets an example for others to follow. Such a manual is easier to update than an \\nEnglish-language standards manual, and it effortlessly presents subtleties in coding \\nstyle that are hard to capture point by point in prose descriptions.\\nCross-Reference A large \\npart of programming is com-\\nmunicating your work to \\nother people. For details, see \\nSection 33.5 and Section 34.3.\\nEmphasize that code listings are public assets Programmers sometimes feel that the \\ncode they’ve written is “their code,” as if it were private property. Although it is the \\nresult of their work, code is part of the project and should be freely available to anyone \\nelse on the project who needs it. It should be seen by others during reviews and main-\\ntenance, even if at no other time.\\nOne of the most successful projects ever reported developed 83,000 lines of code in \\n11 work-years of effort. Only one error that resulted in system failure was detected in \\nthe first 13 months of operation. This accomplishment is even more dramatic when \\nyou realize that the project was completed in the late 1960s, without online compila-\\ntion or interactive debugging. Productivity on the project—7500 lines of code per \\nwork-year in the late 1960s—is still impressive by today’s standards. The chief pro-\\ngrammer on the project reported that one key to the project’s success was the identi-\\nfication of all computer runs (erroneous and otherwise) as public rather than private \\nassets (Baker and Mills 1973). This idea has extended into modern contexts, includ-\\ning Open Source Software (Raymond 2000) and Extreme Programming’s idea of col-\\nlective ownership (Beck 2000), as well as in other contexts.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 700}, page_content='664 Chapter 28: Managing Construction\\nReward good code Use your organization’s reward system to reinforce good coding \\npractices. Keep these considerations in mind as you develop your reinforcement system:\\n■ The reward should be something that the programmer wants. (Many program-\\nmers find “attaboy” rewards distasteful, especially when they come from non-\\ntechnical managers.)\\n■ Code that receives an award should be exceptionally good. If you give an award \\nto a programmer everyone else knows does bad work, you look like Homer \\nSimpson trying to run a nuclear reactor. It doesn’t matter that the programmer \\nhas a cooperative attitude or always comes to work on time. You lose credibility \\nif your reward doesn’t match the technical merits of the situation. If you’re not \\ntechnically skilled enough to make the good-code judgment, don’t! Don’t make \\nthe award at all, or let yo ur team choose the recipient.\\nOne easy standard If you’re managing a programming project and you have a pro-\\ngramming background, an easy and effective technique for eliciting good work is to \\nsay “I must be able to read and understand any code written for the project.” That the \\nmanager isn’t the hottest technical hotshot can be an advantage in that it might dis-\\ncourage “clever” or tricky code.\\nThe Role of This Book\\nMost of this book is a discussion of good programming practices. It isn’t intended to be \\nused to justify rigid standards, and it’s intended even less to be used as a set of rigid stan-\\ndards. Use this book as a basis for discussion, as a sourcebook of good programming \\npractices, and for identifying practices that could be beneficial in your environment.\\n28.2 Configuration Management\\nA software project is dynamic. The code changes, the design changes, and the require-\\nments change. What’s more, changes in the requirements lead to more changes in the \\ndesign, and changes in the design lead to even more changes in the code and test cases.\\nWhat Is Configuration Management?\\nConfiguration management is the practice of identifying project artifacts and handling \\nchanges systematically so that a system can maintain its integrity over time. Another \\nname for it is “change control.” It includes techniques for evaluating proposed changes, \\ntracking changes, and keeping copies of the system as it existed at various points in time.\\nIf you don’t control changes to requirements, you can end up writing code for parts of \\nthe system that are eventually eliminated. You can write code that’s incompatible with \\nnew parts of the system. You might not detect many of the incompatibilities until'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 701}, page_content='28.2 Configuration Management 665\\nintegration time, which will become finger-pointing time because nobody will really \\nknow what’s going on.\\nIf changes to code aren’t controlled, you might change a routine that someone else is \\nchanging at the same time; successfully combining your changes with theirs will be prob-\\nlematic. Uncontrolled code changes can make code seem more tested than it is. The ver-\\nsion that’s been tested will probably be the old, unchanged version; the modified version \\nmight not have been tested. Without good change control, you can make changes to a \\nroutine, find new errors, and not be able to back up to the old, working routine.\\nThe problems go on indefinitely. If changes aren’t handled systematically, you’re tak-\\ning random steps in the fog rather than moving directly toward a clear destination. \\nWithout good change control, rather than developing code you’re wasting your time \\nthrashing. Configuration management helps you use your time effectively.\\nIn spite of the obvious need for configuration management, many programmers have \\nbeen avoiding it for decades. A survey more than 20 years ago found that over a third \\nof programmers weren’t even familiar with the idea (Beck and Perkins 1983), and \\nthere’s little indication that that has changed. A more recent study by the Software \\nEngineering Institute found that, of organizations using informal software-develop-\\nment practices, less than 20 percent had adequate configuration management (SEI \\n2003).\\nConfiguration management wasn’t invented by programmers, but because program-\\nming projects are so volatile, it’s especially useful to programmers. Applied to software \\nprojects, configuration management is usually called “software configuration manage-\\nment” (SCM). SCM focuses on a program’s requirements, source code, documenta-\\ntion, and test data.\\nThe systemic problem with SCM is overcontrol. The surest way to stop car accidents is \\nto prevent everyone from driving, and one sure way to prevent software-development \\nproblems is to stop all software development. Although that’s one way to control \\nchanges, it’s a terrible way to develop software. You have to plan SCM carefully so that \\nit’s an asset rather than an albatross around your neck.\\nCross-Reference For details \\non the effects of project size \\non construction, see Chapter \\n27, “How Program Size \\nAffects Construction.”\\nOn a small, one-person project, you can probably do well with no SCM beyond plan-\\nning for informal periodic backups. Nonetheless, configuration management is still \\nuseful (and, in fact, I used configuration management in creating this manuscript). \\nOn a large, 50-person project, you’ll probably need a full-blown SCM scheme, includ-\\ning fairly formal procedures for backups, change control for requirements and design, \\nand control over documents, source code, content, test cases, and other project arti-\\nfacts. If your project is neither very large nor very small, you’ll have to settle on a \\ndegree of formality somewhere between the two extremes. The following subsections \\ndescribe some of the options in implementing SCM.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 702}, page_content='666 Chapter 28: Managing Construction\\nRequirements and Design Changes\\nCross-Reference Some \\ndevelopment approaches \\nsupport changes better than \\nothers. For details, see Section \\n3.2, “Determine the Kind of \\nSoftware You’re Working On.”\\nDuring development, you’re bound to be bristling with ideas about how to improve the \\nsystem. If you implement each change as it occurs to you, you’ll soon find yourself walk-\\ning on a software treadmill—for all that the system will be changing, it won’t be moving \\ncloser to completion. Here are some guidelines for controlling design changes:\\nFollow a systematic change-control procedure As Section 3.4 noted, a systematic \\nchange-control procedure is a godsend when you have a lot of change requests. By \\nestablishing a systematic procedure, you make it clear that changes will be considered \\nin the context of what’s best for the project overall.\\nHandle change requests in groups It’s tempting to implement easy changes as ideas \\narise. The problem with handling changes in this way is that good changes can get \\nlost. If you think of a simple change 25 percent of the way through the project and \\nyou’re on schedule, you’ll make the change. If you think of another simple change 50 \\npercent of the way through the project and you’re already behind, you won’t. When \\nyou start to run out of time at the end of the project, it won’t matter that the second \\nchange is 10 times as good as the first—you won’t be in a position to make any nones-\\nsential changes. Some of the best changes can slip through the cracks merely because \\nyou thought of them later rather than sooner.\\nA solution to this problem is to write down all ideas and suggestions, no matter how \\neasy they would be to implement, and save them until you have time to work on them. \\nThen, viewing them as a group, choose the ones that will be the most beneficial.\\nEstimate the cost of each change Whenever your customer, your boss, or you are \\ntempted to change the system, estimate the time it would take to make the change, \\nincluding review of the code for the change and retesting the whole system. Include in \\nyour estimate time for dealing with the change’s ripple effect through requirements to \\ndesign to code to test to changes in the user documentation. Let all the interested par-\\nties know that software is intricately interwoven and that time estimation is necessary \\neven if the change appears small at first glance.\\nRegardless of how optimistic you feel when the change is first suggested, refrain from giv-\\ning an off-the-cuff estimate. Such estimates are often mistaken by a factor of 2 or more.\\nCross-Reference For \\nanother angle on handling \\nchanges, see “Handling \\nRequirements Changes Dur-\\ning Construction” in Section \\n3.4. For advice on handling \\ncode changes safely when \\nthey do occur, see Chapter \\n24, “Refactoring.” \\nBe wary of high change volumes While some degree of change is inevitable, a high \\nvolume of change requests is a key warning sign that requirements, architecture, or \\ntop-level designs weren’t done well enough to support effective construction. Backing \\nup to work on requirements or architecture might seem expensive, but it won’t be \\nnearly as expensive as constructing the software more than once or throwing away \\ncode for features that you really didn’t need.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 703}, page_content='28.2 Configuration Management 667\\nEstablish a change-control board or its equivalent in a way that makes sense for your \\nproject The job of a change-control board is to separate the wheat from the chaff in \\nchange requests. Anyone who wants to propose a change submits the change request \\nto the change-control board. The term “change request” refers to any request that \\nwould change the software: an idea for a new feature, a change to an existing feature, \\nan “error report” that might or might not be reporting a real error, and so on. The \\nboard meets periodically to review proposed changes. It approves, disapproves, or \\ndefers each change. Change-control boards are considered a best practice for prioritiz-\\ning and controlling requirements changes; however, they are still fairly uncommon in \\ncommercial settings (Jones 1998, Jones 2000).\\nWatch for bureaucracy, but don’t let the fear of bureaucracy preclude effective change \\ncontrol Lack of disciplined change control is one of the biggest management prob-\\nlems facing the software industry today. A significant percentage of the projects that \\nare perceived to be late would actually be on time if they accounted for the impact of \\nuntracked but agreed-upon changes. Poor change control allows changes to accumu-\\nlate off the books, which undermines status visibility, long-range predictability, \\nproject planning, risk management specifically, and project management generally.\\nChange control tends to drift toward bureaucracy, so it’s important to look for ways to \\nstreamline the change-control process. If you’d rather not use traditional change \\nrequests, set up a simple “ChangeBoard” e-mail alias and have people e-mail change \\nrequests to the address. Or have people present change proposals interactively at a \\nchange board meeting. An especially powerful approach is to log change requests as \\ndefects in your defect-tracking software. Purists will classify such changes as “require-\\nments defects,” or you could classify them as changes rather than defects.\\nYou can implement the Change-Control Board itself formally, or you can define a \\nProduct Planning Group or War Council that carries the traditional responsibilities of \\na change-control board. Or you can identify a single person to be the Change Czar. But \\nwhatever you call it, do it! \\nI occasionally see projects suffering from ham-handed implementations of change \\ncontrol. But 10 times as often I see projects suffering from no meaningful change con-\\ntrol at all. The substance of change control is what’s important, so don’t let fear of \\nbureaucracy stop you from realizing its many benefits.\\nSoftware Code Changes\\nAnother configuration-management issue is controlling source code. If you change the \\ncode and a new error surfaces that seems unrelated to the change you made, you’ll \\nprobably want to compare the new version of the code to the old in your search for the \\nsource of the error. If that doesn’t tell you anything, you might want to look at a ver-\\nsion that’s even older. This kind of excursion through history is easy if you have ver-\\nsion-control tools that keep track of multiple versions of source code.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 704}, page_content='668 Chapter 28: Managing Construction\\nVersion-control software Good version-control software works so easily that you \\nbarely notice you’re using it. It’s especially helpful on team projects. One style of ver-\\nsion control locks source files so that only one person can modify a file at a time. Typ-\\nically, when you need to work on source code in a particular file, you check the file out \\nof version control. If someone else has already checked it out, you’re notified that you \\ncan’t check it out. When you can check the file out, you work on it just as you would \\nwithout version control until you’re ready to check it in. Another style allows multiple \\npeople to work on files simultaneously and handles the issue of merging changes \\nwhen the code is checked in. In either case, when you check the file in, version control \\nasks why you changed it, and you type in a reason.\\nFor this modest investment of effort, you get several big benefits:\\n■ You don’t step on anyone’s toes by working on a file while someone else is work-\\ning on it (or at least you’ll know about it if you do).\\n■ You can easily update your copies of all the project’s files to the current versions, \\nusually by issuing a single command.\\n■ You can backtrack to any version of any file that was ever checked into version \\ncontrol.\\n■ You can get a list of the changes made to any version of any file.\\n■ You don’t have to worry about personal backups because the version-control \\ncopy is a safety net.\\nVersion control is indispensable on team projects. It becomes even more powerful \\nwhen version control, defect tracking, and change management are integrated. The \\napplications division of Microsoft found its proprietary version-control tool to be a \\n“major competitive advantage” (Moore 1992).\\nTool Versions\\nFor some kinds of projects, it may be necessary to be able to reconstruct the exact \\nenvironment used to create each specific version of the software, including compilers, \\nlinkers, code libraries, and so on. In that case, you should put all of those tools into \\nversion control, too.\\nMachine Configurations\\nMany companies (including my company) have experienced good results from creat-\\ning standardized development machine configurations. A disk image is created of a \\nstandard developer workstation, including all the common developer tools, office \\napplications, and so on. That image is loaded onto each developer’s machine. Having \\nstandardized configurations helps to avoid a raft of problems associated with slightly \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 705}, page_content='28.2 Configuration Management 669\\ndifferent configuration settings, different versions of tools used, and so on. A stan-\\ndardized disk image also greatly streamlines setting up new machines compared to \\nhaving to install each piece of software individually.\\nBackup Plan\\nA backup plan isn’t a dramatic new concept; it’s the idea of backing up your work peri-\\nodically. If you were writing a book by hand, you wouldn’t leave the pages in a pile on \\nyour porch. If you did, they might get rained on or blown away, or your neighbor’s dog \\nmight borrow them for a little bedtime reading. You’d put them somewhere safe. Soft-\\nware is less tangible, so it’s easier to forget that you have something of enormous value \\non one machine.\\nMany things can happen to computerized data: a disk can fail; you or someone else can \\ndelete key files accidentally; an angry employee can sabotage your machine; or you \\ncould lose a machine to theft, flood, or fire. Take steps to safeguard your work. Your \\nbackup plan should include making backups on a periodic basis and periodic transfer \\nof backups to off-site storage, and it should encompass all the important materials on \\nyour project—documents, graphics, and notes—in addition to source code.\\nOne often-overlooked aspect of devising a backup plan is a test of your backup proce-\\ndure. Try doing a restore at some point to make sure that the backup contains every-\\nthing you need and that the recovery works.\\nWhen you finish a project, make a project archive. Save a copy of everything: source \\ncode, compilers, tools, requirements, design, documentation—everything you need to \\nre-create the product. Keep it all in a safe place.\\ncc2e.com/2843 CHECKLIST: Configuration Management\\nGeneral\\n❑ Is your software configuration management plan designed to help pro-\\ngrammers and minimize overhead?\\n❑ Does your SCM approach avoid overcontrolling the project?\\n❑ Do you group change requests, either through informal means (such as a \\nlist of pending changes) or through a more systematic approach (such as \\na change-control board)?\\n❑ Do you systematically estimate the cost, schedule, and quality impact of \\neach proposed change?\\n❑ Do you view major changes as a warning that requirements development \\nisn’t yet complete?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 706}, page_content='670 Chapter 28: Managing Construction\\nTools\\n❑ Do you use version-control software to facilitate configuration management?\\n❑ Do you use version-control software to reduce coordination problems of \\nworking in teams?\\nBackup\\n❑ Do you back up all project materials periodically?\\n❑ Are project backups transferred to off-site storage periodically?\\n❑ Are all materials backed up, including source code, documents, graphics, \\nand important notes?\\n❑ Have you tested the backup-recovery procedure?\\nAdditional Resources on Configuration Management\\ncc2e.com/2850 Because this book is about construction, this section has focused on change control \\nfrom a construction point of view. But changes affect projects at all levels, and a com-\\nprehensive change-control strategy needs to do the same.\\nHass, Anne Mette Jonassen. Configuration Management Principles and Practices. Boston, \\nMA: Addison-Wesley, 2003. This book provides the big-picture view of software config-\\nuration management and practical details on how to incorporate it into your software-\\ndevelopment process. It focuses on managing and controlling configuration items.\\nBerczuk, Stephen P. and Brad Appleton. Software Configuration Management Patterns: \\nEffective Teamwork, Practical Integration. Boston, MA: Addison-Wesley, 2003. Like \\nHass’s book, this book provides a SCM overview and is practical. It complements \\nHass’s book by providing practical guidelines that allow teams of developers to isolate \\nand coordinate their work.\\ncc2e.com/2857 SPMN. Little Book of Configuration Management. Arlington, VA: Software Program Man-\\nagers Network, 1998. This pamphlet is an introduction to configuration management \\nactivities and defines critical success factors. It’s available as a free download from the \\nSPMN website at www.spmn.com/products_guidebooks.html.\\nBays, Michael. Software Release Methodology. Englewood Cliffs, NJ: Prentice Hall, 1999. \\nThis book discusses software configuration management with an emphasis on releas-\\ning software into production.\\nBersoff, Edward H., and Alan M. Davis. “Impacts of Life Cycle Models on Software \\nConfiguration Management.” Communications of the ACM 34, no. 8 (August 1991): \\n104–118. This article describes how SCM is affected by newer approaches to software \\ndevelopment, especially prototyping approaches. The article is especially applicable \\nin environments that are using agile development practices.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 707}, page_content='28.3 Estimating a Construction Schedule 671\\n28.3 Estimating a Construction Schedule\\nManaging a software project is one of the formidable challenges of the twenty-first cen-\\ntury, and estimating the size of a project and the effort required to complete it is one of \\nthe most challenging aspects of software-project management. The average large soft-\\nware project is one year late and 100 percent over budget (Standish Group 1994, Jones \\n1997, Johnson 1999). At the individual level, surveys of estimated vs. actual schedules \\nhave found that developers’ estimates tend to have an optimism factor of 20 to 30 per-\\ncent (van Genuchten 1991).This has as much to do with poor size and effort estimates \\nas with poor development efforts. This section outlines the issues involved in estimating \\nsoftware projects and indicates where to look for more information.\\nEstimation Approaches\\nFurther Reading For further \\nreading on schedule-\\nestimation techniques, see \\nChapter 8 of Rapid Devel-\\nopment (McConnell 1996) \\nand Software Cost Estima-\\ntion with Cocomo II (Boehm \\net al. 2000).\\nYou can estimate the size of a project and the effort required to complete it in any of \\nseveral ways:\\n■ Use estimating software.\\n■ Use an algorithmic approach, such as Cocomo II, Barry Boehm’s estimation \\nmodel (Boehm et al. 2000).\\n■ Have outside estimation experts estimate the project.\\n■ Have a walk-through meeting for estimates.\\n■ Estimate pieces of the project, and then add the pieces together.\\n■ Have people estimate their own tasks, and then add the task estimates together.\\n■ Refer to experience on previous projects.\\n■ Keep previous estimates and see how accurate they were. Use them to adjust \\nnew estimates.\\nPointers to more information on these approaches are given in “Additional Resources \\non Software Estimation” at the end of this section. Here’s a good approach to estimat-\\ning a project:\\nFurther Reading This \\napproach is adapted from \\nSoftware Engineering Eco-\\nnomics (Boehm 1981).\\nEstablish objectives Why do you need an estimate? What are you estimating? Are \\nyou estimating only construction activities, or all of development? Are you estimating \\nonly the effort for your project, or your project plus vacations, holidays, training, and \\nother nonproject activities? How accurate does the estimate need to be to meet your \\nobjectives? What degree of certainty needs to be associated with the estimate? Would \\nan optimistic or a pessimistic estimate produce substantially different results?\\nAllow time for the estimate, and plan it Rushed estimates are inaccurate estimates. If \\nyou’re estimating a large project, treat estimation as a miniproject and take the time to \\nminiplan the estimate so that you can do it well.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 708}, page_content='672 Chapter 28: Managing Construction\\nCross-Reference For more \\ninformation on software \\nrequirements, see Section 3.4, \\n“Requirements Prerequisite.”\\nSpell out software requirements Just as an architect can’t estimate how much a \\n“pretty big” house will cost, you can’t reliably estimate a “pretty big” software project. \\nIt’s unreasonable for anyone to expect you to be able to estimate the amount of work \\nrequired to build something when “something” has not yet been defined. Define \\nrequirements or plan a preliminary exploration phase before making an estimate.\\nEstimate at a low level of detail Depending on the objectives you identified, base \\nthe estimate on a detailed examination of project activities. In general, the more \\ndetailed your examination is, the more accurate your estimate will be. The Law of \\nLarge Numbers says that a 10 percent error on one big piece will be 10 percent high or \\n10 percent low. On 50 small pieces, some of the 10 percent errors in the pieces will be \\nhigh and some will be low, and the errors will tend to cancel each other out.\\nCross-Reference It’s hard to \\nfind an area of software \\ndevelopment in which itera-\\ntion is not valuable. Estima-\\ntion is one case in which \\niteration is useful. For a \\nsummary of iterative tech-\\nniques, see Section 34.8, \\n“Iterate, Repeatedly, Again \\nand Again.”\\nUse several different estimation techniques, and compare the results The list of esti-\\nmation approaches at the beginning of the section identified several techniques. They \\nwon’t all produce the same results, so try several of them. Study the different results \\nfrom the different approaches. Children learn early that if they ask each parent indi-\\nvidually for a third bowl of ice cream, they have a better chance of getting at least one \\n“yes” than if they ask only one parent. Sometimes the parents wise up and give the \\nsame answer; sometimes they don’t. See what different answers you can get from dif-\\nferent estimation techniques.\\nNo approach is best in all circumstances, and the differences among them can be illu-\\nminating. For example, for the first edition of this book, my original eyeball estimate \\nfor the length of the book was 250–300 pages. When I finally did an in-depth esti-\\nmate, the estimate came out to 873 pages. “That can’t be right,” I thought. So I esti-\\nmated it using a completely different technique. The second estimate came out to 828 \\npages. Considering that these estimates were within about five percent of each other, \\nI concluded that the book was going to be much closer to 850 pages than to 250 \\npages, and I was able to adjust my writing plans accordingly.\\nReestimate periodically Factors on a software project change after the initial esti-\\nmate, so plan to update your estimates periodically. As Figure 28-2 illustrates, the \\naccuracy of your estimates should improve as you move toward completing the \\nproject. From time to time, compare your actual results to your estimated results, and \\nuse that evaluation to refine estimates for the remainder of the project.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 709}, page_content='28.3 Estimating a Construction Schedule 673\\ncc2e.com/2864\\nFigure 28-2 Estimates created early in a project are inherently inaccurate. As the project \\nprogresses, estimates can become more accurate. Reestimate periodically throughout a \\nproject, and use what you learn during each activity to improve your estimate for the next \\nactivity.\\nEstimating the Amount of Construction\\nCross-Reference For details \\non the amount of coding for \\nprojects of various sizes, see \\n“Activity Proportions and \\nSize” in Section 27.5.\\nThe extent to which construction will be a major influence on a project’s schedule \\ndepends in part on the proportion of the project that will be devoted to construc-\\ntion—understood as detailed design, coding and debugging, and unit testing. Take \\nanother look at Figure 27-3 on page 654. As the figure shows, the proportion varies \\nby project size. Until your company has project-history data of its own, the propor-\\ntion of time devoted to each activity shown in the figure is a good place to start esti-\\nmates for your projects.\\nThe best answer to the question of how much construction a project will call for is that \\nthe proportion will vary from project to project and organization to organization. \\nKeep records of your organization’s experience on projects, and use them to estimate \\nthe time future projects will take.\\n0.67x\\n0.8x\\n1.0x\\n0.25x\\nTime\\n2x\\n4x\\n1.5x\\n1.25x\\nVariation in Project \\nScope Estimates \\n(Effort, Cost, or \\nFeatures)'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 710}, page_content='674 Chapter 28: Managing Construction\\nInfluences on Schedule\\nCross-Reference The effect \\nof a program’s size on pro-\\nductivity and quality isn’t \\nalways intuitively apparent. \\nSee Chapter 27, “How Pro-\\ngram Size Affects Construc-\\ntion,” for an explanation of \\nhow size affects construction.\\nThe largest influence on a software project’s schedule is the size of the program to be \\nproduced. But many other factors also influence a software-development schedule. \\nStudies of commercial programs have quantified some of the factors, and they’re \\nshown in Table 28-1.\\nHere are some of the less easily quantified factors that can influence a software-devel-\\nopment schedule. These factors are drawn from Barry Boehm’s Software Cost Estima-\\ntion with Cocomo II (2000) and Capers Jones’s Estimating Software Costs (1998).\\n■ Requirements developer experience and capability\\n■ Programmer experience and capability\\nTable 28-1 Factors That Influence Software-Project Effort\\nFactor\\nPotential \\nHelpful \\nInfluence\\nPotential \\nHarmful \\nInfluence\\nCo-located vs. multisite development -14% 22%\\nDatabase size -10% 28%\\nDocumentation match to project needs -19% 23%\\nFlexibility allowed in interpreting requirements -9% 10%\\nHow actively risks are addressed -12% 14%\\nLanguage and tools experience -16% 20%\\nPersonnel continuity (turnover) -19% 29%\\nPlatform volatility -13% 30%\\nProcess maturity -13% 15%\\nProduct complexity -27% 74%\\nProgrammer capability -24% 34%\\nReliability required -18% 26%\\nRequirements analyst capability -29% 42%\\nReuse requirements -5% 24%\\nState-of-the-art application -11% 12%\\nStorage constraint (how much of available storage \\nwill be consumed)\\n0% 46%\\nTeam cohesion -10% 11%\\nTeam’s experience in the applications area -19% 22%\\nTeam’s experience on the technology platform -15% 19%\\nTime constraint (of the application itself) 0% 63%\\nUse of software tools -22% 17%\\nSource: Software Cost Estimation with Cocomo II (Boehm et al. 2000).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 711}, page_content='28.3 Estimating a Construction Schedule 675\\n■ Team motivation\\n■ Management quality\\n■ Amount of code reused\\n■ Personnel turnover\\n■ Requirements volatility\\n■ Quality of relationship with customer\\n■ User participation in requirements\\n■ Customer experience with the type of application\\n■ Extent to which programmers participate in requirements development\\n■ Classified security environment for computer, programs, and data\\n■ Amount of documentation\\n■ Project objectives (schedule vs. quality vs. usability vs. the many other possible \\nobjectives)\\nEach of these factors can be significant, so consider them along with the factors \\nshown in Table 28-1 (which includes some of these factors).\\nEstimation vs. Control\\nThe important question is, \\ndo you want prediction, or \\ndo you want control? \\n—Tom Gilb\\nEstimation is an important part of the planning needed to complete a software project \\non time. Once you have a delivery date and a product specification, the main problem \\nis how to control the expenditure of human and technical resources for an on-time \\ndelivery of the product. In that sense, the accuracy of the initial estimate is much less \\nimportant than your subsequent success at controlling resources to meet the sched-\\nule.\\nWhat to Do If You’re Behind\\nThe average project overruns its planned schedule by about 100 percent, as men-\\ntioned earlier in this chapter. When you’re behind, increasing the amount of time usu-\\nally isn’t an option. If it is, do it. Otherwise, you can try one or more of these solutions:\\nHope that you’ll catch up Hopeful optimism is a common response to a project’s \\nfalling behind schedule. The rationalization typically goes like this: “Requirements \\ntook a little longer than we expected, but now they’re solid, so we’re bound to save \\ntime later. We’ll make up the shortfall during coding and testing.” This is hardly ever \\nthe case. One survey of over 300 software projects concluded that delays and over-\\nruns generally increase toward the end of a project (van Genuchten 1991). Projects \\ndon’t make up lost time later; they fall further behind.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 712}, page_content='676 Chapter 28: Managing Construction\\nExpand the team According to Fred Brooks’s law, adding people to a late software \\nproject makes it later (Brooks 1995). It’s like adding gas to a fire. Brooks’s explanation \\nis convincing: new people need time to familiarize themselves with a project before \\nthey can become productive. Their training takes up the time of the people who have \\nalready been trained. And merely increasing the number of people increases the com-\\nplexity and amount of project communication. Brooks points out that the fact that \\none woman can have a baby in nine months does not imply that nine women can have \\na baby in one month.\\nUndoubtedly the warning in Brooks’s law should be heeded more often than it is. It’s \\ntempting to throw people at a project and hope that they’ll bring it in on time. Manag-\\ners need to understand that developing software isn’t like riveting sheet metal: more \\nworkers working doesn’t necessarily mean more work will get done.\\nThe simple statement that adding programmers to a late project makes it later, how-\\never, masks the fact that under some circumstances it’s possible to add people to a late \\nproject and speed it up. As Brooks points out in the analysis of his law, adding people \\nto software projects in which the tasks can’t be divided and performed independently \\ndoesn’t help. But if a project’s tasks are partitionable, you can divide them further and \\nassign them to different people, even to people who are added late in the project. \\nOther researchers have formally identified circumstances under which you can add \\npeople to a late project without making it later (Abdel-Hamid 1989, McConnell 1999).\\nFurther Reading For an \\nargument in favor of build-\\ning only the most-needed \\nfeatures, see Chapter 14, \\n“Feature-Set Control,” in \\nRapid Development (McCon-\\nnell 1996).\\nReduce the scope of the project The powerful technique of reducing the scope of the \\nproject is often overlooked. If you eliminate a feature, you eliminate the design, cod-\\ning, debugging, testing, and documentation of that feature. You eliminate that fea-\\nture’s interface to other features.\\nWhen you plan the product initially, partition the product’s capabilities into “must \\nhaves,” “nice to haves,” and “optionals.” If you fall behind, prioritize the “optionals” \\nand “nice to haves” and drop the ones that are the least important.\\nShort of dropping a feature altogether, you can provide a cheaper version of the same \\nfunctionality. You might provide a version that’s on time but that hasn’t been tuned \\nfor performance. You might provide a version in which the least important functional-\\nity is implemented crudely. You might decide to back off on a speed requirement \\nbecause it’s much easier to provide a slow version. You might back off on a space \\nrequirement because it’s easier to provide a memory-intensive version.\\nReestimate development time for the least important features. What functionality can \\nyou provide in two hours, two days, or two weeks? What do you gain by building the \\ntwo-week version rather than the two-day version, or the two-day version rather than \\nthe two-hour version?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 713}, page_content='28.4 Measurement 677\\nAdditional Resources on Software Estimation\\ncc2e.com/2871 Here are some additional references about software estimation:\\nBoehm, Barry, et al. Software Cost Estimation with Cocomo II . Boston, MA: Addison-\\nWesley, 2000. This book describes the in s and outs of the Cocomo II estimating \\nmodel, which is undoubtedly the most popular model in use today.\\nBoehm, Barry W. Software Engineering Economics. Englewood Cliffs, NJ: Prentice Hall, \\n1981. This older book contains an exhaustive treatment of software-project estimation \\nconsidered more generally than in Boehm’s newer book.\\nHumphrey, Watts S. A Discipline for Software Engineering. Reading, MA: Addison-\\nWesley, 1995. Chapter 5 of this book describes Humphrey’s Probe method, which is \\na technique for estimating work at  the individual developer level.\\nConte, S. D., H. E. Dunsmore, and V. Y. Shen. Software Engineering Metrics and Models. \\nMenlo Park, CA: Benjamin/Cummings, 1986. Chapter 6 contains a good survey of \\nestimation techniques, including a history of estimation, statistical models, theoreti-\\ncally based models, and composite models. The book also demonstrates the use of \\neach estimation technique on a database of projects and compares the estimates to the \\nprojects’ actual lengths.\\nGilb, Tom. Principles of Software Engineering Management . Wokingham, England: \\nAddison-Wesley, 1988. The title of Chapter 16 , “Ten Principles for Estimating Soft-\\nware Attributes,” is somewhat tongue-in-ch eek. Gilb argues against project estima-\\ntion and in favor of project control. Pointing out that people don’t really want to predict \\naccurately but do want to control final results, Gilb lays out 10 principles you can use \\nto steer a project to meet a calendar deadline, a cost goal, or another project objective.\\n28.4 Measurement\\nSoftware projects can be measured in numerous ways. Here are two solid reasons to \\nmeasure your process:\\nFor any project attribute, it’s possible to measure that attribute in a way that’s superior \\nto not measuring it at all The measurement might not be perfectly precise, it might \\nbe difficult to make, and it might need to be refined over time, but measurement will \\ngive you a handle on your software-development process that you don’t have with-\\nout it (Gilb 2004).\\nIf data is to be used in a scientific experiment, it must be quantified. Can you imagine a \\nscientist recommending a ban on a new food product because a group of white rats “just \\nseemed to get sicker” than another group? That’s absurd. You’d demand a quantified \\nreason, like “Rats that ate the new food product were sick 3.7 more days per month than \\nrats that didn’t.” To evaluate software-development methods, you must measure them. \\nStatements like “This new method seems more productive” aren’t good enough.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 714}, page_content='678 Chapter 28: Managing Construction\\nWhat gets measured, gets \\ndone. \\n—Tom Peters\\nBe aware of measurement side effects Measurement has a motivational effect. People \\npay attention to whatever is measured, assuming that it’s used to evaluate them. \\nChoose what you measure carefully. People tend to focus on work that’s measured \\nand to ignore work that isn’t.\\nTo argue against measurement is to argue that it’s better not to know what’s really \\nhappening on your project When you measure an aspect of a project, you know \\nsomething about it that you didn’t know before. You can see whether the aspect gets \\nbigger or smaller or stays the same. The measurement gives you a window into at least \\nthat aspect of your project. The window might be small and cloudy until you refine \\nyour measurements, but it will be better than no window at all. To argue against all \\nmeasurements because some are inconclusive is to argue against windows because \\nsome happen to be cloudy.\\nYou can measure virtually any aspect of the software-development process. Table 28-2 \\nlists some measurements that other practitioners have found to be useful.\\nTable 28-2 Useful Software-Development Measurements\\nSize Overall Quality\\nTotal lines of code written\\nTotal comment lines\\nTotal number of classes or routines\\nTotal data declarations\\nTotal blank lines\\nTotal number of defects\\nNumber of defects in each class or routine\\nAverage defects per thousand lines of code\\nMean time between failures\\nCompiler-detected errors\\nDefect Tracking Maintainability\\nSeverity of each defect\\nLocation of each defect (class or routine)\\nOrigin of each defect (requirements, design,\\nconstruction, test)\\nWay in which each defect is corrected\\nPerson responsible for each defect\\nNumber of lines affected by each defect correction\\nWork hours spent correcting each defect\\nAverage time required to find a defect\\nAverage time required to fix a defect\\nNumber of attempts made to correct each defect\\nNumber of new errors resulting from defect \\ncorrection\\nNumber of public routines on each class\\nNumber of parameters passed to each routine\\nNumber of private routines and/or variables on each \\nclass\\nNumber of local variables used by each routine\\nNumber of routines called by each class or routine\\nNumber of decision points in each routine\\nControl-flow complexity in each routine\\nLines of code in each class or routine\\nLines of comments in each class or routine\\nNumber of data declarations in each class or routine\\nNumber of blank lines in each class or routine\\nNumber of gotos in each class or routine\\nNumber of input or output statements in each class \\nor routine\\nProductivity\\nWork-hours spent on the project\\nWork-hours spent on each class or routine\\nNumber of times each class or routine changed\\nDollars spent on project\\nDollars spent per line of code\\nDollars spent per defect'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 715}, page_content='28.4 Measurement 679\\nYou can collect most of these measurements with software tools that are currently \\navailable. Discussions throughout the book indicate the reasons that each measure-\\nment is useful. At this time, most of the measurements aren’t useful for making fine \\ndistinctions among programs, classes, and routines (Shepperd and Ince 1989). \\nThey’re useful mainly for identifying routines that are “outliers”; abnormal measure-\\nments in a routine are a warning sign that you should reexamine that routine, check-\\ning for unusually low quality.\\nDon’t start by collecting data on all possible measurements—you’ll bury yourself in \\ndata so complex that you won’t be able to figure out what any of it means. Start with \\na simple set of measurements, such as the number of defects, the number of work-\\nmonths, the total dollars, and the total lines of code. Standardize the measurements \\nacross your projects, and then refine them and add to them as your understanding of \\nwhat you want to measure improves (Pietrasanta 1990).\\nMake sure you’re collecting data for a reason. Set goals, determine the questions you \\nneed to ask to meet the goals, and then measure to answer the questions (Basili and \\nWeiss 1984). Be sure that you ask for only as much information as is feasible to obtain, \\nand keep in mind that data collection will always take a back seat to deadlines (Basili \\net al. 2002).\\nAdditional Resources on Software Measurement\\ncc2e.com/2878 Here are addtional resources:\\nOman, Paul and Shari Lawrence Pfleeger, eds. Applying Software Metrics. Los Alamitos, \\nCA: IEEE Computer Society Press, 1996. This volume collects more than 25 key \\npapers on software measurement under one cover.\\nJones, Capers. Applied Software Measurement: Assuring Productivity and Quality, 2d ed. \\nNew York, NY: McGraw-Hill, 1997. Jones is a leader in software measurement, and his \\nbook is an accumulation of knowledge in this area. It provides the definitive theory \\nand practice of current measurement techniques and describes problems with tradi-\\ntional measurements. It lays out a full program for collecting “function-point metrics.” \\nJones has collected and analyzed a huge amount of quality and productivity data, and \\nthis book distills the results in one place—including a fascinating chapter on averages \\nfor U.S. software development.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 716}, page_content='680 Chapter 28: Managing Construction\\nGrady, Robert B. Practical Software Metrics for Project Management and Process Improve-\\nment. Englewood Cliffs, NJ: Prentice Hall PTR, 1992. Grady describes lessons learned \\nfrom establishing a software-measurement program at Hewlett-Packard and tells you \\nhow to establish a software-measurement program in your organization.\\nConte, S. D., H. E. Dunsmore, and V. Y. Shen. Software Engineering Metrics and Models. \\nMenlo Park, CA: Benjamin/Cummings, 1986. This book catalogs current knowledge \\nof software measurement circa 1986, including commonly used measurements, \\nexperimental techniques, and criteria for evaluating experimental results.\\nBasili, Victor R., et al. 2002. “Lessons learned from 25 years of process improvement: \\nThe Rise and Fall of the NASA Software Engineering Laboratory,” Proceedings of the \\n24th International Conference on Software Engineering. Orlando, FL, 2002. This paper \\ncatalogs lessons learned by one of the world’s most sophisticated software-develop-\\nment organizations. The lessons focus on measurement topics.\\ncc2e.com/2892 NASA Software Engineering Laboratory. Software Measurement Guidebook, June 1995, \\nNASA-GB-001-94. This guidebook of about 100 pages is probably the best source of \\npractical information on how to set up and run a measurement program. It can be \\ndownloaded from NASA’s website.\\ncc2e.com/2899 Gilb, Tom. Competitive Engineering. Boston, MA: Addison-Wesley, 2004. This book pre-\\nsents a measurement-focused approach to defining requirements, evaluating designs, \\nmeasuring quality, and, in general, managing projects. It can be downloaded from \\nGilb’s website.\\n28.5 Treating Programmers as People\\nThe abstractness of the programming activity calls for an offsetting naturalness in the \\noffice environment and rich contacts among coworkers. Highly technical companies \\noffer parklike corporate campuses, organic organizational structures, comfortable \\noffices, and other “high-touch” environmental features to balance the intense, some-\\ntimes arid intellectuality of the work itself. The most successful technical companies \\ncombine elements of high-tech and high-touch (Naisbitt 1982). This section describes \\nways in which programmers are more than organic reflections of their silicon alter egos.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 717}, page_content='28.5 Treating Programmers as People 681\\nHow Do Programmers Spend Their Time?\\nProgrammers spend their time programming, but they also spend time in meetings, \\non training, on reading their mail, and on just thinking. A 1964 study at Bell Labora-\\ntories found that programmers spent their time this way as described in Table 28-3.\\nThis data is based on a time-and-motion study of 70 programmers. The data is old, \\nand the proportions of time spent in the different activities would vary among pro-\\ngrammers, but the results are nonetheless thought-provoking. About 30 percent of a \\nprogrammer’s time is spent in nontechnical activities that don’t directly help the \\nproject: walking, personal business, and so on. Programmers in this study spent six \\npercent of their time walking; that’s about 2.5 hours a week, about 125 hours a year. \\nThat might not seem like much until you realize that programmers spend as much \\ntime each year walking as they spend in training, three times as much time as they \\nspend reading technical manuals, and six times as much as they spend talking with \\ntheir managers. I personally have not seen much change in this pattern today.\\nVariation in Performance and Quality\\nTalent and effort among individual programmers vary tremendously, as they do in all \\nfields. One study found that in a variety of professions—writing, football, invention, \\npolice work, and aircraft piloting—the top 20 percent of the people produced about 50 \\npercent of the output (Augustine 1979). The results of the study are based on an anal-\\nysis of productivity data, such as touchdowns, patents, solved cases, and so on. Since \\nsome people make no tangible contribution whatsoever and weren’t considered in the \\nstudy (quarterbacks who make no touchdowns, inventors who own no patents, detec-\\ntives who don’t close cases, and so on), the data probably understates the actual vari-\\nation in productivity.\\nTable 28-3 One View of How Programmers Spend Their Time\\nActivity\\nSource \\nCode Business Personal Meetings Training\\nMail/Misc. \\nDocuments\\nTechnical \\nManuals\\nOperating \\nProcedures, \\nMisc.\\nProgram \\nTest Totals\\nTalk or listen 4% 17% 7% 3% 1% 32%\\nTalk with \\nmanager\\n1% 1%\\nTelephone 2% 1% 3%\\nRead 14% 2% 2% 18%\\nWrite/record 13% 1% 14%\\nAway or out 4% 1% 4% 6% 15%\\nWalking 2% 2% 1% 1% 6%\\nMiscellaneous 2% 3% 3% 1% 1% 1% 11%\\nTotals 35% 29% 13% 7% 6% 5% 2% 2% 1% 100%\\nSource: “Research Studies of Programmers and Programming” (Bairdain 1964, reported in Boehm 1981).\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 718}, page_content='682 Chapter 28: Managing Construction\\nIn programming specifically, many studies have shown order-of-magnitude differ-\\nences in the quality of the programs written, the sizes of the programs written, and the \\nproductivity of programmers.\\nIndividual Variation\\nThe original study that showed huge variations in individual programming productiv-\\nity was conducted in the late 1960s by Sackman, Erikson, and Grant (1968). They \\nstudied professional programmers with an average of 7 years’ experience and found \\nthat the ratio of initial coding time between the best and worst programmers was \\nabout 20 to 1, the ratio of debugging times over 25 to 1, of program size 5 to 1, and of \\nprogram execution speed about 10 to 1. They found no relationship between a pro-\\ngrammer’s amount of experience and code quality or productivity.\\nAlthough specific ratios such as 25 to 1 aren’t particularly meaningful, more general \\nstatements such as “There are order-of-magnitude differences among programmers” \\nare meaningful and have been confirmed by many other studies of professional pro-\\ngrammers (Curtis 1981, Mills 1983, DeMarco and Lister 1985, Curtis et al. 1986, Card \\n1987, Boehm and Papaccio 1988, Valett and McGarry 1989, Boehm et al. 2000).\\nTeam Variation\\nProgramming teams also exhibit sizable differences in software quality and productiv-\\nity. Good programmers tend to cluster, as do bad programmers, an observation that \\nhas been confirmed by a study of 166 professional programmers from 18 organiza-\\ntions (Demarco and Lister 1999).\\nIn one study of seven identical projects, the efforts expended varied by a factor of 3.4 \\nto 1 and program sizes by a factor of 3 to 1 (Boehm, Gray, and Seewaldt 1984). In spite \\nof the productivity range, the programmers in this study were not a diverse group. \\nThey were all professional programmers with several years of experience who were \\nenrolled in a computer-science graduate program. It’s reasonable to assume that a \\nstudy of a less homogeneous group would turn up even greater differences.\\nAn earlier study of programming teams observed a 5-to-1 difference in program size \\nand a 2.6-to-1 variation in the time required for a team to complete the same project \\n(Weinberg and Schulman 1974).\\nAfter reviewing more than 20 years of data in constructing the Cocomo II estimation \\nmodel, Barry Boehm and other researchers concluded that developing a program with \\na team in the 15th percentile of programmers ranked by ability typically requires about \\n3.5 times as many work-months as developing a program with a team in the 90th per-\\ncentile (Boehm et al. 2000). Boehm and other researchers have found that 80 percent of \\nthe contribution comes from 20 percent of the contributors (Boehm 1987b).\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 719}, page_content='28.5 Treating Programmers as People 683\\nThe implication for recruiting and hiring is clear. If you have to pay more to get a top-10-\\npercent programmer rather than a bottom-10-percent programmer, jump at the chance. \\nYou’ll get an immediate payoff in the quality and productivity of the programmer you \\nhire, and you’ll get a residual effect in the quality and productivity of the other program-\\nmers your organization is able to retain because good programmers tend to cluster.\\nReligious Issues\\nManagers of programming projects aren’t always aware that certain programming \\nissues are matters of religion. If you’re a manager and you try to require compliance \\nwith certain programming practices, you’re inviting your programmers’ ire. Here’s a \\nlist of religious issues:\\n■ Programming language\\n■ Indentation style\\n■ Placing of braces\\n■ Choice of IDE \\n■ Commenting style\\n■ Efficiency vs. readability tradeoffs\\n■ Choice of methodology—for example, Scrum vs. Extreme Programming vs. evo-\\nlutionary delivery\\n■ Programming utilities\\n■ Naming conventions\\n■ Use of gotos\\n■ Use of global variables\\n■ Measurements, especially productivity measures such as lines of code per day\\nThe common denominator among these topics is that a programmer’s position on \\neach is a reflection of personal style. If you think you need to control a programmer in \\nany of these religious areas, consider these points:\\nBe aware that you’re dealing with a sensitive area Sound out the programmer on \\neach emotional topic before jumping in with both feet.\\nUse “suggestions” or “guidelines” with respect to the area Avoid setting rigid “rules” \\nor “standards.”\\nFinesse the issues you can by sidestepping explicit mandates To finesse indentation \\nstyle or brace placement, require source code to be run through a pretty-printer for-\\nmatter before it’s declared finished. Let the pretty printer do the formatting. To finesse \\ncommenting style, require that all code be reviewed and that unclear code be modi-\\nfied until it’s clear.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 720}, page_content='684 Chapter 28: Managing Construction\\nHave your programmers develop their own standards As mentioned elsewhere, the \\ndetails of a specific standard are often less important than the fact that some standard \\nexists. Don’t set standards for your programmers, but do insist they standardize in the \\nareas that are important to you.\\nWhich of the religious topics are important enough to warrant going to the mat? Con-\\nformity in minor matters of style in any area probably won’t produce enough benefit \\nto offset the effects of lower morale. If you find indiscriminate use of gotos or global \\nvariables, unreadable styles, or other practices that affect whole projects, be prepared \\nto put up with some friction to improve code quality. If your programmers are consci-\\nentious, this is rarely a problem. The biggest battles tend to be over nuances of coding \\nstyle, and you can stay out of those with no loss to the project.\\nPhysical Environment\\nHere’s an experiment: go out to the country, find a farm, find a farmer, and ask how \\nmuch money in equipment the farmer has for each worker. The farmer will look at the \\nbarn and see a few tractors, some wagons, a combine for wheat, and a peaviner for \\npeas and will tell you that it’s over $100,000 per employee.\\nNext go to the city, find a programming shop, find a programming manager, and ask \\nhow much money in equipment the programming manager has for each worker. The \\nprogramming manager will look at an office and see a desk, a chair, a few books, and \\na computer and will tell you that it’s under $25,000 per employee.\\nPhysical environment makes a big difference in productivity. DeMarco and Lister asked \\n166 programmers from 35 organizations about the quality of their physical environments. \\nMost employees rated their workplaces as not acceptable. In a subsequent programming \\ncompetition, the programmers who performed in the top 25 percent had bigger, quieter, \\nmore private offices and fewer interruptions from people and phone calls. Here’s a \\nsummary of the differences in office space between the best and worst performers:\\nEnvironmental Factor Top 25% Bottom 25%\\nDedicated floor space 78 sq. ft. 46 sq. ft.\\nAcceptably quiet workspace 57% yes 29% yes\\nAcceptably private workspace 62% yes 19% yes\\nAbility to silence phone 52% yes 10% yes\\nAbility to divert calls 76% yes 19% yes\\nFrequent needless interruptions 38% yes 76% yes\\nWorkspace that makes programmer \\nfeel appreciated 57% yes 29% yes\\nSource: Peopleware (DeMarco and Lister 1999).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 721}, page_content='28.5 Treating Programmers as People 685\\nThe data shows a strong correlation between productivity and the quality of the work-\\nplace. Programmers in the top 25 percent were 2.6 times more productive than pro-\\ngrammers in the bottom 25 percent. DeMarco and Lister thought that the better \\nprogrammers might naturally have better offices because they had been promoted, but \\nfurther examination revealed that this wasn’t the case. Programmers from the same \\norganizations had similar facilities, regardless of differences in their performance.\\nLarge software-intensive organizations have had similar experiences. Xerox, TRW, \\nIBM, and Bell Labs have indicated that they realize significantly improved productivity \\nwith a $10,000 to $30,000 capital investment per person, sums that were more than \\nrecaptured in improved productivity (Boehm 1987a). With “productivity offices,” self-\\nreported estimates ranged from 39 to 47 percent improvement in productivity \\n(Boehm et al. 1984).\\nIn summary, if your workplace is a bottom-25 percent environment, you can realize \\nabout a 100 percent improvement in productivity by making it a top-25 percent envi-\\nronment. If your workplace is average, you can still realize a productivity improvement \\nof 40 percent or more by making it a top-25 percent environment.\\nAdditional Resources on Programmers as Human Beings\\ncc2e.com/2806 Here are additional resources:\\nWeinberg, Gerald M. The Psychology of Computer Programming, 2d ed. New York, NY: \\nVan Nostrand Reinhold, 1998. This is the first book to explicitly identify program-\\nmers as human beings, and it’s still the best on programming as a human activity. It’s \\ncrammed with acute observations about the human nature of programmers and its \\nimplications.\\nDeMarco, Tom and Timothy Lister. Peopleware: Productive Projects and Teams, 2d ed. New \\nYork, NY: Dorset House, 1999. As the title suggests, this book also deals with the human \\nfactor in the programming equation. It’s filled with anecdotes about managing people, \\nthe office environment, hiring and developing the right people, growing teams, and \\nenjoying work. The authors lean on the anecdotes to support some uncommon view-\\npoints and their logic is thin in places, but the people-centered spirit of the book is \\nwhat’s important and the authors deliver that message without faltering.\\ncc2e.com/2820 McCue, Gerald M. “IBM’s Santa Teresa Laboratory—Architectural Design for Pro-\\ngram Development,” IBM Systems Journal  17, no. 1 (1978): 4–25. McCue describes \\nthe process that IBM used to create its Santa Teresa office complex. IBM studied pro-\\ngrammer needs, created architectural guidelines, and designed the facility with pro-\\ngrammers in mind. Programmers participat ed throughout. The result is that in \\nannual opinion surveys each year, the physic al facilities at the Santa Teresa facility \\nare rated the highest in the company.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 722}, page_content='686 Chapter 28: Managing Construction\\nMcConnell, Steve. Professional Software Development. Boston, MA: Addison-Wesley, \\n2004. Chapter 7, “Orphans Preferred,” summarizes studies on programmer demo-\\ngraphics, including personality types, educational backgrounds, and job prospects.\\nCarnegie, Dale. How to Win Friends and Influence People, Revised Edition. New York, \\nNY: Pocket Books, 1981. When Dale Carnegie wrote the title for the first edition of this \\nbook in 1936, he couldn’t have realized the connotation it would carry today. It \\nsounds like a book Machiavelli would have displayed on his shelf. The spirit of the \\nbook is diametrically opposed to Machiavellian manipulation, however, and one of \\nCarnegie’s key points is the importance of developing a genuine interest in other peo-\\nple. Carnegie has a keen insight into everyday relationships and explains how to work \\nwith other people by understanding them better. The book is filled with memorable \\nanecdotes, sometimes two or three to a page. Anyone who works with people should \\nread it at some point, and anyone who manages people should read it now.\\n28.6 Managing Your Manager\\nIn software development, nontechnical managers are common, as are managers who \\nhave technical experience but who are 10 years behind the times. Technically compe-\\ntent, technically current managers are rare. If you work for one, do whatever you can \\nto keep your job. It’s an unusual treat.\\nIn a hierarchy, every \\nemployee tends to rise to his \\nlevel of incompetence.\\n—The Peter Principle\\nIf your manager is more typical, you’re faced with the unenviable task of managing \\nyour manager. “Managing your manager” means that you need to tell your manager \\nwhat to do rather than the other way around. The trick is to do it in a way that allows \\nyour manager to continue believing that you are the one being managed. Here are \\nsome approaches to dealing with your manager:\\n■ Plant ideas for what you want to do, and then wait for your manager to have a \\nbrainstorm (your idea) about doing what you want to do.\\n■ Educate your manager about the right way to do things. This is an ongoing job \\nbecause managers are often promoted, transferred, or fired.\\n■ Focus on your manager’s interests, doing what he or she really wants you to do, \\nand don’t distract your manager with unnecessary implementation details. \\n(Think of it as “encapsulation” of your job.)\\n■ Refuse to do what your manager tells you, and insist on doing your job the right \\nway.\\n■ Find another job.\\nThe best long-term solution is to try to educate your manager. That’s not always an \\neasy task, but one way you can prepare for it is by reading Dale Carnegie’s How to Win \\nFriends and Influence People.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 723}, page_content='Additional Resources on Managing Construction 687\\nAdditional Resources on Managing Construction\\ncc2e.com/2813 Here are a few books that cover issues of general concern in managing software projects:\\nGilb, Tom. Principles of Software Engineering Management. Wokingham, England: Addi-\\nson-Wesley, 1988. Gilb has charted his own course for thirty years, and most of the time \\nhe’s been ahead of the pack whether or not the pack realizes it. This book is a good \\nexample. This was one of the first books to discuss evolutionary development practices, \\nrisk management, and the use of formal inspections. Gilb is keenly aware of leading-\\nedge approaches; indeed, this book published more than 15 years ago contains most of \\nthe good practices currently flying under the “Agile” banner. Gilb is incredibly prag-\\nmatic, and the book is still one of the best software-management books.\\nMcConnell, Steve. Rapid Development. Redmond, WA: Microsoft Press, 1996. This \\nbook covers project-leadership and project-management issues from the perspective \\nof projects that are experiencing significant schedule pressure, which in my experi-\\nence is most projects.\\nBrooks, Frederick P., Jr. The Mythical Man-Month: Essays on Software Engineering, Anni-\\nversary Edition (2d ed). Reading, MA: Addison-Wesley, 1995. This book is a hodge-\\npodge of metaphors and folklore related to managing programming projects. It’s \\nentertaining, and it will give you many illuminating insights into your own projects. \\nIt’s based on Brooks’s challenges in developing the OS/360 operating system, which \\ngives me some reservations. It’s full of advice along the lines of “We did this and it \\nfailed” and “We should have done this because it would have worked.” Brooks’s obser-\\nvations about techniques that failed are well grounded, but his claims that other tech-\\nniques would have worked are too speculative. Read the book critically to separate the \\nobservations from the speculations. This warning doesn’t diminish the book’s basic \\nvalue. It’s still cited in computing literature more often than any other book, and even \\nthough it was originally published in 1975, it seems fresh today. It’s hard to read it \\nwithout saying “Right on!” every couple of pages.\\nRelevant Standards\\nIEEE Std 1058-1998, Standard for Software Project Management Plans.\\nIEEE Std 12207-1997, Information Technology—Software Life Cycle Processes.\\nIEEE Std 1045-1992, Standard for Software Productivity Metrics.\\nIEEE Std 1062-1998, Recommended Practice for Software Acquisition.\\nIEEE Std 1540-2001, Standard for Software Life Cycle Processes—Risk Management.\\nIEEE Std 828-1998, Standard for Software Configuration Management Plans\\nIEEE Std 1490-1998, Guide—Adoption of PMI Standard—A Guide to the Project Management \\nBody of Knowledge.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 724}, page_content='688 Chapter 28: Managing Construction\\nKey Points\\n■ Good coding practices can be achieved either through enforced standards or \\nthrough more light-handed approaches.\\n■ Configuration management, when properly applied, makes programmers’ jobs \\neasier. This especially includes change control.\\n■ Good software estimation is a significant challenge. Keys to success are using \\nmultiple approaches, tightening down your estimates as you work your way into \\nthe project, and making use of data to create the estimates.\\n■ Measurement is a key to successful construction management. You can find \\nways to measure any aspect of a project that are better than not measuring it at \\nall. Accurate measurement is a key to accurate scheduling, to quality control, \\nand to improving your development process.\\n■ Programmers and managers are people, an d they work best when treated as \\nsuch.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 725}, page_content='689\\nChapter 29\\nIntegration\\ncc2e.com/2985 Contents\\n■ 29.1 Importance of the Integration Approach: page 689\\n■ 29.2 Integration Frequency—Phased or Incremental?: page 691\\n■ 29.3 Incremental Integration Strategies: page 694\\n■ 29.4 Daily Build and Smoke Test: page 702\\nRelated Topics\\n■ Developer testing: Chapter 22\\n■ Debugging: Chapter 23\\n■ Managing construction: Chapter 28\\nThe term “integration” refers to the software-development activity in which you com-\\nbine separate software components into a single system. On small projects, integra-\\ntion might consist of a morning spent hooking a handful of classes together. On large \\nprojects, it might consist of weeks or months of hooking sets of programs together. \\nRegardless of the size of the task, common principles apply.\\nThe topic of integration is intertwined with the topic of construction sequence. The \\norder in which you build classes or components affects the order in which you can \\nintegrate them—you can’t integrate something that hasn’t been built yet. Both integra-\\ntion and construction sequence are important topics. This chapter addresses both \\ntopics from the integration point of view.\\n29.1 Importance of the Integration Approach\\nIn engineering fields other than software, the importance of proper integration is well \\nknown. The Pacific Northwest, where I live, saw a dramatic illustration of the hazards \\nof poor integration when the football stadium at the University of Washington col-\\nlapsed partway through construction, as shown in Figure 29-1.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 726}, page_content='690 Chapter 29: Integration\\nFigure 29-1 The football stadium add-on at the University of Washington collapsed \\nbecause it wasn’t strong enough to support itse lf during construction. It likely would have \\nbeen strong enough when completed, but it was constructed in the wrong order—an \\nintegration error.\\nIt doesn’t matter that the stadium would have been strong enough by the time it was \\ndone; it needed to be strong enough at each step. If you construct and integrate soft-\\nware in the wrong order, it’s harder to code, harder to test, and harder to debug. If \\nnone of it will work until all of it works, it can seem as though it will never be finished. \\nIt too can collapse under its own weight during construction—the bug count might \\nseem insurmountable, progress might be invisible, or the complexity might be over-\\nwhelming—even though the finished product would have worked.\\nBecause it’s done after a developer has finished developer testing and in conjunction \\nwith system testing, integration is sometimes thought of as a testing activity. It’s com-\\nplex enough, however, that it should be viewed as an independent activity.\\nYou can expect some of these benefits from careful integration:\\n■ Easier defect diagnosis\\n■ Fewer defects\\n■ Less scaffolding\\n■ Shorter time to first working product\\n■ Shorter overall development schedules\\n■ Better customer relations\\n■ Improved morale\\n■ Improved chance of project completion\\n■ More reliable schedule estimates\\n■ More accurate status reporting\\n■ Improved code quality\\n■ Less documentation\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 727}, page_content='29.2 Integration Frequency—Phased or Incremental? 691\\nThese might seem like elevated claims for system testing’s forgotten cousin, but the \\nfact that it’s overlooked in spite of its importance is precisely the reason integration \\nhas its own chapter in this book.\\n29.2 Integration Frequency—Phased or Incremental?\\nPrograms are integrated by means of either the phased or the incremental approach.\\nPhased Integration\\nUntil a few years ago, phased integration was the norm. It follows these well-defined \\nsteps, or phases:\\n1. Design, code, test, and debug each class. This step is called “unit development.”\\n2. Combine the classes into one whopping -big system (“system integration”).\\n3. Test and debug the whole system. This is called “system dis-integration.” \\n(Thanks to Meilir Page-Jones for this witty observation.)\\nOne problem with phased integration is that when the classes in a system are put \\ntogether for the first time, new problems inevitably surface and the causes of the prob-\\nlems could be anywhere. Since you have a large number of classes that have never \\nworked together before, the culprit might be a poorly tested class, an error in the inter-\\nface between two classes, or an error caused by an interaction between two classes. All \\nclasses are suspect.\\nThe uncertainty about the location of any of the specific problems is compounded \\nby the fact that all the problems suddenly present themselves at once. This forces \\nyou to deal not only with problems caused  by interactions between classes but with \\nproblems that are hard to diagnose beca use the problems themselves interact. For \\nthis reason, another name for phased integration is “big bang integration,” as shown \\nin Figure 29-2.\\nFigure 29-2 Phased integration is also called “big bang” integration for a good reason!\\nBig Bang \\nIntegration\\nPoorly \\ndocumented\\ninterfaces\\nWeak \\nencapsulation\\nDifferent error- \\nhandling  \\nassumptions\\nGlobal \\nvariables'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 728}, page_content='692 Chapter 29: Integration\\nPhased integration can’t begin until late in the project, after all the classes have been \\ndeveloper-tested. When the classes are finally combined and errors surface by the \\nscore, programmers immediately go into panicky debugging mode rather than \\nmethodical error detection and correction.\\nFor small programs—no, for tiny programs—phased integration might be the best \\napproach. If the program has only two or three classes, phased integration might save \\nyou time, if you’re lucky. But in most cases, another approach is better.\\nIncremental Integration\\nCross-Reference Metaphors \\nappropriate for incremental \\nintegration are discussed in \\n“Software Oyster Farming: \\nSystem Accretion” and “Soft-\\nware Construction: Building \\nSoftware,” both in Section 2.3.\\nIn incremental integration, you write and test a program in small pieces and then \\ncombine the pieces one at a time. In this one-piece-at-a-time approach to integration, \\nyou follow these steps:\\n1. Develop a small, functional part of the system. It can be the smallest functional \\npart, the hardest part, a key part, or some combination. Thoroughly test and \\ndebug it. It will serve as a skeleton on which to hang the muscles, nerves, and \\nskin that make up the remaining parts of the system.\\n2. Design, code, test, and debug a class.\\n3. Integrate the new class with the skeleton. Test and debug the combination of \\nskeleton and new class. Make sure the combination works before you add any \\nnew classes. If work remains to be done, repeat the process starting at step 2.\\nOccasionally, you might want to integrate units larger than a single class. If a compo-\\nnent has been thoroughly tested, for example, and each of its classes put through a \\nmini-integration, you can integrate the whole component and still be doing incremen-\\ntal integration. As you add pieces to it, the system grows and gains momentum in the \\nsame way that a snowball grows and gains momentum when it rolls down a hill, as \\nshown in Figure 29-3.\\nFigure 29-3 Incremental integration helps a project build momentum, like a snowball \\ngoing down a hill.\\nIncremental Integration\\nSnowballing \\nIntegration'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 729}, page_content='29.2 Integration Frequency—Phased or Incremental? 693\\nBenefits of Incremental Integration\\nThe incremental approach offers many advantages over the traditional phased \\napproach regardless of which incremental strategy you use:\\nErrors are easy to locate When new problems surface during incremental integra-\\ntion, the new class is obviously involved. Either its interface to the rest of the program \\ncontains an error or its interaction with a previously integrated class produces an \\nerror. Either way, as suggested by Figure 29-4, you know exactly where to look. More-\\nover, simply because you have fewer problems at once, you reduce the risk that multi-\\nple problems will interact or that one problem will mask another. The more interface \\nerrors you tend to have, the more this benefit of incremental integration will help your \\nprojects. An accounting of errors for one project revealed that 39 percent were inter-\\nmodule interface errors (Basili and Perricone 1984). Because developers on many \\nprojects spend up to 50 percent of their time debugging, maximizing debugging effec-\\ntiveness by making errors easy to locate provides benefits in quality and productivity.\\nFigure 29-4 In phased integration, you integrate so many components at once that it’s \\nhard to know where the error is. It might be in any of the components or in any of their con-\\nnections. In incremental integration, the error is usually either in the new component or in \\nthe connection between the new component and the system.\\nThe system succeeds early in the project When code is integrated and running, even \\nif the system isn’t usable, it’s apparent that it soon will be. With incremental integra-\\ntion, programmers see early results from their work, so their morale is better than \\nwhen they suspect that their project will never draw its first breath.\\nYou get improved progress monitoring When you integrate frequently, the features \\nthat are present and not present are obvious. Management will have a better sense of \\nprogress from seeing 50 percent of a system’s capability working than from hearing \\nthat coding is “99 percent complete.”\\n1\\n2\\n3\\nHARD DATA\\nPhased \\nIntegration\\nIncremental \\nIntegration\\nYlkr kis m ik ocos ptosm.  U jy eteb\\nnsucn d yubwebd susnd Ubr id ksi.\\nSi dios b ydbs ;ld9oiicv  dolsn.  Jst\\nsksi kiuebna Idiopi iwj oispoj.\\nDyubwebd susnd Ubr id ksi.  B\\nydbs ldoicv . Zust si kibna\\nIdiopi iwj oispoj.\\nTst sksi kiuebna Idiopi iwj poj.  Ylkr\\nkis m ik ocos ptosm.\\nYlkr kis m ik\\nocos ptosm.\\n U jy eteb\\nnsucn d yubw\\nebd susnd Ubr id ksi.\\nSi dios b ydbs \\n;ld9oiicv  dols\\nn.  Jst\\nsksi kiuebna Id\\niopi iwj oispo\\nj.\\nDyubwebd susnd Ubr\\nid ksi. B\\nydbs ldoicv. Zust si kibna\\nIdiopi iwj oisp\\noj.\\nTst sksi kiuebna\\n Idiopi iwj poj\\n.  Ylkr\\nkis m ik ocos ptosm.\\nYlkr kis m ik ocos ptosm.\\n U jyeteb\\nnsucn d\\nyubwebd susnd Ubr\\nid ksi.\\nSi dios b ydbs ;\\nld9oiicv  dolsn\\n.  Jst\\nsksi kiuebna Id\\niopi iwj oispoj\\n.\\nDyubwebd susnd Ubr\\nid ksi.\\n B\\nydbs ldoicv\\n. Zust si kibna\\nIdiopi iwj oisp\\noj.\\nTst sksi kiuebna Idiopi iwj poj.  \\nYlkr\\nkis m ik\\nocos ptosm.\\nnsucn d yubwebd susnd Ubr\\nSi dios b ydbs ;ld9oiicv  dolsn.  Jst\\nsksi kiuebna Idiopi iwj oispoj.\\nDyubwebd susnd Ubr id ksi.  B\\nydbs ldoicv . Zust si kibna\\nIdiopi iwj oispoj.\\nTst sksi kiuebna Idiopi iwj poj.  Ylkr\\nkis m ik ocos ptosm.\\nnsucn dyub\\ndios b ydbs ;ld9oiicv  dolsn. Jst sksi\\nkiuebna Idiopi iwj oispoj.\\nDyubwebd susnd Ubrid ksi. B ydbs\\nldoicv. Zust si kibna Idiopi iwj\\noispoj.\\nTst sksi kiuebna Idiopi iwj poj. Ylkr kis\\nm ikocos ptosm.\\nYlkr kis m ik ocos ptosm.  U jy eteb\\nnsucn d yubw\\nebd susnd Ubr\\nid ksi.\\nSi dios b ydbs ;l\\nd9oiicv  dol\\nsn.\\n Jst\\nsksi kiuebna Idiop\\ni iwj oisp\\noj.\\nDyubwebd susnd Ubr\\nid ksi.\\n B\\nydbs ldoicv\\n. Zust si kibna\\nIdiopi iwj oispoj.\\nTst sksi kiuebna Id\\niopi iwj poj.\\n Ylkr\\nkis m ik\\nocos ptosm.\\nYlkr kis m ikocos ptosm. U jy\\neteb\\nnsucn dyub\\nwebd susnd Ubrid \\nksi. Si\\ndios b y\\ndbs ;ld9oiicv  dolsn. Jst sksikiuebna Idiopi iwj \\noispoj.\\nDyub\\nwebd susnd Ubrid ksi. B y\\ndbs\\nldoicv\\n. Zust si kibna Id\\niopi iwj\\noispoj.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 729}, page_content='eteb\\nnsucn dyub\\nwebd susnd Ubrid \\nksi. Si\\ndios b y\\ndbs ;ld9oiicv  dolsn. Jst sksikiuebna Idiopi iwj \\noispoj.\\nDyub\\nwebd susnd Ubrid ksi. B y\\ndbs\\nldoicv\\n. Zust si kibna Id\\niopi iwj\\noispoj.\\nTst sksi kiuebna Idiopi iwj poj. Ylk\\nr kis\\nm ikocos ptosm.\\nYlkr kis m ik\\nocos ptosm.\\n U jy eteb\\nnsucn d yubwebd susnd Ubr\\nid ksi.\\nSi dios b ydbs ;ld9oiicv  dolsn.  Jst\\nsksi kiuebna Idiopi iwj oispoj.\\nDyubwebd susnd Ubr\\nid ksi.  B\\nydbs ldoicv . Zust si kibna\\nIdiopi iwj oispo\\nj.\\nTst sksi kiuebna Idiopi iwj poj.\\n Ylkr\\nkis m ik ocos ptosm.\\nYlkr kis m ik\\nocos ptosm. U jyete\\nb\\nnsucn dyubwebd susnd Ubrid ksi. Si\\ndios b ydbs ;ld9oiicv  dolsn. Jst sksi\\nkiuebna Idiopi iwj oispoj.\\nDyubwebd susnd Ubrid ksi. B y\\ndbs\\nldoicv. Zust si kibna Idiopi iwj\\noispoj.\\nTst sksi kiuebna Idiopi iwj poj. Yl\\nkr kis\\nm ikocos ptosm.\\nYlkr kis m ik ocos ptosm.  U jy eteb\\nnsucn d yubw\\nebd susnd Ubr id ksi.\\nSi dios b ydbs ;ld9oiicv  dolsn.  Jst\\nsksi kiuebna\\n Idiopi iwj oispoj.\\nDyubw\\nebd susnd Ubr id ksi.\\n B\\nydbs ldoicv . Zust si kibna\\nIdiopi iwj oispoj.\\nTst sksi kiuebna Idiopi iwj poj.\\n Ylkr\\nkis m ik\\nocos ptosm. Ylkr kis m ikocos ptosm. U jyeteb\\nnsucn dyubwebd susnd Ubrid ksi. Si\\ndios b ydbs ;ld9oiicv  dolsn. Jst sksi\\nkiuebna Idiopi iwj oispoj.\\nDyubwebd susnd Ubrid ksi. B ydbs\\nldoicv. Zust si kibna Idiopi iwj\\noispoj.\\nTst sksi kiuebna Idiopi iwj poj. Ylkr kis\\nm ikocos ptosm.\\nYlkr kis m ikocos ptosm. U jyet\\neb\\nnsucn dyubwebd susnd Ubrid k\\nsi. Si\\ndios b ydbs ;ld9oiicv  dol\\nsn. Jst sksi\\nkiuebna Idiopi iw\\nj oispoj.\\nDyubwebd susnd Ubrid ksi. B ydbs\\nldoicv. Zust si kibna I\\ndiopi iwj\\noispoj.\\nTst sksi kiuebna Idiopi iwj poj.\\n Ylkr kis\\nm ikocos ptosm.\\nYlkr kis m ik\\nocos ptosm. U jyet\\neb\\nnsucn dyubw\\nebd susnd Ubrid ksi. Si\\ndios b ydbs ;ld9oiicv  dolsn. Jst sksi\\nkiuebna Idiopi iwj oispoj.\\nDyubwebd susnd Ubrid ksi. B y\\ndbs\\nldoicv. Zust si kibna I\\ndiopi iwj\\noispoj.\\nTst sksi kiuebna Idiopi iwj poj\\n. Ylkr kis\\nm ikocos ptosm.\\nYlkr kis m ikocos ptosm. U jyeteb\\nnsucn dyub\\nwebd susnd Ub\\nrid ksi. Si\\ndios b ydbs ;ld9oiicv  dolsn. Jst sksi\\nkiuebna Idiopi iwj oispoj.\\nDyubwebd susnd Ubrid ksi. B y\\ndbs\\nldoicv. Zust si kibna Idiopi iwj\\noispoj.\\nTst sksi kiuebna Id\\niopi iwj poj. Ylkr kis\\nm ikocos ptosm.\\nYlkr kis m ik ocos ptosm.\\n U jy\\neteb\\nnsucn d\\nyubwebd susnd Ubr\\nid ksi.\\nSi dios b ydb\\ns ;ld9oiicv  dolsn.  Jst\\nsksi kiuebna Idiopi iwj oispoj.\\nDyubw\\nebd susnd Ubr\\nid ksi.\\n B\\nydbs ldoicv\\n. Zust si kibna\\nIdiopi iwj ois\\npoj.\\nTst sksi kiuebna Idiopi iwj \\npoj.\\n Ylkr\\nkis m ik ocos ptosm.\\nYlkr kis m ik\\nocos ptosm. U j\\nyeteb\\nnsucn dyub\\nwebd susnd Ubri\\nd ksi. Si\\ndios b ydbs ;ld9oiicv  dolsn. Jst sksi\\nkiuebna Idiopi iwj oispoj.\\nDyub\\nwebd susnd Ubrid ksi. B y\\ndbs\\nldoicv\\n. Zust si kibna Idiopi iwj\\noispoj.\\nTst sksi kiuebna Idiopi iwj poj. Ylkr kis\\nm ik\\nocos ptosm.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 730}, page_content='694 Chapter 29: Integration\\nYou’ll improve customer relations If frequent integration has an effect on developer \\nmorale, it also has an effect on customer morale. Customers like signs of progress, and \\nincremental builds provide signs of progress frequently.\\nThe units of the system are tested more fully Integration starts early in the project. \\nYou integrate each class as it’s developed, rather than waiting for one magnificent \\nbinge of integration at the end. Classes are developer-tested in both cases, but each \\nclass is exercised as a part of the overall system more often with incremental integra-\\ntion than it is with phased integration.\\nYou can build the system with a shorter development scheduleIf integration is \\nplanned carefully, you can design part of the system while another part is being \\ncoded. This doesn’t reduce the total number of work-hours required to develop the \\ncomplete design and code, but it allows some work to be done in parallel, an advan-\\ntage when calendar time is at a premium.\\nIncremental integration supports and encourages other incremental strategies. The \\nadvantages of incrementalism applied to integration are the tip of the iceberg.\\n29.3 Incremental Integration Strategies\\nWith phased integration, you don’t have to plan the order in which project compo-\\nnents are built. All components are integrated at the same time, so you can build them \\nin any order as long as they’re all ready by D-day.\\nWith incremental integration, you have to plan more carefully. Most systems will call \\nfor the integration of some components before the integration of others. Planning for \\nintegration thus affects planning for construction; the order in which components are \\nconstructed has to support the order in which they will be integrated.\\nIntegration-order strategies come in a variety of shapes and sizes, and none is best in \\nevery case. The best integration approach varies from project to project, and the best \\nsolution is always the one that you create to meet the specific demands of a specific \\nproject. Knowing the points on the methodological number line will give you insight \\ninto the possible solutions.\\nTop-Down Integration\\nIn top-down integration, the class at the top of the hierarchy is written and integrated \\nfirst. The top is the main window, the applications control loop, the object that con-\\ntains main() in Java, WinMain() for Microsoft Windows programming, or similar. \\nStubs have to be written to exercise the top class. Then, as classes are integrated from \\nthe top down, stub classes are replaced with real ones. This kind of integration pro-\\nceeds as illustrated in Figure 29-5.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 731}, page_content='29.3 Incremental Integration Strategies 695\\nFigure 29-5 In top-down integration, you add classes at the top first, at the bottom last.\\nAn important aspect of top-down integration is that the interfaces between classes \\nmust be carefully specified. The most troublesome errors to debug are not the ones \\nthat affect single classes but those that arise from subtle interactions between classes. \\nCareful interface specification can reduce the problem. Interface specification isn’t an \\nintegration activity, but making sure that the interfaces have been specified well is.\\nIn addition to the advantages you get from any kind of incremental integration, an \\nadvantage of top-down integration is that the control logic of the system is tested rel-\\natively early. All the classes at the top of the hierarchy are exercised a lot so that big, \\nconceptual, design problems are exposed quickly.\\nAnother advantage of top-down integration is that, if you plan it carefully, you can \\ncomplete a partially working system early in the project. If the user-interface parts are \\nat the top, you can get a basic interface working quickly and flesh out the details later. \\nThe morale of both users and programmers benefits from getting something visible \\nworking early.\\nTop-down incremental integration also allows you to begin coding before the low-\\nlevel design details are complete. Once the design has been driven down to a fairly low \\nlevel of detail in all areas, you can begin implementing and integrating the classes at \\nthe higher levels without waiting to dot every “i” and cross every “t.”\\nIn spite of these advantages, pure top-down integration usually involves disadvantages \\nthat are more troublesome than you’ll want to put up with. Pure top-down integration \\nleaves exercising the tricky system interfaces until last. If system interfaces are buggy \\nor a performance problem, you’d usually like to get to them long before the end of the \\nproject. It’s not unusual for a low-level problem to bubble its way to the top of the sys-\\ntem, causing high-level changes and reducing the benefit of earlier integration work. \\nMinimize the bubbling problem through careful, early developer testing and perfor-\\nmance analysis of the classes that exercise system interfaces.\\nStart\\nFinish'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 732}, page_content='696 Chapter 29: Integration\\nAnother problem with pure top-down integration is that you need a dump truck full of \\nstubs to integrate from the top down. Many low-level classes haven’t been integrated, \\nwhich implies that a large number of stubs will be needed during intermediate steps \\nin integration. Stubs are problematic in that, as test code, they’re more likely to con-\\ntain errors than the more carefully designed production code. Errors in the new stubs \\nthat support a new class defeat the purpose of incremental integration, which is to \\nrestrict the source of errors to one new class.\\nCross-Reference Top-down \\nintegration is related to top-\\ndown design in name only. \\nFor details on top-down \\ndesign, see “Top-Down \\nand Bottom-Up Design \\nApproaches” in Section 5.4.\\nTop-down integration is also nearly impossible to implement purely. In top-down inte-\\ngration done by the book, you start at the top—call it Level 1—and then integrate all \\nthe classes at the next level (Level 2). When you’ve integrated all the classes from \\nLevel 2, and not before, you integrate the classes from Level 3. The rigidity in pure top-\\ndown integration is completely arbitrary. It’s hard to imagine anyone going to the \\ntrouble of using pure top-down integration. Most people use a hybrid approach, such \\nas integrating from the top down in sections instead.\\nFinally, you can’t use top-down integration if the collection of classes doesn’t have a \\ntop. In many interactive systems, the location of the “top” is subjective. In many sys-\\ntems, the user interface is the top. In other systems, main() is the top.\\nA good alternative to pure top-down integration is the vertical-slice approach shown \\nin Figure 29-6. In this approach, the system is implemented top-down in sections, per-\\nhaps fleshing out areas of functionality one by one and then moving to the next area.\\nFigure 29-6 As an alternative to proceeding strictly top to bottom, you can integrate from \\nthe top down in vertical slices.\\nEven though pure top-down integration isn’t workable, thinking about it will help you \\ndecide on a general approach. Some of the benefits and hazards that apply to a pure \\ntop-down approach apply, less obviously, to looser top-down approaches like vertical-\\nslice integration, so keep them in mind.\\nStart\\nFinishFinishFinish'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 733}, page_content='29.3 Incremental Integration Strategies 697\\nBottom-Up Integration\\nIn bottom-up integration, you write and integrate the classes at the bottom of the hier-\\narchy first. Adding the low-level classes one at a time rather than all at once is what \\nmakes bottom-up integration an incremental integration strategy. You write test driv-\\ners to exercise the low-level classes initially and add classes to the test-driver scaffold-\\ning as they’re developed. As you add higher-level classes, you replace driver classes \\nwith real ones. Figure 29-7 shows the order in which classes are integrated in the bot-\\ntom-up approach.\\nFigure 29-7 In bottom-up integration, you integrate classes at the bottom first, at the top \\nlast.\\nBottom-up integration provides a limited set of incremental integration advantages. It \\nrestricts the possible sources of error to the single class being integrated, so errors are \\neasy to locate. Integration can start early in the project. Bottom-up integration also \\nexercises potentially troublesome system interfaces early. Since system limitations \\noften determine whether you can meet the system’s goals, making sure the system has \\ndone a full set of calisthenics is worth the trouble.\\nThe main problem with bottom-up integration is that it leaves integration of the \\nmajor, high-level system interfaces until last. If the system has conceptual design prob-\\nlems at the higher levels, construction won’t find them until all the detailed work has \\nbeen done. If the design must be changed significantly, some of the low-level work \\nmight have to be discarded.\\nBottom-up integration requires you to complete the design of the whole system before \\nyou start integration. If you don’t, assumptions that needn’t have controlled the design \\nmight end up deeply embedded in low-level code, giving rise to the awkward situation \\nin which you design high-level classes to work around problems in low-level ones. Let-\\nting low-level details drive the design of higher-level classes contradicts principles of \\ninformation hiding and object-oriented design. The problems of integrating higher-level \\nclasses are but a teardrop in a rainstorm compared to the problems you’ll have if you \\ndon’t complete the design of high-level classes before you begin low-level coding.\\nStart\\nFinish'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 734}, page_content='698 Chapter 29: Integration\\nAs with top-down integration, pure bottom-up integration is rare, and you can use a \\nhybrid approach instead, including integrating in slices as shown in Figure 29-8.\\nFigure 29-8 As an alternative to proceeding purely bottom to top, you can integrate from \\nthe bottom up in sections. This blurs the line between bottom-up integration and feature-\\noriented integration, which is described later in this chapter.\\nSandwich Integration\\nThe problems with pure top-down and pure bottom-up integration have led some \\nexperts to recommend a sandwich approach (Myers 1976). You first integrate the \\nhigh-level business-object classes at the top of the hierarchy. Then you integrate the \\ndevice-interface classes and widely used utility classes at the bottom. These high-level \\nand low-level classes are the bread of the sandwich.\\nYou leave the middle-level classes until later. These make up the meat, cheese, and toma-\\ntoes of the sandwich. If you’re a vegetarian, they might make up the tofu and bean \\nsprouts of the sandwich, but the author of sandwich integration is silent on this point—\\nmaybe his mouth was full. Figure 29-9 offers an illustration of the sandwich approach.\\nFigure 29-9 In sandwich integration, you integrate top-level and widely used bottom-level \\nclasses first and you save middle-level classes for last.\\nFinish\\nStartStartStart\\nStart\\nFinish'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 735}, page_content='29.3 Incremental Integration Strategies 699\\nThis approach avoids the rigidity of pure bottom-up or top-down integration. It inte-\\ngrates the often-troublesome classes first and has the potential to minimize the \\namount of scaffolding you’ll need. It’s a realistic, practical approach. The next \\napproach is similar but has a different emphasis.\\nRisk-Oriented Integration\\nRisk-oriented integration is also called “hard part first integration.” It’s like sandwich \\nintegration in that it seeks to avoid the problems inherent in pure top-down or pure \\nbottom-up integration. Coincidentally, it also tends to integrate the classes at the top \\nand the bottom first, saving the middle-level classes for last. The motivation, however, \\nis different.\\nIn risk-oriented integration, you identify the level of risk associated with each class. \\nYou decide which will be the most challenging parts to implement, and you imple-\\nment them first. Experience indicates that top-level interfaces are risky, so they are \\noften at the top of the risk list. System interfaces, usually at the bottom level of the \\nhierarchy, are also risky, so they’re also at the top of the risk list. In addition, you might \\nknow of classes in the middle that will be challenging. Perhaps a class implements a \\npoorly understood algorithm or has ambitious performance goals. Such classes can \\nalso be identified as high risks and integrated relatively early.\\nThe remainder of the code, the easy stuff, can wait until later. Some of it will probably \\nturn out to be harder than you thought, but that’s unavoidable. Figure 29-10 presents \\nan illustration of risk-oriented integration.\\nFigure 29-10 In risk-oriented integration, you integrate classes that you expect to be most \\ntroublesome first; you implement easier classes later.\\nMost risk: \\ndo first.\\nLeast risk: \\ndo last.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 736}, page_content='700 Chapter 29: Integration\\nFeature-Oriented Integration\\nAnother approach is to integrate one feature at a time. The term “feature” doesn’t refer \\nto anything fancy, just an identifiable function of the system you’re integrating. If \\nyou’re writing a word processor, a feature might be displaying underlining on the \\nscreen or reformatting the document automatically—something like that.\\nWhen the feature to be integrated is bigger than a single class, the “increment” in \\nincremental integration is bigger than a single class. This diminishes the benefit of \\nincrementalism a little in that it reduces your certainty about the source of new errors, \\nbut if you have thoroughly tested the classes that implement the new feature before \\nyou integrate them, that’s only a small disadvantage. You can use the incremental inte-\\ngration strategies recursively by integrating small pieces to form features and then \\nincrementally integrating features to form a system.\\nYou’ll usually want to start with a skeleton you’ve chosen for its ability to support the \\nother features. In an interactive system, the first feature might be the interactive menu \\nsystem. You can hang the rest of the features on the feature that you integrate first. Fig-\\nure 29-11 shows how it looks graphically.\\nFigure 29-11 In feature-oriented integration, you integrate classes in groups that make up \\nidentifiable features—usually, but not always, multiple classes at a time.\\nComponents are added in “feature trees,” hierarchical collections of classes that make \\nup a feature. Integration is easier if each feature is relatively independent, perhaps call-\\ning the same low-level library code as the classes for other features but having no calls \\nto middle-level code in common with other features. (The shared, low-level library \\nclasses aren’t shown in Figure 29-11.)\\nFeature-oriented integration offers three main advantages. First, it eliminates scaffold-\\ning for virtually everything except low-level library classes. The skeleton might need a \\nlittle scaffolding, or some parts of the skeleton might simply not be operational until \\nparticular features have been added. When each feature has been hung on the struc-\\nFeature 2\\nFeature 1 skeleton \\n(menus, perhaps)\\nFeature 3 Feature 4 Feature 5 Feature 6'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 737}, page_content='29.3 Incremental Integration Strategies 701\\nture, however, no additional scaffolding is needed. Since each feature is self-contained, \\neach feature contains all the support code it needs.\\nThe second main advantage is that each newly integrated feature brings about an \\nincremental addition in functionality. This provides evidence that the project is mov-\\ning steadily forward. It also creates functional software that you can provide to your \\ncustomers for evaluation or that you can release earlier and with less functionality \\nthan originally planned.\\nA third advantage is that feature-oriented integration works well with object-oriented \\ndesign. Objects tend to map well to features, which makes feature-oriented integration \\na natural choice for object-oriented systems.\\nPure feature-oriented integration is as difficult to pursue as pure top-down or bottom-\\nup integration. Usually some of the low-level code must be integrated before certain \\nsignificant features can be.\\nT-Shaped Integration\\nA final approach that often addresses the problems associated with top-down and bot-\\ntom-up integration is called “T-shaped integration.” In this approach, one specific ver-\\ntical slice is selected for early development and integration. That slice should exercise \\nthe system end-to-end and should be capable of flushing out any major problems in \\nthe system’s design assumptions. Once that vertical slice has been implemented—and \\nany associated problems have been corrected—the overall breadth of the system can \\nbe developed (such as the menu system in a desktop application). This approach, \\nillustrated in Figure 29-12, is often combined with risk-oriented or feature-oriented \\nintegration.\\nFigure 29-12 In T-shaped integration, you build and integrate a deep slice of the system to \\nverify architectural assumptions, and then you build and integrate the breadth of the system \\nto provide a framework for developing the remaining functionality.\\nStart'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 738}, page_content='702 Chapter 29: Integration\\nSummary of Integration Approaches\\nBottom-up, top-down, sandwich, risk-oriented, feature-oriented, T-shaped—do you get the \\nfeeling that people are making these names up as they go along? They are. None of these \\napproaches are robust procedures that you should follow methodically from step 1 to \\nstep 47 and then declare yourself to be done. Like software-design approaches, they are \\nheuristics more than algorithms, and rather than following any procedure dogmatically, \\nyou come out ahead by making up a unique strategy tailored to your specific project.\\n29.4 Daily Build and Smoke Test\\nFurther Reading Much of \\nthis discussion is adapted \\nfrom Chapter 18 of Rapid \\nDevelopment (McConnell \\n1996). If you’ve read that dis-\\ncussion, you might skip \\nahead to the “Continuous \\nIntegration” section.\\nWhatever integration strategy you select, a good approach to integrating the software \\nis the “daily build and smoke test.” Every file is compiled, linked, and combined into \\nan executable program every day, and the program is then put through a “smoke test,” \\na relatively simple check to see whether the product “smokes” when it runs.\\nThis simple process produces several significant benefits. It reduces the risk of low \\nquality, which is a risk related to the risk of unsuccessful or problematic integration. \\nBy smoke-testing all the code daily, quality problems are prevented from taking con-\\ntrol of the project. You bring the system to a known, good state, and then you keep it \\nthere. You simply don’t allow it to deteriorate to the point where time-consuming \\nquality problems can occur.\\nThis process also supports easier defect diagnosis. When the product is built and \\ntested every day, it’s easy to pinpoint why the product is broken on any given day. If \\nthe product worked on Day 17 and is broken on Day 18, something that happened \\nbetween the two builds broke the product.\\nIt improves morale. Seeing a product work provides an incredible boost to morale. It \\nalmost doesn’t matter what the product does. Developers can be excited just to see it \\ndisplay a rectangle! With daily builds, a bit more of the product works every day, and \\nthat keeps morale high.\\nOne side effect of frequent integration is that it surfaces work that can otherwise accu-\\nmulate unseen until it appears unexpectedly at the end of the project. That accumula-\\ntion of unsurfaced work can turn into an end-of-project tar pit that takes weeks or \\nmonths to struggle out of. Teams that haven’t used the daily build process sometimes \\nfeel that daily builds slow their progress to a snail’s crawl. What’s really happening is \\nthat daily builds amortize work more steadily throughout the project, and the project \\nteam is just getting a more accurate picture of how fast it’s been working all along.\\nHere are some of the ins and outs of using daily builds:\\nBuild daily The most fundamental part of the daily build is the “daily” part. As Jim \\nMcCarthy says, treat the daily build as the heartbeat of the project (McCarthy 1995).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 739}, page_content='29.4 Daily Build and Smoke Test 703\\nIf there’s no heartbeat, the project is dead. A little less metaphorically, Michael \\nCusumano and Richard W. Selby describe the daily build as the sync pulse of a project \\n(Cusumano and Selby 1995). Different developers’ code is allowed to get a little out of \\nsync between these pulses, but every time there’s a sync pulse, the code has to come \\nback into alignment. When you insist on keeping the pulses close together, you pre-\\nvent developers from getting out of sync entirely.\\nSome organizations build every week, rather than every day. The problem with this is \\nthat if the build is broken one week, you might go for several weeks before the next \\ngood build. When that happens, you lose virtually all of the benefit of frequent builds.\\nCheck for broken builds For the daily-build process to work, the software that’s \\nbuilt has to work. If the software isn’t usable, the build is considered to be broken and \\nfixing it becomes top priority.\\nEach project sets its own standard for what constitutes “breaking the build.” The stan-\\ndard needs to set a quality level that’s strict enough to keep showstopper defects out \\nbut lenient enough to disregard trivial defects, which can paralyze progress if given \\nundue attention.\\nAt a minimum, a “good” build should \\n■ Compile all files, libraries, and other components successfully.\\n■ Link all files, libraries, and other components successfully.\\n■ Not contain any showstopper bugs that prevent the program from being \\nlaunched or that make it hazardous to operate; in other words, a good build \\nshould pass the smoke test.\\nSmoke test daily The smoke test should exercise the entire system from end to end. \\nIt does not have to be exhaustive, but it should be capable of exposing major prob-\\nlems. The smoke test should be thorough enough that if the build passes, you can \\nassume that it is stable enough to be tested more thoroughly.\\nThe daily build has little value without the smoke test. The smoke test is the sentry \\nthat guards against deteriorating product quality and creeping integration problems. \\nWithout it, the daily build becomes just a time-wasting exercise in ensuring that you \\nhave a clean compile every day.\\nKeep the smoke test current The smoke test must evolve as the system evolves. At \\nfirst, the smoke test will probably test something simple, such as whether the system \\ncan say “Hello, World.” As the system develops, the smoke test will become more \\nthorough. The first test might take a matter of seconds to run; as the system grows, the \\nsmoke test can grow to 10 minutes, an hour, or more. If the smoke test isn’t kept cur-\\nrent, the daily build can become an exercise in self-deception, in which a fractional set \\nof test cases creates a false sense of confidence in the product’s quality.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 740}, page_content='704 Chapter 29: Integration\\nAutomate the daily build and smoke test Care and feeding of the build can become \\ntime-consuming. Automating the build and smoke test helps ensure that the code gets \\nbuilt and the smoke test gets run. It isn’t practical to build and smoke test daily with-\\nout automation.\\nEstablish a build group On most projects, tending the daily build and keeping the \\nsmoke test up to date becomes a big enough task to be an explicit part of someone’s \\njob. On large projects, it can become a full-time job for more than one person. On the \\nfirst release of Microsoft Windows NT, for example, there were four full-time people in \\nthe build group (Zachary 1994).\\nAdd revisions to the build only when it makes sense to do so... Individual developers \\nusually don’t write code quickly enough to add meaningful increments to the system \\non a daily basis. They should work on a chunk of code and then integrate it when they \\nhave a collection of code in a consistent state—usually once every few days.\\n...but don’t wait too long to add a set of revisions Beware of checking in code infre-\\nquently. It’s possible for a developer to become so embroiled in a set of revisions that \\nevery file in the system seems to be involved. That undermines the value of the daily \\nbuild. The rest of the team will continue to realize the benefit of incremental integra-\\ntion, but that particular developer will not. If a developer goes more than a couple of \\ndays without checking in a set of changes, consider that developer’s work to be at risk. \\nAs Kent Beck points out, frequent integration sometimes forces you to break the con-\\nstruction of a single feature into multiple episodes. That overhead is an acceptable \\nprice to pay for the reduced integration risk, improved status visibility, improved test-\\nability, and other benefits of frequent integration (Beck 2000).\\nRequire developers to smoke test their code before adding it to the systemDevelopers \\nneed to test their own code before they add it to the build. A developer can do this by cre-\\nating a private build of the system on a personal machine, which the developer then tests \\nindividually. Or the developer can release a private build to a “testing buddy,” a tester \\nwho focuses on that developer’s code. The goal in either case is to be sure that the new \\ncode passes the smoke test before it’s allowed to influence other parts of the system.\\nCreate a holding area for code that’s to be added to the build Part of the success of \\nthe daily build process depends on knowing which builds are good and which are not. \\nIn testing their own code, developers need to be able to rely on a known good system.\\nMost groups solve this problem by creating  a holding area for code that developers \\nthink is ready to be added to the build. New code goes into the holding area, the \\nnew build is built, and if the build is acceptable, the new code is migrated into the \\nmaster sources.\\nOn small and medium-sized projects, a version-control system can serve this function. \\nDevelopers check new code into the version-control system. Developers who want to'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 741}, page_content='29.4 Daily Build and Smoke Test 705\\nuse a known good build simply set a date flag in their version-control options file that \\ntells the system to retrieve files based on the date of the last-known good build.\\nOn large projects or projects that use unsophisticated version-control software, the \\nholding area function has to be handled manually. The author of a set of new code \\nsends e-mail to the build group to tell them where to find the new files to be checked \\nin. Or the group establishes a “check-in” area on a file server where developers put \\nnew versions of their source files. The build group then assumes responsibility for \\nchecking new code into version control after they have verified that the new code \\ndoesn’t break the build.\\nCreate a penalty for breaking the build Most groups that use daily builds create a \\npenalty for breaking the build. Make it clear from the beginning that keeping the build \\nhealthy is one of the project’s top priorities. A broken build should be the exception, \\nnot the rule. Insist that developers who have broken the build stop all other work \\nuntil they’ve fixed it. If the build is broken too often, it’s hard to take seriously the job \\nof not breaking the build.\\nA light-hearted penalty can help to emphasize this priority. Some groups give out lol-\\nlipops to each “sucker” who breaks the build. This developer then has to tape the \\nsucker to his office door until he fixes the problem. Other groups have guilty develop-\\ners wear goat horns or contribute $5 to a morale fund.\\nSome projects establish a penalty with more bite. Microsoft developers on high-profile \\nprojects such as Windows 2000 and Microsoft Office have taken to wearing beepers \\nin the late stages of their projects. If they break the build, they get called in to fix it \\neven if their defect is discovered at 3 a.m.\\nRelease builds in the morningSome groups have found that they prefer to build over-\\nnight, smoke test in the early morning, and release new builds in the morning rather than \\nthe afternoon. Smoke testing and releasing builds in the morning has several advantages.\\nFirst, if you release a build in the morning, testers can test with a fresh build that day. \\nIf you generally release builds in the afternoon, testers feel compelled to launch their \\nautomated tests before they leave for the day. When the build is delayed, which it \\noften is, the testers have to stay late to launch their tests. Because it’s not their fault \\nthat they have to stay late, the build process becomes demoralizing.\\nWhen you complete the build in the morning, you have more reliable access to devel-\\nopers when there are problems with the build. During the day, developers are down \\nthe hall. During the evening, developers can be anywhere. Even when developers are \\ngiven beepers, they’re not always easy to locate.\\nIt might be more macho to start smoke testing at the end of the day and call people in \\nthe middle of the night when you find problems, but it’s harder on the team, it wastes \\ntime, and in the end you lose more than you gain.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 742}, page_content='706 Chapter 29: Integration\\nBuild and smoke test even under pressure When schedule pressure becomes intense, \\nthe work required to maintain the daily build can seem like extravagant overhead. The \\nopposite is true. Under stress, developers lose some of their discipline. They feel pres-\\nsure to take construction shortcuts that they would not take under less stressful circum-\\nstances. They review and test their own code less carefully than usual. The code tends \\ntoward a state of entropy more quickly than it does during less stressful times.\\nAgainst this backdrop, daily builds enforce discipline and keep pressure-cooker \\nprojects on track. The code still tends toward a state of entropy, but the build process \\nbrings that tendency to heel every day.\\nWhat Kinds of Projects Can Use the Daily Build Process? \\nSome developers protest that it’s impractical to build every day because their projects \\nare too large. But what was perhaps the most complex software project in recent his-\\ntory used daily builds successfully. By the time it was released, Microsoft Windows \\n2000 consisted of about 50 million lines of code spread across tens of thousands of \\nsource files. A complete build took as many as 19 hours on several machines, but the  \\nWindows 2000 development team still managed to build every day. Far from being a \\nnuisance, the Windows 2000 team attributed much of its success on that huge project \\nto their daily builds. The larger the project, the more important incremental integra-\\ntion becomes.\\nA review of 104 projects in the U.S., India, Japan, and Europe found that only 20–25 \\npercent of projects used daily builds at either the beginning or middle of their projects \\n(Cusumano et al. 2003), so this represents a significant opportunity for improvement.\\nContinuous Integration\\nSome software writers have taken daily builds as a jumping-off point and recommend \\nintegrating continuously (Beck 2000). Most of the published references to continuous \\nintegration use the word “continuous” to mean “at least daily” (Beck 2000), which I think \\nis reasonable. But I occasionally encounter people who take the word “continuous” liter-\\nally. They aim to integrate each change with the latest build every couple of hours. For \\nmost projects, I think literal continuous integration is too much of a good thing.\\nIn my free time, I operate a discussion group consisting of the top technical executives \\nfrom companies like Amazon.com, Boeing, Expedia, Microsoft, Nordstrom, and other \\nSeattle-area companies. In a poll of these top technical executives, none of them \\nthought that continuous integration was superior to daily integration. On medium-\\nsized and large projects, there is value in letting the code get out of sync for short peri-\\nods. Developers frequently get out of sync when they make larger-scale changes. They \\ncan then resynchronize after a short time. Daily builds allow the project team rendez-\\nvous points that are frequently enough. As long as the team syncs up every day, they \\ndon’t need to rendezvous continuously.\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 743}, page_content='Additional Resources 707\\ncc2e.com/2992 CHECKLIST: Integration\\nIntegration Strategy\\n❑ Does the strategy identify the optimal order in which subsystems, classes, \\nand routines should be integrated?\\n❑ Is the integration order coordinated with the construction order so that \\nclasses will be ready for integration at the right time? \\n❑ Does the strategy lead to easy diagnosis of defects?\\n❑ Does the strategy keep scaffolding to a minimum?\\n❑ Is the strategy better than other approaches?\\n❑ Have the interfaces between components been specified well? (Specifying \\ninterfaces isn’t an integration task, but verifying that they have been spec-\\nified well is.)\\nDaily Build and Smoke Test\\n❑ Is the project building frequently—ideally, daily—to support incremental \\nintegration?\\n❑ Is a smoke test run with each build so that you know whether the build \\nworks?\\n❑ Have you automated the build and the smoke test? \\n❑ Do developers check in their code frequently—going no more than a day or \\ntwo between check-ins? \\n❑ Is the smoke test kept up to date with the code, expanding as the code \\nexpands? \\n❑ Is a broken build a rare occurrence?\\n❑ Do you build and smoke test the software even when you’re under pres-\\nsure? \\nAdditional Resources\\ncc2e.com/2999 Following are additional resources related to this chapter’s subjects:\\nIntegration\\nLakos, John. Large-Scale C++ Software Design. Boston, MA: Addison-Wesley, 1996. \\nLakos argues that a system’s “physical design”—its hierarchy of files, directories, and \\nlibraries—significantly affects a development team’s ability to build software. If you \\ndon’t pay attention to the physical design, build times will become long enough to \\nundermine frequent integration. Lakos’s discussion focuses on C++, but the insights \\nrelated to “physical design” apply just as much to projects in other languages.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 744}, page_content='708 Chapter 29: Integration\\nMyers, Glenford J. The Art of Software Testing. New York, NY: John Wiley & Sons, 1979. \\nThis classic testing book discusses integration as a testing activity.\\nIncrementalism\\nMcConnell, Steve. Rapid Development. Redmond, WA: Microsoft Press, 1996. Chapter \\n7, “Lifecycle Planning,” goes into much detail about the tradeoffs involved with more-\\nflexible and less-flexible life-cycle models. Chapters 20, 21, 35, and 36 discuss specific \\nlife-cycle models that support various degrees of incrementalism. Chapter 19 \\ndescribes “designing for change,” a key activity needed to support iterative and incre-\\nmental development models.\\nBoehm, Barry W. “A Spiral Model of Software Development and Enhancement.” Com-\\nputer, May 1988: 61–72. In this paper, Boehm describes his “spiral model” of soft-\\nware development. He presents the model as an approach to managing risk in a \\nsoftware-development project, so the paper is about development generally rather \\nthan about integration specifically. Boehm is  one of the world’s foremost experts on \\nthe big-picture issues of software development, and the clarity of his explanations \\nreflects the quality of his understanding.\\nGilb, Tom. Principles of Software Engineering Management . Wokingham, England: \\nAddison-Wesley, 1988. Chapters 7 and 15 contain thorough discussions of evolu-\\ntionary delivery, one of the first incremental development approaches.\\nBeck, Kent. Extreme Programming Explained: Embrace Change. Reading, MA: Addison-\\nWesley, 2000. This book contains a more modern, more concise, and more evangeli-\\ncal presentation of many of the ideas in Gilb’s book. I personally prefer the depth of \\nanalysis presented in Gilb’s book, but some readers may find Beck’s presentation \\nmore accessible or more directly applicable to the kind of project they’re working on.\\nKey Points\\n■ The construction sequence and integration approach affect the order in which \\nclasses are designed, coded, and tested.\\n■ A well-thought-out integration order reduces testing effort and eases debugging.\\n■ Incremental integration comes in several varieties, and, unless the project is triv-\\nial, any one of them is better than phased integration.\\n■ The best integration approach for any specific project is usually a combination \\nof top-down, bottom-up, risk-oriented, and other integration approaches. T-\\nshaped integration and vertical-slice integration are two approaches that often \\nwork well.\\n■ Daily builds can reduce integration problems, improve developer morale, and \\nprovide useful project management information.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 745}, page_content='709\\nChapter 30\\nProgramming Tools\\ncc2e.com/3084 Contents\\n■ 30.1 Design Tools: page 710\\n■ 30.2 Source-Code Tools: page 710\\n■ 30.3 Executable-Code Tools: page 716\\n■ 30.4 Tool-Oriented Environments: page 720\\n■ 30.5 Building Your Own Programming Tools: page 721\\n■ 30.6 Tool Fantasyland: page 722\\nRelated Topics\\n■ Version-control tools: in Section 28.2\\n■ Debugging tools: Section 23.5\\n■ Test-support tools: Section 22.5\\nModern programming tools decrease the amount of time required for construction. \\nUse of a leading-edge tool set—and familiarity with the tools used—can increase pro-\\nductivity by 50 percent or more (Jones 2000; Boehm et al. 2000). Programming tools \\ncan also reduce the amount of tedious detail work that programming requires.\\nA dog might be man’s best friend, but a few good tools are a programmer’s best \\nfriends. As Barry Boehm discovered long ago, 20 percent of the tools tend to account \\nfor 80 percent of the tool usage (1987b). If you’re missing one of the more helpful \\ntools, you’re missing something that you could use a lot.\\nThis chapter is focused in two ways. First, it covers only construction tools. Require-\\nments-specification, management, and end-to-end-development tools are outside the \\nscope of the book. Refer to the “Additional Resources” section at the end of the chap-\\nter for more information on tools for those aspects of software development. Second, \\nthis chapter covers kinds of tools rather than specific brands. A few tools are so com-\\nmon that they’re discussed by name, but specific versions, products, and companies \\nchange so quickly that information about most of them would be out of date before \\nthe ink on these pages was dry.\\nA programmer can work for many years without discovering some of the most valu-\\nable tools available. The mission of this chapter is to survey available tools and help \\nyou determine whether you’ve overlooked any tools that might be useful. If you’re a \\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 746}, page_content='710 Chapter 30: Programming Tools\\ntool expert, you won’t find much new information in this chapter. You might skim the \\nearlier parts of the chapter, read Section 30.6 on “Tool Fantasyland,” and then move \\non to the next chapter.\\n30.1 Design Tools\\nCross-Reference For details \\non design, see Chapters 5 \\nthrough 9.\\nCurrent design tools consist mainly of graphical tools that create design diagrams. \\nDesign tools are sometimes embedded in a computer-aided software engineering \\n(CASE) tool with broader functions; some vendors advertise standalone design tools \\nas CASE tools. Graphical design tools generally allow you to express a design in com-\\nmon graphical notations: UML, architecture block diagrams, hierarchy charts, entity \\nrelationship diagrams, or class diagrams. Some graphical design tools support only \\none notation. Others support a variety.\\nIn one sense, these design tools are just fancy drawing packages. Using a simple \\ngraphics package or pencil and paper, you can draw everything that the tool can draw. \\nBut the tools offer valuable capabilities that a simple graphics package can’t. If you’ve \\ndrawn a bubble chart and you delete a bubble, a graphical design tool will automati-\\ncally rearrange the other bubbles, including connecting arrows and lower-level bub-\\nbles connected to the bubble. The tool takes care of the housekeeping when you add \\na bubble, too. A design tool can enable you to move between higher and lower levels \\nof abstraction. A design tool will check the consistency of your design, and some tools \\ncan create code directly from your design.\\n30.2 Source-Code Tools\\nThe tools available for working with source code are richer and more mature than the \\ntools available for working with designs.\\nEditing\\nThis group of tools relates to editing source code.\\nIntegrated Development Environments (IDEs)\\nSome programmers estimate that they spend as much as 40 percent of their time edit-\\ning source code (Parikh 1986, Ratliff 1987). If that’s the case, spending a few extra \\ndollars for the best possible IDE is a good investment.\\nIn addition to basic word-processing functions, good IDEs offer these features:\\n■ Compilation and error detection from within the editor\\n■ Integration with source-code control, build, test, and debugging tools\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 747}, page_content='30.2 Source-Code Tools 711\\n■ Compressed or outline views of programs (class names only or logical struc-\\ntures without the contents, also known as “folding”) \\n■ Jump to definitions of classes, routines, and variables\\n■ Jump to all places where a class, routine, or variable is used\\n■ Language-specific formatting\\n■ Interactive help for the language being edited\\n■ Brace (begin-end) matching\\n■ Templates for common language constructs (the editor completing the struc-\\nture of a for loop after the programmer types for, for example)\\n■ Smart indenting (including easily changing the indentation of a block of state-\\nments when logic changes)\\n■ Automated code transforms or refactorings\\n■ Macros programmable in a familiar programming language\\n■ Listing of search strings so that commonly used strings don’t need to be retyped\\n■ Regular expressions in search-and-replace\\n■ Search-and-replace across a group of files \\n■ Editing multiple files simultaneously\\n■ Side-by-side diff comparisons\\n■ Multilevel undo\\nConsidering some of the primitive editors still in use, you might be surprised to learn \\nthat several editors include all these capabilities.\\nMultiple-File String Searching and Replacing\\nIf your editor doesn’t support search-and-replace across multiple files, you can still \\nfind supplementary tools to do that job. These tools are useful for search for all occur-\\nrences of a class name or routine name. When you find an error in your code, you can \\nuse such tools to check for similar errors in other files.\\nYou can search for exact strings, similar strings (ignoring differences in capitalization), \\nor regular expressions. Regular expressions are particularly powerful because they let \\nyou search for complex string patterns. If you wanted to find all the array references \\ncontaining magic numbers (digits “0” through “9”), you could search for “[“, followed \\nby zero or more spaces, followed by one or more digits, followed by zero or more \\nspaces, followed by “]”. One widely available search tool is called “grep.” A grep query \\nfor magic numbers would look like this:\\ngrep \"\\\\[ *[0–9]+ *\\\\]\" *.cpp'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 748}, page_content='712 Chapter 30: Programming Tools\\nYou can make the search criteria more sophisticated to fine-tune the search.\\nIt’s often helpful to be able to change strings across multiple files. For example, if you \\nwant to give a routine, constant, or global variable a better name, you might have to \\nchange the name in several files. Utilities that allow string changes across multiple \\nfiles make that easy to do, which is good because you should have as few obstructions \\nas possible to creating excellent class names, routine names, and constant names. \\nCommon tools for handling multiple-file string changes include Perl, AWK, and sed.\\nDiff Tools\\nProgrammers often need to compare two files. If you make several attempts to correct \\nan error and need to remove the unsuccessful attempts, a file comparator will make a \\ncomparison of the original and modified files and list the lines you’ve changed. If \\nyou’re working on a program with other people and want to see the changes they have \\nmade since the last time you worked on the code, a comparator tool such as Diff will \\nmake a comparison of the current version with the last version of the code you \\nworked on and show the differences. If you discover a new defect that you don’t \\nremember encountering in an older version of a program, rather than seeing a neurol-\\nogist about amnesia, you can use a comparator to compare current and old versions of \\nthe source code, determine exactly what changed, and find the source of the problem. \\nThis functionality is often built into revision-control tools.\\nMerge Tools\\nOne style of revision control locks source files so that only one person can modify a \\nfile at a time. Another style allows multiple people to work on files simultaneously and \\nhandles merging changes at check-in time. In this working mode, tools that merge \\nchanges are critical. These tools typically perform simple merges automatically and \\nquery the user for merges that conflict with other merges or that are more involved.\\nSource-Code Beautifiers\\nCross-Reference For details \\non program layout, see \\nChapter 31, “Layout and \\nStyle.”\\nSource-code beautifiers spruce up your source code so that it looks consistent. They \\nhighlight class and routine names, standardize your indentation style, format comments \\nconsistently, and perform other similar functions. Some beautifiers can put each routine \\nonto a separate Web page or printed page or perform even more dramatic formatting. \\nMany beautifiers let you customize the way in which the code is beautified.\\nThere are at least two classes of source-code beautifiers. One class takes the source \\ncode as input and produces much better looking output without changing the origi-\\nnal source code. Another kind of tool changes the source code itself—standardizing \\nindentation, parameter list formatting, and so on. This capability is useful when work-\\ning with large quantities of legacy code. The tool can do much of the tedious format-\\nting work needed to make the legacy code conform to your coding style conventions.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 749}, page_content='30.2 Source-Code Tools 713\\nInterface Documentation Tools\\nSome tools extract detailed programmer-interface documentation from source-code \\nfiles. The code inside the source file uses clues such as @tag fields to identify text that \\nshould be extracted. The interface documentation tool then extracts that tagged text \\nand presents it with nice formatting. Javadoc is a prominent example of this kind of \\ntool.\\nTemplates\\nTemplates help you exploit the simple idea of streamlining keyboarding tasks that you \\ndo often and want to do consistently. Suppose you want a standard comment prolog \\nat the beginning of your routines. You could build a skeleton prolog with the correct \\nsyntax and places for all the items you want in the standard prolog. This skeleton \\nwould be a “template” you’d store in a file or a keyboard macro. When you created a \\nnew routine, you could easily insert the template into your source file. You can use the \\ntemplate technique for setting up larger entities, such as classes and files, or smaller \\nentities, such as loops.\\nIf you’re working on a group project, templates are an easy way to encourage consis-\\ntent coding and documentation styles. Make templates available to the whole team at \\nthe beginning of the project, and the team will use them because they make its job eas-\\nier—you get the consistency as a side benefit.\\nCross-Reference Tools\\nA cross-reference tool lists variables and routines and all the places in which they’re \\nused—typically on Web pages.\\nClass Hierarchy Generators\\nA class-hierarchy generator produces information about inheritance trees. This is \\nsometimes useful in debugging but is more often used for analyzing a program’s \\nstructure or modularizing a program into packages or subsystems. This functionality \\nis also available in some IDEs.\\nAnalyzing Code Quality\\nTools in this category examine the static source code to assess its quality.\\nPicky Syntax and Semantics Checkers\\nSyntax and semantics checkers supplement your compiler by checking code more \\nthoroughly than the compiler normally does. Your compiler might check for only \\nrudimentary syntax errors. A picky syntax checker might use nuances of the language'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 750}, page_content='714 Chapter 30: Programming Tools\\nto check for more subtle errors—things that aren’t wrong from a compiler’s point of \\nview but that you probably didn’t intend to write. For example, in C++, the statement\\nwhile ( i = 0 ) ...\\nis a perfectly legal statement, but it’s usually meant to be\\nwhile ( i == 0 ) ...\\nThe first line is syntactically correct, but switching = and == is a common mistake and \\nthe line is probably wrong. Lint is a picky syntax and semantics checker you can find \\nin many C/C++ environments. Lint warns you about uninitialized variables, com-\\npletely unused variables, variables that are assigned values and never used, parame-\\nters of a routine that are passed out of the routine without being assigned a value, \\nsuspicious pointer operations, suspicious logical comparisons (like the one in the \\nexample just shown), inaccessible code, and many other common problems. Other \\nlanguages offer similar tools.\\nMetrics Reporters\\nCross-Reference For more \\ninformation on metrics, see \\nSection 28.4, “Measure-\\nment.”\\nSome tools analyze your code and report on its quality. For example, you can obtain \\ntools that report on the complexity of each routine so that you can target the most \\ncomplicated routines for extra review, testing, or redesign. Some tools count lines of \\ncode, data declarations, comments, and blank lines in either entire programs or indi-\\nvidual routines. They track defects and associate them with the programmers who \\nmade them, the changes that correct them, and the programmers who make the cor-\\nrections. They count modifications to the software and note the routines that are mod-\\nified the most often. Complexity analysis tools have been found to have about a 20 \\npercent positive impact on maintenance productivity (Jones 2000).\\nRefactoring Source Code\\nA few tools aid in converting source code from one format to another.\\nRefactorers\\nCross-Reference For more \\non refactoring, see Chapter \\n24, “Refactoring.”\\nA refactoring program supports common code refactorings either on a standalone \\nbasis or integrated into an IDE. Refactoring browsers allow you to change the name of \\na class across an entire code base easily. They allow you to extract a routine simply by \\nhighlighting the code you’d like to turn into a new routine, entering the new routine’s \\nname, and ordering parameters in a parameter list. Refactorers make code changes \\nquicker and less error-prone. They’re available for Java and Smalltalk and are becom-\\ning available for other languages. For more about refactoring tools, see Chapter 14, \\n“Refactoring Tools” in Refactoring (Fowler 1999).'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 751}, page_content='30.2 Source-Code Tools 715\\nRestructurers\\nA restructurer will convert a plate of spaghetti code with gotos to a more nutritious \\nentrée of better-structured code without gotos. Capers Jones reports that in mainte-\\nnance environments code restructuring tools can have a 25–30 percent positive \\nimpact on maintenance productivity (Jones 2000). A restructurer has to make a lot of \\nassumptions when it converts code, and if the logic is terrible in the original, it will \\nstill be terrible in the converted version. If you’re doing a conversion manually, how-\\never, you can use a restructurer for the general case and hand-tune the hard cases. \\nAlternatively, you can run the code through the restructurer and use it for inspiration \\nfor the hand conversion.\\nCode Translators\\nSome tools translate code from one language to another. A translator is useful when \\nyou have a large code base that you’re moving to another environment. The hazard in \\nusing a language translator is that if you start with bad code the translator simply \\ntranslates the bad code into an unfamiliar language.\\nVersion Control\\nCross-Reference These tools \\nand their benefits are \\ndescribed in “Software Code \\nChanges” in Section 28.2.\\nYou can deal with proliferating software versions by using version-control tools for\\n■ Source-code control\\n■ Dependency control like that offered by the make utility associated with UNIX\\n■ Project documentation versioning\\n■ Relating project artifacts like requirements, code, and test cases so that when a \\nrequirement changes, you can find the code and tests that are affected\\nData Dictionaries\\nA data dictionary is a database that describes all the significant data in a project. In \\nmany cases, the data dictionary focuses primarily on database schemas. On large \\nprojects, a data dictionary is also useful for keeping track of the hundreds or thou-\\nsands of class definitions. On large team projects, it’s useful for avoiding naming \\nclashes. A clash might be a direct, syntactic clash, in which the same name is used \\ntwice, or it might be a more subtle clash (or gap) in which different names are used to \\nmean the same thing or the same name is used to mean subtly different things. For \\neach data item (database table or class), the data dictionary contains the item’s name \\nand description. The dictionary might also contain notes about how the item is used.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 752}, page_content='716 Chapter 30: Programming Tools\\n30.3 Executable-Code Tools\\nTools for working with executable code are as rich as the tools for working with \\nsource code.\\nCode Creation\\nThe tools described in this section help with code creation.\\nCompilers and Linkers\\nCompilers convert source code to executable code. Most programs are written to be \\ncompiled, although some are still interpreted.\\nA standard linker links one or more object files, which the compiler has generated \\nfrom your source files, with the standard code needed to make an executable pro-\\ngram. Linkers typically can link files from multiple languages, allowing you to choose \\nthe language that’s most appropriate for each part of your program without your hav-\\ning to handle the integration details yourself.\\nAn overlay linker helps you put 10 pounds in a five-pound sack by developing pro-\\ngrams that execute in less memory than the total amount of space they consume. An \\noverlay linker creates an executable file that loads only part of itself into memory at \\nany one time, leaving the rest on a disk until it’s needed.\\nBuild Tools\\nThe purpose of a build tool is to minimize the time needed to build a program using cur-\\nrent versions of the program’s source files. For each target file in your project, you spec-\\nify the source files that the target file depends on and how to make it. Build tools also \\neliminate errors related to sources being in inconsistent states; the build tool ensures \\nthey are all brought to a consistent state. Common build tools include the make utility \\nthat’s associated with UNIX and the ant tool that’s used for Java programs.\\nSuppose you have a target file named userface.obj. In the make file, you indicate that to \\nmake userface.obj, you have to compile the file userface.cpp. You also indicate that \\nuserface.cpp depends on userface.h, stdlib.h, and project.h. The concept of “depends on” \\nsimply means that if userface.h, stdlib.h, or project.h changes, userface.cpp needs to be \\nrecompiled.\\nWhen you build your program, the make tool checks all the dependencies you’ve \\ndescribed and determines the files that need  to be recompiled. If five of your 250 \\nsource files depend on data definitions in userface.h and it changes, make automati-\\ncally recompiles the five files that depend on it. It doesn’t recompile the 245 files that \\ndon’t depend on userface.h. Using make or ant beats the alternatives of recompiling all'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 753}, page_content='30.3 Executable-Code Tools 717\\n250 files or recompiling each file manually, forgetting one, and getting weird out-of-\\nsynch errors. Overall, build tools like make or ant substantially improve the time and \\nreliability of the average compile-link-run cycle.\\nSome groups have found interesting alternatives to dependency-checking tools like \\nmake. For example, the Microsoft Word group found that simply rebuilding all source \\nfiles was faster than performing extensive dependency checking with make as long as \\nthe source files themselves were optimized (header file contents and so on). With this \\napproach, the average developer’s machine on the Word project could rebuild the \\nentire Word executable—several million lines of code—in about 13 minutes.\\nCode Libraries\\nA good way to write high-quality code in a short amount of time is not to write it all \\nbut to find an open source version or buy it instead. You can find high-quality libraries \\nin at least these areas:\\n■ Container classes\\n■ Credit card transaction services (e-commerce services)\\n■ Cross-platform development tools. You might write code that executes in \\nMicrosoft Windows, Apple Macintosh, and the X Window System just by recom-\\npiling for each environment.\\n■ Data compression tools\\n■ Data types and algorithms\\n■ Database operations and data-file manipulation tools\\n■ Diagramming, graphing, and charting tools\\n■ Imaging tools\\n■ License managers\\n■ Mathematical operations\\n■ Networking and internet communications tools\\n■ Report generators and report query builders\\n■ Security and encryption tools\\n■ Spreadsheet and grid tools\\n■ Text and spelling tools\\n■ Voice, phone, and fax tools'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 754}, page_content='718 Chapter 30: Programming Tools\\nCode-Generation Wizards\\nIf you can’t find the code you want, how about getting someone else to write it \\ninstead? You don’t have to put on your yellow plaid jacket and slip into a car sales-\\nman’s patter to con someone else into writing your code. You can find tools that write \\ncode for you, and such tools are often integrated into IDEs.\\nCode-generating tools tend to focus on database applications, but that includes a lot \\nof applications. Commonly available code generators write code for databases, user \\ninterfaces, and compilers. The code they generate is rarely as good as code generated \\nby a human programmer, but many applications don’t require handcrafted code. It’s \\nworth more to some users to have 10 working applications than to have one that \\nworks exceptionally well.\\nCode generators are also useful for making prototypes of production code. Using a \\ncode generator, you might be able to hack out a prototype in a few hours that demon-\\nstrates key aspects of a user interface or you might be able to experiment with various \\ndesign approaches. It might take you several weeks to hand-code as much functional-\\nity. If you’re just experimenting, why not do it in the cheapest possible way?\\nThe common drawback of code generators is that they tend to generate code that’s \\nnearly unreadable. If you ever have to maintain such code, you can regret not writing \\nit by hand in the first place.\\nSetup and Installation\\nNumerous vendors provide tools that support creation of setup programs. These tools \\ntypically support the creation of disks, CDs, or DVDs or installation over the Web. \\nThey check whether common library files al ready exist on the target installation \\nmachine, perform version checking, and so on.\\nPreprocessors\\nCross-Reference For details \\non moving debugging aids \\nin and out of the code, see \\n“Plan to Remove Debugging \\nAids” in Section 8.6.\\nPreprocessors and preprocessor macro functions are useful for debugging because \\nthey make it easy to switch between development code and production code. During \\ndevelopment, if you want to check memory fragmentation at the beginning of each \\nroutine, you can use a macro at the beginning of each routine. You might not want to \\nleave the checks in production code, so for the production code you can redefine the \\nmacro so that it doesn’t generate any code at all. For similar reasons, preprocessor \\nmacros are good for writing code that’s targeted to be compiled in multiple environ-\\nments—for example, in both Windows and Linux.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 755}, page_content='30.3 Executable-Code Tools 719\\nIf you use a language with primitive control constructs, such as assembler, you can \\nwrite a control-flow preprocessor to emulate the structured constructs of if-then-else \\nand while loops in your language.\\ncc2e.com/3091 If your language doesn’t have a preprocessor, you can use a standalone preprocessor \\nas part of your build process. One readily available preprocessor is M4, available from \\nwww.gnu.org/software/m4/.\\nDebugging\\nCross-Reference These tools \\nand their benefits are \\ndescribed in Section 23.5, \\n“Debugging Tools—Obvi-\\nous and Not-So-Obvious.” \\nThese tools help in debugging:\\n■ Compiler warning messages\\n■ Test scaffolding\\n■ Diff tools (for comparing different versions of source-code files)\\n■ Execution profilers\\n■ Trace monitors\\n■ Interactive debuggers—both software and hardware\\nTesting tools, discussed next, are related to debugging tools.\\nTesting\\nCross-Reference These tools \\nand their benefits are \\ndescribed in Section 22.5, \\n“Test-Support Tools.”\\nThese features and tools can help you do effective testing:\\n■ Automated test frameworks like JUnit, NUnit, CppUnit, and so on\\n■ Automated test generators\\n■ Test-case record and playback utilities\\n■ Coverage monitors (logic analyzers and execution profilers)\\n■ Symbolic debuggers\\n■ System perturbers (memory fillers, memory shakers, selective memory failers, \\nmemory-access checkers)\\n■ Diff tools (for comparing data files, captured output, and screen images)\\n■ Scaffolding\\n■ Defect-injection tools\\n■ Defect-tracking software'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 756}, page_content='720 Chapter 30: Programming Tools\\nCode Tuning\\nThese tools can help you fine-tune your code.\\nExecution Profilers\\nAn execution profiler watches your code while it runs and tells you how many times each \\nstatement is executed or how much time the program spends on each statement or exe-\\ncution path. Profiling your code while it’s running is like having a doctor press a stetho-\\nscope to your chest and tell you to cough. It gives you insight into how your program \\nworks, where the hot spots are, and where you should focus your code-tuning efforts.\\nAssembler Listings and Disassemblers\\nSome day you might want to look at the assembler code generated by your high-level \\nlanguage. Some high-level-language compilers generate assembler listings. Others \\ndon’t, and you have to use a disassembler to re-create the assembler from the machine \\ncode that the compiler generates. Looking at the assembler code generated by your \\ncompiler shows you how efficiently your compiler translates high-level-language code \\ninto machine code. It can tell you why high-level code that looks fast runs slowly. In \\nChapter 26, “Code-Tuning Techniques,” several of the benchmark results are counter-\\nintuitive. While benchmarking that code, I frequently referred to the assembler list-\\nings to better understand the results that didn’t make sense in the high-level language.\\nIf you’re not comfortable with assembly language and you want an introduction, \\nyou won’t find a better one than comparin g each high-level-language statement you \\nwrite to the assembler instru ctions generated by the compiler. A first exposure to \\nassembler is often a loss of innocence. When you see how much code the compiler \\ncreates—how much more than it needs to—you’ll never look at your compiler in quite \\nthe same way again.\\nConversely, in some environments the compiler must generate extremely complex \\ncode. Studying the compiler output can foster an appreciation for just how much \\nwork would be required to program in a lower level language.\\n30.4 Tool-Oriented Environments\\nSome environments have proven to be better suited to tool-oriented programming \\nthan others.\\nThe UNIX environment is famous for its collection of small tools with funny names \\nthat work well together: grep, diff, sort, make, crypt, tar, lint, ctags, sed, awk, vi, and \\nothers. The C and C++ languages, closely coupled with UNIX, embody the same phi-\\nlosophy; the standard C++ library is composed of small functions that can easily be \\ncomposed into larger functions because they work so well together.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 757}, page_content='30.5 Building Your Own Programming Tools 721\\ncc2e.com/3026 Some programmers work so productively in UNIX that they take it with them. They \\nuse UNIX work-alike tools to support their UNIX habits in Windows and other envi-\\nronments. One tribute to the success of the UNIX paradigm is the availability of tools \\nthat put a UNIX costume on other machines. For example, cygwin provides UNIX-\\nequivalent tools that work under Windows (www.cygwin.com).\\nEric Raymond’s The Art of Unix Programming (2004) contains an insightful discussion \\nof the UNIX programming culture.\\n30.5 Building Your Own Programming Tools\\nSuppose you’re given five hours to do the job and you have a choice:\\n■ Do the job comfortably in five hours, or\\n■ Spend four hours and 45 minutes feverishly building a tool to do the job, and \\nthen have the tool do the job in 15 minutes.\\nMost good programmers would choose the first option one time out of a million and \\nthe second option in every other case. Building tools is part of the warp and woof of \\nprogramming. Nearly all large organizations (organizations with more than 1000 pro-\\ngrammers) have internal tool and support groups. Many have proprietary require-\\nments and design tools that are superior to those on the market (Jones 2000).\\nYou can write many of the tools described in this chapter. Doing so might not be cost-\\neffective, but there aren’t any mountainous technical barriers to doing it.\\nProject-Specific Tools\\nMost medium-sized and large projects need special tools unique to the project. For \\nexample, you might need tools to generate special kinds of test data, to verify the qual-\\nity of data files, or to emulate hardware that isn’t yet available. Here are some exam-\\nples of project-specific tool support:\\n■ An aerospace team was responsible for developing in-flight software to control an \\ninfrared sensor and analyze its data. To verify the performance of the software, an \\nin-flight data recorder documented the actions of the in-flight software. Engineers \\nwrote custom data-analysis tools to analyze the performance of the in-flight sys-\\ntems. After each flight, they used the custom tools to check the primary systems.\\n■ Microsoft planned to include a new font technology in a release of its Windows \\ngraphical environment. Since both the font data files and the software to display \\nthe fonts were new, errors could have arisen from either the data or the software. \\nMicrosoft developers wrote several custom tools to check for errors in the data \\nfiles, which improved their ability to discriminate between font data errors and \\nsoftware errors.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 758}, page_content='722 Chapter 30: Programming Tools\\n■ An insurance company developed an ambitious system to calculate its rate \\nincreases. Because the system was complicated and accuracy was essential, hun-\\ndreds of computed rates needed to be checked carefully, even though hand cal-\\nculating a single rate took several minutes. The company wrote a separate \\nsoftware tool to compute rates one at a time. With the tool, the company could \\ncompute a single rate in a few seconds and check rates from the main program \\nin a small fraction of the time it would have taken to check the main program’s \\nrates by hand.\\nPart of planning for a project should be thinking about the tools that might be needed \\nand allocating time for building them.\\nScripts\\nA script is a tool that automates a repetitive chore. In some systems, scripts are called \\nbatch files or macros. Scripts can be simple or complex, and some of the most useful \\nare the easiest to write. For example, I keep a journal, and to protect my privacy, I \\nencrypt it except when I’m writing in it. To make sure that I always encrypt and \\ndecrypt it properly, I have a script that decrypts my journal, executes the word proces-\\nsor, and then encrypts the journal. The script looks like this:\\ncrypto c:\\\\word\\\\journal.* %1 /d /Es /s \\nword c:\\\\word\\\\journal.doc \\ncrypto c:\\\\word\\\\journal.* %1 /Es /s\\nThe %1 is the field for my password which, for obvious reasons, isn’t included in the \\nscript. The script saves me the work of typing (and mistyping) all the parameters and \\nensures that I always perform all the operations and perform them in the right order.\\nIf you find yourself typing something longer than about five characters more than a \\nfew times a day, it’s a good candidate for a script or batch file. Examples include com-\\npile/link sequences, backup commands, and any command with a lot of parameters.\\n30.6 Tool Fantasyland\\nCross-Reference Tool avail-\\nability depends partly on the \\nmaturity of the technical \\nenvironment. For more on \\nthis, see Section 4.3, “Your \\nLocation on the Technology \\nWave.”\\nFor decades, tool vendors and industry pundits have promised that the tools needed \\nto eliminate programming are just over the horizon. The first, and perhaps most \\nironic, tool to receive this moniker was Fortran. Fortran or “Formula Translation Lan-\\nguage” was conceived so that scientists and engineers could simply type in formulas, \\nthus supposedly eliminating the need for programmers.\\nFortran did succeed in making it possible for scientists and engineers to write pro-\\ngrams, but from our vantage point today, Fortran appears to be a comparatively low-\\nlevel programming language. It hardly eliminated the need for programmers, and \\nwhat the industry experienced with Fortran is indicative of progress in the software \\nindustry as a whole.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 759}, page_content='30.6 Tool Fantasyland 723\\nThe software industry constantly develops new tools that reduce or eliminate some of \\nthe most tedious aspects of programming: details of laying out source statements; \\nsteps needed to edit, compile, link, and run a program; work needed to find mis-\\nmatched braces; the number of steps needed to create standard message boxes; and \\nso on. As each of these new tools begins to demonstrate incremental gains in produc-\\ntivity, pundits extrapolate those gains out to infinity, assuming that the gains will \\neventually “eliminate the need for programming.” But what’s happening in reality is \\nthat each new programming innovation arrives with a few blemishes. As time goes by, \\nthe blemishes are removed and that innovation’s full potential is realized. However, \\nonce the fundamental tool concept is realized, further gains are achieved by stripping \\naway the accidental difficulties that were created as side effects of creating the new \\ntool. Elimination of these accidental difficulties does not increase productivity per se; \\nit simply eliminates the “one step back” from the typical “two steps forward, one step \\nback” equation.\\nOver the past several decades, programmers have seen numerous tools that were sup-\\nposed to eliminate programming. First it was third-generation languages. Then it was \\nfourth generation languages. Then it was automatic programming. Then it was CASE \\ntools. Then it was visual programming. Each of these advances spun off valuable, incre-\\nmental improvements to computer programming—and collectively they have made pro-\\ngramming unrecognizable to anyone who learned programming before these advances. \\nBut none of these innovations succeeded in eliminating programming.\\nCross-Reference  Reasons \\nfor the difficulty of program-\\nming are described in \\n“Accidental and Essential \\nDifficulties” in Section 5.2.\\nThe reason for this dynamic is that, at its essence, programming is fundamentally \\nhard—even with good tool support.  No matter what tools are available, programmers \\nwill have to wrestle with the messy real world; we will have to think rigorously about \\nsequences, dependencies, and exceptions; and we’ll have to deal with end users who \\ncan’t make up their minds. We will always have to wrestle with ill-defined interfaces to \\nother software and hardware, and we’ll have to account for regulations, business \\nrules, and other sources of complexity that arise from outside the world of computer \\nprogramming.\\nWe will always need people who can bridge the gap between the real-world problem \\nto be solved and the computer that is supposed to be solving the problem. These peo-\\nple will be called programmers regardless of whether we’re manipulating machine \\nregisters in assembler or dialog boxes in Microsoft Visual Basic. As long as we have \\ncomputers, we’ll need people who tell the computers what to do, and that activity will \\nbe called programming.\\nWhen you hear a tool vendor claim “This new tool will eliminate computer program-\\nming,” run! Or at least smile to yourself at the vendor’s naive optimism.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 760}, page_content='724 Chapter 30: Programming Tools\\nAdditional Resources\\ncc2e.com/3098 Take a look at these additional resources for more on programming tools:\\ncc2e.com/3005 www.sdmagazine.com/jolts. Software Development Magazine’s annual Jolt Productivity \\naward website is a good source of information about the best current tools.\\nHunt, Andrew and David Thomas. The Pragmatic Programmer. Boston, MA: Addison-\\nWesley, 2000. Section 3 of this book provides an in-depth discussion of program-\\nming tools, including editors, code generators, debuggers, source-code control, and \\nrelated tools.\\ncc2e.com/3012 Vaughn-Nichols, Steven. “Building Better Software with Better Tools,” IEEE Computer, \\nSeptember 2003, pp. 12–14. This article surveys tool initiatives led by IBM, Microsoft \\nResearch, and Sun Research.\\nGlass, Robert L. Software Conflict: Essays on the Art and Science of Software Engineering. \\nEnglewood Cliffs, NJ: Yourdon Press, 1991. The chapter titled “Recommended: A Min-\\nimum Standard Software Toolset” provides a thoughtful counterpoint to the more-\\ntools-is-better view. Glass argues for the identification of a minimum set of tools that \\nshould be available to all developers and proposes a starting kit.\\nJones, Capers. Estimating Software Costs. New York, NY: McGraw-Hill, 1998.\\nBoehm, Barry, et al. Software Cost Estimation with Cocomo II. Reading, MA: Addison-\\nWesley, 2000. Both the Jones and the Boehm books devote sections to the impact of \\ntool use on productivity.\\ncc2e.com/3019 Checklist: Programming Tools\\n❑ Do you have an effective IDE? \\n❑ Does your IDE support integration with source-code control; build, test, \\nand debugging tools; and other useful functions? \\n❑ Do you have tools that automate common refactorings? \\n❑ Are you using version control to manage source code, content, require-\\nments, designs, project plans, and other project artifacts? \\n❑ If you’re working on a very large project, are you using a data dictionary or \\nsome other central repository that contains authoritative descriptions of \\neach class used in the system? \\n❑ Have you considered code libraries as alternatives to writing custom code, \\nwhere available?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 761}, page_content='Key Points 725\\n❑ Are you making use of an interactive debugger?\\n❑ Do you use make or other dependency-control software to build programs \\nefficiently and reliably?\\n❑ Does your test environment include an automated test framework, auto-\\nmated test generators, coverage monitors, system perturbers, diff tools, \\nand defect-tracking software?\\n❑ Have you created any custom tools that would help support your specific \\nproject’s needs, especially tools that automate repetitive tasks? \\n❑ Overall, does your environment benefit from adequate tool support? \\nKey Points\\n■ Programmers sometimes overlook some of the most powerful tools for years \\nbefore discovering them.\\n■ Good tools can make your life a lot easier.\\n■ Tools are readily available for editing, analyzing code quality, refactoring, ver-\\nsion control, debugging, testing, and code tuning.\\n■ You can make many of the special-purpose tools you need.\\n■ Good tools can reduce the more tedious aspects of software development, but \\nthey can’t eliminate the need for programming, although they will continue to \\nreshape what we mean by “programming.”'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 763}, page_content='Part VII\\nSoftware Craftsmanship\\nIn this part:\\nChapter 31: Layout and Style  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .729\\nChapter 32: Self-Documenting Code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .777\\nChapter 33: Personal Character  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .819\\nChapter 34: Themes in Software Craftsmanship  . . . . . . . . . . . . . . . . . . . .837\\nChapter 35: Where to Find More Information . . . . . . . . . . . . . . . . . . . . . .855'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 765}, page_content='729\\nChapter 31\\nLayout and Style\\ncc2e.com/3187 Contents\\n■ 31.1 Layout Fundamentals: page 730\\n■ 31.2 Layout Techniques: page 736\\n■ 31.3 Layout Styles: page 738\\n■ 31.4 Laying Out Control Structures: page 745\\n■ 31.5 Laying Out Individual Statements: page 753\\n■ 31.6 Laying Out Comments: page 763\\n■ 31.7 Laying Out Routines: page 766\\n■ 31.8 Laying Out Classes: page 768\\nRelated Topics\\n■ Self-documenting code: Chapter 32\\n■ Code formatting tools: “Editing” in Section 30.2\\nThis chapter turns to an aesthetic aspect of computer programming: the layout of pro-\\ngram source code. The visual and intellectual enjoyment of well-formatted code is a plea-\\nsure that few nonprogrammers can appreciate. But programmers who take pride in their \\nwork derive great artistic satisfaction from polishing the visual structure of their code.\\nThe techniques in this chapter don’t affect execution speed, memory use, or other \\naspects of a program that are visible from outside the program. They affect how easy it is \\nto understand the code, review it, and revise it months after you write it. They also affect \\nhow easy it is for others to read, understand, and modify once you’re out of the picture.\\nThis chapter is full of the picky details that people refer to when they talk about “atten-\\ntion to detail.” Over the life of a project, attention to such details makes a difference in the \\ninitial quality and the ultimate maintainability of the code you write. Such details are too \\nintegral to the coding process to be changed effectively later. If they’re to be done at all, \\nthey must be done during initial construction. If you’re working on a team project, have \\nyour team read this chapter and agree on a team style before you begin coding.\\nYou might not agree with everything you read here, but my point is less to win your \\nagreement than to convince you to consider the issues involved in formatting style. If \\nyou have high blood pressure, move on to the next chapter—it’s less controversial.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 766}, page_content='730 Chapter 31: Layout and Style\\n31.1 Layout Fundamentals\\nThis section explains the theory of good la yout. The rest of the chapter explains the \\npractice.\\nLayout Extremes\\nConsider the routine shown in Listing 31-1:\\nListing 31-1 Java layout example #1.\\n/* Use the insertion sort technique to sort the \"data\" array in ascending order. \\nThis routine assumes that data[ firstElement ] is not the first element in data and \\nthat data[ firstElement-1 ] can be accessed. */ public void InsertionSort( int[] \\ndata, int firstElement, int lastElement ) { /* Replace element at lower boundary \\nwith an element guaranteed to be first in a sorted list. */ int lowerBoundary = \\ndata[ firstElement-1 ]; data[ firstElement-1 ] = SORT_MIN; /* The elements in \\npositions firstElement through sortBoundary-1 are always sorted. In each pass \\nthrough the loop, sortBoundary is increased, and the element at the position of the \\nnew sortBoundary probably isn\\'t in its sorted place in the array, so it\\'s inserted \\ninto the proper place somewhere between firstElement and sortBoundary. */ for ( \\nint sortBoundary = firstElement+1; sortBoundary <= lastElement; sortBoundary++  ) \\n{ int insertVal = data[ sortBoundary ]; int insertPos = sortBoundary; while ( \\ninsertVal < data[ insertPos-1 ] ) { data[ insertPos ] = data[ insertPos-1 ]; \\ninsertPos = insertPos-1; } data[ insertPos ] = insertVal; } /* Replace original \\nlower-boundary element */ data[ firstElement-1 ] = lowerBoundary; }\\nThe routine is syntactically correct. It’s thoroughly commented and has good variable \\nnames and clear logic. If you don’t believe that, read it and find a mistake! What the \\nroutine doesn’t have is good layout. This is an extreme example, headed toward “neg-\\native infinity” on the number line of bad-to-good layout. Listing 31-2 is a less extreme \\nexample:\\nListing 31-2 Java layout example #2.\\n/* Use the insertion sort technique to sort the \"data\" array in ascending \\norder. This routine assumes that data[ firstElement ] is not the  \\nfirst element in data and that data[ firstElement-1 ] can be accessed. */ \\npublic void InsertionSort( int[] data, int firstElement, int lastElement ) { \\n/* Replace element at lower boundary with an element guaranteed to be first in a \\nsorted list. */ \\nint lowerBoundary = data[ firstElement-1 ]; \\ndata[ firstElement-1 ] = SORT_MIN; \\n/* The elements in positions firstElement through sortBoundary-1 are  \\nalways sorted. In each pass through the loop, sortBoundary  \\nis increased, and the element at the position of the  \\nnew sortBoundary probably isn\\'t in its sorted place in the  \\narray, so it\\'s inserted into the proper place somewhere  \\nbetween firstElement and sortBoundary. */ \\nfor ( \\nint sortBoundary = firstElement+1; \\nsortBoundary <= lastElement;  \\nCODING \\nHORROR\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 767}, page_content='31.1 Layout Fundamentals 731\\nsortBoundary++  \\n) { \\nint insertVal = data[ sortBoundary ]; \\nint insertPos = sortBoundary; \\nwhile ( insertVal < data[ insertPos-1 ] ) { \\ndata[ insertPos ] = data[ insertPos-1 ]; \\ninsertPos = insertPos-1; \\n} \\ndata[ insertPos ] = insertVal; \\n} \\n/* Replace original lower-boundary element */ \\ndata[ firstElement-1 ] = lowerBoundary; \\n}\\nThis code is the same as Listing 31-1’s. Although most people would agree that the \\ncode’s layout is much better than the first example’s, the code is still not very read-\\nable. The layout is still crowded and offers no clue to the routine’s logical organization. \\nIt’s at about 0 on the number line of bad-to-good layout. The first example was con-\\ntrived, but the second one isn’t at all uncommon. I’ve seen programs several thousand \\nlines long with layout at least as bad as this. With no documentation and bad variable \\nnames, overall readability was worse than in this example. This code is formatted for \\nthe computer; there’s no evidence that the author expected the code to be read by \\nhumans. Listing 31-3 is an improvement.\\nListing 31-3 Java layout example #3.\\n/* Use the insertion sort technique to sort the \"data\" array in ascending \\norder. This routine assumes that data[ firstElement ] is not the  \\nfirst element in data and that data[ firstElement-1 ] can be accessed.  \\n*/ \\n \\npublic void InsertionSort( int[] data, int firstElement, int lastElement ) { \\n   // Replace element at lower boundary with an element guaranteed to be  \\n   // first in a sorted list.  \\n   int lowerBoundary = data[ firstElement-1 ]; \\n   data[ firstElement-1 ] = SORT_MIN; \\n \\n   /* The elements in positions firstElement through sortBoundary-1 are  \\n   always sorted. In each pass through the loop, sortBoundary  \\n   is increased, and the element at the position of the  \\n   new sortBoundary probably isn\\'t in its sorted place in the  \\n   array, so it\\'s inserted into the proper place somewhere  \\n   between firstElement and sortBoundary.  \\n   */ \\n   for ( int sortBoundary = firstElement + 1; sortBoundary <= lastElement;  \\n      sortBoundary++ ) { \\n      int insertVal = data[ sortBoundary ]; \\n      int insertPos = sortBoundary; \\n      while ( insertVal < data[ insertPos - 1 ] ) { \\n         data[ insertPos ] = data[ insertPos - 1 ]; \\n         insertPos = insertPos - 1; \\n      }'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 768}, page_content='732 Chapter 31: Layout and Style\\n      data[ insertPos ] = insertVal; \\n   } \\n    \\n   // Replace original lower-boundary element \\n   data[ firstElement - 1 ] = lowerBoundary; \\n}\\nThis layout of the routine is a strong positive on the number line of bad-to-good layout. \\nThe routine is now laid out according to principles that are explained throughout this \\nchapter. The routine has become much more readable, and the effort that has been put \\ninto documentation and good variable names is now evident. The variable names were \\njust as good in the earlier examples, but the layout was so poor that they weren’t helpful.\\nThe only difference between this example and the first two is the use of white space—\\nthe code and comments are exactly the same. White space is of use only to human \\nreaders—your computer could interpret any of the three fragments with equal ease. \\nDon’t feel bad if you can’t do as well as your computer!\\nThe Fundamental Theorem of Formatting\\nThe Fundamental Theorem of Formatting says that good visual layout shows the log-\\nical structure of a program.\\nMaking the code look pretty is worth something, but it’s worth less than showing the \\ncode’s structure. If one technique shows the structure better and another looks better, \\nuse the one that shows the structure better. This chapter presents numerous exam-\\nples of formatting styles that look good but that misrepresent the code’s logical orga-\\nnization. In practice, prioritizing logical representation usually doesn’t create ugly \\ncode—unless the logic of the code is ugly. Techniques that make good code look good \\nand bad code look bad are more useful than techniques that make all code look good.\\nHuman and Computer Interpretations of a Program\\nAny fool can write code that \\na computer can understand. \\nGood programmers write \\ncode that humans can \\nunderstand.  \\n—Martin Fowler\\nLayout is a useful clue to the structure of a program. Whereas the computer might \\ncare exclusively about braces or begin and end, a human reader is apt to draw clues \\nfrom the visual presentation of the code. Consider the code fragment in Listing 31-4, \\nin which the indentation scheme makes it look to a human as if three statements are \\nexecuted each time the loop is executed.\\nListing 31-4 Java example of layout that tells different stories to humans and computers.\\n// swap left and right elements for whole array \\nfor ( i = 0; i < MAX_ELEMENTS; i++ ) \\n   leftElement = left[ i ]; \\n   left[ i ]   = right[ i ]; \\n   right[ i ]  = leftElement;\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 769}, page_content='31.1 Layout Fundamentals 733\\nIf the code has no enclosing braces, the compiler will execute the first statement \\nMAX_ELEMENTS times and the second and third statements one time each. The \\nindentation makes it clear to you and me that the author of the code wanted all three \\nstatements to be executed together and intended to put braces around them. That \\nwon’t be clear to the compiler. Listing 31-5 is another example:\\nListing 31-5 Another Java example of layout that tells different stories to humans and \\ncomputers.\\nx = 3+4 * 2+7;\\nA human reader of this code would be inclined to interpret the statement to mean that \\nx is assigned the value (3+4) * (2+7), or 63. The computer will ignore the white space \\nand obey the rules of precedence, interpreting the expression as 3 + (4*2) + 7, or 18. The \\npoint is that a good layout scheme would make the visual structure of a program match \\nthe logical structure, or tell the same story to the human that it tells to the computer.\\nHow Much Is Good Layout Worth?\\nOur studies support the claim that knowledge of programming plans and rules \\nof programming discourse can have a significant impact on program compre-\\nhension. In their book called [The] Elements of [Programming] Style, Kernighan \\nand Plauger also identify what we would call discourse rules. Our empirical \\nresults put teeth into these rules: It is not merely a matter of aesthetics that pro-\\ngrams should be written in a particular style. Rather there is a psychological \\nbasis for writing programs in a conventional manner: programmers have strong \\nexpectations that other programmers will follow these discourse rules. If the \\nrules are violated, then the utility afforded by the expectations that program-\\nmers have built up over time is effectively nullified. The results from the experi-\\nments with novice and advanced student programmers and with professional \\nprogrammers described in this paper provide clear support for these claims.\\n—Elliot Soloway and Kate Ehrlich\\nCross-Reference Good lay-\\nout is one key to readability. \\nFor details on the value of \\nreadability, see Section 34.3, \\n“Write Programs for People \\nFirst, Computers Second.”\\nIn layout, perhaps more than in any other aspect of programming, the difference \\nbetween communicating with the computer and communicating with human readers \\ncomes into play. The smaller part of the job of programming is writing a program so that \\nthe computer can read it; the larger part is writing it so that other humans can read it.\\nIn their classic paper “Perception in Chess,” Chase and Simon reported on a study \\nthat compared the abilities of experts and novices to remember the positions of pieces \\nin chess (1973). When pieces were arranged  on the board as they might be during \\na game, the experts’ memories were far superior to the novices’. When the pieces \\nwere arranged randomly, there was little difference between the memories of the \\nexperts and the novices. The traditional interpretation of this result is that an'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 770}, page_content='734 Chapter 31: Layout and Style\\nexpert’s memory is not inherently better than a novice’s  but that the expert has a \\nknowledge structure that helps him or her remember particular kinds of informa-\\ntion. When new information corresponds to the knowledge structure—in this case, \\nthe sensible placement of chess pieces—the expert can remember it easily. When \\nnew information doesn’t correspond to a knowledge structure—the chess pieces are \\nrandomly positioned—the expert can’t remember it any better than the novice.\\nA few years later, Ben Shneiderman duplicated Chase and Simon’s results in the com-\\nputer-programming arena and reported his results in a paper called “Exploratory Exper-\\niments in Programmer Behavior” (1976). Shneiderman found that when program \\nstatements were arranged in a sensible order, experts were able to remember them bet-\\nter than novices. When statements were shuffled, the experts’ superiority was reduced. \\nShneiderman’s results have been confirmed in other studies (McKeithen et al. 1981, \\nSoloway and Ehrlich 1984). The basic concept has also been confirmed in the games Go \\nand bridge and in electronics, music, and physics (McKeithen et al. 1981).\\nAfter I published the first edition of this book, Hank, one of the programmers who \\nreviewed the manuscript, said “I was surprised that you didn’t argue more strongly in \\nfavor of a brace style that looks like this:\\nfor ( ...) \\n   { \\n   }\\n“I was surprised that you even included the brace style that looked like this:\\nfor ( ...) { \\n}\\n“I thought that, with both Tony and me arguing for the first style, you’d prefer that.” \\nI responded, “You mean you were arguing for the first style, and Tony was arguing for \\nthe second style, don’t you? Tony argued for the second style, not the first.” \\nHank responded, “That’s funny. The last project Tony and I worked on together, I pre-\\nferred style #2, and Tony preferred style #1. We spent the whole project arguing about \\nwhich style was best. I guess we talked one another into preferring each other’s \\nstyles!”\\nThis experience, as well as the studies cited above, suggest that structure helps \\nexperts to perceive, comprehend, and remember important features of programs. \\nExpert programmers often cling to their own styles tenaciously, even when they’re \\nvastly different from other styles used by other expert programmers. The bottom line \\nis that the details of a specific method of structuring a program are much less impor-\\ntant than the fact that the program is structured consistently.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 771}, page_content='31.1 Layout Fundamentals 735\\nLayout as Religion\\nThe importance to comprehension and memory of structuring one’s environment in a \\nfamiliar way has led some researchers to hypothesize that layout might harm an expert’s \\nability to read a program if the layout is different from the scheme the expert uses (Sheil \\n1981, Soloway and Ehrlich 1984). That possibility, compounded by the fact that layout \\nis an aesthetic as well as a logical exercise, means that debates about program formatting \\noften sound more like religious wars than philosophical discussions.\\nCross-Reference If you’re \\nmixing software and reli-\\ngion, you might read Section \\n34.9, “Thou Shalt Rend Soft-\\nware and Religion Asunder” \\nbefore reading the rest of \\nthis chapter.\\nAt a coarse level, it’s clear that some forms of layout are better than others. The succes-\\nsively better layouts of the same code at the beginning of this chapter made that evi-\\ndent. This book won’t steer clear of the finer points of layout just because they’re \\ncontroversial. Good programmers should be open-minded about their layout prac-\\ntices and accept practices proven to be better than the ones they’re used to, even if \\nadjusting to a new method results in some initial discomfort.\\nObjectives of Good Layout\\nThe results point out the fra-\\ngility of programming exper-\\ntise: advanced programmers \\nhave strong expectations \\nabout what programs should \\nlook like, and when those \\nexpectations are violated—\\nin seemingly innocuous \\nways—their performance \\ndrops drastically.  \\n—Elliot Soloway and \\nKate Ehrlich\\nMany decisions about layout details are a matter of subjective aesthetics; often, you \\ncan accomplish the same goal in many ways. You can make debates about subjective \\nissues less subjective if you explicitly specify the criteria for your preferences. Explic-\\nitly, then, a good layout scheme should do the following:\\nAccurately represent the logical structure of the code That’s the Fundamental Theo-\\nrem of Formatting again: the primary purpose of good layout is to show the logical \\nstructure of the code. Typically, programmers use indentation and other white space \\nto show the logical structure.\\nConsistently represent the logical structure of the code Some styles of layout have \\nrules with so many exceptions that it’s hard to follow the rules consistently. A good \\nstyle applies to most cases.\\nImprove readabilityAn indentation strategy that’s logical but that makes the code \\nharder to read is useless. A layout scheme that calls for spaces only where they are \\nrequired by the compiler is logical but not readable. A good layout scheme makes \\ncode easier to read.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 772}, page_content='736 Chapter 31: Layout and Style\\nWithstand modifications The best layout schemes hold up well under code modifi-\\ncation. Modifying one line of code shouldn’t require modifying several others.\\nIn addition to these criteria, minimizing the number of lines of code needed to imple-\\nment a simple statement or block is also sometimes considered.\\nHow to Put the Layout Objectives to Use\\nYou can use the criteria for a good layout scheme to ground a discussion of layout so \\nthat the subjective reasons for preferring one style over another are brought into the \\nopen.\\nWeighting the criteria in different ways might lead to different conclusions. For exam-\\nple, if you feel strongly that minimizing the number of lines used on the screen is \\nimportant—perhaps because you have a small computer screen—you might criticize \\none style because it uses two more lines for a routine parameter list than another.\\n31.2 Layout Techniques\\nYou can achieve good layout by using a few layout tools in several different ways. This \\nsection describes each of them.\\nWhite Space\\nUsewhitespacetoenhancereadability. White space, including spaces, tabs, line breaks, \\nand blank lines, is the main tool available to you for showing a program’s structure.\\nCross-Reference Some \\nresearchers have explored \\nthe similarity between the \\nstructure of a book and the \\nstructure of a program. For \\ninformation, see “The Book \\nParadigm for Program Doc-\\numentation” in Section 32.5.\\nYou wouldn’t think of writing a book with no spaces between words, no paragraph \\nbreaks, and no divisions into chapters. Such a book might be readable cover to cover, \\nbut it would be virtually impossible to skim it for a line of thought or to find an impor-\\ntant passage. Perhaps more important, the book’s layout wouldn’t show the reader \\nhow the author intended to organize the information. The author’s organization is an \\nimportant clue to the topic’s logical organization.\\nBreaking a book into chapters, paragraphs, and sentences shows a reader how to men-\\ntally organize a topic. If the organization isn’t evident, the reader has to provide the \\norganization, which puts a much greater burden on the reader and adds the possibil-\\nity that the reader may never figure out how the topic is organized.\\nThe information contained in a program is  denser than the information contained \\nin most books. Whereas you might read and understand a page of a book in a \\nminute or two, most programmers can’t read and understand a naked program list-\\ning at anything close to that rate. A program should give more organizational clues \\nthan a book, not fewer.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 773}, page_content='31.2 Layout Techniques 737\\nGrouping From the other side of the looking glass, white space is grouping, making \\nsure that related statements are grouped together.\\nIn writing, thoughts are grouped into paragraphs. A well-written paragraph contains \\nonly sentences that relate to a particular thought. It shouldn’t contain extraneous sen-\\ntences. Similarly, a paragraph of code should contain statements that accomplish a \\nsingle task and that are related to each other.\\nBlank lines Just as it’s important to group related statements, it’s important to sepa-\\nrate unrelated statements from each other. The start of a new paragraph in English is \\nidentified with indentation or a blank line. The start of a new paragraph of code \\nshould be identified with a blank line.\\nUsing blank lines is a way to indicate how a program is organized. You can use them \\nto divide groups of related statements into paragraphs, to separate routines from one \\nanother, and to highlight comments.\\nAlthough this particular statistic may be hard to put to work, a study by Gorla, \\nBenander, and Benander found that the optimal number of blank lines in a program \\nis about 8 to 16 percent. Above 16 percent, debug time increases dramatically (1990).\\nIndentation Use indentation to show the logical structure of a program. As a rule, \\nyou should indent statements under the statement to which they are logically subor-\\ndinate.\\nIndentation has been shown to be correlated with increased programmer comprehen-\\nsion. The article “Program Indentation and Comprehensibility” reported that several \\nstudies found correlations between indentation and improved comprehension \\n(Miaria et al. 1983). Subjects scored 20 to 30 percent higher on a test of comprehen-\\nsion when programs had a two-to-four-spaces indentation scheme than they did when \\nprograms had no indentation at all.\\nThe same study found that it was important to neither underemphasize nor overem-\\nphasize a program’s logical structure. The lowest comprehension scores were \\nachieved on programs that were not indented at all. The second lowest were achieved \\non programs that used six-space indentation. The study concluded that two-to-four-\\nspace indentation was optimal. Interestingly, many subjects in the experiment felt that \\nthe six-space indentation was easier to use than the smaller indentations, even though \\ntheir scores were lower. That’s probably because six-space indentation looks pleasing. \\nBut regardless of how pretty it looks, six-space indentation turns out to be less read-\\nable. This is an example of a collision between aesthetic appeal and readability.\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 774}, page_content='738 Chapter 31: Layout and Style\\nParentheses\\nUse more parentheses than you think you need. Use parentheses to clarify expres-\\nsions that involve more than two terms. They may not be needed, but they add clarity \\nand they don’t cost you anything. For example, how are the following expressions \\nevaluated?\\nC++ version: 12 + 4 % 3 * 7 / 8\\nMicrosoft Visual Basic version: 12 + 4 mod 3 * 7 / 8\\nThe key question is, did you have to think about how the expressions are evaluated? \\nCan you be confident in your answer without checking some references? Even experi-\\nenced programmers don’t answer confidently, and that’s why you should use paren-\\ntheses whenever there’s any doubt about how an expression is evaluated.\\n31.3 Layout Styles\\nMost layout issues have to do with laying out blocks, the groups of statements below \\ncontrol statements. A block is enclosed between braces or keywords: { and } in C++ \\nand Java, if-then-endif in Visual Basic, and other similar structures in other languages. \\nFor simplicity, much of this discussion uses begin and end generically, assuming that \\nyou can figure out how the discussion applies to braces in C++ and Java or other \\nblocking mechanisms in other languages. The following sections describe four general \\nstyles of layout:\\n■ Pure blocks\\n■ Emulating pure blocks\\n■ Using begin-end pairs (braces) to designate block boundaries\\n■ Endline layout\\nPure Blocks\\nMuch of the layout controversy stems from the inherent awkwardness of the more \\npopular programming languages. A well-designed language has clear block structures \\nthat lend themselves to a natural indentation style. In Visual Basic, for example, each \\ncontrol construct has its own terminator and you can’t use a control construct with-\\nout using the terminator. Code is blocked naturally. Some examples in Visual Basic \\nare shown in Listing 31-6, Listing 31-7, and Listing 31-8:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 775}, page_content='31.3 Layout Styles 739\\nListing 31-6 Visual Basic example of a pure if block.\\nIf pixelColor = Color_Red Then \\n   statement1 \\n   statement2 \\n   ... \\nEnd If\\nListing 31-7 Visual Basic example of a pure while block.\\nWhile pixelColor = Color_Red \\n   statement1 \\n   statement2 \\n   ... \\nWend\\nListing 31-8 Visual Basic example of a pure case block.\\nSelect Case pixelColor \\n   Case Color_Red \\n      statement1 \\n      statement2 \\n      ... \\n   Case Color_Green \\n      statement1 \\n      statement2 \\n      ... \\n   Case Else \\n      statement1 \\n      statement2 \\n      ... \\nEnd Select\\nA control construct in Visual Basic always has a beginning statement—If-Then, While, \\nand Select-Case in the examples—and it always has a corresponding End statement. \\nIndenting the inside of the structure isn’t a controversial practice, and the options for \\naligning the other keywords are somewhat limited. Listing 31-9 is an abstract repre-\\nsentation of how this kind of formatting works:\\nListing 31-9 Abstract example of the pure-block layout style.\\nA   XXXXXXXXXXXXXXXXXXXX \\nB      XXXXXXXXXXXX \\nC      XXXXXXXXXXXXXXX \\nD   XXXX'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 776}, page_content='740 Chapter 31: Layout and Style\\nIn this example, statement A begins the control construct and statement D ends the \\ncontrol construct. The alignment between the two provides solid visual closure.\\nThe controversy about formatting control structures arises in part from the fact that \\nsome languages don’t require block structures. You can have an if-then followed by a \\nsingle statement and not have a formal block. You have to add a begin-end pair or \\nopening and closing braces to create a block rather than getting one automatically \\nwith each control construct. Uncoupling begin and end from the control structure—as \\nlanguages like C++ and Java do with { and }—leads to questions about where to put the \\nbegin and end. Consequently, many indentation problems are problems only because \\nyou have to compensate for poorly designed language structures. Various ways to \\ncompensate are described in the following sections.\\nEmulating Pure Blocks\\nA good approach in languages that don’t have pure blocks is to view the begin and end \\nkeywords (or { and } tokens) as extensions of the control construct they’re used with. \\nThen it’s sensible to try to emulate the Visual Basic formatting in your language. List-\\ning 31-10 is an abstract view of the visual structure you’re trying to emulate:\\nListing 31-10 Abstract example of the pure-block layout style.\\nA   XXXXXXXXXXXXXXXXXXXX \\nB      XXXXXXXXXXXX \\nC      XXXXXXXXXXXXXXX \\nD   XXXX\\nIn this style, the control structure opens the block in statement A and finishes the \\nblock in statement D. This implies that the begin should be at the end of statement A \\nand the end should be statement D. In the abstract, to emulate pure blocks, you’d have \\nto do something like Listing 31-11:\\nListing 31-11 Abstract example of emulating the pure-block style.\\nA   XXXXXXXXXXXXXX{X \\nB      XXXXXXXXXXXXXX \\nC      XXXXXXXXXXXXXXXXX \\nD   }X'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 777}, page_content='31.3 Layout Styles 741\\nSome examples of how the style looks in C++ are shown in Listing 31-12, Listing 31-13, \\nand Listing 31-14:\\nListing 31-12 C++ example of emulating a pure if block.\\nif ( pixelColor == Color_Red ) { \\n   statement1; \\n   statement2; \\n   ... \\n}\\nListing 31-13 C++ example of emulating a pure while block.\\nwhile ( pixelColor == Color_Red ) { \\n   statement1; \\n   statement2; \\n   ... \\n}\\nListing 31-14 C++ example of emulating a pure switch/case block.\\nswitch ( pixelColor ) { \\n   case Color_Red: \\n      statement1; \\n      statement2; \\n      ... \\n   break; \\n   case Color_Green: \\n      statement1; \\n      statement2; \\n      ... \\n   break; \\n   default:  \\n      statement1; \\n      statement2; \\n      ... \\n   break; \\n}\\nThis style of alignment works pretty well. It looks good, you can apply it consistently, \\nand it’s maintainable. It supports the Fundamental Theorem of Formatting in that it \\nhelps to show the logical structure of the code. It’s a reasonable style choice. This style \\nis standard in Java and common in C++.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 778}, page_content='742 Chapter 31: Layout and Style\\nUsing begin-end Pairs (Braces) to Designate Block Boundaries\\nA substitute for a pure-block structure is to view begin-end pairs as block boundaries. \\n(The following discussion uses begin-end to refer generically to begin-end pairs, braces, \\nand other equivalent language structures.) If you take that approach, you view the \\nbegin and the end as statements that follow the control construct rather than as frag-\\nments that are part of it. Graphically, this is the ideal, just as it was with the pure-block \\nemulation shown again in Listing 31-15:\\nListing 31-15 Abstract example of the pure-block layout style.\\nA   XXXXXXXXXXXXXXXXXXX \\nB      XXXXXXXXXXXX \\nC      XXXXXXXXXXXXXX \\nD   XXXX\\nBut in this style, to treat the begin and the end as parts of the block structure rather \\nthan the control statement, you have to put the begin at the beginning of the block \\n(rather than at the end of the control statement) and the end at the end of the block \\n(rather than terminating the control statement). In the abstract, you’ll have to do \\nsomething like what’s done in Listing 31-16:\\nListing 31-16 Abstract example of using begin and end as block boundaries.\\nA   XXXXXXXXXXXXXXXXXXXX \\n       {XXXXXXXXXXXXXXXX \\nB      XXXXXXXXXXXXXXXXX \\nC      XXXXXXXXXXXXXXXXX \\n       }X\\nSome examples of how using begin and end as block boundaries looks in C++ are \\nshown in Listing 31-17, Listing 31-18, and Listing 31-19:\\nListing 31-17 C++ example of using begin and end as block boundaries in an if block.\\nif ( pixelColor == Color_Red )  \\n   { \\n   statement1; \\n   statement2; \\n   ... \\n   }\\nListing 31-18 C++ example of using begin and end as block boundaries in a while block.\\nwhile ( pixelColor == Color_Red ) \\n   { \\n   statement1; \\n   statement2; \\n   ... \\n   }'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 779}, page_content='31.3 Layout Styles 743\\nListing 31-19 C++ example of using begin and end as block boundaries in a switch/case \\nblock.\\nswitch ( pixelColor )  \\n   { \\n   case Color_Red: \\n      statement1; \\n      statement2; \\n      ... \\n      break; \\n   case Color_Green: \\n      statement1; \\n      statement2; \\n      ... \\n      break; \\n   default: \\n      statement1; \\n      statement2; \\n      ... \\n      break; \\n   }\\nThis alignment style works well; it supports the Fundamental Theorem of Formatting \\n(once again, by exposing the code’s underlying logical structure). Its only limitation is \\nthat it can’t be applied literally in switch/case statements in C++ and Java, as shown by \\nListing 31-19. (The break keyword is a substitute for the closing brace, but there is no \\nequivalent to the opening brace.)\\nEndline Layout\\nAnother layout strategy is “endline layout,” which refers to a large group of layout \\nstrategies in which the code is indented to the middle or end of the line. The endline \\nindentation is used to align a block with the keyword that began it, to make a routine’s \\nsubsequent parameters line up under its first parameter, to line up cases in a case \\nstatement, and for other similar purposes. Listing 31-20 is an abstract example:\\nListing 31-20 Abstract example of the endline layout style.\\nA  XXXXXX  XXXXXXXXXXXXXXXXXXXXXXXXXXX \\nB          XXXXXXXXXXXXXXX \\nC          XXXXXXXXXXXXXXX \\nD          XX\\nIn this example, statement A begins the control construct and statement D ends it. State-\\nments B, C, and D are aligned under the keyword that began the block in statement A.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 780}, page_content='744 Chapter 31: Layout and Style\\nThe uniform indentation of B, C, and D shows that they’re grouped together. Listing \\n31-21 is a less abstract example of code formatted using this strategy:\\nListing 31-21 Visual Basic example of endline layout of a while block.\\nWhile ( pixelColor = Color_Red )  \\n        statement1; \\n        statement2; \\n        ... \\n        Wend\\nIn the example, the begin is placed at the end of the line rather than under the corre-\\nsponding keyword. Some people prefer to put begin under the keyword, but choosing \\nbetween those two fine points is the least of this style’s problems.\\nThe endline layout style works acceptably in a few cases. Listing 31-22 is an example \\nin which it works:\\nListing 31-22 A rare Visual Basic example in which endline layout seems appealing.\\nIf ( soldCount > 1000 ) Then \\n                             markdown = 0.10 \\n                             profit = 0.05\\nThe else keyword is aligned \\nwith the then keyword \\nabove it.\\n                        Else  \\n                             markdown = 0.05 \\n                        End If\\nIn this case, the Then, Else, and End If keywords are aligned and the code following \\nthem is also aligned. The visual effect is a clear logical structure.\\nIf you look critically at the earlier case-statement example, you can probably predict the \\nunraveling of this style. As the conditional expression becomes more complicated, the \\nstyle will give useless or misleading clues about the logical structure. Listing 31-23 is an \\nexample of how the style breaks down when it’s used with a more complicated conditional:\\nListing 31-23 A more typical Visual Basic example, in which endline layout breaks down.\\nIf ( soldCount > 10 And prevMonthSales > 10 ) Then \\n   If ( soldCount > 100 And prevMonthSales > 10 ) Then \\n      If ( soldCount > 1000 ) Then \\n                                 markdown = 0.1 \\n                                 profit = 0.05 \\n                              Else \\n                                 markdown = 0.05 \\n                              End If \\n                                                  Else \\n                                                     markdown = 0.025 \\n                                                  End If \\n                                              Else \\n                                                 markdown = 0.0 \\n                                              End If\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 781}, page_content='31.4 Laying Out Control Structures 745\\nWhat’s the reason for the bizarre formatting of the Else clauses at the end of the exam-\\nple? They’re consistently indented under the corresponding keywords, but it’s hard to \\nargue that their indentations clarify the logi cal structure. And if the code were modi-\\nfied so that the length of the first line changed, the endline style would require that \\nthe indentation of corresponding statements be changed. This poses a maintenance \\nproblem that pure block, pure-block emulation, and using begin-end to designate \\nblock boundaries do not.\\nYou might think that these examples are contrived just to make a point, but this \\nstyle has been persistent despite its drawbacks. Numerous textbooks and program-\\nming references have recommended this style. The earliest book I saw that recom-\\nmended this style was published in th e mid-1970s, and the most recent was \\npublished in 2003.\\nOverall, endline layout is inaccurate, hard to apply consistently, and hard to maintain. \\nYou’ll see other problems with endline layout throughout the chapter.\\nWhich Style Is Best?\\nIf you’re working in Visual Basic, use pure-block indentation. (The Visual Basic IDE \\nmakes it hard not to use this style anyway.)\\nIn Java, standard practice is to use pure-block indentation.\\nIn C++, you might simply choose the style you like or the one that is preferred by the \\nmajority of people on your team. Either pure-block emulation or begin-end block \\nboundaries work equally well. The only study that has compared the two styles found \\nno statistically significant difference between the two as far as understandability is \\nconcerned (Hansen and Yim 1987).\\nNeither of the styles is foolproof, and each requires an occasional “reasonable and obvi-\\nous” compromise. You might prefer one or the other for aesthetic reasons. This book \\nuses pure-block style in its code examples, so you can see many more illustrations of \\nhow that style works just by skimming through its examples. Once you’ve chosen a \\nstyle, you reap the most benefit from good layout when you apply it consistently.\\n31.4 Laying Out Control Structures\\nCross-Reference For details \\non documenting control \\nstructures, see “Commenting \\nControl Structures” in Sec-\\ntion 32.5. For a discussion of \\nother aspects of control \\nstructures, see Chapters 14 \\nthrough 19.\\nThe layout of some program elements is primarily a matter of aesthetics. Layout of \\ncontrol structures, however, affects readability and comprehensibility and is therefore \\na practical priority.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 782}, page_content='746 Chapter 31: Layout and Style\\nFine Points of Formatting Control-Structure Blocks\\nWorking with control-structure blocks requires attention to some fine details. Here \\nare some guidelines:\\nAvoid unindented begin-end pairs In the style shown in Listing 31-24, the begin-end \\npair is aligned with the control structure, and the statements that begin and end \\nenclose are indented under begin.\\nListing 31-24 Java example of unindented begin-end pairs.\\nThe begin is aligned with \\nthe for.\\nThe statements are indented \\nunder begin.\\nThe end is aligned with \\nthe for.\\nfor ( int i = 0; i < MAX_LINES; i++ )  \\n{\\n   ReadLine( i ); \\n   ProcessLine( i );\\n}\\nAlthough this approach looks fine, it violates the Fundamental Theorem of Formatting; \\nit doesn’t show the logical structure of the code. Used this way, the begin and end aren’t \\npart of the control construct, but they aren’t part of the statement(s) after it either.\\nListing 31-25 is an abstract view of this approach:\\nListing 31-25 Abstract example of misleading indentation.\\nA   XXXXXXXXXXXXXXXXXXXX \\nB   XXXXXXX \\nC      XXXXXXXX \\nD      XXXXXXXXXXXXXX \\nE   XXXX\\nIn this example, is statement B subordinate to statement A? It doesn’t look like part of \\nstatement A, and it doesn’t look as if it’s subordinate to it either. If you have used this \\napproach, change to one of the two layout styles described earlier and your formatting \\nwill be more consistent.\\nAvoid double indentation with begin and end A corollary to the rule against nonin-\\ndented begin-end pairs is the rule against doubly indented begin-end pairs. In this style, \\nshown in Listing 31-26, begin and end are indented and the statements they enclose \\nare indented again:\\nListing 31-26 Java example of inappropriate double indentation of begin-end block.\\nfor ( int i = 0; i < MAX_LINES; i++ ) \\n   {\\nThe statements below the \\nbegin are indented as if they \\nwere subordinate to it.\\n      ReadLine( i ); \\n      ProcessLine( i ); \\n   }\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 783}, page_content='31.4 Laying Out Control Structures 747\\nThis is another example of a style that looks fine but violates the Fundamental Theo-\\nrem of Formatting. One study showed no difference in comprehension between pro-\\ngrams that are singly indented and programs that are doubly indented (Miaria et al. \\n1983), but this style doesn’t accurately show the logical structure of the program. \\nReadLine() and ProcessLine() are shown as if they are logically subordinate to the begin-\\nend pair, and they aren’t.\\nThe approach also exaggerates the complexity of a program’s logical structure. Which \\nof the structures shown in Listing 31-27 and Listing 31-28 looks more complicated?\\nListing 31-27 Abstract Structure 1.\\nXXXXXXXXXXXXXXXXXXXX \\n   XXXXX \\n      XXXXXXXXX \\n      XXXXXXXXXXXX \\n   XXXXX\\nListing 31-28 Abstract Structure 2.\\nXXXXXXXXXXXXXXXXXXXX \\n   XXXXX \\n   XXXXXXXXXX \\n   XXXXXXXXXXXXX \\n   XXXXX\\nBoth are abstract representations of the structure of the for loop. Abstract Structure 1 \\nlooks more complicated even though it represents the same code as Abstract Struc-\\nture 2. If you were to nest statements to two or three levels, double indentation would \\ngive you four or six levels of indentation. The layout that resulted would look more \\ncomplicated than the actual code would be. Avoid the problem by using pure-block \\nemulation or by using begin and end as block boundaries and aligning begin and end \\nwith the statements they enclose.\\nOther Considerations\\nAlthough indentation of blocks is the majo r issue in formatting control structures, \\nyou’ll run into a few other kinds of issues, so here are some more guidelines:\\nUse blank lines between paragraphs Some blocks of code aren’t demarcated with \\nbegin-end pairs. A logical block—a group of statements that belong together—should be \\ntreated the way paragraphs in English are. Separate them from one another with \\nblank lines. Listing 31-29 shows an example of paragraphs that should be separated:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 784}, page_content='748 Chapter 31: Layout and Style\\nListing 31-29 C++ example of code that should be grouped and separated.\\ncursor.start = startingScanLine; \\ncursor.end   = endingScanLine; \\nwindow.title = editWindow.title; \\nwindow.dimensions      = editWindow.dimensions; \\nwindow.foregroundColor = userPreferences.foregroundColor; \\ncursor.blinkRate       = editMode.blinkRate; \\nwindow.backgroundColor = userPreferences.backgroundColor; \\nSaveCursor( cursor ); \\nSetCursor( cursor );\\nCross-Reference If you use \\nthe Pseudocode Program-\\nming Process, your blocks of \\ncode will be separated auto-\\nmatically. For details, see \\nChapter 9, “The Pseudocode \\nProgramming Process.”\\nThis code looks all right, but blank lines would improve it in two ways. First, when \\nyou have a group of statements that don’t have to be executed in any particular order, \\nit’s tempting to lump them all together this way. You don’t need to further refine the \\nstatement order for the computer, but human readers appreciate more clues about \\nwhich statements need to be performed in a specific order and which statements are \\njust along for the ride. The discipline of putting blank lines throughout a program \\nmakes you think harder about which statements really belong together. The revised \\nfragment in Listing 31-30 shows how this collection should really be organized.\\nListing 31-30 C++ example of code that is appropriately grouped and separated.\\nThese lines set up a text \\nwindow.\\nThese lines set up a cursor \\nand should be separated \\nfrom the preceding lines.\\nwindow.dimensions = editWindow.dimensions; \\nwindow.title = editWindow.title; \\nwindow.backgroundColor = userPreferences.backgroundColor; \\nwindow.foregroundColor = userPreferences.foregroundColor; \\ncursor.start = startingScanLine; \\ncursor.end = endingScanLine; \\ncursor.blinkRate = editMode.blinkRate; \\nSaveCursor( cursor ); \\nSetCursor( cursor );\\nThe reorganized code shows that two things are happening. In the first example, the \\nlack of statement organization and blank lines, and the old aligned–equals signs trick, \\nmake the statements look more related than they are.\\nThe second way in which using blank lines tends to improve code is that it opens up \\nnatural spaces for comments. In Listing 31-30, a comment above each block would \\nnicely supplement the improved layout.\\nFormat single-statement blocks consistentlyA single-statement block is a single \\nstatement following a control structure, such as one statement following an if test. In \\nsuch a case, begin and end aren’t needed for correct compilation and you have the \\nthree style options shown in Listing 31-31:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 785}, page_content=\"31.4 Laying Out Control Structures 749\\nListing 31-31 Java example of style options for single-statement blocks.\\nStyle 1 if ( expression )  \\n   one-statement; \\nStyle 2a if ( expression ) { \\n   one-statement; \\n} \\nStyle 2b if ( expression )  \\n   { \\n   one-statement; \\n   } \\nStyle 3 if ( expression ) one-statement;\\nThere are arguments in favor of each of these approaches. Style 1 follows the indenta-\\ntion scheme used with blocks, so it’s consistent with other approaches. Style 2 (either \\n2a or 2b) is also consistent, and the begin-end pair reduces the chance that you’ll add \\nstatements after the if test and forget to add begin and end. This would be a particularly \\nsubtle error because the indentation would tell you that everything is OK, but the \\nindentation wouldn’t be interpreted the same way by the compiler. Style 3’s main \\nadvantage over Style 2 is that it’s easier to type. Its advantage over Style 1 is that if it’s \\ncopied to another place in the program, it’s more likely to be copied correctly. Its dis-\\nadvantage is that in a line-oriented debugger, the debugger treats the line as one line \\nand the debugger doesn’t show you whether it executes the statement after the if test.\\nI’ve used Style 1 and have been the victim of incorrect modification many times. I \\ndon’t like the exception to the indentation strategy caused by Style 3, so I avoid it alto-\\ngether. On a group project, I favor either variation of Style 2 for its consistency and \\nsafe modifiability. Regardless of the style you choose, use it consistently and use the \\nsame style for if tests and all loops.\\nFor complicated expressions, put separate conditions on separate lines Put each part \\nof a complicated expression on its own line. Listing 31-32 shows an expression that’s \\nformatted without any attention to readability:\\nListing 31-32 Java example of an essentially unformatted (and unreadable) complicated \\nexpression.\\nif ((('0' <= inChar) && (inChar <= '9')) || (('a' <= inChar) &&  \\n   (inChar <= 'z')) || (('A' <= inChar) && (inChar <= 'Z')))  \\n   ...\\nThis is an example of formatting for the computer instead of for human readers. By break-\\ning the expression into several lines, as in Listing 31-33, you can improve readability.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 786}, page_content=\"750 Chapter 31: Layout and Style\\nListing 31-33 Java example of a readable complicated expression.\\nCross-Reference Another \\ntechnique for making com-\\nplicated expressions read-\\nable is to put them into \\nboolean functions. For \\ndetails on that technique \\nand other readability tech-\\nniques, see Section 19.1, \\n“Boolean Expressions.”\\nif ( ( ( '0' <= inChar ) && ( inChar <= '9' ) ) || \\n   ( ( 'a' <= inChar ) && ( inChar <= 'z' ) ) || \\n   ( ( 'A' <= inChar ) && ( inChar <= 'Z' ) ) )  \\n   ...\\nThe second fragment uses several formatting techniques—indentation, spacing, num-\\nber-line ordering, and making each incomplete line obvious—and the result is a read-\\nable expression. Moreover, the intent of the test is clear. If the expression contained a \\nminor error, such as using a z instead of a Z, it would be obvious in code formatted \\nthis way, whereas the error wouldn’t be clear with less careful formatting.\\nCross-Reference For details \\non the use of gotos, see Sec-\\ntion 17.3, “goto.”\\nAvoid gotos The original reason to avoid gotos was that they made it difficult to \\nprove that a program was correct. That’s a nice argument for all the people who want \\nto prove their programs correct, which is practically no one. The more pressing prob-\\nlem for most programmers is that gotos make code hard to format. Do you indent all \\nthe code between the goto and the label it goes to? What if you have several gotos to the \\nsame label? Do you indent each new one under the previous one? Here’s some advice \\nfor formatting gotos:\\nGoto labels should be left-\\naligned in all caps and \\nshould include the program-\\nmer’s name, home phone \\nnumber, and credit card \\nnumber.\\n—Abdul Nizar\\n■ Avoid gotos. This sidesteps the formatting problem altogether.\\n■ Use a name in all caps for the label the code goes to. This makes the label obvi-\\nous.\\n■ Put the statement containing the goto on a line by itself. This makes the goto \\nobvious.\\n■ Put the label the goto goes to on a line by itself. Surround it with blank lines. This \\nmakes the label obvious. Outdent the line containing the label to the left margin \\nto make the label as obvious as possible.\\nListing 31-34 shows these goto layout conventions at work.\\nCross-Reference For other \\nmethods of addressing this \\nproblem, see “Error Process-\\ning and gotos” in Section \\n17.3.\\nListing 31-34 C++ example of making the best of a bad situation (using goto).\\nvoid PurgeFiles( ErrorCode & errorCode ) { \\n   FileList fileList; \\n   int numFilesToPurge = 0; \\n   MakePurgeFileList( fileList, numFilesToPurge ); \\n \\n   errorCode = FileError_Success; \\n   int fileIndex = 0; \\n   while ( fileIndex < numFilesToPurge ) { \\n      DataFile fileToPurge; \\n      if ( !FindFile( fileList[ fileIndex ], fileToPurge ) ) { \\n         errorCode = FileError_NotFound;\\nHere’s a goto.          goto END_PROC; \\n      }\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 787}, page_content='31.4 Laying Out Control Structures 751\\n      if ( !OpenFile( fileToPurge ) ) { \\n         errorCode = FileError_NotOpen;\\nHere’s a goto.          goto END_PROC; \\n      } \\n \\n      if ( !OverwriteFile( fileToPurge ) ) { \\n         errorCode = FileError_CantOverwrite;\\nHere’s a goto.          goto END_PROC; \\n      } \\n \\n      if ( !Erase( fileToPurge ) ) { \\n         errorCode = FileError_CantErase;\\nHere’s a goto.          goto END_PROC; \\n      } \\n      fileIndex++; \\n   } \\nHere’s the goto label. The \\nintent of the capitalization \\nand layout is to make the \\nlabel hard to miss.\\nEND_PROC: \\n \\n   DeletePurgeFileList( fileList, numFilesToPurge ); \\n}\\nCross-Reference For details \\non using case statements, \\nsee Section 15.2, “case \\nStatements.” \\nThe C++ example in Listing 31-34 is relatively long so that you can see a case in which \\nan expert programmer might conscientiously decide that a goto is the best design \\nchoice. In such a case, the formatting shown is about the best you can do.\\nNo endline exception for case statements One of the hazards of endline layout \\ncomes up in the formatting of case statements. A popular style of formatting cases is to \\nindent them to the right of the description of each case, as shown in Listing 31-35. The \\nbig problem with this style is that it’s a maintenance headache.\\nListing 31-35 C++ example of hard-to-maintain endline layout of a case statement.\\nswitch ( ballColor ) { \\n   case BallColor_Blue:             Rollout(); \\n                                    break; \\n   case BallColor_Orange:           SpinOnFinger(); \\n                                    break; \\n   case BallColor_FluorescentGreen: Spike(); \\n                                    break; \\n   case BallColor_White:            KnockCoverOff(); \\n                                    break; \\n   case BallColor_WhiteAndBlue:     if ( mainColor == BallColor_White ) { \\n                                       KnockCoverOff(); \\n                                    } \\n                                    else if ( mainColor == BallColor_Blue ) { \\n                                       RollOut(); \\n                                    } \\n                                    break; \\n   default:                         FatalError( \"Unrecognized kind of ball.\" ); \\n                                    break; \\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 788}, page_content='752 Chapter 31: Layout and Style\\nIf you add a case with a longer name than any of the existing names, you have to shift \\nout all the cases and the code that goes with them. The large initial indentation makes \\nit awkward to accommodate any more logic, as shown in the WhiteAndBlue case. The \\nsolution is to switch to your standard indentation increment. If you indent statements \\nin a loop three spaces, indent cases in a case statement the same number of spaces, as \\nin Listing 31-36:\\nListing 31-36 C++ example of good standard indentation of a case statement.\\nswitch ( ballColor ) { \\n   case BallColor_Blue: \\n      Rollout(); \\n      break; \\n   case BallColor_Orange: \\n      SpinOnFinger(); \\n      break; \\n   case BallColor_FluorescentGreen: \\n      Spike(); \\n      break; \\n   case BallColor_White: \\n      KnockCoverOff(); \\n      break; \\n   case BallColor_WhiteAndBlue: \\n      if ( mainColor == BallColor_White ) { \\n         KnockCoverOff(); \\n      } \\n      else if ( mainColor == BallColor_Blue ) { \\n         RollOut(); \\n      } \\n      break; \\n   default: \\n      FatalError( \"Unrecognized kind of ball.\" ); \\n      break; \\n}\\nThis is an instance in which many people might prefer the looks of the first example. \\nFor the ability to accommodate longer lines, consistency, and maintainability, how-\\never, the second approach wins hands down.\\nIf you have a case statement in which all the cases are exactly parallel and all the \\nactions are short, you could consider putting the case and action on the same line. In \\nmost instances, however, you’ll live to regret it. The formatting is a pain initially and \\nbreaks under modification, and it’s hard to keep the structure of all the cases parallel \\nas some of the short actions become longer ones.\\nC31619670.fm  Page 752  Tuesday, April 12, 2011  3:30 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 789}, page_content=\"31.5 Laying Out Individual Statements 753\\n31.5 Laying Out Individual Statements\\nThis section explains many ways to improve individual statements in a program.\\nStatement Length\\nCross-Reference For details \\non documenting individual \\nstatements, see “Comment-\\ning Individual Lines” in Sec-\\ntion 32.5.\\nA common and somewhat outdated rule is to limit statement line length to 80 charac-\\nters. Here are the reasons:\\n■ Lines longer than 80 characters are hard to read.\\n■ The 80-character limitation discourages deep nesting.\\n■ Lines longer than 80 characters often won’t fit on 8.5” x 11” paper, especially \\nwhen code is printed “2 up” (2 pages of code to each physical printout page).\\nWith larger screens, narrow typefaces, and landscape mode, the 80-character limit \\nappears increasingly arbitrary. A single 90-character-long line is usually more readable \\nthan one that has been broken in two just to avoid spilling over the 80th column. \\nWith modern technology, it’s probably all right to exceed 80 columns occasionally.\\nUsing Spaces for Clarity\\nAdd white space within a statement for the sake of readability:\\nUse spaces to make logical expressions readable The expression\\nwhile(pathName[startPath+position]<>';') and \\n   ((startPath+position)<length(pathName)) do\\nis about as readable as Idareyoutoreadthis.\\nAs a rule, you should separate identifiers from other identifiers with spaces. If you use \\nthis rule, the while expression looks like this:\\nwhile ( pathName[ startPath+position ] <> ';' ) and \\n   (( startPath + position ) < length( pathName )) do\\nSome software artists might recommend enhancing this particular expression with \\nadditional spaces to emphasize its logical structure, this way:\\nwhile ( pathName[ startPath + position ] <> ';' ) and \\n   ( ( startPath + position ) < length( pathName ) ) do\\nThis is fine, although the first use of spaces was sufficient to ensure readability. Extra \\nspaces hardly ever hurt, however, so be generous with them.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 790}, page_content=\"754 Chapter 31: Layout and Style\\nUse spaces to make array references readable The expression\\ngrossRate[census[groupId].gender,census[groupId].ageGroup]\\nis no more readable than the earlier dense while expression. Use spaces around each \\nindex in the array to make the indexes readable. If you use this rule, the expression \\nlooks like this:\\ngrossRate[ census[ groupId ].gender, census[ groupId ].ageGroup ]\\nUse spaces to make routine arguments readable What is the fourth argument to the \\nfollowing routine?\\nReadEmployeeData(maxEmps,empData,inputFile,empCount,inputError);\\nNow, what is the fourth argument to the following routine?\\nGetCensus( inputFile, empCount, empData, maxEmps, inputError );\\nWhich one was easier to find? This is a realistic, worthwhile question because argu-\\nment positions are significant in all major procedural languages. It’s common to have \\na routine specification on one half of your screen and the call to the routine on the \\nother half, and to compare each formal parameter with each actual parameter.\\nFormatting Continuation Lines\\nOne of the most vexing problems of program layout is deciding what to do with the \\npart of a statement that spills over to the next line. Do you indent it by the normal \\nindentation amount? Do you align it under the keyword? What about assignments?\\nHere’s a sensible, consistent approach that’s particularly useful in Java, C, C++, Visual \\nBasic, and other languages that encourage long variable names:\\nMake the incompleteness of a statement obvi   . Sometimes a statement must be \\nbroken across lines, either because it’s longer than programming standards allow or \\nbecause it’s too absurdly long to put on one line. Make it obvious that the part of the \\nstatement on the first line is only part of a statement. The easiest way to do that is to \\nbreak up the statement so that the part on the first line is blatantly incorrect syntacti-\\ncally if it stands alone. Some examples are shown in Listing 31-37:\\nListing 31-37 Java examples of obviously incomplete statements.\\nThe && signals that the \\nstatement isn’t complete.\\nwhile ( pathName[ startPath + position ] != ';' ) && \\n   ( ( startPath + position ) <= pathName.length() ) \\n... \\nThe plus sign (+) signals that \\nthe statement isn’t complete.\\ntotalBill = totalBill + customerPurchases[ customerID ] + \\n   SalesTax( customerPurchases[ customerID ] ); \\n... \\nThe comma (,) signals that \\nthe statement isn’t complete.\\nDrawLine( window.north, window.south, window.east, window.west, \\n   currentWidth, currentAttribute ); \\n...\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 791}, page_content=\"31.5 Laying Out Individual Statements 755\\nIn addition to telling the reader that the statement isn’t complete on the first line, the \\nbreak helps prevent incorrect modifications. If the continuation of the statement were \\ndeleted, the first line wouldn’t look as if you had merely forgotten a parenthesis or \\nsemicolon—it would clearly need something more.\\nAn alternative approach that also works well is to put the continuation character at the \\nbeginning of the continuation line, as shown in Listing 31-38.\\nListing 31-38 Java examples of obviously incomplete statements—alternate style.\\nwhile ( pathName[ startPath + position ] != ';' ) \\n   && ( ( startPath + position ) <= pathName.length() ) \\n... \\n \\ntotalBill = totalBill + customerPurchases[ customerID ] \\n   + SalesTax( customerPurchases[ customerID ] );\\nWhile this style won’t induce a syntax error with a hanging && or +, it does make it \\neasier to scan for operators at the left edge of the column, where the text is aligned, \\nthan at the right edge, where it’s ragged. It has the additional advantage of illuminat-\\ning the structure of operations, as illustrated in Listing 31-39.\\nListing 31-39  Java example of a style that illuminates complex operations.\\ntotalBill = totalBill \\n   + customerPurchases[ customerID ] \\n   + CitySalesTax( customerPurchases[ customerID ] ) \\n   + StateSalesTax( customerPurchases[ customerID ] ) \\n   + FootballStadiumTax() \\n   - SalesTaxExemption( customerPurchases[ customerID ] );\\nKeep closely related elements together When you break a line, keep things together \\nthat belong together: array references, arguments to a routine, and so on. The example \\nshown in Listing 31-40 is poor form:\\nListing 31-40 Java example of breaking a line poorly.\\ncustomerBill = PreviousBalance( paymentHistory[ customerID ] ) + LateCharge( \\n   paymentHistory[ customerID ] );\\nAdmittedly, this line break follows the guideline of making the incompleteness of the \\nstatement obvious, but it does so in a way that makes the statement unnecessarily \\nhard to read. You might find a case in which the break is necessary, but in this case it \\nisn’t. It’s better to keep the array references all on one line. Listing 31-41 shows better \\nformatting:\\nCODING \\nHORROR\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 792}, page_content='756 Chapter 31: Layout and Style\\nListing 31-41  Java example of breaking a line well.\\ncustomerBill = PreviousBalance( paymentHistory[ customerID ] ) + \\n   LateCharge( paymentHistory[ customerID ] );\\nIndent routine-call continuation lines the standard amount If you normally indent \\nthree spaces for statements in a loop or a conditional, indent the continuation lines \\nfor a routine by three spaces. Some examples are shown in Listing 31-42:\\nListing 31-42  Java examples of indenting routine-call continuation lines using the stan-\\ndard indentation increment.\\nDrawLine( window.north, window.south, window.east, window.west, \\n   currentWidth, currentAttribute ); \\nSetFontAttributes( faceName[ fontId ], size[ fontId ], bold[ fontId ],  \\n   italic[ fontId ], syntheticAttribute[ fontId ].underline, \\n   syntheticAttribute[ fontId ].strikeout );\\nOne alternative to this approach is to line up the continuation lines under the first \\nargument to the routine, as shown in Listing 31-43:\\nListing 31-43  Java examples of indenting a routine-call continuation line to emphasize \\nroutine names.\\nDrawLine( window.north, window.south, window.east, window.west, \\n          currentWidth, currentAttribute ); \\nSetFontAttributes( faceName[ fontId ], size[ fontId ], bold[ fontId ],  \\n                   italic[ fontId ], syntheticAttribute[ fontId ].underline, \\n                   syntheticAttribute[ fontId ].strikeout );\\nFrom an aesthetic point of view, this looks a little ragged compared to the first approach. \\nIt is also difficult to maintain as routine names change, argument names change, and so \\non. Most programmers tend to gravitate toward the first style over time.\\nMake it easy to find the end of a continuation line One problem with the approach \\nshown above is that you can’t easily find the end of each line. Another alternative is to \\nput each argument on a line of its own and indicate the end of the group with a clos-\\ning parenthesis. Listing 31-44 shows how it looks.\\nListing 31-44 Java examples of formatting routine-call continuation lines one argument to \\na line.\\nDrawLine( \\n   window.north, \\n   window.south, \\n   window.east, \\n   window.west, \\n   currentWidth,'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 793}, page_content=\"31.5 Laying Out Individual Statements 757\\n   currentAttribute \\n); \\n \\nSetFontAttributes( \\n   faceName[ fontId ], \\n   size[ fontId ], \\n   bold[ fontId ], \\n   italic[ fontId ], \\n   syntheticAttribute[ fontId ].underline, \\n   syntheticAttribute[ fontId ].strikeout \\n);\\nObviously, this approach takes up a lot of real estate. If the arguments to a routine are \\nlong object-field references or pointer names, however, as the last two are, using one \\nargument per line improves readability substantially. The ); at the end of the block \\nmakes the end of the call clear. You also don’t have to reformat when you add a param-\\neter; you just add a new line.\\nIn practice, usually only a few routines need to be broken into multiple lines. You can \\nhandle others on one line. Any of the three options for formatting multiple-line rou-\\ntine calls works all right if you use it consistently.\\nIndent control-statement continuation lines the standard amount If you run out of \\nroom for a for loop, a while loop, or an if statement, indent the continuation line by the \\nsame amount of space that you indent statements in a loop or after an if statement. \\nTwo examples are shown in Listing 31-45:\\nListing 31-45 Java examples of indenting control-statement continuation lines.\\nwhile ( ( pathName[ startPath + position ] != ';' ) &&\\nThis continuation line is \\nindented the standard \\nnumber of spaces...\\n   ( ( startPath + position ) <= pathName.length() ) ) { \\n   ... \\n} \\n \\nfor ( int employeeNum = employee.first + employee.offset;\\n...as is this one.    employeeNum < employee.first + employee.offset + employee.total; \\n   employeeNum++ ) { \\n   ... \\n}\\nCross-Reference Some-\\ntimes the best solution to a \\ncomplicated test is to put it \\ninto a boolean function. For \\nexamples, see “Making \\nComplicated Expressions \\nSimple” in Section 19.1.\\nThis meets the criteria set earlier in the chapter. The continuation part of the state-\\nment is done logically—it’s always indented underneath the statement it continues. \\nThe indentation can be done consistently—it uses only a few more spaces than the \\noriginal line. It’s as readable as anything else, and it’s as maintainable as anything else. \\nIn some cases you might be able to improve readability by fine-tuning the indentation \\nor spacing, but be sure to keep the maintainability tradeoff in mind when you con-\\nsider fine-tuning.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 794}, page_content='758 Chapter 31: Layout and Style\\nDo not align right sides of assignment statements In the first edition of this book I \\nrecommended aligning the right sides of statements containing assignments as \\nshown in Listing 31-46: \\nListing 31-46 Java example of endline layout used for assignment-statement continua-\\ntion—bad practice.\\ncustomerPurchases = customerPurchases + CustomerSales( CustomerID ); \\ncustomerBill      = customerBill + customerPurchases; \\ntotalCustomerBill = customerBill + PreviousBalance( customerID ) +  \\n                    LateCharge( customerID ); \\ncustomerRating    = Rating( customerID, totalCustomerBill );\\nWith the benefit of 10 years’ hindsight, I have found that, while this indentation style \\nmight look attractive, it becomes a headache to maintain the alignment of the equals \\nsigns as variable names change and code is run through tools that substitute tabs for \\nspaces and spaces for tabs. It is also hard to maintain as lines are moved among differ-\\nent parts of the program that have different levels of indentation.\\nFor consistency with the other indentation guidelines as well as maintainability, treat \\ngroups of statements containing assignment operations just as you would treat other \\nstatements, as Listing 31-47 shows:\\nListing 31-47 Java example of standard indentation for assignment-statement continua-\\ntion—good practice.\\ncustomerPurchases = customerPurchases + CustomerSales( CustomerID ); \\ncustomerBill = customerBill + customerPurchases; \\ntotalCustomerBill = customerBill + PreviousBalance( customerID ) +  \\n   LateCharge( customerID ); \\ncustomerRating = Rating( customerID, totalCustomerBill );\\nIndent assignment-statement continuation lines the standard amount In Listing 31-47, \\nthe continuation line for the third assignment statement is indented the standard \\namount. This is done for the same reasons that assignment statements in general are \\nnot formatted in any special way: general readability and maintainability.\\nUsing Only One Statement Per Line\\nModern languages such as C++ and Java allow multiple statements per line. The \\npower of free formatting is a mixed blessing, however, when it comes to putting mul-\\ntiple statements on a line. This line contains several statements that could logically be \\nseparated onto lines of their own:\\ni = 0; j = 0; k = 0; DestroyBadLoopNames( i, j, k );\\nC31619670.fm  Page 758  Tuesday, April 12, 2011  3:36 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 795}, page_content='31.5 Laying Out Individual Statements 759\\nOne argument in favor of putting several statements on one line is that it requires \\nfewer lines of screen space or printer paper, which allows more of the code to be \\nviewed at once. It’s also a way to group related statements, and some programmers \\nbelieve that it provides optimization clues to the compiler.\\nThese are good reasons, but the reasons to limit yourself to one statement per line are \\nmore compelling:\\n■ Putting each statement on a line of its own provides an accurate view of a pro-\\ngram’s complexity. It doesn’t hide complexity by making complex statements \\nlook trivial. Statements that are complex look complex. Statements that are easy \\nlook easy.\\nCross-Reference Code-level \\nperformance optimizations \\nare discussed in Chapter 25, \\n“Code-Tuning Strategies,” \\nand Chapter 26, “Code-Tun-\\ning Techniques.”\\n■ Putting several statements on one line doesn’t provide optimization clues to \\nmodern compilers. Today’s optimizing compilers don’t depend on formatting \\nclues to do their optimizations. This is illustrated later in this section.\\n■ With statements on their own lines, the code reads from top to bottom, instead \\nof top to bottom and left to right. When you’re looking for a specific line of code, \\nyour eye should be able to follow the left margin of the code. It shouldn’t have to \\ndip into each and every line just because a single line might contain two state-\\nments.\\n■ With statements on their own lines, it’s easy to find syntax errors when your \\ncompiler provides only the line numbers of the errors. If you have multiple state-\\nments on a line, the line number doesn’t tell you which statement is in error.\\n■ With one statement to a line, it’s easy to step through the code with line-ori-\\nented debuggers. If you have several statements on a line, the debugger executes \\nthem all at once and you have to switch to assembler to step through individual \\nstatements.\\n■ With one to a line, it’s easy to edit individual statements—to delete a line or tem-\\nporarily convert a line to a comment. If you have multiple statements on a line, \\nyou have to do your editing between other statements.\\nIn C++, avoid using multiple operations per line (side effects) Side effects are conse-\\nquences of a statement other than its main consequence. In C++, the ++ operator on a \\nline that contains other operations is a side effect. Likewise, assigning a value to a vari-\\nable and using the left side of the assignment in a conditional is a side effect.\\nSide effects tend to make code difficult to read. For example, if n equals 4, what is the \\nprintout of the statement shown in Listing 31-48?\\nListing 31-48 C++ example of an unpredictable side effect.\\nPrintMessage( ++n, n + 2 );'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 796}, page_content=\"760 Chapter 31: Layout and Style\\nIs it 4 and 6? Is it 5 and 7? Is it 5 and 6? The answer is “None of the above.” The first \\nargument, ++n, is 5. But the C++ language does not define the order in which terms in \\nan expression or arguments to a routine are evaluated. So the compiler can evaluate \\nthe second argument, n + 2, either before or after the first argument; the result might \\nbe either 6 or 7, depending on the compiler. Listing 31-49 shows how you should \\nrewrite the statement so that the intent is clear:\\nListing 31-49  C++ example of avoiding an unpredictable side effect.\\n++n; \\nPrintMessage( n, n + 2 );\\nIf you’re still not convinced that you should put side effects on lines by themselves, try \\nto figure out what the routine shown in Listing 31-50 does:\\nListing 31-50 C example of too many operations on a line.\\nstrcpy( char * t, char * s ) { \\n   while ( *++t = *++s ) \\n      ; \\n}\\nSome experienced C programmers don’t see the complexity in that example because it’s \\na familiar function. They look at it and say, “That’s strcpy().” In this case, however, it’s not \\nquite strcpy(). It contains an error. If you said, “That’s strcpy()” when you saw the code, \\nyou were recognizing the code, not reading it. This is exactly the situation you’re in \\nwhen you debug a program: the code that you overlook because you “recognize” it \\nrather than read it can contain the error that’s harder to find than it needs to be.\\nThe fragment shown in Listing 31-51 is functionally identical to the first and is more \\nreadable:\\nListing 31-51 C example of a readable number of operations on each line.\\nstrcpy( char * t, char * s ) { \\n   do { \\n      ++t; \\n      ++s; \\n      *t = *s; \\n    } \\n   while ( *t != '\\\\0' ); \\n}\\nIn the reformatted code, the error is apparent. Clearly, t and s are incremented before \\n*s is copied to *t. The first character is missed.\\nThe second example looks more elaborate than the first, even though the operations \\nperformed in the second example are identical. The reason it looks more elaborate is \\nthat it doesn’t hide the complexity of the operations.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 797}, page_content='31.5 Laying Out Individual Statements 761\\nCross-Reference For details \\non code tuning, see Chapter \\n25, “Code-Tuning Strate-\\ngies,” and Chapter 26, \\n“Code-Tuning Techniques.”\\nImproved performance doesn’t justify putting multiple operations on the same line \\neither. Because the two strcpy() routines are logically equivalent, you would expect the \\ncompiler to generate identical code for them. When both versions of the routine were \\nprofiled, however, the first version took 4.81 seconds to copy 5,000,000 strings and \\nthe second took 4.35 seconds.\\nIn this case, the “clever” version carries an 11 percent speed penalty, which makes it \\nlook a lot less clever. The results vary from compiler to compiler, but in general they \\nsuggest that until you’ve measured performance gains, you’re better off striving for \\nclarity and correctness first, performance second.\\nEven if you read statements with side effects easily, take pity on other people who will \\nread your code. Most good programmers need to think twice to understand expres-\\nsions with side effects. Let them use their brain cells to understand the larger ques-\\ntions of how your code works rather than the syntactic details of a specific expression.\\nLaying Out Data Declarations\\nCross-Reference For details \\non documenting data decla-\\nrations, see “Commenting \\nData Declarations” in Section \\n32.5. For aspects of data use, \\nsee Chapters 10 through 13.\\nUse only one data declaration per line As shown in the previous examples, you \\nshould give each data declaration its own line. It’s easier to put a comment next to \\neach declaration if each one is on its own line. It’s easier to modify declarations \\nbecause each declaration is self-contained. It’s easier to find specific variables because \\nyou can scan a single column rather than reading each line. It’s easier to find and fix \\nsyntax errors because the line number the compiler gives you has only one declara-\\ntion on it.\\nQuickly—in the data declaration in Listing 31-52, what type of variable is currentBot-\\ntom?\\nListing 31-52 C++ example of crowding more than one variable declaration onto a line.\\nint rowIndex, columnIdx; Color previousColor, currentColor, nextColor; Point \\npreviousTop, previousBottom, currentTop, currentBottom, nextTop, nextBottom; Font \\npreviousTypeface, currentTypeface, nextTypeface; Color choices[ NUM_COLORS ];\\nThis is an extreme example, but it’s not too far removed from a much more common \\nstyle shown in Listing 31-53: \\nListing 31-53 C++ example of crowding more than one variable declaration onto a line.\\nint rowIndex, columnIdx;  \\nColor previousColor, currentColor, nextColor; \\nPoint previousTop, previousBottom, currentTop, currentBottom, nextTop, \\nnextBottom;  \\nFont previousTypeface, currentTypeface, nextTypeface; \\nColor choices[ NUM_COLORS ];\\nCODING \\nHORROR\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 798}, page_content='762 Chapter 31: Layout and Style\\nThis is not an uncommon style of declaring variables, and the variable is still hard to \\nfind because all the declarations are jammed together. The variable’s type is hard to \\nfind, too. Now, what is nextColor’s type in Listing 31-54?\\nListing 31-54 C++ example of readability achieved by putting only one variable declara-\\ntion on each line.\\nint rowIndex;  \\nint columnIdx;  \\nColor previousColor;  \\nColor currentColor;  \\nColor nextColor; \\nPoint previousTop;  \\nPoint previousBottom;  \\nPoint currentTop;  \\nPoint currentBottom;  \\nPoint nextTop;  \\nPoint nextBottom;  \\nFont previousTypeface;  \\nFont currentTypeface;  \\nFont nextTypeface; \\nColor choices[ NUM_COLORS ];\\nThe variable nextColor was probably easier to find than nextTypeface was in Listing 31-\\n53. This style is characterized by one declaration per line and a complete declaration, \\nincluding the variable type, on each line.\\nAdmittedly, this style chews up a lot of screen space—20 lines instead of the three in \\nthe first example, although those three lines were pretty ugly. I can’t point to any stud-\\nies that show that this style leads to fewer bugs or greater comprehension. If Sally Pro-\\ngrammer, Jr., asked me to review her code, however, and her data declarations looked \\nlike the first example, I’d say “No way—too hard to read.” If they looked like the sec-\\nond example, I’d say “Uh...maybe I’ll get back to you.” If they looked like the final \\nexample, I would say “Certainly—it’s a pleasure.”\\nDeclare variables close to where they’re first used A style that’s preferable to declar-\\ning all variables in a big block is to declare each variable close to where it’s first used. \\nThis reduces “span” and “live time” and facilitates refactoring code into smaller rou-\\ntines when necessary. For more details, see “Keep Variables ‘Live’ for as Short a Time \\nas Possible” in Section 10.4.\\nOrder declarations sensibly In Listing 31-54, the declarations are grouped by types. \\nGrouping by types is usually sensible since variables of the same type tend to be used \\nin related operations. In other cases, you might choose to order them alphabetically \\nby variable name. Although alphabetical ordering has many advocates, my feeling is \\nthat it’s too much work for what it’s worth. If your list of variables is so long that alpha-'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 799}, page_content='31.6 Laying Out Comments 763\\nbetical ordering helps, your routine is probably too big. Break it up so that you have \\nsmaller routines with fewer variables.\\nIn C++, put the asterisk next to the variable name in pointer declarations or declare \\npointer types It’s common to see pointer declarations that put the asterisk next to \\nthe type, as in Listing 31-55:\\nListing 31-55 C++ example of asterisks in pointer declarations.\\nEmployeeList* employees; \\nFile* inputFile;\\nThe problem with putting the asterisk next to the type name rather than the variable \\nname is that, when you put more than one declaration on a line, the asterisk will apply \\nonly to the first variable even though the visual formatting suggests it applies to all \\nvariables on the line. You can avoid this problem by putting the asterisk next to the \\nvariable name rather than the type name, as in Listing 31-56:\\nListing 31-56 C++ example of using asterisks in pointer declarations.\\nEmployeeList *employees; \\nFile *inputFile;\\nThis approach has the weakness of suggesting that the asterisk is part of the variable \\nname, which it isn’t. The variable can be used either with or without the asterisk.\\nThe best approach is to declare a type for the pointer and use that instead. An example \\nis shown in Listing 31-57:\\nListing 31-57 C++ example of good uses of a pointer type in declarations.\\nEmployeeListPointer employees; \\nFilePointer inputFile;\\nThe particular problem addressed by this approach can be solved either by requiring \\nall pointers to be declared using pointer types, as shown in Listing 31-57, or by requir-\\ning no more than one variable declaration per line. Be sure to choose at least one of \\nthese solutions!\\n31.6 Laying Out Comments\\nCross-Reference For details \\non other aspects of com-\\nments, see Chapter 32, “Self-\\nDocumenting Code.”\\nComments done well can greatly enhance a program’s readability; comments done \\npoorly can actually hurt it. The layout of comments plays a large role in whether they \\nhelp or hinder readability.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 800}, page_content=\"764 Chapter 31: Layout and Style\\nIndent a comment with its corresponding code Visual indentation is a valuable aid to \\nunderstanding a program’s logical structure, and good comments don’t interfere with \\nthe visual indentation. For example, what is the logical structure of the routine shown \\nin Listing 31-58?\\nListing 31-58 Visual Basic example of poorly indented comments.\\nFor transactionId = 1 To totalTransactions \\n' get transaction data \\n   GetTransactionType( transactionType ) \\n   GetTransactionAmount( transactionAmount ) \\n \\n' process transaction based on transaction type \\n   If transactionType = Transaction_Sale Then \\n      AcceptCustomerSale( transactionAmount ) \\n \\n   Else  \\n      If transactionType = Transaction_CustomerReturn Then \\n \\n' either process return automatically or get manager approval, if required \\n         If transactionAmount >= MANAGER_APPROVAL_LEVEL Then \\n \\n' try to get manager approval and then accept or reject the return \\n' based on whether approval is granted \\n            GetMgrApproval( isTransactionApproved ) \\n            If ( isTransactionApproved ) Then \\n               AcceptCustomerReturn( transactionAmount ) \\n            Else \\n               RejectCustomerReturn( transactionAmount ) \\n            End If \\n         Else \\n \\n' manager approval not required, so accept return \\n            AcceptCustomerReturn( transactionAmount ) \\n         End If \\n      End If \\n   End If \\nNext \\nIn this example, you don’t get much of a clue to the logical structure because the com-\\nments completely obscure the visual indentation of the code. You might find it hard to \\nbelieve that anyone ever makes a conscious decision to use such an indentation style, \\nbut I’ve seen it in professional programs and know of at least one textbook that rec-\\nommends it.\\nThe code shown in Listing 31-59 is exactly the same as that in Listing 31-58, except for \\nthe indentation of the comments.\\nCODING \\nHORROR\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 801}, page_content=\"31.6 Laying Out Comments 765\\nListing 31-59 Visual Basic example of nicely indented comments.\\nFor transactionId = 1 To totalTransactions \\n   ' get transaction data \\n   GetTransactionType( transactionType ) \\n   GetTransactionAmount( transactionAmount ) \\n \\n   ' process transaction based on transaction type \\n   If transactionType = Transaction_Sale Then \\n      AcceptCustomerSale( transactionAmount ) \\n \\n   Else  \\n      If transactionType = Transaction_CustomerReturn Then \\n \\n         ' either process return automatically or get manager approval, if required \\n         If transactionAmount >= MANAGER_APPROVAL_LEVEL Then \\n \\n            ' try to get manager approval and then accept or reject the return \\n            ' based on whether approval is granted \\n            GetMgrApproval( isTransactionApproved ) \\n            If ( isTransactionApproved ) Then \\n               AcceptCustomerReturn( transactionAmount ) \\n            Else \\n               RejectCustomerReturn( transactionAmount ) \\n            End If \\n         Else \\n            ' manager approval not required, so accept return \\n            AcceptCustomerReturn( transactionAmount ) \\n         End If \\n      End If \\n   End If \\nNext \\nIn Listing 31-59, the logical structure is more apparent. One study of the effectiveness \\nof commenting found that the benefit of having comments was not conclusive, and \\nthe author speculated that it was because they “disrupt visual scanning of the pro-\\ngram” (Shneiderman 1980). From these examples, it’s obvious that the style of com-\\nmenting strongly influences whether comments are disruptive.\\nSet off each comment with at least one blank line If someone is trying to get an over-\\nview of your program, the most effective way to do it is to read the comments without \\nreading the code. Setting comments off with blank lines helps a reader scan the code. \\nAn example is shown in Listing 31-60:\\nListing 31-60 Java example of setting off a comment with a blank line.\\n// comment zero \\nCodeStatementZero; \\nCodeStatementOne; \\n \\n// comment one \\nCodeStatementTwo; \\nCodeStatementThree;\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 802}, page_content='766 Chapter 31: Layout and Style\\nSome people use a blank line both before and after the comment. Two blanks use \\nmore display space, but some people think the code looks better than with just one. \\nAn example is shown in Listing 31-61:\\nListing 31-61 Java example of setting off a comment with two blank lines.\\n \\n// comment zero  \\n \\nCodeStatementZero; \\nCodeStatementOne; \\n \\n// comment one \\n \\nCodeStatementTwo; \\nCodeStatementThree;\\nUnless your display space is at a premium, this is a purely aesthetic judgment and you \\ncan make it accordingly. In this, as in many other areas, the fact that a convention \\nexists is more important than the convention’s specific details.\\n31.7 Laying Out Routines\\nCross-Reference For details \\non documenting routines, \\nsee “Commenting Routines” \\nin Section 32.5. For details \\non the process of writing a \\nroutine, see Section 9.3, \\n“Constructing Routines by \\nUsing the PPP .” For a discus-\\nsion of the differences \\nbetween good and bad rou-\\ntines, see Chapter 7, “High-\\nQuality Routines.”\\nRoutines are composed of individual statements, data, control structures, comments—\\nall the things discussed in the other parts of the chapter. This section provides layout \\nguidelines unique to routines.\\nUse blank lines to separate parts of a routine Use blank lines between the routine \\nheader, its data and named-constant declarations (if any), and its body.\\nUse standard indentation for routine argumentsThe options with routine-header \\nlayout are about the same as they are in a lot of other areas of layout: no conscious lay-\\nout, endline layout, or standard indentation. As in most other cases, standard inden-\\ntation does better in terms of accuracy, consistency, readability, and modifiability. \\nListing 31-62 shows two examples of routine headers with no conscious layout:\\nListing 31-62  C++ examples of routine headers with no conscious layout.\\nbool ReadEmployeeData(int maxEmployees,EmployeeList *employees, \\n   EmployeeFile *inputFile,int *employeeCount,bool  *isInputError) \\n... \\n \\nvoid InsertionSort(SortArray data,int firstElement,int lastElement)\\nThese routine headers are purely utilitarian. The computer can read them as well as it \\ncan read headers in any other format, but they cause trouble for humans. Without a \\nconscious effort to make the headers hard to read, how could they be any worse?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 803}, page_content='31.7 Laying Out Routines 767\\nThe second approach in routine-header layout is the endline layout, which usually \\nworks all right. Listing 31-63 shows the same routine headers reformatted:\\nListing 31-63  C++ example of routine headers with mediocre endline layout.\\nbool ReadEmployeeData( int               maxEmployees, \\n                       EmployeeList      *employees, \\n                       EmployeeFile      *inputFile, \\n                       int               *employeeCount, \\n                       bool              *isInputError ) \\n... \\nvoid InsertionSort( SortArray   data, \\n                    int         firstElement, \\n                    int         lastElement )\\nCross-Reference For more \\ndetails on using routine \\nparameters, see Section 7.5, \\n“How to Use Routine \\nParameters.”\\nThe endline approach is neat and aesthetically appealing. The main problem is that it \\ntakes a lot of work to maintain, and styles that are hard to maintain aren’t maintained. \\nSuppose that the function name changes from ReadEmployeeData() to ReadNewEmploy-\\neeData(). That would throw the alignment of the first line off from that of the other four \\nlines. You’d have to reformat the other four lines of the parameter list to align with the \\nnew position of maxEmployees caused by the longer function name. And you’d probably \\nrun out of space on the right side since the elements are so far to the right already.\\nThe examples shown in Listing 31-64, formatted using standard indentation, are just \\nas appealing aesthetically but take less work to maintain.\\nListing 31-64 C++ example of routine headers with readable, maintainable standard \\nindentation.\\npublic bool ReadEmployeeData( \\n   int maxEmployees, \\n   EmployeeList *employees, \\n   EmployeeFile *inputFile, \\n   int *employeeCount, \\n   bool *isInputError \\n) \\n... \\n \\npublic void InsertionSort( \\n   SortArray data, \\n   int firstElement, \\n   int lastElement \\n)\\nThis style holds up better under modification. If the routine name changes, the \\nchange has no effect on any of the parameters. If parameters are added or deleted, \\nonly one line has to be modified—plus or minus a comma. The visual cues are similar \\nto those in the indentation scheme for a loop or an if statement. Your eye doesn’t have \\nto scan different parts of the page for every individual routine to find meaningful infor-\\nmation; it knows where the information is every time.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 804}, page_content='768 Chapter 31: Layout and Style\\nThis style translates to Visual Basic in a straightforward way, though it requires the use \\nof line-continuation characters, as shown in Listing 31-65:\\nListing 31-65 Visual Basic example of routine headers with readable, maintainable stan-\\ndard indentation.\\nHere’s the “_” character \\nused as a line-continuation \\ncharacter.\\nPublic Sub ReadEmployeeData ( _ \\n   ByVal maxEmployees As Integer, _ \\n   ByRef employees As EmployeeList, _ \\n   ByRef inputFile As EmployeeFile, _ \\n   ByRef employeeCount As Integer, _ \\n   ByRef isInputError As Boolean _ \\n)\\n31.8 Laying Out Classes\\nThis section presents  guidelines for laying out code in classes. The first subsection \\ndescribes how to lay out the class interface. The second subsection describes how to \\nlay out the class implementations. The final subsection discusses laying out files and \\nprograms.\\nLaying Out Class Interfaces\\nCross-Reference For details \\non documenting classes, see \\n“Commenting Classes, Files, \\nand Programs” in Section \\n32.5. For a discussion of the \\ndifferences between good \\nand bad classes, see Chapter \\n6, “Working Classes.”\\nIn laying out class interfaces, the convention is to present the class members in the fol-\\nlowing order:\\n1. Header comment that describes the class and provides any notes about the over-\\nall usage of the class\\n2. Constructors and destructors\\n3. Public routines\\n4. Protected routines\\n5. Private routines and member data\\nLaying Out Class Implementations\\nClass implementations are generally laid out in this order:\\n1. Header comment that describes the contents of the file the class is in\\n2. Class data\\n3. Public routines\\n4. Protected routines\\n5. Private routines'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 805}, page_content='31.8 Laying Out Classes 769\\nIf you have more than one class in a file, identify each class clearly Routines that are \\nrelated should be grouped together into classes. A reader scanning your code should be \\nable to tell easily which class is which. Identify each class clearly by using several blank \\nlines between it and the classes next to it. A class is like a chapter in a book. In a book, you \\nstart each chapter on a new page and use big print for the chapter title. Emphasize the \\nstart of each class similarly. An example of separating classes is shown in Listing 31-66:\\nListing 31-66 C++ example of formatting the separation between classes.\\nThis is the last routine in a \\nclass.\\n// create a string identical to sourceString except that the \\n// blanks are replaced with underscores. \\nvoid EditString::ConvertBlanks(  \\n   char *sourceString,  \\n   char *targetString  \\n   ) { \\n   Assert( strlen( sourceString ) <= MAX_STRING_LENGTH ); \\n   Assert( sourceString != NULL ); \\n   Assert( targetString != NULL ); \\n   int charIndex = 0; \\n   do { \\n      if ( sourceString[ charIndex ] == \" \" ) { \\n         targetString[ charIndex ] = \\'_\\'; \\n      } \\n      else { \\n         targetString[ charIndex ] = sourceString[ charIndex ]; \\n      } \\n      charIndex++; \\n   } while sourceString[ charIndex ] != \\'\\\\0\\'; \\n} \\nThe beginning of the new \\nclass is marked with several \\nblank lines and the name of \\nthe class.\\n//---------------------------------------------------------------------- \\n// MATHEMATICAL FUNCTIONS \\n// \\n// This class contains the program\\'s mathematical functions. \\n//---------------------------------------------------------------------- \\nThis is the first routine in a \\nnew class.\\n// find the arithmetic maximum of arg1 and arg2 \\nint Math::Max( int arg1, int arg2 ) {  \\n   if ( arg1 > arg2 ) {  \\n      return arg1;  \\n   }  \\n   else { \\n      return arg2;  \\n   } \\n} \\n \\nThis routine is separated \\nfrom the previous routine \\nby blank lines only.\\n// find the arithmetic minimum of arg1 and arg2 \\nint Math::Min( int arg1, int arg2 ) { \\n   if ( arg1 < arg2 ) {  \\n      return arg1; \\n   }  \\n   else { \\n      return arg2; \\n   } \\n}'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 806}, page_content='770 Chapter 31: Layout and Style\\nAvoid overemphasizing comments within classes. If you mark every routine and com-\\nment with a row of asterisks instead of blank lines, you’ll have a hard time coming up \\nwith a device that effectively emphasizes the start of a new class. An example is shown \\nin Listing 31-67:\\nListing 31-67 C++ example of overformatting a class.\\n//********************************************************************** \\n//********************************************************************** \\n// MATHEMATICAL FUNCTIONS \\n// \\n// This class contains the program’s mathematical functions. \\n//********************************************************************** \\n//********************************************************************** \\n \\n//********************************************************************** \\n// find the arithmetic maximum of arg1 and arg2 \\n//********************************************************************** \\nint Math::Max( int arg1, int arg2 ) {  \\n//********************************************************************** \\n   if ( arg1 > arg2 ) {  \\n      return arg1; \\n   }  \\n   else { \\n      return arg2; \\n   } \\n} \\n \\n//********************************************************************** \\n// find the arithmetic minimum of arg1 and arg2 \\n//********************************************************************** \\nint Math::Min( int arg1, int arg2 ) { \\n//********************************************************************** \\n   if ( arg1 < arg2 ) {  \\n      return arg1; \\n   }  \\n   else { \\n      return arg2; \\n   } \\n}\\nIn this example, so many things are highlighted with asterisks that nothing is really \\nemphasized. The program becomes a dense forest of asterisks. Although it’s more an \\naesthetic than a technical judgment, in formatting, less is more.\\nIf you must separate parts of a program with long lines of special characters, develop \\na hierarchy of characters (from densest to lightest) instead of relying exclusively on \\nasterisks. For example, use asterisks for class divisions, dashes for routine divisions, \\nand blank lines for important comments. Refrain from putting two rows of asterisks \\nor dashes together. An example is shown in Listing 31-68:\\nC31619670.fm  Page 770  Tuesday, April 12, 2011  3:37 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 807}, page_content=\"31.8 Laying Out Classes 771\\nListing 31-68 C++ example of good formatting with restraint.\\n//********************************************************************** \\n// MATHEMATICAL FUNCTIONS \\n// \\n// This class contains the program's mathematical functions. \\n//********************************************************************** \\nThe lightness of this line \\ncompared to the line of \\nasterisks visually reinforces \\nthe fact that the routine is \\nsubordinate to the class.\\n//---------------------------------------------------------------------- \\n// find the arithmetic maximum of arg1 and arg2 \\n//---------------------------------------------------------------------- \\nint Math::Max( int arg1, int arg2 ) { \\n   if ( arg1 > arg2 ) {  \\n      return arg1; \\n   }  \\n   else { \\n      return arg2; \\n   } \\n} \\n \\n//---------------------------------------------------------------------- \\n// find the arithmetic minimum of arg1 and arg2 \\n//---------------------------------------------------------------------- \\nint Math::Min( int arg1, int arg2 ) { \\n   if ( arg1 < arg2 ) {  \\n      return arg1; \\n   }  \\n   else { \\n      return arg2; \\n   } \\n}\\nThis advice about how to identify multiple classes within a single file applies only \\nwhen your language restricts the number of files you can use in a program. If you’re \\nusing C++, Java, Visual Basic, or other languages that support multiple source files, \\nput only one class in each file unless you have a compelling reason to do otherwise \\n(such as including a few small classes that make up a single pattern). Within a single \\nclass, however, you might still have subgroups of routines, and you can group them \\nusing techniques such as the ones shown here.\\nLaying Out Files and Programs\\nCross-Reference For docu-\\nmentation details, see “Com-\\nmenting Classes, Files, and \\nPrograms” in Section 32.5.\\nBeyond the formatting techniques for classes is a larger formatting issue: how do you \\norganize classes and routines within a file, and how do you decide which classes to \\nput in a file in the first place?\\nPut one class in one file A file isn’t just a bucket that holds some code. If your language \\nallows it, a file should hold a collection of routines that supports one and only one pur-\\npose. A file reinforces the idea that a collection of routines are in the same class.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 808}, page_content=\"772 Chapter 31: Layout and Style\\nCross-Reference For details \\non the differences between \\nclasses and routines and \\nhow to make a collection of \\nroutines into a class, see \\nChapter 6, “Working \\nClasses.”\\nAll the routines within a file make up the class. The class might be one that the pro-\\ngram really recognizes as such, or it might be just a logical entity that you’ve created as \\npart of your design.\\nClasses are a semantic language concept. Files are a physical operating-system con-\\ncept. The correspondence between classes and files is coincidental and continues to \\nweaken over time as more environments support putting code into databases or oth-\\nerwise obscuring the relationship between routines, classes, and files.\\nGive the file a name related to the class name Most projects have a one-to-one cor-\\nrespondence between class names and file names. A class named CustomerAccount \\nwould have files named CustomerAccount.cpp and CustomerAccount.h, for example.\\nSeparate routines within a file clearly Separate each routine from other routines \\nwith at least two blank lines. The blank lines are as effective as big rows of asterisks or \\ndashes, and they’re a lot easier to type and maintain. Use two or three to produce a \\nvisual difference between blank lines that are part of a routine and blank lines that \\nseparate routines. An example is shown in Listing 31-69:\\nListing 31-69 Visual Basic example of using blank lines between routines.\\n'find the arithmetic maximum of arg1 and arg2 \\nFunction Max( arg1 As Integer, arg2 As Integer ) As Integer \\n   If ( arg1 > arg2 ) Then \\n      Max = arg1 \\n   Else \\n      Max = arg2 \\n   End If \\nEnd Function\\nAt least two blank lines \\nseparate the two routines.\\n \\n \\n \\n'find the arithmetic minimum of arg1 and arg2 \\nFunction Min( arg1 As Integer, arg2 As Integer ) As Integer \\n   If ( arg1 < arg2 ) Then \\n      Min = arg1 \\n   Else \\n      Min = arg2 \\n   End If \\nend Function\\nBlank lines are easier to type than any other kind of separator and look at least as \\ngood. Three blank lines are used in this example so that the separation between rou-\\ntines is more noticeable than the blank lines within each routine.\\nSequence routines alphabetically An alternative to grouping related routines in a file \\nis to put them in alphabetical order. If you can’t break a program up into classes or if \\nyour editor doesn’t allow you to find functions easily, the alphabetical approach can \\nsave search time.\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 809}, page_content='31.8 Laying Out Classes 773\\nIn C++, order the source file carefully Here’s a typical order of source-file contents \\nin C++:\\n1. File-description comment\\n2. #include files\\n3. Constant definitions that apply to more than one class (if more than one class in \\nthe file)\\n4. Enums that apply to more than one class (if more than one class in the file)\\n5. Macro function definitions\\n6. Type definitions that apply to more than one class (if more than one class in the \\nfile)\\n7. Global variables and functions imported\\n8. Global variables and functions exported\\n9. Variables and functions that are private to the file\\n10. Classes, including constant definitions, enums, and type definitions within each \\nclass\\ncc2e.com/3194 CHECKLIST: Layout\\nGeneral\\n❑ Is formatting done primarily to illuminate the logical structure of the \\ncode?\\n❑ Can the formatting scheme be used consistently?\\n❑ Does the formatting scheme result in code that’s easy to maintain?\\n❑ Does the formatting scheme improve code readability?\\nControl Structures\\n❑ Does the code avoid doubly indented begin-end or {} pairs?\\n❑ Are sequential blocks separated from each other with blank lines?\\n❑ Are complicated expressions formatted for readability?\\n❑ Are single-statement blocks formatted consistently?\\n❑ Are case statements formatted in a way that’s consistent with the format-\\nting of other control structures?\\n❑ Have gotos been formatted in a way that makes their use obvious?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 810}, page_content='774 Chapter 31: Layout and Style\\nIndividual Statements\\n❑ Is white space used to make logical expressions, array references, and rou-\\ntine arguments readable?\\n❑ Do incomplete statements end the line in a way that’s obviously incorrect?\\n❑ Are continuation lines indented the standard indentation amount?\\n❑ Does each line contain at most one statement?\\n❑ Is each statement written without side effects?\\n❑ Is there at most one data declaration per line?\\nComments\\n❑ Are the comments indented the same number of spaces as the code they \\ncomment?\\n❑ Is the commenting style easy to maintain?\\nRoutines\\n❑ Are the arguments to each routine formatted so that each argument is easy \\nto read, modify, and comment?\\n❑ Are blank lines used to separate parts of a routine?\\nClasses, Files and Programs\\n❑ Is there a one-to-one relationship between classes and files for most classes \\nand files?\\n❑ If a file does contain multiple classes, are all the routines in each class \\ngrouped together and is each class clearly identified?\\n❑ Are routines within a file clearly separated with blank lines?\\n❑ In lieu of a stronger organizing principle, are all routines in alphabetical \\nsequence?\\nAdditional Resources\\ncc2e.com/3101 Most programming textbooks say a few words about layout and style, but thorough \\ndiscussions of programming style are rare; discussions of layout are rarer still. The fol-\\nlowing books talk about layout and programming style:\\nKernighan, Brian W. and Rob Pike. The Practice of Programming Reading, MA: Addison-\\nWesley, 1999. Chapter 1 of this book disc usses programming style focusing on C \\nand C++.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 811}, page_content='Key Points 775\\nVermeulen, Allan, et al. The Elements of Java Style. Cambridge University Press, 2000.\\nMisfeldt, Trevor, Greg Bumgardner, and Andrew Gray. The Elements of C++ Style. Cam-\\nbridge University Press, 2004.\\nKernighan, Brian W., and P. J. Plauger. The Elements of Programming Style, 2d ed. New \\nYork, NY: McGraw-Hill, 1978. This is the classic book on programming style—the first \\nin the genre of programming-style books.\\nFor a substantially different approach to readability, take a look at the following book:\\nKnuth, Donald E. Literate Programming. Cambridge University Press, 2001. This is a \\ncollection of papers describing the “literate programming” approach of combining a \\nprogramming language and a documentation language. Knuth has been writing about \\nthe virtues of literate programming for about 20 years, and in spite of his strong claim \\nto the title Best Programmer on the Planet, literate programming isn’t catching on. \\nRead some of his code to form your own conclusions about the reason.\\nKey Points\\n■ The first priority of visual layout is to illuminate the logical organization of the \\ncode. Criteria used to assess whether that priority is achieved include accuracy, \\nconsistency, readability, and maintainability.\\n■ Looking good is secondary to the other criteria—a distant second. If the other \\ncriteria are met and the underlying code is good, however, the layout will look \\nfine.\\n■ Visual Basic has pure blocks and the conventional practice in Java is to use pure-\\nblock style, so you can use a pure-block layout if you program in those lan-\\nguages. In C++, either pure-block emulation or begin-end block boundaries work \\nwell.\\n■ Structuring code is important for its own sake. The specific convention you fol-\\nlow is less important than the fact that you follow some convention consistently. \\nA layout convention that’s followed inconsistently can actually hurt readability.\\n■ Many aspects of layout are religious issues. Try to separate objective preferences \\nfrom subjective ones. Use explicit criteria to help ground your discussions about \\nstyle preferences.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 813}, page_content='777\\nChapter 32\\nSelf-Documenting Code\\ncc2e.com/3245 Contents\\n■ 32.1 External Documentation: page 777\\n■ 32.2 Programming Style as Documentation: page 778\\n■ 32.3 To Comment or Not to Comment: page 781\\n■ 32.4 Keys to Effective Comments: page 785\\n■ 32.5 Commenting Techniques: page 792\\n■ 32.6 IEEE Standards: page 813\\nRelated Topics\\n■ Layout: Chapter 31\\n■ The Pseudocode Programming Process: Chapter 9\\n■ Working classes: Chapter 6\\n■ High-quality routines: Chapter 7\\n■ Programming as communication: Sections 33.5 and 34.3 \\nCode as if whoever main-\\ntains your program is a vio-\\nlent psychopath who knows \\nwhere you live. \\n—Anonymous\\nMost programmers enjoy writing documentation if the documentation standards \\naren’t unreasonable. Like layout, good documentation is a sign of the professional \\npride a programmer puts into a program. Software documentation can take many \\nforms, and, after describing the sweep of the documentation landscape, this chapter \\ncultivates the specific patch of documentation known as “comments.”\\n32.1 External Documentation\\nCross-Reference For more \\non external documentation, \\nsee Section 32.6, “IEEE \\nStandards.”\\nDocumentation on a software project consists of information both inside the source-\\ncode listings and outside them—usually in the form of separate documents or unit \\ndevelopment folders. On large, formal projects, most of the documentation is outside \\nthe source code (Jones 1998). External construction documentation tends to be at a \\nhigh level compared to the code, at a low level compared to the documentation from \\nthe problem definition, requirements, and architecture activities.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 814}, page_content='778 Chapter 32: Self-Documenting Code\\nFurther Reading For a \\ndetailed description, see \\n“The Unit Development \\nFolder (UDF): An Effective \\nManagement Tool for Soft-\\nware Development” (Ingras-\\nsia 1976) or “The Unit \\nDevelopment Folder (UDF): \\nA Ten-Year Perspective” \\n(Ingrassia 1987).\\nUnit development folders A unit-development folder (UDF), or software-develop-\\nment folder (SDF), is an informal document that contains notes used by a developer \\nduring construction. A “unit” is loosely defined, usually to mean a class, although it \\ncould also mean a package or a component. The main purpose of a UDF is to provide \\na trail of design decisions that aren’t documented elsewhere. Many projects have stan-\\ndards that specify the minimum content of a UDF, such as copies of the relevant \\nrequirements, the parts of the top-level design the unit implements, a copy of the \\ndevelopment standards, a current code listing, and design notes from the unit’s devel-\\noper. Sometimes the customer requires a software developer to deliver the project’s \\nUDFs; often they are for internal use only.\\nDetailed-design document The detailed-design document is the low-level design \\ndocument. It describes the class-level or routine-level design decisions, the alterna-\\ntives that were considered, and the reasons for selecting the approaches that were \\nselected. Sometimes this information is contained in a formal document. In such \\ncases, detailed design is usually considered to be separate from construction. Some-\\ntimes it consists mainly of developers’ notes collected into a UDF. And sometimes—\\noften—it exists only in the code itself.\\n32.2 Programming Style as Documentation\\nIn contrast to external documentation, in ternal documentation is found within the \\nprogram listing itself. It’s the most deta iled kind of documentation, at the source-\\nstatement level. Because it’s most closely associated with the code, internal docu-\\nmentation is also the kind of documentation most likely to remain correct as the \\ncode is modified.\\nThe main contributor to code-level documentation isn’t comments, but good pro-\\ngramming style. Style includes good program structure, use of straightforward and \\neasily understandable approaches, good variable names, good routine names, use of \\nnamed constants instead of literals, clear layout, and minimization of control-flow and \\ndata-structure complexity.\\nHere’s a code fragment with poor style:\\nJava Example of Poor Documentation Resulting from Bad Programming Style\\nfor ( i = 2; i <= num; i++ ) { \\nmeetsCriteria[ i ] = true; \\n} \\nfor ( i = 2; i <= num / 2; i++ ) { \\nj = i + i; \\nwhile ( j <= num ) { \\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 815}, page_content='32.2 Programming Style as Documentation 779\\nmeetsCriteria[ j ] = false; \\nj = j + i; \\n} \\n} \\nfor ( i = 2; i <= num; i++ ) { \\nif ( meetsCriteria[ i ] ) { \\nSystem.out.println ( i + \" meets criteria.\" ); \\n} \\n}\\nWhat do you think this routine does? It’s unnecessarily cryptic. It’s poorly docu-\\nmented not because it lacks comments, but because it lacks good programming style. \\nThe variable names are uninformative, and the layout is crude. Here’s the same code \\nimproved—just improving the programming style makes its meaning much clearer:\\nCross-Reference In this \\ncode, the variable factor-\\nableNumber is added solely \\nfor the sake of clarifying the \\noperation. For details on \\nadding variables to clarify \\noperations, see \"Making \\nComplicated Expressions \\nSimple\" in Section 19.1.\\nJava Example of Documentation Without Comments (with Good Style)\\nfor ( primeCandidate = 2; primeCandidate <= num; primeCandidate++ ) { \\n   isPrime[ primeCandidate ] = true; \\n} \\n \\nfor ( int factor = 2; factor < ( num / 2 ); factor++ ) { \\n   int factorableNumber = factor + factor; \\n   while ( factorableNumber <= num ) { \\n      isPrime[ factorableNumber ] = false; \\n      factorableNumber = factorableNumber + factor; \\n   } \\n} \\n \\nfor ( primeCandidate = 2; primeCandidate <= num; primeCandidate++ ) { \\n   if ( isPrime[ primeCandidate ] ) { \\n      System.out.println( primeCandidate + \" is prime.\" ); \\n   } \\n}\\nUnlike the first piece of code, this one lets you know at first glance that it has some-\\nthing to do with prime numbers. A second glance reveals that it finds the prime num-\\nbers between 1 and Num. With the first code fragment, it takes more than two glances \\njust to figure out where the loops end.\\nThe difference between the two code fragments has nothing to do with comments—\\nneither fragment has any. The second one is much more readable, however, and \\napproaches the Holy Grail of legibility: self-documenting code. Such code relies on \\ngood programming style to carry the greater part of the documentation burden. In \\nwell-written code, comments are the icing on the readability cake.\\nC32619670.fm  Page 779  Tuesday, April 12, 2011  3:43 PM\\nDownload from Wow! eBook <www.wowebook.com>'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 816}, page_content='780 Chapter 32: Self-Documenting Code\\ncc2e.com/3252 CHECKLIST: Self-Documenting Code\\nClasses\\n❑ Does the class’s interface present a consistent abstraction?\\n❑ Is the class well named, and does its name describe its central purpose? \\n❑ Does the class’s interface make obvious how you should use the class? \\n❑ Is the class’s interface abstract enough that you don’t have to think about \\nhow its services are implemented? Can you treat the class as a black box?\\nRoutines\\n❑ Does each routine’s name describe exactly what the routine does?\\n❑ Does each routine perform one well-defined task?\\n❑ Have all parts of each routine that would benefit from being put into their \\nown routines been put into their own routines?\\n❑ Is each routine’s interface obvious and clear?\\nData Names\\n❑ Are type names descriptive enough to help document data declarations?\\n❑ Are variables named well?\\n❑ Are variables used only for the purpose for which they’re named?\\n❑ Are loop counters given more informative names than i, j, and k?\\n❑ Are well-named enumerated types used instead of makeshift flags or bool-\\nean variables?\\n❑ Are named constants used instead of magic numbers or magic strings?\\n❑ Do naming conventions distinguish among type names, enumerated types, \\nnamed constants, local variables, class variables, and global variables?\\nData Organization\\n❑ Are extra variables used for clarity when needed?\\n❑ Are references to variables close together?\\n❑ Are data types simple so that they minimize complexity?\\n❑ Is complicated data accessed through abstract access routines (abstract \\ndata types)?\\nControl\\n❑ Is the nominal path through the code clear?\\n❑ Are related statements grouped together?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 817}, page_content='32.3 To Comment or Not to Comment 781\\n❑ Have relatively independent groups of statements been packaged into \\ntheir own routines?\\n❑ Does the normal case follow the if rather than the else?\\n❑ Are control structures simple so that they minimize complexity?\\n❑ Does each loop perform one and only one function, as a well-defined rou-\\ntine would?\\n❑ Is nesting minimized?\\n❑ Have boolean expressions been simplified by using additional boolean \\nvariables, boolean functions, and decision tables?\\nLayout\\n❑ Does the program’s layout show its logical structure?\\nDesign\\n❑ Is the code straightforward, and does it avoid cleverness?\\n❑ Are implementation details hidden as much as possible?\\n❑ Is the program written in terms of the problem domain as much as possi-\\nble rather than in terms of computer-science or programming-language \\nstructures?\\n32.3 To Comment or Not to Comment\\nComments are easier to write poorly than well, and commenting can be more damag-\\ning than helpful. The heated discussions over the virtues of commenting often sound \\nlike philosophical debates over moral virtues, which makes me think that if Socrates \\nhad been a computer programmer, he and his students might have had the following \\ndiscussion.\\nThe Commento\\nCharacters:\\nTHRASYMACHUS A green, theoretical puris t who believes everything he reads\\nCALLICLES A battle-hardened veteran from  the old school—a “real” programmer\\nGLAUCON A young, confident, hot-shot computer jock\\nISMENE A senior programmer tired of big pr omises, just looking for a few practices \\nthat work\\nSOCRATES The wise old programmer'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 818}, page_content='782 Chapter 32: Self-Documenting Code\\nSetting:\\nEND OF THE TEAM’S DAILY STANDUP MEETING\\n“Does anyone have any other issues before we get back to work?” Socrates asked.\\n“I want to suggest a commenting standard for our projects,” Thrasymachus said. \\n“Some of our programmers barely comment their code, and everyone knows that \\ncode without comments is unreadable.”\\n“You must be fresher out of college than I thought,” Callicles responded. “Comments \\nare an academic panacea, but everyone who’s done any real programming knows that \\ncomments make the code harder to read, not easier. English is less precise than Java or \\nVisual Basic and makes for a lot of excess verbiage. Programming-language statements \\nare short and to the point. If you can’t make the code clear, how can you make the \\ncomments clear? Plus, comments get out of date as the code changes. If you believe an \\nout-of-date comment, you’re sunk.”\\n“I agree with that,” Glaucon joined in. “Heavily commented code is harder to read \\nbecause it means more to read. I already have to read the code; why should I have to \\nread a lot of comments, too?”\\n“Wait a minute,” Ismene said, putting down her coffee mug to put in her two drach-\\nmas’ worth. “I know that commenting can be abused, but good comments are worth \\ntheir weight in gold. I’ve had to maintain code that had comments and code that \\ndidn’t, and I’d rather maintain code with comments. I don’t think we should have a \\nstandard that says use one comment for every x lines of code, but we should encour-\\nage everyone to comment.”\\n“If comments are a waste of time, why does anyone use them, Callicles?” Socrates \\nasked.\\n“Either because they’re required to or because they read somewhere that they’re use-\\nful. No one who’s thought about it could ever decide they’re useful.”\\n“Ismene thinks they’re useful. She’s been here three years, maintaining your code \\nwithout comments and other code with comments, and she prefers the code with \\ncomments. What do you make of that?”\\n“Comments are useless because they just repeat the code in a more verbose—”\\n“Wait right there,” Thrasymachus interrupted. “Good comments don’t repeat the \\ncode or explain it. They clarify its intent. Comments should explain, at a higher level \\nof abstraction than the code, what you’re trying to do.”\\n“Right,” Ismene said. “I scan the comments to find the section that does what I need \\nto change or fix. You’re right that comments that repeat the code don’t help at all \\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 819}, page_content='32.3 To Comment or Not to Comment 783\\nbecause the code says everything already. When I read comments, I want it to be like \\nreading headings in a book or a table of contents. Comments help me find the right \\nsection, and then I start reading the code. It’s a lot faster to read one sentence in \\nEnglish than it is to parse 20 lines of code in a programming language.” Ismene \\npoured herself another cup of coffee.\\n“I think that people who refuse to write comments (1) think their code is clearer than \\nit could possibly be, (2) think that other programmers are far more interested in their \\ncode than they really are, (3) think other programmers are smarter than they really \\nare, (4) are lazy, or (5) are afraid someone else might figure out how their code works.\\n“Code reviews would be a big help here, Socrates,” Ismene continued. “If someone \\nclaims they don’t need to write comments and are bombarded by questions during a \\nreview—when several peers start saying, ‘What the heck are you trying to do in this \\npiece of code?’—then they’ll start putting in comments. If they don’t do it on their \\nown, at least their manager will have the ammo to make them do it.\\n“I’m not accusing you of being lazy or afraid that people will figure out your code, Cal-\\nlicles. I’ve worked on your code and you’re one of the best programmers in the com-\\npany. But have a heart, huh? Your code would be easier for me to work on if you used \\ncomments.”\\n“But they’re a waste of resources,” Callicles countered. “A good programmer’s code \\nshould be self-documenting; everything you need to know should be in the code.”\\n“No way!” Thrasymachus was out of his chair. “Everything the compiler needs to \\nknow is in the code! You might as well argue that everything you need to know is in \\nthe binary executable file! If you were smart enough to read it! What is meant to hap-\\npen is not in the code.”\\nThrasymachus realized he was standing up and sat down. “Socrates, this is ridiculous. \\nWhy do we have to argue about whether comments are valuable? Everything I’ve ever \\nread says they’re valuable and should be used liberally. We’re wasting our time.”\\nClearly, at some level com-\\nments have to be useful. To \\nbelieve otherwise would be \\nto believe that the compre-\\nhensibility of a program is \\nindependent of how much \\ninformation the reader \\nmight already have about it.  \\n—B. A. Sheil\\n“Cool down, Thrasymachus. Ask Callicles how long he’s been programming.”\\n“How long, Callicles?”\\n“Well, I started on the Acropolis IV about 15 years ago. I guess I’ve seen about a dozen \\nmajor systems from the time they were born to the time we gave them a cup of hemlock. \\nAnd I’ve worked on major parts of a dozen more. Two of those systems had over half a \\nmillion lines of code, so I know what I’m talking about. Comments are pretty useless.”\\nSocrates looked at the younger programmer. “As Callicles says, comments have a lot of \\nlegitimate problems, and you won’t realize that without more experience. If they’re \\nnot done right, they’re worse than useless.”'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 820}, page_content='784 Chapter 32: Self-Documenting Code\\n“Even when they’re done right, they’re useless,” Callicles said. “Comments are less \\nprecise than a programming language. I’d rather not have them at all.”\\n“Wait a minute,” Socrates said. “Ismene agrees that comments are less precise. Her \\npoint is that comments give you a higher level of abstraction, and we all know that lev-\\nels of abstraction are one of a programmer’s most powerful tools.”\\n“I don’t agree with that,” Glaucon replied. “Instead of focusing on commenting, you \\nshould focus on making code more readable. Refactoring eliminates most of my com-\\nments. Once I’ve refactored, my code might have 20 or 30 routine calls without need-\\ning any comments. A good programmer can read the intent from the code itself, and \\nwhat good does it do to read about somebody’s intent when you know the code has \\nan error?” Glaucon was pleased with his contribution. Callicles nodded.\\n“It sounds like you guys have never had to modify someone else’s code,” Ismene said. \\nCallicles suddenly seemed very interested in the pencil marks on the ceiling tiles. \\n“Why don’t you try reading your own code six months or a year after you write it? You \\ncan improve your code-reading ability and your commenting. You don’t have to \\nchoose one or the other. If you’re reading a novel, you might not want section head-\\nings. But if you’re reading a technical book, you’d like to be able to find what you’re \\nlooking for quickly. I shouldn’t have to switch into ultra-concentration mode and read \\nhundreds of lines of code just to find the two lines I want to change.”\\n“All right, I can see that it would be handy to be able to scan code,” Glaucon said. He’d \\nseen some of Ismene’s programs and had been impressed. “But what about Callicles’ \\nother point, that comments get out of date as the code changes? I’ve only been program-\\nming for a couple of years, but even I know that nobody updates their comments.”\\n“Well, yes and no,” Ismene said. “If you take the comment as sacred and the code as \\nsuspicious, you’re in deep trouble. Actually, finding a disagreement between the com-\\nment and the code tends to mean both are wrong. The fact that some comments are \\nbad doesn’t mean that commenting is bad. I’m going to the lunchroom to get another \\npot of coffee.” Ismene left the room.\\n“My main objection to comments,” Callicles said, “is that they’re a waste of resources.”\\n“Can anyone think of ways to minimize the time it takes to write the comments?” \\nSocrates asked.\\n“Design routines in pseudocode, and then convert the pseudocode to comments and \\nfill in the code between them,” Glaucon said.\\n“OK, that would work as long as the comments don’t repeat the code,” Callicles said.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 821}, page_content='32.4 Keys to Effective Comments 785\\n“Writing a comment makes you think harder about what your code is doing,” Ismene \\nsaid, returning from the lunchroom. “If it’s hard to comment, either it’s bad code or \\nyou don’t understand it well enough. Either way, you need to spend more time on the \\ncode, so the time you spent commenting wasn’t wasted because it pointed you to \\nrequired work.”\\n“All right,” Socrates said. “I can’t think of any more questions, and I think Ismene got \\nthe best of you guys today. We’ll encourage commenting, but we won’t be naive about \\nit. We’ll have code reviews so that everyone will get a good sense of the kind of com-\\nments that actually help. If you have trouble understanding someone else’s code, let \\nthem know how they can improve it.”\\n32.4 Keys to Effective Comments\\nAs long as there are ill-\\ndefined goals, bizarre bugs, \\nand unrealistic schedules, \\nthere will be Real Program-\\nmers willing to jump in and \\nSolve The Problem, saving \\nthe documentation for later. \\nLong live Fortran! \\n—Ed Post\\nWhat does the following routine do?\\nJava Mystery Routine Number One\\n// write out the sums 1..n for all n from 1 to num \\ncurrent = 1; \\nprevious = 0; \\nsum = 1; \\nfor ( int i = 0; i < num; i++ ) { \\n   System.out.println( \"Sum = \" + sum ); \\n   sum = current + previous; \\n   previous = current; \\n   current = sum; \\n}\\nYour best guess?\\nThis routine computes the first num Fibonacci numbers. Its coding style is a little bet-\\nter than the style of the routine at the beginning of the chapter, but the comment is \\nwrong, and if you blindly trust the comment, you head down the primrose path in the \\nwrong direction.\\nWhat about this one?\\nJava Mystery Routine Number Two\\n// set product to \"base\" \\nproduct = base; \\n \\n// loop from 2 to \"num\" \\nfor ( int i = 2; i <= num; i++ ) { \\n   // multiply \"base\" by \"product\"  \\n   product = product * base; \\n} \\nSystem.out.println( \"Product = \" + product );'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 822}, page_content='786 Chapter 32: Self-Documenting Code\\nThis routine raises an integer base to the integer power num. The comments in this \\nroutine are accurate, but they add nothing to the code. They are merely a more ver-\\nbose version of the code itself.\\nHere’s one last routine:\\nJava Mystery Routine Number Three\\n// compute the square root of Num using the Newton-Raphson approximation  \\nr = num / 2; \\nwhile ( abs( r - (num/r) ) > TOLERANCE ) { \\n   r = 0.5 * ( r + (num/r) ); \\n} \\nSystem.out.println( \"r = \" + r );\\nThis routine computes the square root of num. The code isn’t great, but the comment \\nis accurate.\\nWhich routine was easiest for you to figure out correctly? None of the routines is par-\\nticularly well written—the variable names are especially poor. In a nutshell, however, \\nthese routines illustrate the strengths and weaknesses of internal comments. Routine \\nOne has an incorrect comment. Routine Two’s commenting merely repeats the code \\nand is therefore useless. Only Routine Three’s commenting earns its rent. Poor com-\\nments are worse than no comments. Routines One and Two would be better with no \\ncomments than with the poor comments they have.\\nThe following subsections describe keys to writing effective comments.\\nKinds of Comments\\nComments can be classified into six categories:\\nRepeat of the Code\\nA repetitious comment restates what the code does in different words. It merely gives \\nthe reader of the code more to read without providing additional information.\\nExplanation of the Code\\nExplanatory comments are typically used to explain complicated, tricky, or sensitive \\npieces of code. In such situations they are useful, but usually that’s only because the \\ncode is confusing. If the code is so complicated that it needs to be explained, it’s \\nnearly always better to improve the code than it is to add comments. Make the code \\nitself clearer, and then use summary or intent comments.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 823}, page_content='32.4 Keys to Effective Comments 787\\nMarker in the Code\\nA marker comment is one that isn’t intended to be left in the code. It’s a note to the \\ndeveloper that the work isn’t done yet. Some developers type in a marker that’s syntac-\\ntically incorrect (******, for example) so that the compiler flags it and reminds them \\nthat they have more work to do. Other developers put a specified set of characters in \\ncomments that don’t interfere with compilation so that they can search for them.\\nFew feelings are worse than having a customer report a problem in the code, debugging \\nthe problem, and tracing it to a section of code where you find something like this:\\nreturn NULL; // ****** NOT DONE! FIX BEFORE RELEASE!!!\\nReleasing defective code to customers is bad enough; releasing code that you knew \\nwas defective is even worse.\\nI’ve found that standardizing the style of marker comments is helpful. If you don’t \\nstandardize, some programmers will use *******, some will use !!!!!!, some will use \\nTBD, and some will use various other conventions. Using a variety of notations makes \\nmechanical searching for incomplete code error-prone or impossible. Standardizing \\non one specific marker style allows you to do a mechanical search for incomplete sec-\\ntions of code as one of the steps in a release checklist, which avoids the FIX BEFORE \\nRELEASE!!! problem. Some editors support “to do” tags and allow you to navigate to \\nthem easily.\\nSummary of the Code\\nA comment that summarizes code does just that: it distills a few lines of code into one \\nor two sentences. Such comments are more valuable than comments that merely \\nrepeat the code because a reader can scan them more quickly than the code. Sum-\\nmary comments are particularly useful when someone other than the code’s original \\nauthor tries to modify the code.\\nDescription of the Code’s Intent\\nA comment at the level of intent explains the purpose of a section of code. Intent com-\\nments operate more at the level of the problem than at the level of the solution. For \\nexample,\\n-- get current employee information\\nis an intent comment, whereas\\n-- update employeeRecord object'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 824}, page_content='788 Chapter 32: Self-Documenting Code\\nis a summary comment in terms of the solution. A six-month study conducted by IBM \\nfound that maintenance programmers “most often said that understanding the original \\nprogrammer’s intent was the most difficult problem” (Fjelstad and Hamlen 1979). The \\ndistinction between intent and summary comments isn’t always clear, and it’s usually \\nnot important. Examples of intent comments are given throughout this chapter.\\nInformation That Cannot Possibly Be Expressed by the Code Itself \\nSome information can’t be expressed in code but must still be in the source code. This \\ncategory of comments includes copyright notices, confidentiality notices, version \\nnumbers, and other housekeeping details; notes about the code’s design; references to \\nrelated requirements or architecture documentation; pointers to online references; \\noptimization notes; comments required by editing tools such as Javadoc and Doxy-\\ngen; and so on.\\nThe three kinds of comments that are acceptable for completed code are information \\nthat can’t be expressed in code, intent comments, and summary comments.\\nCommenting Efficiently\\nEffective commenting isn’t that time-consuming. Too many comments are as bad as \\ntoo few, and you can achieve a middle ground economically.\\nComments can take a lot of time to write for two common reasons. First, the com-\\nmenting style might be time-consuming or tedious. If it is, find a new style. A com-\\nmenting style that requires a lot of busy work is a maintenance headache. If the \\ncomments are hard to change, they won’t be changed and they’ll become inaccurate \\nand misleading, which is worse than having no comments at all.\\nSecond, commenting might be difficult because the words to describe what the pro-\\ngram is doing don’t come easily. That’s usually a sign that you don’t understand what \\nthe program does. The time you spend “commenting” is really time spent understand-\\ning the program better, which is time that needs to be spent regardless of whether you \\ncomment.\\nFollowing are guidelines for commenting efficiently:\\nUse styles that don’t break down or discourage modificationAny style that’s too \\nfancy is annoying to maintain. For example, pick out the part of the comment below \\nthat won’t be maintained:\\nJava Example of a Commenting Style That’s Hard to Maintain\\n//  Variable        Meaning \\n//  --------        ------- \\n//  xPos .......... XCoordinate Position (in meters) \\n//  yPos .......... YCoordinate Position (in meters) \\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 825}, page_content=\"32.4 Keys to Effective Comments 789\\n//  ndsCmptng...... Needs Computing (= 0 if no computation is needed, \\n//                                   = 1 if computation is needed) \\n//  ptGrdTtl....... Point Grand Total \\n//  ptValMax....... Point Value Maximum \\n//  psblScrMax..... Possible Score Maximum\\nIf you said that the leader dots (.....) will be hard to maintain, you’re right! They look \\nnice, but the list is fine without them. Th ey add busy work to the job of modifying \\ncomments, and you’d rather have accurate comments than nice-looking ones, if that’s \\nthe choice—and it usually is.\\nHere’s another example of a common style that’s hard to maintain:\\nC+ + Example of a Commenting Style That’s Hard to Maintain\\n/********************************************************************** \\n * class:  GigaTron (GIGATRON.CPP)                                    * \\n *                                                                    * \\n * author: Dwight K. Coder                                            * \\n * date:   July 4, 2014                                               * \\n *                                                                    * \\n * Routines to control the twenty-first century's code evaluation     * \\n * tool. The entry point to these routines is the EvaluateCode()      * \\n * routine at the bottom of this file.                                * \\n**********************************************************************/\\nThis is a nice-looking block comment. It’s clear that the whole block belongs together, \\nand the beginning and ending of the block are obvious. What isn’t clear about this \\nblock is how easy it is to change. If you have to add the name of a file to the bottom of \\nthe comment, chances are pretty good that you’ll have to fuss with the pretty column \\nof asterisks at the right. If you need to change the paragraph comments, you’ll have to \\nfuss with asterisks on both the left and the right. In practice, this means that the block \\nwon’t be maintained because it will be too much work. If you can press a key and get \\nneat columns of asterisks, that’s great. Use it. The problem isn’t the asterisks but that \\nthey’re hard to maintain. The following comment looks almost as good and is a cinch \\nto maintain:\\nC+ + Example of a Commenting Style That’s Easy to Maintain\\n/********************************************************************** \\n   class:  GigaTron (GIGATRON.CPP)  \\n \\n   author: Dwight K. Coder \\n   date:   July 4, 2014 \\n \\n   Routines to control the twenty-first century's code evaluation  \\n   tool. The entry point to these routines is the EvaluateCode()  \\n   routine at the bottom of this file. \\n **********************************************************************/\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 826}, page_content=\"790 Chapter 32: Self-Documenting Code\\nHere’s a particularly difficult style to maintain:\\nMicrosoft Visual Basic Example of a Commenting Style That’s Hard to Maintain\\n'  set up Color enumerated type \\n'  +--------------------------+ \\n   ... \\n \\n'  set up Vegetable enumerated type \\n'  +------------------------------+ \\n   ...\\nIt’s hard to know what value the plus sign at the beginning and end of each dashed \\nline adds to the comment, but it’s easy to guess that every time a comment changes, \\nthe underline has to be adjusted so that the ending plus sign is in precisely the right \\nplace. And what do you do when a comment spills over into two lines? How do you \\nalign the plus signs? Take words out of the comment so that it takes up only one line? \\nMake both lines the same length? The problems with this approach multiply when \\nyou try to apply it consistently.\\nA common guideline for Java and C++ that arises from a similar motivation is to use \\n// syntax for single-line comments and /* ... */  syntax for longer comments, as \\nshown here:\\nJava Example of Using Different Comment Syntaxes for Different Purposes\\n// This is a short comment \\n... \\n/* This is a much longer comment. Four score and seven years ago our fathers  \\nbrought forth on this continent a new nation, conceived in liberty and dedicated to  \\nthe proposition that all men are created equal. Now we are engaged in a great civil  \\nwar, testing whether that nation or any nation so conceived and so dedicated can  \\nlong endure. We are met on a great battlefield of that war. We have come to  \\ndedicate a portion of that field as a final resting-place for those who here gave  \\ntheir lives that that nation might live. It is altogether fitting and proper that  \\nwe should do this. \\n*/\\nThe first comment is easy to maintain as long as it’s kept short. For longer comments, \\nthe task of creating long columns of double slashes, manually breaking lines of text \\nbetween rows, and similar activities is not very rewarding, and so the /* ... */ syntax is \\nmore appropriate for multiline comments.\\nThe point is that you should pay attention to how you spend your time. If you spend \\na lot of time entering and deleting dashes to make plus signs line up, you’re not pro-\\ngramming; you’re wasting time. Find a more efficient style. In the case of the under-\\nlines with plus signs, you could choose to have just the comments without any \\nunderlining. If you need to use underlines for emphasis, find some way other than \\nCODING \\nHORROR\\nKEY POINT\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 827}, page_content='32.4 Keys to Effective Comments 791\\nunderlines with plus signs to emphasize those comments. One way would be to have \\na standard underline that’s always the same length regardless of the length of the \\ncomment. Such a line requires no maintenance, and you can use a text-editor macro to \\nenter it in the first place.\\nCross-Reference For details \\non the Pseudocode Pro-\\ngramming Process, see \\nChapter 9, \"The Pseudocode \\nProgramming Process.\"\\nUse the Pseudocode Programming Process to reduce commenting time If you outline \\nthe code in comments before you write it, you win in several ways. When you finish \\nthe code, the comments are done. You don’t have to dedicate time to comments. You \\nalso gain all the design benefits of writing in high-level pseudocode before filling in \\nthe low-level programming-language code.\\nIntegrate commenting into your development style The alternative to integrating \\ncommenting into your development style is leaving commenting until the end of the \\nproject, and that has too many disadvantages. It becomes a task in its own right, which \\nmakes it seem like more work than when it’s done a little bit at a time. Commenting \\ndone later takes more time because you have to remember or figure out what the code \\nis doing instead of just writing down what you’re already thinking about. It’s also less \\naccurate because you tend to forget assumptions or subtleties in the design.\\nThe common argument against commenting as you go along is “When you’re concen-\\ntrating on the code, you shouldn’t break your concentration to write comments.” The \\nappropriate response is that, if you have to concentrate so hard on writing code that \\ncommenting interrupts your thinking, you need to design in pseudocode first and \\nthen convert the pseudocode to comments. Code that requires that much concentra-\\ntion is a warning sign.\\nIf your design is hard to code, simplify the design before you worry about comments \\nor code. If you use pseudocode to clarify your thoughts, coding is straightforward and \\nthe comments are automatic.\\nPerformance is not a good reason to avoid commenting One recurring attribute of \\nthe rolling wave of technology discussed in Section 4.3, “Your Location on the Tech-\\nnology Wave,” is interpreted environments in which commenting imposes a measur-\\nable performance penalty. In the 1980s, comments in Basic programs on the original \\nIBM PC slowed programs. In the 1990s, .asp pages did the same thing. In the 2000s, \\nJavaScript code and other code that needs to be sent across network connections pre-\\nsents a similar problem.\\nIn each of these cases, the ultimate solution has not been to avoid commenting; it’s \\nbeen to create a release version of the code that’s different from the development ver-\\nsion. This is typically accomplished by running the code through a tool that strips out \\ncomments as part of the build process.\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 828}, page_content='792 Chapter 32: Self-Documenting Code\\nOptimum Number of Comments\\nCapers Jones points out that studies at IBM found that a commenting density of one \\ncomment roughly every 10 statements was the density at which clarity seemed to \\npeak. Fewer comments made the code hard to understand. More comments also \\nreduced code understandability (Jones 2000).\\nThis kind of research can be abused, and projects sometimes adopt a standard such as \\n“programs must have one comment at least every five lines.” This standard addresses \\nthe symptom of programmers’ not writing clear code, but it doesn’t address the cause.\\nIf you use the Pseudocode Programming Process effectively, you’ll probably end up with \\na comment for every few lines of code. The number of comments, however, will be a side \\neffect of the process itself. Rather than focusing on the number of comments, focus on \\nwhether each comment is efficient. If the comments describe why the code was written \\nand meet the other criteria established in this chapter, you’ll have enough comments.\\n32.5 Commenting Techniques\\nCommenting is amenable to several different techniques depending on the level to \\nwhich the comments apply: program, file, routine, paragraph, or individual line.\\nCommenting Individual Lines\\nIn good code, the need to comment individual lines of code is rare. Here are two pos-\\nsible reasons a line of code would need a comment:\\n■ The single line is complicated enough to need an explanation.\\n■ The single line once had an error, and you want a record of the error.\\nHere are some guidelines for commenting a line of code:\\nAvoid self-indulgent comments Many years ago, I heard the story of a maintenance \\nprogrammer who was called out of bed to fix a malfunctioning program. The program’s \\nauthor had left the company and couldn’t be reached. The maintenance programmer \\nhadn’t worked on the program before, and after examining the documentation care-\\nfully, he found only one comment. It looked like this:\\nMOV AX, 723h    ; R. I. P. L. V. B.\\nAfter working with the program through the night and puzzling over the comment, \\nthe programmer made a successful patch and went home to bed. Months later, he met \\nthe program’s author at a conference and found out that the comment stood for “Rest \\nin peace, Ludwig van Beethoven.” Beethoven died in 1827 (decimal), which is 723 \\n(hexadecimal). The fact that 723h was needed in that spot had nothing to do with the \\ncomment. Aaarrrrghhhhh!\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 829}, page_content=\"32.5 Commenting Techniques 793\\nEndline Comments and Their Problems\\nEndline comments are comments that appear at the ends of lines of code:\\nVisual Basic Example of Endline Comments\\nFor employeeId = 1 To employeeCount \\n   GetBonus( employeeId, employeeType, bonusAmount ) \\n   If employeeType = EmployeeType_Manager Then \\n      PayManagerBonus( employeeId, bonusAmount ) ' pay full amount \\n   Else  \\n      If employeeType = EmployeeType_Programmer Then \\n         If bonusAmount >= MANAGER_APPROVAL_LEVEL Then \\n            PayProgrammerBonus( employeeId, StdAmt() ) ' pay std. amount \\n         Else \\n            PayProgrammerBonus( employeeId, bonusAmount ) ' pay full amount \\n         End If \\n      End If \\n   End If \\nNext \\nAlthough useful in some circumstances, endline comments pose several problems. \\nThe comments have to be aligned to the right of the code so that they don’t interfere \\nwith the visual structure of the code. If you don’t align them neatly, they’ll make your \\nlisting look like it’s been through the washing machine. Endline comments tend to be \\nhard to format. If you use many of them, it takes time to align them. Such time is not \\nspent learning more about the code; it’s dedicated solely to the tedious task of press-\\ning the spacebar or the Tab key.\\nEndline comments are also hard to maintain. If the code on any line containing an end-\\nline comment grows, it bumps the comment farther out and all the other endline com-\\nments will have to be bumped out to match. Styles that are hard to maintain aren’t \\nmaintained, and the commenting deteriorates under modification rather than improving.\\nEndline comments also tend to be cryptic. The right side of the line usually doesn’t \\noffer much room, and the desire to keep the comment on one line means that the \\ncomment must be short. Work then goes into making the line as short as possible \\ninstead of as clear as possible.\\nAvoid endline comments on single lines In addition to their practical problems, end-\\nline comments pose several conceptual problems. Here’s an example of a set of end-\\nline comments:\\nC+ + Example of Useless Endline Comments\\nThe comments merely \\nrepeat the code.\\nmemoryToInitialize = MemoryAvailable();    // get amount of memory available \\npointer = GetMemory( memoryToInitialize ); // get a ptr to the available memory \\nZeroMemory( pointer, memoryToInitialize ); // set memory to 0 \\n... \\nFreeMemory( pointer );                     // free memory allocated\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 830}, page_content=\"794 Chapter 32: Self-Documenting Code\\nA systemic problem with endline comments is that it’s hard to write a meaningful \\ncomment for one line of code. Most endline comments just repeat the line of code, \\nwhich hurts more than it helps.\\nAvoid endline comments for multiple lines of code If an endline comment is \\nintended to apply to more than one line of code, the formatting doesn’t show which \\nlines the comment applies to:\\nVisual Basic Example of a Confusing Endline Comment on Multiple Lines of Code\\nFor rateIdx = 1 to rateCount                  ' Compute discounted rates \\n   LookupRegularRate( rateIdx, regularRate ) \\n   rate( rateIdx ) = regularRate * discount( rateIdx ) \\nNext\\nEven though the content of this particular comment is fine, its placement isn’t. You \\nhave to read the comment and the code to know whether the comment applies to a \\nspecific statement or to the entire loop.\\nWhen to Use Endline Comments\\nConsider three exceptions to the recommendation against using endline comments:\\nCross-Reference Other \\naspects of endline com-\\nments on data declarations \\nare described in “Comment-\\ning Data Declarations,” later \\nin this section.\\nUse endline comments to annotate data declarations Endline comments are useful \\nfor annotating data declarations because they don’t have the same systemic problems \\nas endline comments on code, provided that you have enough width. With 132 col-\\numns, you can usually write a meaningful comment beside each data declaration:\\nJava Example of Good Endline Comments for Data Declarations\\nint boundary = 0;         // upper index of sorted part of array  \\nString insertVal = BLANK; // data elmt to insert in sorted part of array  \\nint insertPos = 0;        // position to insert elmt in sorted part of array \\nAvoid using endline comments for maintenance notes Endline comments are some-\\ntimes used for recording modifications to code after its initial development. This kind \\nof comment typically consists of a date and the programmer’s initials, or possibly an \\nerror-report number. Here’s an example:\\nfor i = 1 to maxElmts – 1   -- fixed error #A423 10/1/05 (scm)\\nAdding such a comment can be gratifying after a late-night debugging session on soft-\\nware that’s in production, but such comments really have no place in production \\ncode. Such comments are handled better by version-control software. Comments \\nshould explain why the code works now, not why the code didn’t work at some point \\nin the past.\\nCODING \\nHORROR\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 831}, page_content='32.5 Commenting Techniques 795\\nCross-Reference Use of \\nendline comments to mark \\nends of blocks is described \\nfurther in “Commenting \\nControl Structures,” later in \\nthis section.\\nUse endline comments to mark ends of blocks An endline comment is useful for \\nmarking the end of a long block of code—the end of a while loop or an if statement, for \\nexample. This is described in more detail later in this chapter.\\nAside from a couple of special cases, endline comments have conceptual problems \\nand tend to be used for code that’s too complicated. They are also difficult to format \\nand maintain. Overall, they’re best avoided.\\nCommenting Paragraphs of Code\\nMost comments in a well-documented program are one-sentence or two-sentence \\ncomments that describe paragraphs of code:\\nJava Example of a Good Comment for a Paragraph of Code\\n// swap the roots \\noldRoot = root[0]; \\nroot[0] = root[1]; \\nroot[1] = oldRoot;\\nThe comment doesn’t repeat the code—it describes the code’s intent. Such comments \\nare relatively easy to maintain. Even if you find an error in the way the roots are \\nswapped, for example, the comment won’t need to be changed. Comments that aren’t \\nwritten at the level of intent are harder to maintain.\\nWrite comments at the level of the code’s intent Describe the purpose of the block of \\ncode that follows the comment. Here’s an example of a comment that’s ineffective \\nbecause it doesn’t operate at the level of intent:\\nJava Example of an Ineffective Comment\\nCross-Reference This code \\nthat performs a simple string \\nsearch is used only for \\npurposes of illustration. For \\nreal code, you’d use Java’s \\nbuilt-in string library func-\\ntions instead. For more on \\nthe importance of under-\\nstanding your language’s \\ncapabilities, see “Read!” in \\nSection 33.3.\\n/* check each character in \"inputString\" until a dollar sign  \\nis found or all characters have been checked \\n*/ \\ndone = false; \\nmaxLen = inputString.length(); \\ni = 0; \\nwhile ( !done && ( i < maxLen ) ) { \\n   if ( inputString[ i ] == \\'$\\' ) { \\n      done = true; \\n   } \\n   else { \\n      i++; \\n   } \\n}\\nYou can figure out that the loop looks for a $ by reading the code, and it’s somewhat \\nhelpful to have that summarized in the comment. The problem with this comment is'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 832}, page_content=\"796 Chapter 32: Self-Documenting Code\\nthat it merely repeats the code and doesn’t give you any insight into what the code is \\nsupposed to be doing. This comment would be a little better:\\n// find '$' in inputString\\nThis comment is better because it indicates that the goal of the loop is to find a $. But \\nit still doesn’t give you much insight into why the loop would need to find a $—in \\nother words, into the deeper intent of the loop. Here’s a comment that’s better still:\\n// find the command-word terminator ($)\\nThis comment actually contains information that the code listing does not, namely \\nthat the $ terminates a command word. In no way could you deduce that fact merely \\nfrom reading the code fragment, so the comment is genuinely helpful.\\nAnother way of thinking about commenting at the level of intent is to think about what \\nyou would name a routine that did the same thing as the code you want to comment. If \\nyou’re writing paragraphs of code that have one purpose each, it isn’t difficult. The com-\\nment in the previous code sample is a good example. FindCommandWordTerminator() \\nwould be a decent routine name. The other options, Find$InInputString() and Check-\\nEachCharacterInInputStrUntilADollarSignIsFoundOrAllCharactersHaveBeenChecked(), are \\npoor names (or invalid) for obvious reasons. Type the description without shortening \\nor abbreviating it, as you might for a routine name. That description is your com-\\nment, and it’s probably at the level of intent.\\nFocus your documentation efforts on the code itself For the record, the code itself is \\nalways the first documentation you should check. In the previous example, the literal, \\n$, should be replaced with a named constant and the variables should provide more \\nof a clue about what’s going on. If you want to push the edge of the readability enve-\\nlope, add a variable to contain the result of the search. Doing that clearly distinguishes \\nbetween the loop index and the result of the loop. Here’s the code rewritten with \\ngood comments and good style:\\nJava Example of a Good Comment and Good Code\\n// find the command-word terminator \\nfoundTheTerminator = false; \\ncommandStringLength = inputString.length(); \\ntestCharPosition = 0; \\nwhile ( !foundTheTerminator && ( testCharPosition < commandStringLength ) ) { \\n   if ( inputString[ testCharPosition ] == COMMAND_WORD_TERMINATOR ) { \\n      foundTheTerminator = true;\\nHere’s the variable that \\ncontains the result of the \\nsearch.\\n      terminatorPosition = testCharPosition; \\n   } \\n   else { \\n      testCharPosition = testCharPosition + 1; \\n   } \\n}\\nKEY POINT\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 833}, page_content='32.5 Commenting Techniques 797\\nIf the code is good enough, it begins to read at close to the level of intent, encroaching \\non the comment’s explanation of the code’s intent. At that point, the comment and the \\ncode might become somewhat redundant, but that’s a problem few programs have.\\nCross-Reference For more \\non moving a section of code \\ninto its own routine, see \\n\"Extract routine/extract \\nmethod\" in Section 24.3.\\nAnother good step for this code would be to create a routine called something like \\nFindCommandWordTerminator() and move the code from the sample into that routine. \\nA comment that describes that thought is us eful but is more likely than a routine \\nname to become inaccurate as the software evolves.\\nFocus paragraph comments on the why rather than the how Comments that explain \\nhow something is done usually operate at the programming-language level rather \\nthan the problem level. It’s nearly impossible for a comment that focuses on how an \\noperation is done to explain the intent of the operation, and comments that tell how \\nare often redundant. What does the following comment tell you that the code doesn’t?\\nJava Example of a Comment That Focuses on How\\n// if account flag is zero \\nif ( accountFlag == 0 ) ...\\nThe comment tells you nothing more than the code itself does. What about this \\ncomment?\\nJava Example of a Comment That Focuses on Why\\n// if establishing a new account \\nif ( accountFlag == 0 ) ...\\nThis comment is a lot better because it tells you something you couldn’t infer from the \\ncode itself. The code itself could still be improved by use of a meaningful enumerated \\ntype name instead of O and a better variable name. Here’s the best version of this com-\\nment and code:\\nJava Example of Using Good Style In Addition to a “Why” Comment\\n// if establishing a new account \\nif ( accountType == AccountType.NewAccount ) ...\\nWhen code attains this level of readability, it’s appropriate to question the value of the \\ncomment. In this case, the comment has been made redundant by the improved code, \\nand it should probably be removed. Alternatively, the purpose of the comment could \\nbe subtly shifted, like this:\\nJava Example of Using a “Section Heading” Comment\\n// establish a new account \\nif ( accountType == AccountType.NewAccount ) { \\n   ... \\n}\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 834}, page_content='798 Chapter 32: Self-Documenting Code\\nIf this comment documents the whole block of code following the if test, it serves as a \\nsummary-level comment and it’s appropriate to retain it as a section heading for the \\nparagraph of code it references.\\nUse comments to prepare the reader for what is to follow Good comments tell the \\nperson reading the code what to expect. A reader should be able to scan only the com-\\nments and get a good idea of what the code does and where to look for a specific activ-\\nity. A corollary to this rule is that a comment should always precede the code it \\ndescribes. This idea isn’t always taught in programming classes, but it’s a well-estab-\\nlished convention in commercial practice.\\nMake every comment count There’s no virtue in excessive commenting—too many \\ncomments obscure the code they’re meant to clarify. Rather than writing more com-\\nments, put the extra effort into making the code itself more readable.\\nDocument surprises If you find anything that isn’t obvious from the code itself, put \\nit into a comment. If you have used a tricky technique instead of a straightforward one \\nto improve performance, use comments to point out what the straightforward tech-\\nnique would be and quantify the performance gain achieved by using the tricky tech-\\nnique. Here’s an example:\\nC+ + Example of Documenting a Surprise\\nfor ( element = 0; element < elementCount; element++ ) { \\n   // Use right shift to divide by two. Substituting the \\n   // right-shift operation cuts the loop time by 75%. \\n   elementList[ element ] = elementList[ element ] >> 1; \\n}\\nThe selection of the right shift in this example is intentional. Among experienced pro-\\ngrammers, it’s common knowledge that for integers, right shift is functionally equiva-\\nlent to divide-by-two.\\nIf it’s common knowledge, why document it? Because the purpose of the operation is \\nnot to perform a right shift; it is to perform a divide-by-two. The fact that the code \\ndoesn’t use the technique most suited to its purpose is significant. Moreover, most \\ncompilers optimize integer division-by-two to be a right shift anyway, meaning that the \\nreduced clarity is usually unnecessary. In this particular case, the compiler evidently \\ndoesn’t optimize the divide-by-two, and the time saved will be significant. With the \\ndocumentation, a programmer reading the code would see the motivation for using \\nthe nonobvious technique. Without the comment, the same programmer would be \\ninclined to grumble that the code is unnecessarily “clever” without any meaningful \\ngain in performance. Usually such grumbling is justified, so it’s important to docu-\\nment the exceptions.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 835}, page_content='32.5 Commenting Techniques 799\\nAvoid abbreviations Comments should be unambiguous, readable without the work \\nof figuring out abbreviations. Avoid all but the most common abbreviations in com-\\nments. Unless you’re using endline comments, using abbreviations isn’t usually a \\ntemptation. If you are and it is, realize that abbreviations are another strike against a \\ntechnique that struck out several pitches ago.\\nDifferentiate between major and minor comments In a few cases, you might want to \\ndifferentiate between different levels of comments, indicating that a detailed comment \\nis part of a previous, broader comment. You can handle this in a couple of ways. You \\ncan try underlining the major comment and not underlining the minor comment:\\nC+ + Example of Differentiating Between Major and Minor Comments with \\nUnderlines—Not Recommended\\nThe major comment is \\nunderlined.\\nA minor comment that’s \\npart of the action described \\nby the major comment \\nisn’t underlined here...\\n...or here.\\n// copy the string portion of the table, along the way omitting  \\n// strings that are to be deleted \\n//-------------------------------------------------------------------------- \\n// determine number of strings in the table \\n...  \\n// mark the strings to be deleted \\n...\\nThe weakness of this approach is that it forces you to underline more comments than \\nyou’d really like to. If you underline a comment, it’s assumed that all the nonunder-\\nlined comments that follow it are subordinate to it. Consequently, when you write the \\nfirst comment that isn’t subordinate to the underlined comment, it too must be under-\\nlined and the cycle starts all over. The result is too much underlining or inconsistent \\nunderlining in some places and no underlining in others.\\nThis theme has several variations that all have the same problem. If you put the major \\ncomment in all caps and the minor comments in lowercase, you substitute the prob-\\nlem of too many all-caps comments for too many underlined comments. Some pro-\\ngrammers use an initial cap on major statements and no initial cap on minor ones, but \\nthat’s a subtle visual cue too easily overlooked.\\nA better approach is to use ellipses in front of the minor comments:\\nThe major comment is \\nformatted normally.\\nA minor comment that’s part \\nof the action described by \\nthe major comment is pre-\\nceded by an ellipsis here...\\n...and here.\\nC+ + Example of Differentiating Between Major and Minor Comments with Ellipses\\n// copy the string portion of the table, along the way omitting \\n// strings that are to be deleted  \\n// ... determine number of strings in the table \\n... \\n \\n// ... mark the strings to be deleted \\n...'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 836}, page_content=\"800 Chapter 32: Self-Documenting Code\\nAnother approach that’s often best is to put the major-comment operation into its own \\nroutine. Routines should be logically “flat,” with all their activities on about the same \\nlogical level. If your code differentiates between major and minor activities within a rou-\\ntine, the routine isn’t flat. Putting the complicated group of activities into its own routine \\nmakes for two logically flat routines instead of one logically lumpy one.\\nThis discussion of major and minor comments doesn’t apply to indented code within \\nloops and conditionals. In such cases, you’ll often have a broad comment at the top of \\nthe loop and more detailed comments about the operations within the indented code. \\nIn those cases, the indentation provides the clue to the logical organization of the \\ncomments. This discussion applies only to sequential paragraphs of code in which \\nseveral paragraphs make up a complete operation and some paragraphs are subordi-\\nnate to others.\\nComment anything that gets around an error or an undocumented feature in a \\nlanguage or an environment If it’s an error, it probably isn’t documented. Even if it’s \\ndocumented somewhere, it doesn’t hurt to document it again in your code. If it’s an \\nundocumented feature, by definition it isn’t documented elsewhere and it should be \\ndocumented in your code.\\nSuppose you find that the library routine WriteData( data, numItems, blockSize ) works \\nproperly except when blockSize equals 500. It works fine for 499, 501, and every other \\nvalue you’ve ever tried, but you’ve found that the routine has a defect that appears \\nonly when blockSize equals 500. In code that uses WriteData(), document why you’re \\nmaking a special case when blockSize is 500. Here’s an example of how it could look:\\nJava Example of Documenting the Workaround for an Error\\nblockSize = optimalBlockSize( numItems, sizePerItem ); \\n \\n/* The following code is necessary to work around an error in \\nWriteData() that appears only when the third parameter \\nequals 500. '500' has been replaced with a named constant \\nfor clarity.  \\n*/ \\nif ( blockSize == WRITEDATA_BROKEN_SIZE ) { \\n   blockSize = WRITEDATA_WORKAROUND_SIZE; \\n} \\nWriteData ( file, data, blockSize );\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 837}, page_content='32.5 Commenting Techniques 801\\nJustify violations of good programming style If you’ve had to violate good program-\\nming style, explain why. That will prevent a well-intentioned programmer from chang-\\ning the code to a better style, possibly breaking your code. The explanation will make \\nit clear that you knew what you were doing and weren’t just sloppy—give yourself \\ncredit where credit is due!\\nDon’t comment tricky code; rewrite it Here’s a comment from a project I worked on:\\nC+ + Example of Commenting Clever Code\\n// VERY IMPORTANT NOTE: \\n// The constructor for this class takes a reference to a UiPublication. \\n// The UiPublication object MUST NOT BE DESTROYED before the DatabasePublication \\n// object. If it is, the DatabasePublication object will cause the program to \\n// die a horrible death.\\nThis is a good example of one of the most prevalent and hazardous bits of program-\\nming folklore: that comments should be used to document especially “tricky” or “sen-\\nsitive” sections of code. The reasoning is that people should know they need to be \\ncareful when they’re working in certain areas.\\nThis is a scary idea.\\nCommenting tricky code is exactly the wrong approach to take. Comments can’t res-\\ncue difficult code. As Kernighan and Plauger emphasize, “Don’t document bad code—\\nrewrite it” (1978).\\nOne study found that areas of source code with large numbers of comments also \\ntended to have the most defects and to consume the most development effort (Lind \\nand Vairavan 1989). The authors hypothesized that programmers tended to comment \\ndifficult code heavily.\\nWhen someone says, “This is really tricky code,” I hear them say, “This is really bad \\ncode.” If something seems tricky to you, it will be incomprehensible to someone else. \\nEven something that doesn’t seem all that tricky to you can seem impossibly convo-\\nluted to another person who hasn’t seen the trick before. If you have to ask yourself “Is \\nthis tricky?” it is. You can always find a rewrite that’s not tricky, so rewrite the code. \\nMake your code so good that you don’t need comments, and then comment it to make \\nit even better.\\nThis advice applies mainly to code you’re writing for the first time. If you’re maintain-\\ning a program and don’t have the latitude to rewrite bad code, commenting the tricky \\nparts is a good practice.\\nCODING \\nHORROR\\n1\\n2\\n3\\nHARD DATA\\nKEY POINT'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 838}, page_content='802 Chapter 32: Self-Documenting Code\\nCommenting Data Declarations\\nCross-Reference For details \\non formatting data, see \"Lay-\\ning Out Data Declarations\" \\nin Section 31.5. For details \\non how to use data effec-\\ntively, see Chapters 10 \\nthrough 13.\\nComments for variable declarations describe aspects of the variable that the variable \\nname can’t describe. It’s important to document data carefully; at least one company \\nthat studied its own practices has concluded that annotations on data are even more \\nimportant than annotations on the processes in which the data is used (SDC, in Glass \\n1982). Here are some guidelines for commenting data:\\nComment the units of numeric data If a number represents length, indicate whether \\nthe length is expressed in inches, feet, meters, or kilometers. If it’s time, indicate \\nwhether it’s expressed in elapsed seconds since 1-1-1980, milliseconds since the start \\nof the program, and so on. If it’s coordinates, indicate whether they represent latitude, \\nlongitude, and altitude and whether they’re in radians or degrees; whether they repre-\\nsent an X, Y, Z coordinate system with its origin at the earth’s center; and so on. Don’t \\nassume that the units are obvious. To a new programmer, they won’t be. To someone \\nwho’s been working on another part of the system, they won’t be. After the program \\nhas been substantially modified, they won’t be.\\nAlternatively, in many cases you should embed the units in the variable names rather \\nthan in comments. An expression like distanceToSurface = marsLanderAltitude looks \\nlike it’s probably correct, but distanceToSurfaceInMeters = marsLanderAltitudeInFeet \\nexposes an obvious error.\\nCross-Reference A stronger \\ntechnique for documenting \\nallowable ranges of variables \\nis to use assertions at the \\nbeginning and end of a rou-\\ntine to assert that the vari-\\nable’s values should be \\nwithin a prescribed range. \\nFor more details, see Section \\n8.2, \"Assertions.\" \\nComment the range of allowable numeric values If a variable has an expected range \\nof values, document the expected range. One of the powerful features of the Ada pro-\\ngramming language was the ability to restrict the allowable values of a numeric vari-\\nable to a range of values. If your language doesn’t support that capability (and most \\nlanguages don’t), use a comment to document the expected range of values. For \\nexample, if a variable represents an amount of money in dollars, indicate that you \\nexpect it to be between $1 and $100. If a variable indicates a voltage, indicate that it \\nshould be between 105v and 125v.\\nComment coded meanings If your language supports enumerated types—as C++ and \\nVisual Basic do—use them to express coded meanings. If it doesn’t, use comments to \\nindicate what each value represents—and use a named constant rather than a literal for \\neach of the values. If a variable represents kinds of electrical current, comment the fact \\nthat 1 represents alternating current, 2 represents direct current, and 3 represents \\nundefined.\\nHere’s an example of documenting variable declarations that illustrates the three pre-\\nceding recommendations—all the range information is given in comments:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 839}, page_content='32.5 Commenting Techniques 803\\nVisual Basic Example of Nicely Documented Variable Declarations\\nDim cursorX As Integer  \\' horizontal cursor position; ranges from 1..MaxCols \\nDim cursorY As Integer  \\' vertical cursor position; ranges from 1..MaxRows \\n \\nDim antennaLength As Long      \\' length of antenna in meters; range is >= 2 \\nDim signalStrength As Integer  \\' strength of signal in kilowatts; range is >= 1 \\n \\nDim characterCode As Integer      \\' ASCII character code; ranges from 0..255 \\nDim characterAttribute As Integer \\' 0=Plain; 1=Italic; 2=Bold; 3=BoldItalic \\nDim characterSize As Integer \\' size of character in points; ranges from 4..127\\nComment limitations on input data Input data might come from an input parame-\\nter, a file, or direct user input. The previous guidelines apply as much to routine-input \\nparameters as to other kinds of data. Make sure that expected and unexpected values \\nare documented. Comments are one way of documenting that a routine is never sup-\\nposed to receive certain data. Assertions are another way to document valid ranges, \\nand if you use them the code becomes that much more self-checking.\\nDocument flags to the bit level If a variable is used as a bit field, document the mean-\\ning of each bit:\\nCross-Reference For details \\non naming flag variables, \\nsee \"Naming Status Vari-\\nables\" in Section 11.2.\\nVisual Basic Example of Documenting Flags to the Bit Level\\n\\' The meanings of the bits in statusFlags are as follows, from most  \\n\\' significant bit to least significant bit: \\n\\' MSB   0     error detected: 1=yes, 0=no \\n\\'       1-2   kind of error: 0=syntax, 1=warning, 2=severe, 3=fatal \\n\\'       3     reserved (should be 0) \\n\\'       4     printer status: 1=ready, 0=not ready \\n\\'       ... \\n\\'       14    not used (should be 0) \\n\\' LSB   15-32 not used (should be 0)  \\nDim statusFlags As Integer\\nIf the example were written in C++, it would call for bit-field syntax so that the bit-field \\nmeanings would be self-documenting.\\nStamp comments related to a variable with the variable’s name If you have com-\\nments that refer to a specific variable, make sure the comment is updated whenever \\nthe variable is updated. One way to improve the odds of a consistent modification is \\nto stamp the comment with the variable name. That way, string searches for the vari-\\nable name will find the comment as well as the variable.\\nCross-Reference For details \\non using global data, see \\nSection 13.3, \"Global Data.\"\\nDocument global data If global data is used, annotate each piece well at the point at \\nwhich it’s declared. The annotation should indicate the purpose of the data and why \\nit needs to be global. At each point at which the data is used, make it clear that the data \\nis global. A naming convention is the first choice for highlighting a variable’s global \\nstatus. If a naming convention isn’t used, comments can fill the gap.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 840}, page_content=\"804 Chapter 32: Self-Documenting Code\\nCommenting Control Structures\\nCross-Reference For other \\ndetails on control structures, \\nsee Section 31.3, “Layout \\nStyles,” Section 31.4, “Laying \\nOut Control Structures,” and \\nChapters 14 through 19.\\nThe space before a control structure is usually a natural place to put a comment. If it’s \\nan if or a case statement, you can provide the reason for the decision and a summary \\nof the outcome. If it’s a loop, you can indicate the purpose of the loop.\\nC+ + Example of Commenting the Purpose of a Control Structure\\nPurpose of the following \\nloop.\\n// copy input field up to comma \\nwhile ( ( *inputString != ',' ) && ( *inputString != END_OF_STRING ) ) { \\n   *field = *inputString; \\n   field++; \\n   inputString++;\\nEnd of the loop (useful for \\nlonger, nested loops—\\nalthough the need for such \\na comment indicates overly \\ncomplicated code).\\nPurpose of the loop. Position \\nof comment makes it clear \\nthat inputString is being set \\nup for the loop.\\n} // while -- copy input field \\n \\n*field = END_OF_STRING; \\n \\nif ( *inputString != END_OF_STRING ) {\\n   // read past comma and subsequent blanks to get to the next input field \\n   inputString++; \\n   while ( ( *inputString == ' ' ) && ( *inputString != END_OF_STRING ) ) { \\n      inputString++; \\n   } \\n} // if -- at end of string\\nThis example suggests some guidelines:\\nPut a comment before each if, case, loop, or block of statements Such a place is a \\nnatural spot for a comment, and these constructs often need explanation. Use a com-\\nment to clarify the purpose of the control structure.\\nComment the end of each control structureUse a comment to show what ended—for \\nexample,\\n} // for clientIndex — process record for each client\\nA comment is especially helpful at the end of long loops and to clarify loop nesting. \\nHere’s a Java example of using comments to clarify the ends of loop structures:\\nJava Example of Using Comments to Show Nesting\\nfor ( tableIndex = 0; tableIndex < tableCount; tableIndex++ ) { \\n   while ( recordIndex < recordCount ) { \\n      if ( !IllegalRecordNumber( recordIndex ) ) { \\n         ...\\nThese comments indicate \\nwhich control structure is \\nending.\\n      } // if \\n   } // while \\n} // for\\nThis commenting technique supplements the visual clues about the logical struc-\\nture given by the code’s indentation. You don’t need to use the technique for short\"),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 841}, page_content='32.5 Commenting Techniques 805\\nloops that aren’t nested. When the nesting is deep or the loops are long, however, \\nthe technique pays off.\\nTreat end-of-loop comments as a warning indicating complicated code If a loop is \\ncomplicated enough to need an end-of-loop comment, treat the comment as a warn-\\ning sign: the loop might need to be simplified. The same rule applies to complicated if \\ntests and case statements.\\nEnd-of-loop comments provide useful clues to logical structure, but writing them ini-\\ntially and then maintaining them can beco me tedious. The best way to avoid such \\ntedious work is often to rewrite any code that’s complicated enough to require tedious \\ndocumentation.\\nCommenting Routines\\nCross-Reference For details \\non formatting routines, see \\nSection 31.7. For details on \\nhow to create high-quality \\nroutines, see Chapter 7.\\nRoutine-level comments are the subject of some of the worst advice in typical com-\\nputer-science textbooks. Many textbooks urge you to pile up a stack of information at \\nthe top of every routine, regardless of its size or complexity:\\nVisual Basic Example of a Monolithic, Kitchen-Sink Routine Prolog\\n\\'********************************************************************** \\n\\' Name: CopyString \\n\\' \\n\\' Purpose:      This routine copies a string from the source \\n\\'               string (source) to the target string (target). \\n\\' \\n\\' Algorithm:    It gets the length of \"source\" and then copies each \\n\\'               character, one at a time, into \"target\". It uses \\n\\'               the loop index as an array index into both \"source\" \\n\\'               and \"target\" and increments the loop/array index \\n\\'               after each character is copied. \\n\\' \\n\\' Inputs:       input    The string to be copied \\n\\' \\n\\' Outputs:      output   The string to receive the copy of \"input\" \\n\\' \\n\\' Interface Assumptions: None \\n\\' \\n\\' Modification History: None \\n\\' \\n\\' Author:       Dwight K. Coder \\n\\' Date Created: 10/1/04 \\n\\' Phone:        (555) 222-2255 \\n\\' SSN:          111-22-3333 \\n\\' Eye Color:    Green \\n\\' Maiden Name:  None \\n\\' Blood Type:   AB- \\n\\' Mother\\'s Maiden Name: None \\n\\' Favorite Car: Pontiac Aztek \\n\\' Personalized License Plate: \"Tek-ie\" \\n\\'**********************************************************************\\nCODING \\nHORROR'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 842}, page_content='806 Chapter 32: Self-Documenting Code\\nThis is ridiculous. CopyString is presumably a trivial routine—probably fewer than five \\nlines of code. The comment is totally out of proportion to the scale of the routine. The \\nparts about the routine’s Purpose and Algorithm are strained because it’s hard to \\ndescribe something as simple as CopyString at a level of detail that’s between “copy a \\nstring” and the code itself. The boilerplate comments Interface Assumptions and Modi-\\nfication History aren’t useful either—they just take up space in the listing. Requiring the \\nauthor’s name is redundant with information that can be retrieved more accurately \\nfrom the revision-control system. To require all these ingredients for every routine is a \\nrecipe for inaccurate comments and maintenance failure. It’s a lot of make-work that \\nnever pays off.\\nAnother problem with heavy routine headers is that they discourage good factoring of \\nthe code—the overhead to create a new routine is so high that programmers will tend \\nto err on the side of creating fewer routines, not more. Coding conventions should \\nencourage good practices; heavy routine headers do the opposite.\\nHere are some guidelines for commenting routines:\\nKeep comments close to the code they describe One reason that the prolog to a rou-\\ntine shouldn’t contain voluminous documentation is that such a practice puts the \\ncomments far away from the parts of the routine they describe. During maintenance, \\ncomments that are far from the code tend not to be maintained with the code. The \\ncomments and the code start to disagree, and suddenly the comments are worthless. \\nInstead, follow the Principle of Proximity and put comments as close as possible to \\nthe code they describe. They’re more likely to be maintained, and they’ll continue to \\nbe worthwhile.\\nSeveral components of routine prologs are described below and should be included as \\nneeded. For your convenience, create a boilerplate documentation prolog. Just don’t \\nfeel obliged to include all the information in every case. Fill out the parts that matter, \\nand delete the rest.\\nCross-Reference Good rou-\\ntine names are key to routine \\ndocumentation. For details \\non how to create them, see \\nSection 7.3, \"Good Routine \\nNames.\"\\nDescribe each routine in one or two sentences at the top of the routine If you can’t \\ndescribe the routine in a short sentence or two, you probably need to think harder \\nabout what it’s supposed to do. Difficulty in creating a short description is a sign that \\nthe design isn’t as good as it should be. Go back to the design drawing board and try \\nagain. The short summary statement should be present in virtually all routines except \\nfor simple Get and Set accessor routines.\\nDocument parameters where they are declared The easiest way to document input \\nand output variables is to put comments next to the parameter declarations:'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 843}, page_content='32.5 Commenting Techniques 807\\nJava Example of Documenting Input and Output Data Where It’s \\nDeclared—Good Practice\\npublic void InsertionSort(  \\n   int[] dataToSort, // elements to sort in locations firstElement..lastElement \\n   int firstElement, // index of first element to sort (>=0) \\n   int lastElement // index of last element to sort (<= MAX_ELEMENTS) \\n)\\nCross-Reference Endline \\ncomments are discussed in \\nmore detail in “Endline Com-\\nments and Their Problems,” \\nearlier in this section.\\nThis practice is a good exception to the rule of not using endline comments; they are \\nexceptionally useful in documenting input and output parameters. This occasion for \\ncommenting is also a good illustration of the value of using standard indentation \\nrather than endline indentation for routine parameter lists—you wouldn’t have room \\nfor meaningful endline comments if you used endline indentation. The comments in \\nthe example are strained for space even with standard indentation. This example also \\ndemonstrates that comments aren’t the only form of documentation. If your variable \\nnames are good enough, you might be able to skip commenting them. Finally, the \\nneed to document input and output variables is a good reason to avoid global data. \\nWhere do you document it? Presumably, you document the globals in the monster \\nprolog. That makes for more work and, unfortunately, in practice usually means that \\nthe global data doesn’t get documented. That’s too bad because global data needs to \\nbe documented at least as much as anything else.\\nTake advantage of code documentation utilities such as JavadocIf the code in the previ-\\nous example were actually written in Java, you would have the additional ability to set up \\nthe code to take advantage of Java’s document extraction utility, Javadoc. In that case, \\n“documenting parameters where they are declared” would change to look like this:\\nJava Example of Documenting Input and Output Data To Take Advantage of Javadoc \\n/** \\n * ... <description of the routine> ... \\n * \\n * @param dataToSort  elements to sort in locations firstElement..lastElement \\n * @param firstElement index of first element to sort (>=0) \\n * @param lastElement  index of last element to sort (<= MAX_ELEMENTS) \\n */ \\npublic void InsertionSort(  \\n   int[] dataToSort, \\n   int firstElement,  \\n   int lastElement  \\n)\\nWith a tool like Javadoc, the benefit of setting up the code to extract documentation out-\\nweighs the risks associated with separating the parameter description from the parame-\\nter’s declaration. If you’re not working in an environment that supports document \\nextraction, like Javadoc, you’re usually better off keeping the comments closer to the \\nparameter names to avoid inconsistent edits and duplication of the names themselves.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 844}, page_content='808 Chapter 32: Self-Documenting Code\\nDifferentiate between input and output data It’s useful to know which data is used \\nas input and which is used as output. Visual Basic makes it relatively easy to tell \\nbecause output data is preceded by the ByRef keyword and input data is preceded by \\nthe ByVal keyword. If your language doesn’t support such differentiation automati-\\ncally, put it into comments. Here’s an example in C++:\\nCross-Reference The order \\nof these parameters follows \\nthe standard order for C++ \\nroutines but conflicts with \\nmore general practices. For \\ndetails, see \"Put parameters \\nin input-modify-output \\norder\" in Section 7.5. For \\ndetails on using a naming \\nconvention to differentiate \\nbetween input and output \\ndata, see Section 11.4.\\nC+ + Example of Differentiating Between Input and Output Data\\nvoid StringCopy( \\n   char *target,       // out: string to copy to \\n   const char *source  // in: string to copy from \\n) \\n...\\nC++-language routine declarations are a little tricky because some of the time the aster-\\nisk (*) indicates that the argument is an output argument and a lot of the time it just \\nmeans that the variable is easier to handle as a pointer than as a nonpointer type. \\nYou’re usually better off identifying input and output arguments explicitly.\\nIf your routines are short enough and you maintain a clear distinction between \\ninput and output data , documenting the data’s input or output status is probably \\nunnecessary. If the routine is longer, however, it’s a useful service to anyone who \\nreads the routine.\\nCross-Reference For details \\non other considerations for \\nroutine interfaces, see Sec-\\ntion 7.5, \"How to Use Rou-\\ntine Parameters.\" To \\ndocument assumptions \\nusing assertions, see “Use \\nassertions to document and \\nverify preconditions and \\npostconditions” in Section \\n8.2.\\nDocument interface assumptions Documenting interface assumptions might be \\nviewed as a subset of the other commenting recommendations. If you have made any \\nassumptions about the state of variables you receive—legal and illegal values, arrays \\nbeing in sorted order, member data being initialized or containing only good data, \\nand so on—document them either in the routine prolog or where the data is declared. \\nThis documentation should be present in virtually every routine.\\nMake sure that global data that’s used is documented. A global variable is as much an \\ninterface to a routine as anything else and is all the more hazardous because it some-\\ntimes doesn’t seem like one.\\nAs you’re writing the routine and realize that you’re making an interface assumption, \\nwrite it down immediately.\\nComment on the routine’s limitations If the routine provides a numeric result, indi-\\ncate the accuracy of the result. If the computations are undefined under some condi-\\ntions, document the conditions. If the routine has a default behavior when it gets into \\ntrouble, document the behavior. If the routine is expected to work only on arrays or \\ntables of a certain size, indicate that. If you know of modifications to the program that \\nwould break the routine, document them. If you ran into gotchas during the develop-\\nment of the routine, document those also.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 845}, page_content='32.5 Commenting Techniques 809\\nDocument the routine’s global effects If the routine modifies global data, describe \\nexactly what it does to the global data. As mentioned in Section 13.3, “Global Data,” \\nmodifying global data is at least an order of magnitude more dangerous than merely \\nreading it, so modifications should be performed carefully, part of the care being clear \\ndocumentation. As usual, if documenting becomes too onerous, rewrite the code to \\nreduce global data.\\nDocument the source of algorithms that are used If you’ve used an algorithm from a \\nbook or magazine, document the volume and page number you took it from. If you \\ndeveloped the algorithm yourself, indicate where the reader can find the notes you’ve \\nmade about it.\\nUse comments to mark parts of your program Some programmers use comments to \\nmark parts of their program so that they can find them easily. One such technique in \\nC++ and Java is to mark the top of each routine with a comment beginning with these \\ncharacters: \\n/** \\nThis allows you to jump from routine to routine by doing a string search for /** or to \\nuse your editor to jump automatically if it supports that.\\nA similar technique is to mark different kinds of comments differently, depending on \\nwhat they describe. For example, in C++ you could use @keyword, where keyword is a \\ncode you use to indicate the kind of comment. The comment @param could indicate \\nthat the comment describes a parameter to a routine, @version could indicate file-ver-\\nsion information, @throws could document the exceptions thrown by a routine, and \\nso on. This technique allows you to use tools to extract different kinds of information \\nfrom your source files. For example, you could search for @throws to retrieve docu-\\nmentation about all the exceptions thrown by all the routines in a program.\\ncc2e.com/3259 This C++ convention is based on the Javadoc convention, which is a well-established \\ninterface documentation convention for Java programs (java.sun.com/j2se/javadoc/). \\nYou can define your own conventions in other languages.\\nCommenting Classes, Files, and Programs\\nCross-Reference For layout \\ndetails, see Section 31.8, \\n\"Laying Out Classes.\" For \\ndetails on using classes, see \\nChapter 6, \"Working \\nClasses.\"\\nClasses, files, and programs are all characterized by the fact that they contain multiple \\nroutines. A file or class should contain a collection of related routines. A program con-\\ntains all the routines in a program. The documentation task in each case is to provide \\na meaningful, top-level view of the contents of the file, class, or program.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 846}, page_content='810 Chapter 32: Self-Documenting Code\\nGeneral Guidelines for Class Documentation\\nFor each class, use a block comment to describe general attributes of the class: \\nDescribe the design approach to the class Overview comments that provide infor-\\nmation that can’t readily be reverse-engineered from coding details are especially use-\\nful. Describe the class’s design philosophy, overall design approach, design \\nalternatives that were considered and discarded, and so on.\\nDescribe limitations, usage assumptions, and so on Similar to routines, be sure to \\ndescribe any limitations imposed by the class’s design. Also describe assumptions \\nabout input and output data, error-handling responsibilities, global effects, sources of \\nalgorithms, and so on.\\nComment the class interface Can another programmer understand how to use a \\nclass without looking at the class’s implementation? If not, class encapsulation is seri-\\nously at risk. The class’s interface should contain all the information anyone needs to \\nuse the class. The Javadoc convention is to require, at a minimum, documentation for \\neach parameter and each return value (Sun Microsystems 2000). This should be done \\nfor all exposed routines of each class (Bloch 2001).\\nDon’t document implementation details in the class interface A cardinal rule of \\nencapsulation is that you expose information only on a need-to-know basis: if there is \\nany question about whether information needs to be exposed, the default is to keep it \\nhidden. Consequently, class interface files should contain information needed to use \\nthe class but not information needed to implement or maintain the inner workings of \\nthe class.\\nGeneral Guidelines for File Documentation\\nAt the top of a file, use a block comment to describe the contents of the file:\\nDescribe the purpose and contents of each file The file header comment should \\ndescribe the classes or routines contained in a file. If all the routines for a program are \\nin one file, the purpose of the file is pretty obvious—it’s the file that contains the whole \\nprogram. If the purpose of the file is to contain one specific class, the purpose is also \\nobvious—it’s the file that contai ns the class with a similar name.\\nIf the file contains more than one class, explain why the classes need to be combined \\ninto a single file.\\nIf the division into multiple source files is made for some reason other than modu-\\nlarity, a good description of the purpose of the file will be even more helpful to a \\nprogrammer who is modifying the program. If  someone is looking for a routine that'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 847}, page_content='32.5 Commenting Techniques 811\\ndoes x, does the file’s header comment help th at person determine whether this file \\ncontains such a routine?\\nPut your name, e-mail address, and phone number in the block comment Author-\\nship and primary responsibility for specific areas of source code becomes important \\non large projects. Small projects (fewer than 10 people) can use collaborative develop-\\nment approaches, such as shared code ownership in which all team members are \\nequally responsible for all sections of code. Larger systems require that programmers \\nspecialize in different areas of code, which makes full-team shared-code ownership \\nimpractical.\\nIn that case, authorship is important information to have in a listing. It gives other pro-\\ngrammers who work on the code a clue about the programming style, and it gives \\nthem someone to contact if they need help. Depending on whether you work on indi-\\nvidual routines, classes, or programs, you should include author information at the \\nroutine, class, or program level.\\nInclude a version-control tag Many version-control tools will insert version informa-\\ntion into a file. In CVS, for example, the characters \\n// $Id$\\nwill automatically expand to\\n// $Id: ClassName.java,v 1.1 2004/02/05 00:36:43 ismene Exp $\\nThis allows you to maintain current versioning information within a file without \\nrequiring any developer effort other than inserting the original $Id$ comment.\\nInclude legal notices in the block comment Many companies like to include copy-\\nright statements, confidentiality notices, and other legal notices in their programs. If \\nyours is one of them, include a line similar to the one below. Check with your com-\\npany’s legal advisor to determine what information, if any, to include in your files.\\nJava Example of a Copyright Statement\\n// (c) Copyright 1993-2004 Steven C. McConnell. All Rights Reserved. \\n...\\nGive the file a name related to its contents Normally, the name of the file should be \\nclosely related to the name of the public class contained in the file. For example, if the \\nclass is named Employee, the file should be named Employee.cpp. Some languages, \\nnotably Java, require the file name to match the class name.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 848}, page_content='812 Chapter 32: Self-Documenting Code\\nThe Book Paradigm for Program Documentation\\nFurther Reading This dis-\\ncussion is adapted from “The \\nBook Paradigm for Improved \\nMaintenance” (Oman and \\nCook 1990a) and “Typo-\\ngraphic Style Is More Than \\nCosmetic” (Oman and Cook \\n1990b). A similar analysis is \\npresented in detail in \\nHuman Factors and Typog-\\nraphy for More Readable \\nPrograms (Baecker and Mar-\\ncus 1990).\\nMost experienced programmers agree that the documentation techniques described \\nin the previous section are valuable. The hard, scientific evidence for the value of any \\none of the techniques is still weak. When the techniques are combined, however, evi-\\ndence of their effectiveness is strong.\\nIn 1990, Paul Oman and Curtis Cook published a pair of studies on the “Book Para-\\ndigm” for documentation (1990a, 1990b). They looked for a coding style that would \\nsupport several different styles of code reading. One goal was to support top-down, \\nbottom-up, and focused searches. Another was to break up the code into chunks that \\nprogrammers could remember more easily than a long listing of homogeneous code. \\nOman and Cook wanted the style to provide for both high-level and low-level clues \\nabout code organization.\\nThey found that by thinking of code as a special kind of book and by formatting it \\naccordingly, they could achieve their goals. In the Book Paradigm, code and its docu-\\nmentation are organized into several components similar to the components of a book \\nto help programmers get a high-level view of the program.\\nThe “preface” is a group of introductory comments such as those usually found at the \\nbeginning of a file. It functions as the preface to a book does. It gives the programmer \\nan overview of the program.\\nThe “table of contents” shows the top-level files, classes, and routines (chapters). They \\nmight be shown in a list, as a traditional book’s chapters are, or graphically in a struc-\\nture chart.\\nThe “sections” are the divisions within routines—routine declarations, data declara-\\ntions, and executable statements, for example.\\nThe “cross-references” are cross-reference maps of the code, including line numbers.\\nThe low-level techniques that Oman and Cook use to take advantage of the similari-\\nties between a book and a code listing ar e similar to the techniques described in \\nChapter 31, “Layout and Style,” and in this chapter.\\nThe upshot of using their techniques to organize code was that when Oman and Cook \\ngave a maintenance task to a group of experienced, professional programmers, the \\naverage time to perform a maintenance task in a 1000-line program was only about \\nthree-quarters of the time it took the programmers to do the same task in a traditional \\nsource listing (1990b). Moreover, the maintenance scores of programmers on code \\ndocumented with the Book Paradigm averaged about 20 percent higher than on tradi-\\ntionally documented code. Oman and Cook concluded that by paying attention to the \\ntypographic principles of book design, you can get a 10 to 20 percent improvement in \\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 849}, page_content='32.6 IEEE Standards 813\\ncomprehension. A study with programmers at the University of Toronto produced \\nsimilar results (Baecker and Marcus 1990).\\nThe Book Paradigm emphasizes the importance of providing documentation that \\nexplains both the high-level and the low-level organization of your program.\\n32.6 IEEE Standards\\nFor documentation beyond the source-code level, valuable sources of information are \\nthe IEEE (Institute for Electric and Electrical Engineers) Software Engineering Stan-\\ndards. IEEE standards are developed by groups composed of practitioners and acade-\\nmicians who are expert in a particular area. Each standard contains a summary of the \\narea covered by the standard and typically contains the outline for the appropriate \\ndocumentation for work in that area.\\nSeveral national and international organizations participate in standards work. The \\nIEEE is a group that has taken the lead in defining software engineering standards. \\nSome standards are jointly adopted by ISO (International Standards Organization), \\nEIA (Electronic Industries Alliance), or IEC (International Engineering Consortium).\\nStandards names are composed of the standards number, the year the standard was \\nadopted, and the name of the standard. So, IEEE/EIA Std 12207-1997, Information \\nTechnology—Software Life Cycle Processes, refers to standard number 12207.2, which was \\nadopted in 1997 by the IEEE and EIA.\\nHere are some of the national and international standards most applicable to software \\nprojects:\\ncc2e.com/3266 The top-level standard is ISO/IEC Std 12207, Information Technology—Software Life Cycle \\nProcesses, which is the international standard th at defines a life-cycle framework for \\ndeveloping and managing software projects. This standard was adopted in the United \\nStates as IEEE/EIA Std 12207, Information Technology—Software Life Cycle Processes.\\nSoftware-Development Standards\\ncc2e.com/3273 Here are software-development standards to consider:\\nIEEE Std 830-1998, Recommended Practice for Software Requirements Specifications\\nIEEE Std 1233-1998, Guide for Developing System Requirements Specifications\\nIEEE Std 1016-1998, Recommended Practice for Software Design Descriptions\\nIEEE Std 828-1998, Standard for Software Configuration Management Plans\\nIEEE Std 1063-2001, Standard for Software User Documentation\\nIEEE Std 1219-1998, Standard for Software Maintenance'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 850}, page_content='814 Chapter 32: Self-Documenting Code\\nSoftware Quality-Assurance Standards\\ncc2e.com/3280 And here are software quality-assurance standards:\\nIEEE Std 730-2002, Standard for Software Quality Assurance Plans\\nIEEE Std 1028-1997, Standard for Software Reviews\\nIEEE Std 1008-1987 (R1993), Standard for Software Unit Testing\\nIEEE Std 829-1998, Standard for Software Test Documentation\\nIEEE Std 1061-1998, Standard for a Software Quality Metrics Methodology\\nManagement Standards\\ncc2e.com/3287 Here are some software-management standards:\\nIEEE Std 1058-1998, Standard for Software Project Management Plans\\nIEEE Std 1074-1997, Standard for Developing Software Life Cycle Processes\\nIEEE Std 1045-1992, Standard for Software Productivity Metrics\\nIEEE Std 1062-1998, Recommended Practice for Software Acquisition\\nIEEE Std 1540-2001, Standard for Software Life Cycle Processes - Risk Management\\nIEEE Std 1490-1998, Guide - Adoption of PMI Standard - A Guide to the Project Manage-\\nment Body of Knowledge\\nOverview of Standards\\ncc2e.com/3294 Here are sources that provide overviews of standards:\\ncc2e.com/3201 IEEE Software Engineering Standards Collection, 2003 Edition. New York, NY: Institute of \\nElectrical and Electronics Engineers (IEEE). This comprehensive volume contains 40 \\nof the most recent ANSI/IEEE standards for software development as of 2003. Each \\nstandard includes a document outline, a description of each component of the outline, \\nand a rationale for that component. The document includes standards for quality-\\nassurance plans, configuration-management plans, test documents, requirements spec-\\nifications, verification and validation plans, design descriptions, project-management \\nplans, and user documentation. The book is a distillation of the expertise of hundreds \\nof people at the top of their fields and would be a bargain at virtually any price. Some \\nof the standards are also available individually. All are available from the IEEE Com-\\nputer Society in Los Alamitos, California and from www.computer.org/cspress.\\nMoore, James W. Software Engineering Standards: A User’s Road Map. Los Alamitos, CA: \\nIEEE Computer Society Press, 1997. Moore provides an overview of IEEE software \\nengineering standards.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 851}, page_content='Additional Resources 815\\nAdditional Resources\\ncc2e.com/3208 In addition to the IEEE standards, numerous other resources are available on pro-\\ngram documentation.\\nSpinellis, Diomidis. Code Reading: The Open Source Perspective. Boston, MA: Addison-\\nWesley, 2003. This book is a pragmatic exploration of techniques for reading code, \\nincluding where to find code to read, tips for reading large code bases, tools that sup-\\nport code reading, and many other useful suggestions.\\ncc2e.com/3215\\nI wonder how many great \\nnovelists have never read \\nsomeone else’s work, how \\nmany great painters have \\nnever studied another’s \\nbrush strokes, how many \\nskilled surgeons never \\nlearned by looking over a \\ncolleague’s shoulder.... And \\nyet that’s what we expect \\nprogrammers to do.\\n—Dave Thomas\\nSourceForge.net. For decades, a perennial problem in teaching software development \\nhas been finding life-size examples of production code to share with students. Many \\npeople learn quickest from studying real-life examples, but most life-size code bases \\nare treated as proprietary information by the companies that created them. This situ-\\nation has improved dramatically through the combination of the Internet and open-\\nsource software. The Source Forge website contains code for thousands of programs \\nin C, C++, Java, Visual Basic, PHP, Perl, Python, and many other languages, all which \\nyou can download for free. Programmers can benefit from wading through the code \\non the website to see much larger real-world examples than Code Complete, Second Edi-\\ntion, is able to show in its short code examples. Junior programmers who haven’t pre-\\nviously seen extensive examples of production code will find this website especially \\nvaluable as a source of both good and bad coding practices.\\ncc2e.com/3222 Sun Microsystems. “How to Write Doc Comments for the Javadoc Tool,” 2000. Avail-\\nable from http://java.sun.com/j2se/javadoc/writingdoccomments/. This article \\ndescribes how to use Javadoc to document Java programs. It includes detailed advice \\nabout how to tag comments by using an @tag style notation. It also includes many \\nspecific details about how to wordsmith the comments themselves. The Javadoc con-\\nventions are probably the most fully developed code-level documentation standards \\ncurrently available.\\nHere are sources of information on other topics in software documentation:\\nMcConnell, Steve. Software Project Survival Guide. Redmond, WA: Microsoft Press, \\n1998. This book describes the documentation required by a medium-sized business-\\ncritical project. A related website provides numerous related document templates.\\ncc2e.com/3229 www.construx.com. This website (my company’s website) contains numerous docu-\\nment templates, coding conventions, and other resources related to all aspects of soft-\\nware development, including software documentation.\\ncc2e.com/3236 Post, Ed. “Real Programmers Don’t Use Pascal,” Datamation, July 1983, pp. 263–265. \\nThis tongue-in-cheek paper argues for a return to the “good old days” of Fortran pro-\\ngramming when programmers didn’t have to worry about pesky issues like readability.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 852}, page_content='816 Chapter 32: Self-Documenting Code\\ncc2e.com/3243 CHECKLIST: Good Commenting Technique\\nGeneral\\n❑ Can someone pick up the code and immediately start to understand it?\\n❑ Do comments explain the code’s intent or summarize what the code does, \\nrather than just repeating the code?\\n❑ Is the Pseudocode Programming Process used to reduce commenting \\ntime?\\n❑ Has tricky code been rewritten rather than commented?\\n❑ Are comments up to date?\\n❑ Are comments clear and correct?\\n❑ Does the commenting style allow comments to be easily modified?\\nStatements and Paragraphs\\n❑ Does the code avoid endline comments?\\n❑ Do comments focus on why rather than how?\\n❑ Do comments prepare the reader for the code to follow?\\n❑ Does every comment count? Have redundant, extraneous, and self-indul-\\ngent comments been removed or improved?\\n❑ Are surprises documented?\\n❑ Have abbreviations been avoided?\\n❑ Is the distinction between major and minor comments clear?\\n❑ Is code that works around an error or undocumented feature commented?\\nData Declarations\\n❑ Are units on data declarations commented?\\n❑ Are the ranges of values on numeric data commented?\\n❑ Are coded meanings commented?\\n❑ Are limitations on input data commented?\\n❑ Are flags documented to the bit level?\\n❑ Has each global variable been commented where it is declared?\\n❑ Has each global variable been identified as such at each usage, by a naming \\nconvention, a comment, or both?\\n❑ Are magic numbers replaced with named constants or variables rather \\nthan just documented?'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 853}, page_content='Key Points 817\\nControl Structures\\n❑ Is each control statement commented?\\n❑ Are the ends of long or complex control structures commented or, when \\npossible, simplified so that they don’t need comments?\\nRoutines\\n❑ Is the purpose of each routine commented?\\n❑ Are other facts about each routine given in comments, when relevant, \\nincluding input and output data, interface assumptions, limitations, error \\ncorrections, global effects, and sources of algorithms?\\nFiles, Classes, and Programs\\n❑ Does the program have a short document, such as that described in the \\nBook Paradigm, that gives an overall view of how the program is orga-\\nnized?\\n❑ Is the purpose of each file described?\\n❑ Are the author’s name, e-mail address, and phone number in the listing?\\nKey Points\\n■ The question of whether to comment is a legitimate one. Done poorly, com-\\nmenting is a waste of time and sometimes harmful. Done well, commenting is \\nworthwhile.\\n■ The source code should contain most of the critical information about the pro-\\ngram. As long as the program is running, the source code is more likely than any \\nother resource to be kept current, and it’s useful to have important information \\nbundled with the code.\\n■ Good code is its own best documentation. If the code is bad enough to require \\nextensive comments, try first to improve the code so that it doesn’t need exten-\\nsive comments.\\n■ Comments should say things about the code that the code can’t say about \\nitself—at the summary level or the intent level.\\n■ Some commenting styles require a lot of tedious clerical work. Develop a style \\nthat’s easy to maintain.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 855}, page_content='819\\nChapter 33\\nPersonal Character\\ncc2e.com/3313 Contents\\n■ 33.1 Isn’t Personal Character Off the Topic?: page 820\\n■ 33.2 Intelligence and Humility: page 821\\n■ 33.3 Curiosity: page 822\\n■ 33.4 Intellectual Honesty: page 826\\n■ 33.5 Communication and Cooperation: page 828\\n■ 33.6 Creativity and Discipline: page 829\\n■ 33.7 Laziness: page 830\\n■ 33.8 Characteristics That Don’t Matter As Much As You Might Think: page 830\\n■ 33.9 Habits: page 833\\nRelated Topics\\n■ Themes in software craftsmanship: Chapter 34\\n■ Complexity: Sections 5.2 and 19.6\\nPersonal character has received a rare degree of attention in software development. \\nEver since Edsger Dijkstra’s landmark 1965 article, “Programming Considered as a \\nHuman Activity,” programmer character has been regarded as a legitimate and fruitful \\narea of inquiry. Titles such as The Psychology of Bridge Construction and “Exploratory \\nExperiments in Attorney Behavior” might seem absurd, but in the computer field The \\nPsychology of Computer Programming, “Exploratory Experiments in Programmer \\nBehavior,” and similar titles are classics.\\nEngineers in every discipline learn the limits of the tools and materials they work \\nwith. If you’re an electrical engineer, you know the conductivity of various metals and \\na hundred ways to use a voltmeter. If you’re a structural engineer, you know the load-\\nbearing properties of wood, concrete, and steel.\\nIf you’re a software engineer, your basic building material is human intellect and your \\nprimary tool is you. Rather than designing a structure to the last detail and then hand-\\ning the blueprints to someone else for construction, you know that once you’ve \\ndesigned a piece of software to the last detail, it’s done. The whole job of program-\\nming is building air castles—it’s one of the most purely mental activities you can do.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 856}, page_content='820 Chapter 33: Personal Character\\nConsequently, when software engineers study the essential properties of their tools \\nand raw materials, they find that they’re studying people: intellect, character, and \\nother attributes that are less tangible than wood, concrete, and steel.\\nIf you’re looking for concrete programming tips, this chapter might seem too abstract \\nto be useful. Once you’ve absorbed the specific advice in the rest of the book, however, \\nthis chapter spells out what you need to do to continue improving. Read the next sec-\\ntion, and then decide whether you want to skip the chapter.\\n33.1 Isn’t Personal Character Off the Topic?\\nThe intense inwardness of programming makes personal character especially \\nimportant. You know how difficult it is to  put in eight concen trated hours in one \\nday. You’ve probably had the experience of being burned out one day from concen-\\ntrating too hard the day before or burn ed out one month from concentrating too \\nhard the month before. You’ve probably had days on which you’ve worked well from \\n8:00 A.M. to 2:00 P.M. and then felt lik e quitting. You didn’t quit, though; you \\npushed on from 2:00 P.M. to 5:00 P.M. an d then spent the rest of the week fixing \\nwhat you wrote from 2:00 to 5:00.\\nProgramming work is essentially unsupervisable because no one ever really knows \\nwhat you’re working on. We’ve all had projects in which we spent 80 percent of the \\ntime working on a small piece we found interesting and 20 percent of the time build-\\ning the other 80 percent of the program.\\nYour employer can’t force you to be a good programmer; a lot of times your employer \\nisn’t even in a position to judge whether you’re good. If you want to be great, you’re \\nresponsible for making yourself great. It’s a matter of your personal character.\\nOnce you decide to make yourself a superior programmer, the potential for improve-\\nment is huge. Study after study has found differences on the order of 10 to 1 in the \\ntime required to create a program. They have also found differences on the order of 10 \\nto 1 in the time required to debug a program and 10 to 1 in the resulting size, speed, \\nerror rate, and number of errors detected (Sackman, Erikson, and Grant 1968; Curtis \\n1981; Mills 1983; DeMarco and Lister 1985; Curtis et al. 1986; Card 1987; Valett and \\nMcGarry 1989).\\nYou can’t do anything about your intelligence, so the classical wisdom goes, but you \\ncan do something about your character. And it turns out that character is the more \\ndecisive factor in the makeup of a superior programmer.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 857}, page_content='33.2 Intelligence and Humility 821\\n33.2 Intelligence and Humility\\nWe become authorities and \\nexperts in the practical and \\nscientific spheres by so many \\nseparate acts and hours of \\nwork. If a person keeps faith-\\nfully busy each hour of the \\nworking day, he can count on \\nwaking up some morning to \\nfind himself one of the com-\\npetent ones of his generation.  \\n—William James\\nIntelligence doesn’t seem like an aspect of personal character, and it isn’t. Coinciden-\\ntally, great intelligence is only loosely connected to being a good programmer.\\nWhat? You don’t have to be superintelligent?\\nNo, you don’t. Nobody is really smart enough to program computers. Fully under-\\nstanding an average program requires an almost limitless capacity to absorb details \\nand an equal capacity to comprehend them all at the same time. The way you focus \\nyour intelligence is more important than how much intelligence you have.\\nAs Chapter 5 (“Design in Construction”) mentioned, at the 1972 Turing Award Lec-\\nture, Edsger Dijkstra delivered a paper titled “The Humble Programmer.” He argued \\nthat most of programming is an attempt to compensate for the strictly limited size of \\nour skulls. The people who are best at programming are the people who realize how \\nsmall their brains are. They are humble. The people who are the worst at program-\\nming are the people who refuse to accept the fact that their brains aren’t equal to the \\ntask. Their egos keep them from being great programmers. The more you learn to \\ncompensate for your small brain, the better a programmer you’ll be. The more humble \\nyou are, the faster you’ll improve.\\nThe purpose of many good programming practices is to reduce the load on your gray \\ncells. Here are a few examples:\\n■ The point of “decomposing” a system is to make it simpler to understand. (See \\n”Levels of Design” in Section 5.2 for more details.) \\n■ Conducting reviews, inspections, and tests is a way of compensating for antici-\\npated human fallibilities. These review techniques originated as part of “egoless \\nprogramming” (Weinberg 1998). If you never made mistakes, you wouldn’t \\nneed to review your software. But you know that your intellectual capacity is lim-\\nited, so you augment it with someone else’s.\\n■ Keeping routines short reduces the load on your brain.\\n■ Writing programs in terms of the problem domain rather than in terms of low-\\nlevel implementation details reduces your mental workload.\\n■ Using conventions of all sorts frees your brain from the relatively mundane \\naspects of programming, which offer little payback.\\nYou might think that the high road would be to develop better mental abilities so that \\nyou wouldn’t need these programming crutches. You might think that a programmer \\nwho uses mental crutches is taking the low road. Empirically, however, it’s been \\nshown that humble programmers who compensate for their fallibilities write code \\nthat’s easier for themselves and others to understand and that has fewer errors. The \\nreal low road is the road of errors and delayed schedules.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 858}, page_content='822 Chapter 33: Personal Character\\n33.3 Curiosity\\nOnce you admit that your brain is too small to understand most programs and you \\nrealize that effective programming is a search for ways to offset that fact, you begin a \\ncareer-long search for ways to compensate. In the development of a superior program-\\nmer, curiosity about technical subjects must be a priority. The relevant technical infor-\\nmation changes continually. Many Web programmers have never had to program in \\nMicrosoft Windows, and many Windows programmers never had to deal with DOS \\nor UNIX or punch cards. Specific features of the technical environment change every \\n5 to 10 years. If you aren’t curious enough to keep up with the changes, you might find \\nyourself down at the old-programmers’ home playing cards with T-Bone Rex and the \\nBrontosaurus sisters.\\nProgrammers are so busy working they often don’t have time to be curious about how \\nthey might do their jobs better. If this is true for you, you’re not alone. The following \\nsubsections describe a few specific actions you can take to exercise your curiosity and \\nmake learning a priority.\\nCross-Reference For a fuller \\ndiscussion of the importance \\nof process in software devel-\\nopment, see Section 34.2, \\n“Pick Your Process.”\\nBuild your awareness of the development process The more aware you are of the \\ndevelopment process, whether from reading or from your own observations about \\nsoftware development, the better position you’re in to understand changes and to \\nmove your group in a good direction.\\nIf your workload consists entirely of short-term assignments that don’t develop your \\nskills, be dissatisfied. If you’re working in a competitive software market, half of what \\nyou now need to know to do your job will be out of date in three years. If you’re not \\nlearning, you’re turning into a dinosaur.\\nYou’re in too much demand to spend time working for management that doesn’t have \\nyour interests in mind. Despite some ups and downs and some jobs moving overseas, \\nthe average number of software jobs available in the U.S. is expected to increase dramat-\\nically between 2002 and 2012. Jobs for systems analysts are expected to increase by \\nabout 60 percent and for software engineers by about 50 percent. For all computer-job \\ncategories combined, about 1 million new jobs will be created beyond the 3 million that \\ncurrently exist (Hecker 2001, BLS 2004). If you can’t learn at your job, find a new one.\\nCross-Reference Several key \\naspects of programming \\nrevolve around the idea of \\nexperimentation. For details, \\nsee “Experimentation” in \\nSection 34.9.\\nExperiment One effective way to learn about programming is to experiment with \\nprogramming and the development process. If you don’t know how a feature of your \\nlanguage works, write a short program to exercise the feature and see how it works. \\nPrototype! Watch the program execute in the debugger. You’re better off working with \\na short program to test a concept than you are writing a larger program with a feature \\nyou don’t quite understand.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 859}, page_content='33.3 Curiosity 823\\nWhat if the short program shows that the feature doesn’t work the way you want it to? \\nThat’s what you wanted to find out. Better to find it out in a small program than a large \\none. One key to effective programming is learning to make mistakes quickly, learning \\nfrom them each time. Making a mistake is no sin. Failing to learn from a mistake is.\\nFurther Reading A great \\nbook that teaches problem \\nsolving is James Adams’s \\nConceptual Blockbusting \\n(2001).\\nRead about problem solving Problem solving is the core activity in building com-\\nputer software. Herbert Simon reported a series of experiments on human problem \\nsolving. They found that human beings don’t always discover clever problem-solving \\nstrategies themselves, even though the same strategies could readily be taught to the \\nsame people (Simon 1996). The implication is that even if you want to reinvent the \\nwheel, you can’t count on success. You might reinvent the square instead.\\nAnalyze and plan before you act You’ll find that there’s a tension between analysis \\nand action. At some point you have to quit gathering data and act. The problem for \\nmost programmers, however, isn’t an excess of analysis. The pendulum is currently so \\nfar on the “acting” side of the arc that you can wait until it’s at least partway to the mid-\\ndle before worrying about getting stuck on the “analysis-paralysis” side.\\ncc2e.com/3320 Learn about successful projects One especially good way to learn about program-\\nming is to study the work of the great programmers. Jon Bentley thinks that you \\nshould be able to sit down with a glass of brandy and a good cigar and read a program \\nthe way you would a good novel. That might not be as far-fetched as it sounds. Most \\npeople wouldn’t want to use their recreational time to scrutinize a 500-page source \\nlisting, but many people would enjoy studying a high-level design and dipping into \\nmore detailed source listings for selected areas.\\nThe software-engineering field makes extraordinarily limited use of examples of past \\nsuccesses and failures. If you were interested in architecture, you’d study the drawings \\nof Louis Sullivan, Frank Lloyd Wright, and I. M. Pei. You’d probably visit some of their \\nbuildings. If you were interested in structural engineering, you’d study the Brooklyn \\nBridge; the Tacoma Narrows Bridge; and a variety of other concrete, steel, and wood \\nstructures. You would study examples of successes and failures in your field.\\nThomas Kuhn points out that a part of any mature science is a set of solved problems \\nthat are commonly recognized as examples of good work in the field and that serve as \\nexamples for future work (Kuhn 1996). Software engineering is only beginning to \\nmature to this level. In 1990, the Computer Science and Technology Board concluded \\nthat there were few documented case studies of either successes or failures in the soft-\\nware field (CSTB 1990).\\nAn article in the Communications of the ACM argued for learning from case studies of \\nprogramming problems (Linn and Clancy 1992). The fact that someone has to argue'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 860}, page_content='824 Chapter 33: Personal Character\\nfor this is significant. That one of the most popular computing columns, “Program-\\nming Pearls,” was built around case studies of programming problems is also sugges-\\ntive. And one of the most popular books in software engineering is The Mythical Man-\\nMonth, a case study in programming management of the IBM OS/360 project.\\nWith or without a book of case studies in programming, find code written by supe-\\nrior programmers and read it. Ask to look at the code of programmers you respect. \\nAsk to look at the code of programmers you don’t. Compare their code, and com-\\npare their code to your own. What are the differences? Why are they different? \\nWhich way is better? Why?\\nIn addition to reading other people’s code, develop a desire to know what expert pro-\\ngrammers think about your code. Find world-class programmers who’ll give you their \\ncriticism. As you listen to the criticism, filter out points that have to do with their per-\\nsonal idiosyncrasies and concentrate on the points that matter. Then change your pro-\\ngramming so that it’s better.\\nRead! Documentation phobia is rampant among programmers. Computer docu-\\nmentation tends to be poorly written and poorly organized, but for all its problems, \\nthere’s much to gain from overcoming an excessive fear of computer-screen photons \\nor paper products. Documentation contains the keys to the castle, and it’s worth \\nspending time reading it. Overlooking information that’s readily available is such a \\ncommon oversight that a familiar acronym on newsgroups and bulletin boards is \\n“RTFM!” which stands for “Read the !#*%*@ Manual!”\\nA modern language product is usually bundled with an enormous set of library code. \\nTime spent browsing through the library documentation is well invested. Often the \\ncompany that provides the language product has already created many of the classes \\nyou need. If it has, make sure you know about them. Skim the documentation every \\ncouple of months.\\nCross-Reference For books \\nyou can use in a personal \\nreading program, see Sec-\\ntion 35.4, “A Software Devel-\\noper’s Reading Plan.”\\nRead other books and periodicals Pat yourself on the back for reading this book. \\nYou’re already learning more than most people in the software industry because one \\nbook is more than most programmers read each year (DeMarco and Lister 1999). A \\nlittle reading goes a long way toward professional advancement. If you read even one \\ngood programming book every two months, roughly 35 pages a week, you’ll soon \\nhave a firm grasp on the industry and di stinguish yourself from nearly everyone \\naround you.\\nAffiliate with other professionals Find other people who care about sharpening \\ntheir software-development skills. Attend a conference, join a local user group, or par-\\nticipate in an online discussion group.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 861}, page_content='33.3 Curiosity 825\\nFurther Reading For other \\ndiscussions of programmer \\nlevels, see “Construx’s Pro-\\nfessional Development Pro-\\ngram” (Chapter 16) in \\nProfessional Software Devel-\\nopment (McConnell 2004).\\nMake a commitment to professional development Good programmers constantly \\nlook for ways to become better. Consider the following professional development lad-\\nder used at my company and several others: \\n■ Level 1: Beginning A beginner is a programmer capable of using the basic \\ncapabilities of one language. Such a person can write classes, routines, loops, \\nand conditionals and use many of the features of a language.\\n■ Level 2: Introductory An intermediate programmer who has moved past the \\nbeginner phase is capable of using the basic capabilities of multiple languages \\nand is very comfortable in at least one language.\\n■ Level 3: Competency A competent programmer has expertise in a language or \\nan environment or both. A programmer at this level might know all the intrica-\\ncies of J2EE or have the Annotated C++ Reference Manual memorized. Program-\\nmers at this level are valuable to their companies, and many programmers never \\nmove beyond this level.\\n■ Level 4: Leadership A leader has the expertise of a Level 3 programmer and \\nrecognizes that programming is only 15 percent communicating with the com-\\nputer and 85 percent communicating with people. Only 30 percent of an \\naverage programmer’s time is spent working alone (McCue 1978). Even less \\ntime is spent communicating with the computer. The guru writes code for an \\naudience of people rather than machines. True guru-level programmers write \\ncode that’s crystal-clear, and they document it, too. They don’t want to waste \\ntheir valuable gray cells reconstructing th e logic of a section of code that they \\ncould have read in a one-sentence comment.\\nA great coder who doesn’t emphasize readability is probably stuck at Level 3, but even \\nthat isn’t usually the case. In my experience, the main reason people write unreadable \\ncode is that their code is bad. They don’t say to themselves, “My code is bad, so I’ll \\nmake it hard to read.” They just don’t understand their code well enough to make it \\nreadable, which locks them into one of the lower levels.\\nThe worst code I’ve ever seen was written by someone who wouldn’t let anyone go \\nnear her programs. Finally, her manager threatened to fire her if she didn’t cooperate. \\nHer code was uncommented and littered with variables like x, xx, xxx, xx1, and xx2, \\nall of which were global. Her manager’s boss thought she was a great programmer \\nbecause she fixed errors quickly. The quality of her code gave her abundant opportu-\\nnities to demonstrate her error-correcting ability.\\nIt’s no sin to be a beginner or an intermediate. It’s no sin to be a competent program-\\nmer instead of a leader. The sin is in how long you remain a beginner or intermediate \\nafter you know what you have to do to improve.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 862}, page_content='826 Chapter 33: Personal Character\\n33.4 Intellectual Honesty\\nPart of maturing as a programming professional is developing an uncompromising sense \\nof intellectual honesty. Intellectual honesty commonly manifests itself in several ways:\\n■ Refusing to pretend you’re an expert when you’re not\\n■ Readily admitting your mistakes\\n■ Trying to understand a compiler warning rather than suppressing the message\\n■ Clearly understanding your program—not compiling it to see if it works\\n■ Providing realistic status reports\\n■ Providing realistic schedule estimates and holding your ground when manage-\\nment asks you to adjust them\\nThe first two items on this list—admitting that you don’t know something or that you \\nmade a mistake—echo the theme of intellectual humility discussed earlier. How can you \\nlearn anything new if you pretend that you know everything already? You’d be better off \\npretending that you don’t know anything. Listen to people’s explanations, learn some-\\nthing new from them, and assess whether they know what they are talking about.\\nBe ready to quantify your degree of certainty on any issue. If it’s usually 100 percent, \\nthat’s a warning sign.\\nAny fool can defend his or \\nher mistakes—and most \\nfools do.  \\n—Dale Carnegie\\nRefusing to admit mistakes is a particularly annoying habit. If Sally refuses to admit a \\nmistake, she apparently believes that not admitting the mistake will trick others into \\nbelieving that she didn’t make it. The opposite is true. Everyone will know she made a \\nmistake. Mistakes are accepted as part of the ebb and flow of complex intellectual activ-\\nities, and as long as she hasn’t been negligent, no one will hold mistakes against her.\\nIf she refuses to admit a mistake, the only person she’ll fool is herself. Everyone else \\nwill learn that they’re working with a prideful programmer who’s not completely hon-\\nest. That’s a more damning fault than making a simple error. If you make a mistake, \\nadmit it quickly and emphatically.\\nPretending to understand compiler messages when you don’t is another common \\nblind spot. If you don’t understand a co mpiler warning or if you think you know \\nwhat it means but are too pressed for time to check it, guess what’s really a waste of \\ntime? You’ll probably end up trying to so lve the problem from the ground up while \\nthe compiler waves the solution in your face . I’ve had several peop le ask for help in \\ndebugging programs. I’ ll ask if they have a clean compile, and they’ll say yes. Then \\nthey’ll start to explain the symptoms of the problem, and I’ll say, “Hmmmm. That \\nsounds like it would be an uninitialized pointer, but the compiler should have \\nwarned you about that.” Then they’ll say, “Oh yeah—it did warn about that. We'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 863}, page_content='33.4 Intellectual Honesty 827\\nthought it meant something else.” It’s hard to fool other people about your \\nmistakes. It’s even harder to fool the computer, so don’t waste your time trying.\\nA related kind of intellectual sloppiness occurs when you don’t quite understand your \\nprogram and “just compile it to see if it works.” One example is running the program \\nto see whether you should use < or <=. In that situation, it doesn’t really matter \\nwhether the program works because you don’t understand it well enough to know \\nwhy it works. Remember that testing can show only the presence of errors, not their \\nabsence. If you don’t understand the program, you can’t test it thoroughly. Feeling \\ntempted to compile a program to “see what happens” is a warning sign. It might mean \\nthat you need to back up to design or that you began coding before you were sure you \\nknew what you were doing. Make sure you have a strong intellectual grip on the pro-\\ngram before you relinquish it to the compiler.\\nThe first 90 percent of the \\ncode accounts for the first 90 \\npercent of the development \\ntime. The remaining 10 per-\\ncent of the code accounts for \\nthe other 90 percent of the \\ndevelopment time.  \\n—Tom Cargill\\nStatus reporting is an area of scandalous duplicity. Programmers are notorious for say-\\ning that a program is “90 percent complete” during the last 50 percent of the project. \\nIf your problem is that you have a poor sense of your own progress, you can solve it by \\nlearning more about how you work. But if your problem is that you don’t speak your \\nmind because you want to give the answer your manager wants to hear, that’s a differ-\\nent story. A manager usually appreciates honest observations about the status of a \\nproject, even if they’re not the opinions the manager wants to hear. If your observa-\\ntions are well thought out, give them as dispassionately as you can and in private. \\nManagement needs to have accurate information to coordinate development activi-\\nties, and full cooperation is essential.\\ncc2e.com/3341 An issue related to inaccurate status reporting is inaccurate estimation. The typical \\nscenario goes like this: Management asks Bert for an estimate of how long it would \\ntake to develop a new database product. Bert talks to a few programmers, crunches \\nsome numbers, and comes back with an estimate of eight programmers and six \\nmonths. His manager says, “That’s not really what we’re looking for. Can you do it in \\na shorter time, with fewer programmers?” Bert goes away and thinks about it and \\ndecides that for a short period he could cut training and vacation time and have every-\\none work a little overtime. He comes back with an estimate of six programmers and \\nfour months. His manager says, “That’s great. This is a relatively low-priority project, \\nso try to keep it on time without any overtime because the budget won’t allow it.”\\nThe mistake Bert made was not realizing that estimates aren’t negotiable. He can \\nrevise an estimate to be more accurate, but negotiating with his boss won’t change the \\ntime it takes to develop a software project. IBM’s Bill Weimer says, “We found that \\ntechnical people, in general, were actually very good at estimating project require-\\nments and schedules. The problem they had was defending their decisions; they \\nneeded to learn how to hold their ground” (Weimer in Metzger and Boddie 1996). \\nBert’s not going to make his manager any happier by promising to deliver a project in'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 864}, page_content='828 Chapter 33: Personal Character\\nfour months and delivering it in six than he would by promising and delivering it in \\nsix. He’ll lose credibility by compromising, and he’ll gain respect by standing firm on \\nhis estimate.\\nIf management applies pressure to change your estimate, realize that ultimately the \\ndecision whether to do a project rests with management: “Look. This is how much it’s \\ngoing to cost. I can’t say whether it’s worth this price to the company—that’s your job. \\nBut I can tell you how long it takes to develop a piece of software—that’s my job. I can’t \\n‘negotiate’ how long it will take; that’s like negotiating how many feet are in a mile. \\nYou can’t negotiate laws of nature. We can, however, negotiate other aspects of the \\nproject that affect the schedule and then reestimate the schedule. We can eliminate \\nfeatures, reduce performance, develop the project in increments, or use fewer people \\nand a longer schedule or more people and a shorter schedule.”\\nOne of the scariest exchanges I’ve ever heard was at a lecture on managing software \\nprojects. The speaker was the author of a best-selling software-project-management \\nbook. A member of the audience asked, “What do you do if management asks for an \\nestimate and you know that if you give them an accurate estimate they’ll say it’s too \\nhigh and decide not to do the project?” The speaker responded that that was one of \\nthose tricky areas in which you had to get management to buy into the project by \\nunderestimating it. He said that once they’d invested in the first part of the project, \\nthey’d see it through to the end.\\nWrong answer! Management is responsible for the big-picture issues of running a \\ncompany. If a certain software capability is worth $250K to a company and you esti-\\nmate it will cost $750K to develop, the company shouldn’t develop the software. It’s \\nmanagement’s responsibility to make such judgments. When the speaker advocated \\nlying about the project’s cost, telling management it would cost less than it really \\nwould, he advocated covertly stealing management’s authority. If you think a project \\nis interesting, breaks important new ground for the company, or provides valuable \\ntraining, say so. Management can weigh those factors, too. But tricking management \\ninto making the wrong decision could literally cost the company hundreds of thou-\\nsands of dollars. If it costs you your job, you’ll have gotten what you deserve.\\n33.5 Communication and Cooperation\\nTruly excellent programmers learn how to work and play well with others. Writing \\nreadable code is part of being a team player. The computer probably reads your pro-\\ngram as often as other people do, but it’s a lot better at reading poor code than people \\nare. As a readability guideline, keep the person who has to modify your code in mind. \\nProgramming is communicating with another programmer first and communicating \\nwith the computer second.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 865}, page_content='33.6 Creativity and Discipline 829\\n33.6 Creativity and Discipline\\nWhen I got out of school, I thought I was the best programmer in the world. I \\ncould write an unbeatable tic-tac-toe program, use five different computer lan-\\nguages, and create 1000-line programs that WORKED (really!).  Then I got out \\ninto the Real World. My first task in the Real World was to read and understand \\na 200,000-line Fortran program and then speed it up by a factor of two. Any \\nReal Programmer will tell you that all the Structured Coding in the world won’t \\nhelp you solve a problem like that—it takes actual talent.\\n—Ed Post\\nIt’s hard to explain to a fresh computer-science graduate why you need conventions \\nand engineering discipline. When I was an undergraduate, the largest program I \\nwrote was about 500 lines of executable code. As a professional, I’ve written dozens of \\nutilities that have been smaller than 500 lines, but the average main-project size has \\nbeen 5,000 to 25,000 lines, and I’ve participated in projects with over a half million \\nlines of code. This type of effort requires not the same skills on a larger scale, but a \\nnew set of skills altogether.\\nSome creative programmers view the discipline of standards and conventions as sti-\\nfling to their creativity. The opposite is true. Can you imagine a website on which each \\npage used different fonts, colors, text alignment, graphics styles, and navigation clues? \\nThe effect would be chaotic, not creative. Without standards and conventions on large \\nprojects, project completion itself is impossible. Creativity isn’t even imaginable. \\nDon’t waste your creativity on things that don’t matter. Establish conventions in non-\\ncritical areas so that you can focus your creative energies in the places that count.\\nIn a 15-year retrospective on work at NASA’s Software Engineering Laboratory, \\nMcGarry and Pajerski reported that methods and tools that emphasize human disci-\\npline have been especially effective (1990). Many highly creative people have been \\nextremely disciplined. “Form is liberating,” as the saying goes. Great architects work \\nwithin the constraints of physical materials, time, and cost. Great artists do, too. Any-\\none who has examined Leonardo’s drawings has to admire his disciplined attention \\nto detail. When Michelangelo designed the ceiling of the Sistine Chapel, he divided it \\ninto symmetric collections of geometric forms, such as triangles, circles, and squares. \\nHe designed it in three zones corresponding to three Platonic stages. Without this \\nself-imposed structure and discipline, the 300 human figures would have been merely \\nchaotic rather than the coherent elements of an artistic masterpiece.\\nA programming masterpiece requires just as much discipline. If you don’t try to ana-\\nlyze requirements and design before you begin coding, much of your learning about \\nthe project will occur during coding and the result of your labors will look more like \\na three-year-old’s finger painting than a work of art.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 866}, page_content='830 Chapter 33: Personal Character\\n33.7 Laziness\\nLaziness: The quality that \\nmakes you go to great effort \\nto reduce overall energy \\nexpenditure. It makes you \\nwrite labor-saving programs \\nthat other people will find \\nuseful, and document what \\nyou wrote so that you don’t \\nhave to answer so many \\nquestions about it.\\n—Larry Wall\\nLaziness manifests itself in several ways:\\n■ Deferring an unpleasant task\\n■ Doing an unpleasant task quickly to get it out of the way\\n■ Writing a tool to do the unpleasant task so that you never have to do the task \\nagain\\nSome of these manifestations of laziness are better than others. The first is hardly ever \\nbeneficial. You’ve probably had the experience of spending several hours futzing with \\njobs that didn’t really need to be done so that you wouldn’t have to face a relatively \\nminor job that you couldn’t avoid. I detest data entry, and many programs require a \\nsmall amount of data entry. I’ve been known to delay working on a program for days \\njust to delay the inevitable task of entering several pages of numbers by hand. This \\nhabit is “true laziness.” It manifests itself again in the habit of compiling a class to see \\nif it works so that you can avoid the exercise of checking the class with your mind.\\nThe small tasks are never as bad as they seem. If you develop the habit of doing them \\nright away, you can avoid the procrastinating kind of laziness. This habit is “enlight-\\nened laziness”—the second kind of laziness. You’re still lazy, but you’re getting around \\nthe problem by spending the smallest possible amount of time on something that’s \\nunpleasant.\\nThe third option is to write a tool to do the unpleasant task. This is “long-term lazi-\\nness.” It is undoubtedly the most productive kind of laziness (provided that you ulti-\\nmately save time by having written the tool). In these contexts, a certain amount of \\nlaziness is beneficial.\\nWhen you step through the looking glass, you see the other side of the laziness pic-\\nture. “Hustle” or “making an effort” doesn’t have the rosy glow it does in high-school \\nphysical education class. Hustle is extra, unnecessary effort. It shows that you’re eager \\nbut not that you’re getting your work done. It’s easy to confuse motion with progress, \\nbusy-ness with being productive. The most important work in effective programming \\nis thinking, and people tend not to look busy when they’re thinking. If I worked with \\na programmer who looked busy all the time, I’d assume that he was not a good pro-\\ngrammer because he wasn’t using his most valuable tool, his brain.\\n33.8 Characteristics That Don’t Matter As Much As You \\nMight Think\\nHustle isn’t the only characteristic that you might admire in other aspects of your life \\nbut that doesn’t work very well in software development.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 867}, page_content='33.8 Characteristics That Don’t Matter As Much As You Might Think 831\\nPersistence\\nDepending on the situation, persistence can be either an asset or a liability. Like most \\nvalue-laden concepts, it’s identified by different words depending on whether you \\nthink it’s a good quality or a bad one. If you want to identify persistence as a bad qual-\\nity, you say it’s “stubbornness” or “pigheadedness.” If you want it to be a good quality, \\nyou call it “tenacity” or “perseverance.”\\nMost of the time, persistence in software development is pigheadedness—it has little \\nvalue. Persistence when you’re stuck on a piece of new code is hardly ever a virtue. Try \\nredesigning the class, try an alternative coding approach, or try coming back to it later. \\nWhen one approach isn’t working, that’s a good time to try an alternative (Pirsig 1974).\\nCross-Reference For a more \\ndetailed discussion of persis-\\ntence in debugging, see \\n“Tips for Finding Defects” in \\nSection 23.2.\\nIn debugging, it can be mighty satisfying to track down the error that has been annoy-\\ning you for four hours, but it’s often better to give up on the error after a certain \\namount of time with no progress—say 15 minutes. Let your subconscious chew on the \\nproblem for a while. Try to think of an alternative approach that would circumvent the \\nproblem altogether. Rewrite the troublesome section of code from scratch. Come back \\nto it later when your mind is fresh. Fighting computer problems is no virtue. Avoiding \\nthem is better.\\nIt’s hard to know when to give up, but it’s essential that you ask. When you notice that \\nyou’re frustrated, that’s a good time to ask the question. Asking doesn’t necessarily \\nmean that it’s time to give up, but it probably means that it’s time to set some param-\\neters on the activity: “If I don’t solve the problem using this approach within the next \\n30 minutes, I’ll take 10 minutes to brainstorm about different approaches and try the \\nbest one for the next hour.”\\nExperience\\nThe value of hands-on experience as compared to book learning is smaller in software \\ndevelopment than in many other fields for several reasons. In many other fields, basic \\nknowledge changes slowly enough that someone who graduated from college 10 \\nyears after you did probably learned the same basic material that you did. In software \\ndevelopment, even basic knowledge changes rapidly. The person who graduated from \\ncollege 10 years after you did probably learned twice as much about effective program-\\nming techniques. Older programmers tend to be viewed with suspicion not just \\nbecause they might be out of touch with specific technology but because they might \\nnever have been exposed to basic programming concepts that became well known \\nafter they left school.\\nIn other fields, what you learn about your job today is likely to help you in your job \\ntomorrow. In software, if you can’t shake the habits of thinking you developed while \\nusing your former programming language or the code-tuning techniques that worked \\non your old machine, your experience will be worse than none at all. A lot of software'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 868}, page_content='832 Chapter 33: Personal Character\\npeople spend their time preparing to fight the last war rather than the next one. If you \\ncan’t change with the times, experience is more a handicap than a help.\\nAside from the rapid changes in software development, people often draw the wrong \\nconclusions from their experiences. It’s hard to view your own life objectively. You can \\noverlook key elements of your experience that would cause you to draw different con-\\nclusions if you recognized them. Reading studies of other programmers is helpful \\nbecause the studies reveal other people’s experience—filtered enough that you can \\nexamine it objectively.\\nPeople also put an absurd emphasis on the amount of experience programmers have. \\n“We want a programmer with five years of C programming experience” is a silly state-\\nment. If a programmer hasn’t learned C after a year or two, the next three years won’t \\nmake much difference. This kind of “experience” has little relationship to performance.\\nThe fact that information changes quickly in programming makes for weird dynamics \\nin the area of “experience.” In many fields, a professional who has a history of achieve-\\nment can coast, relaxing and enjoying the respect earned by a string of successes. In \\nsoftware development, anyone who coasts quickly becomes out of touch. To stay valu-\\nable, you have to stay current. For young, hungry programmers, this is an advantage. \\nOlder programmers sometimes feel they’ve already earned their stripes and resent \\nhaving to prove themselves year after year.\\nThe bottom line on experience is this: if you work for 10 years, do you get 10 years of \\nexperience or do you get 1 year of experience 10 times? You have to reflect on your \\nactivities to get true experience. If you make learning a continuous commitment, \\nyou’ll get experience. If you don’t, you won’t, no matter how many years you have \\nunder your belt.\\nGonzo Programming\\nIf you haven’t spent at least a month working on the same program—working 16 \\nhours a day, dreaming about it during the remaining 8 hours of restless sleep, \\nworking several nights straight through trying to eliminate that “one last bug” \\nfrom the program—then you haven’t really written a complicated computer pro-\\ngram. And you may not have the sense that there is something exhilarating \\nabout programming.\\n—Edward Yourdon\\nThis lusty tribute to programming machismo is pure B.S. and an almost certain recipe \\nfor failure. Those all-night programming stints make you feel like the greatest pro-\\ngrammer in the world, but then you have to spend several weeks correcting the \\ndefects you installed during your blaze of glory. By all means, get excited about pro-\\ngramming. But excitement is no substitute for competency. Remember which is more \\nimportant.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 869}, page_content='33.9 Habits 833\\n33.9 Habits\\nThe moral virtues, then, are engendered in us neither by nor contrary to \\nnature...their full development in us is due to habit....Anything that we have to \\nlearn to do we learn by the actual doing of it....Men will become good builders \\nas a result of building well and bad ones as a result of building badly....So it is \\na matter of no little importance what sort of habits we form from the earliest \\nage—it makes a vast difference, or rather all the difference in the world.\\n—Aristotle\\nGood habits matter because most of what you do as a programmer you do without \\nconsciously thinking about it. For example, at one time, you might have thought \\nabout how you wanted to format indented loops, but now you don’t think about it \\nagain each time you write a new loop. You do it the way you do it out of habit. This is \\ntrue of virtually all aspects of program formatting. When was the last time you seri-\\nously questioned your formatting style? Chances are good that if you’ve been pro-\\ngramming for five years, you last questioned it four and a half years ago. The rest of the \\ntime you’ve relied on habit.\\nCross-Reference For details \\non errors in assignment \\nstatements, see “Errors by \\nClassification” in Section \\n22.4.\\nYou have habits in many areas. For example, programmers tend to check loop indexes \\ncarefully and not to check assignment statements, which makes errors in assignment \\nstatements much harder to find than errors in loop indexes (Gould 1975). You \\nrespond to criticism in a friendly way or in an unfriendly way. You’re always looking \\nfor ways to make code readable or fast, or you’re not. If you have to choose between \\nmaking code fast and making it readable, and you make the same choice every time, \\nyou’re not really choosing—you’re responding out of habit.\\nStudy the quotation from Aristotle and substitute “programming virtues” for “moral vir-\\ntues.” He points out that you are not predisposed to either good or bad behavior but are \\nconstituted in such a way that you can become either a good or a bad programmer. The \\nmain way you become good or bad at what you do is by doing—builders by building and \\nprogrammers by programming. What you do becomes habit, and over time your good \\nand bad habits determine whether you’re a good or a bad programmer.\\nBill Gates says that any programmer who will ever be good is good in the first few \\nyears. After that, whether a programmer is good or not is cast in concrete (Lammers \\n1986). After you’ve been programming a long time, it’s hard to suddenly start saying, \\n“How do I make this loop faster?” or “How do I make this code more readable?” These \\nare habits that good programmers develop early.\\nWhen you first learn something, learn it the right way. When you first do it, you’re \\nactively thinking about it and you still have an easy choice between doing it in a good \\nway and doing it in a bad way. After you’ve done it a few times, you pay less attention \\nto what you’re doing and “force of habit” takes over. Make sure that the habits that \\ntake over are the ones you want to have.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 870}, page_content='834 Chapter 33: Personal Character\\nWhat if you don’t already have the most effective habits? How do you change a bad \\nhabit? If I had the definitive answer to that, I could sell self-help tapes on late-night TV. \\nBut here’s at least part of an answer. You can’t replace a bad habit with no habit at all. \\nThat’s why people who suddenly stop smoking or swearing or overeating have such a \\nhard time unless they substitute something else, like chewing gum. It’s easier to \\nreplace an old habit with a new one than it is to eliminate one altogether. In program-\\nming, try to develop new habits that work. Develop the habits of writing a class in \\npseudocode before coding it and carefully reading the code before compiling it, for \\ninstance. You won’t have to worry about losing the bad habits; they’ll naturally drop \\nby the wayside as new habits take their places.\\nAdditional Resources\\ncc2e.com/3327 Following are additional resources on the human aspects of software development:\\ncc2e.com/3334 Dijkstra, Edsger. “The Humble Programmer.” Turing Award Lecture. Communications \\nof the ACM 15, no. 10 (October 1972): 859–66. This classic paper helped begin the \\ninquiry into how much computer programming depends on the programmer’s men-\\ntal abilities. Dijkstra has persistently stressed the message that the essential task of \\nprogramming is mastering the enormous complexity of computer science. He argues \\nthat programming is the only activity in which humans have to master nine orders of \\nmagnitude of difference between the lowest level of detail and the highest. This paper \\nwould be interesting reading solely for its historical value, but many of its themes \\nsound fresh decades later. It also conveys a good sense of what it was like to be a pro-\\ngrammer in the early days of computer science.\\nWeinberg, Gerald M. The Psychology of Computer Programming: Silver Anniversary \\nEdition. New York, NY: Dorset House, 1998. This classic book contains a detailed \\nexposition of the idea of egoless programming and of many other aspects of the \\nhuman side of computer programming. It contains many entertaining anecdotes and \\nis one of the most readable books yet written about software development.\\nPirsig, Robert M. Zen and the Art of Motorcycle Maintenance: An Inquiry into Values. \\nWilliam Morrow, 1974. Pirsig provides an extended discussion of “quality,” ostensibly \\nas it relates to motorcycle maintenance. Pirsig was working as a software technical \\nwriter when he wrote ZAMM, and his insightful comments apply as much to the psy-\\nchology of software projects as to motorcycle maintenance.  \\nCurtis, Bill, ed. Tutorial: Human Factors in Software Development . Los Angeles, CA: \\nIEEE Computer Society Press, 1985. This is an excellent collection of papers that \\naddress the human aspects of creating computer programs. The 45 papers are \\ndivided into sections on mental models of programming knowledge, learning to pro-\\ngram, problem solving and design, effects of design representations, language char-\\nacteristics, error diagnosis,  and methodology. If programming is one of the most'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 871}, page_content='Key Points 835\\ndifficult intellectual challenges that humank ind has ever faced, learning more about \\nhuman mental capacities is critical to the success of the endeavor. These papers \\nabout psychological factors also help you to turn your mind inward and learn about \\nhow you individually can program more effectively.\\nMcConnell, Steve. Professional Software Development. Boston, MA: Addison-Wesley, \\n2004. Chapter 7, “Orphans Preferred,” provides more details on programmer person-\\nalities and the role of personal character.\\nKey Points\\n■ Your personal character directly affects your ability to write computer programs.\\n■ The characteristics that matter most are humility, curiosity, intellectual honesty, \\ncreativity and discipline, and enlightened laziness.\\n■ The characteristics of a superior programmer have almost nothing to do with \\ntalent and everything to do with a commitment to personal development.\\n■ Surprisingly, raw intelligence, experience, persistence, and guts hurt as much as \\nthey help.\\n■ Many programmers don’t actively seek new information and techniques and \\ninstead rely on accidental, on-the-job exposure to new information. If you \\ndevote a small percentage of your time to reading and learning about program-\\nming, after a few months or years you’ll dramatically distinguish yourself from \\nthe programming mainstream.\\n■ Good character is mainly a matter of having the right habits. To be a great \\nprogrammer, develop the right habits and the rest will come naturally.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 873}, page_content='837\\nChapter 34\\nThemes in Software \\nCraftsmanship\\ncc2e.com/3444 Contents\\n■ 34.1 Conquer Complexity: page 837\\n■ 34.2 Pick Your Process: page 839\\n■ 34.3 Write Programs for People First, Computers Second: page 841\\n■ 34.4 Program into Your Language, Not in It: page 843\\n■ 34.5 Focus Your Attention with the Help of Conventions: page 844\\n■ 34.6 Program in Terms of the Problem Domain: page 845\\n■ 34.7 Watch for Falling Rocks: page 848\\n■ 34.8 Iterate, Repeatedly, Again and Again: page 850\\n■ 34.9 Thou Shalt Rend Software and Religion Asunder: page 851\\nRelated Topics\\n■ The whole book\\nThis book is mostly about the details of software construction: high-quality classes, \\nvariable names, loops, source-code layout, system integration, and so on. This book \\nhas deemphasized abstract topics to emphasize subjects that are more concrete.\\nOnce the earlier parts of the book have put the concrete topics on the table, all you \\nhave to do to appreciate the abstract concepts is to pick up the topics from the various \\nchapters and see how they’re related. This chapter makes the abstract themes explicit: \\ncomplexity, abstraction, process, readability, iteration, and so on. These themes \\naccount in large part for the difference between hacking and software craftsmanship.\\n34.1 Conquer Complexity\\nCross-Reference For details \\non the importance of atti-\\ntude in conquering complex-\\nity, see Section 33.2, \\n“Intelligence and Humility.”\\nThe drive to reduce complexity is at the heart of software development, to such a \\ndegree that Chapter 5, “Design in Construction,” described managing complexity as \\nSoftware’s Primary Technical Imperative. Alth ough it’s tempting to try to be a hero \\nand deal with computer-science problems at all levels, no one’s brain is really capa-\\nble of spanning nine orders of magnitude of detail. Computer science and software'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 874}, page_content='838 Chapter 34: Themes in Software Craftsmanship\\nengineering have developed many intellectual tools for handling such complexity, and \\ndiscussions of other topics in this book have brushed up against several of them:\\n■ Dividing a system into subsystems at the architecture level so that your brain \\ncan focus on a smaller amount of the system at one time.\\n■ Carefully defining class interfaces so that you can ignore the internal workings \\nof the class.\\n■ Preserving the abstraction represented by the class interface so that your brain \\ndoesn’t have to remember arbitrary details.\\n■ Avoiding global data, because global data vastly increases the percentage of the \\ncode you need to juggle in your brain at any one time.\\n■ Avoiding deep inheritance hierarchies because they are intellectually demanding.\\n■ Avoiding deep nesting of loops and conditionals because they can be replaced \\nby simpler control structures that burn up fewer gray cells.\\n■ Avoiding gotos because they introduce nonlinearity that has been found to be \\ndifficult for most people to follow.\\n■ Carefully defining your approach to error handling rather than using an arbi-\\ntrary proliferation of different error-handling techniques.\\n■ Being systematic about the use of the built-in exception mechanism, which can \\nbecome a nonlinear control structure that’s about as hard to understand as gotos \\nif not used with discipline.\\n■ Not allowing classes to grow into monster classes that amount to whole pro-\\ngrams in themselves.\\n■ Keeping routines short.\\n■ Using clear, self-explanatory variable names so that your brain doesn’t have to \\nwaste cycles remembering details like “i stands for the account index, and j \\nstands for the customer index, or was it the other way around?” \\n■ Minimizing the number of parameters passed to a routine, or, more important, \\npassing only the parameters needed to preserve the routine interface’s abstraction.\\n■ Using conventions to spare your brain the challenge of remembering arbitrary, \\naccidental differences between different sections of code.\\n■ In general, attacking what Chapter 5 describes as “accidental difficulties” wher-\\never possible.\\nWhen you put a complicated test into a boolean function and abstract the purpose of \\nthe test, you make the code less complex. When you substitute a table lookup for a \\ncomplicated chain of logic, you do the same thing. When you create a well-defined,'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 875}, page_content='34.2 Pick Your Process 839\\nconsistent class interface, you eliminate the need to worry about implementation \\ndetails of the class and you simplify your job overall.\\nThe point of having coding conventions is also mainly to reduce complexity. When \\nyou can standardize decisions about formatting, loops, variable names, modeling \\nnotations, and so on, you release mental resources that you need to focus on more \\nchallenging aspects of the programming problem. One reason coding conventions are \\nso controversial is that choices among the options have some limited aesthetic base \\nbut are essentially arbitrary. People have the most heated arguments over their small-\\nest differences. Conventions are the most useful when they spare you the trouble of \\nmaking and defending arbitrary decisions. They’re less valuable when they impose \\nrestrictions in more meaningful areas.\\nAbstraction in its various forms is a particularly powerful tool for managing complex-\\nity. Programming has advanced largely through increasing the abstractness of pro-\\ngram components. Fred Brooks argues that the biggest single gain ever made in \\ncomputer science was in the jump from machine language to higher-level languages—\\nit freed programmers from worrying about the detailed quirks of individual pieces of \\nhardware and allowed them to focus on programming (Brooks 1995). The idea of rou-\\ntines was another big step, followed by classes and packages.\\nNaming variables functionally, for the “what” of the problem rather than the “how” of \\nthe implementation-level solution, increases the level of abstraction. If you say, “OK, \\nI’m popping the stack and that means that I’m getting the most recent employee,” \\nabstraction can save you the mental step “I’m popping the stack.” You simply say, “I’m \\ngetting the most recent employee.” This is a small gain, but when you’re trying to \\nreduce a range in complexity of 1 to 109, every step counts. Using named constants \\nrather than literals also increases the level of abstraction. Object-oriented program-\\nming provides a level of abstraction that applies to algorithms and data at the same \\ntime, a kind of abstraction that functional decomposition alone didn’t provide.\\nIn summary, a primary goal of software design and construction is conquering com-\\nplexity. The motivation behind many programming practices is to reduce a program’s \\ncomplexity, and reducing complexity is arguably the most important key to being an \\neffective programmer.\\n34.2 Pick Your Process\\nA second major thread in this book is the idea that the process you use to develop soft-\\nware matters a surprising amount. On a small project, the talents of the individual \\nprogrammer are the biggest influence on the quality of the software. Part of what \\nmakes an individual programmer successful is his or her choice of processes.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 876}, page_content='840 Chapter 34: Themes in Software Craftsmanship\\nOn projects with more than one programmer, organizational characteristics make a big-\\nger difference than the skills of the individuals involved do. Even if you have a great \\nteam, its collective ability isn’t simply the sum of the team members’ individual abilities. \\nThe way in which people work together determines whether their abilities are added to \\neach other or subtracted from each other. The process the team uses determines \\nwhether one person’s work supports the work of the rest of the team or undercuts it.\\nCross-Reference For details \\non making requirements sta-\\nble, see Section 3.4, \\n“Requirements Prerequi-\\nsite.” For details on variations \\nin development approaches, \\nsee Section 3.2, “Determine \\nthe Kind of Software You’re \\nWorking On.”\\nOne example of the way in which process matters is the consequence of not making \\nrequirements stable before you begin designing and coding. If you don’t know what \\nyou’re building, you can’t very well create a superior design for it. If the requirements \\nand subsequently the design change while the software is under development, the \\ncode must change too, which risks degrading the quality of the system.\\n“Sure,” you say, “but in the real world, you never really have stable requirements, so \\nthat’s a red herring.” Again, the process you use determines both how stable your \\nrequirements are and how stable they need to be. If you want to build more flexibility \\ninto the requirements, you can set up an incremental development approach in which \\nyou plan to deliver the software in several increments rather than all at once. This is an \\nattention to process, and it’s the process you use that ultimately determines whether \\nyour project succeeds or fails. Table 3-1 in Section 3.1 makes it clear that requirements \\nerrors are far more costly than construction errors, so focusing on that part of the pro-\\ncess also affects cost and schedule.\\nMy message to the serious \\nprogrammer is: spend a part \\nof your working day examin-\\ning and refining your own \\nmethods. Even though pro-\\ngrammers are always strug-\\ngling to meet some future or \\npast deadline, methodologi-\\ncal abstraction is a wise \\nlong-term investment.  \\n—Robert W. Floyd\\nThe same principle of consciously attending to process applies to design. You have to \\nlay a solid foundation before you can begin building on it. If you rush to coding before \\nthe foundation is complete, it will be harder to make fundamental changes in the sys-\\ntem’s architecture. People will have an emotional investment in the design because \\nthey will have already written code for it. It’s hard to throw away a bad foundation \\nonce you’ve started building a house on it.\\nThe main reason the process matters is that in software, quality must be built in from \\nthe first step onward. This flies in the face of the folk wisdom that you can code like \\nhell and then test all the mistakes out of the software. That idea is dead wrong. Testing \\nmerely tells you the specific ways in which your software is defective. Testing won’t \\nmake your program more usable, faster, smaller, more readable, or more extensible.\\nPremature optimization is another kind of process error. In an effective process, you \\nmake coarse adjustments at the beginning and fine adjustments at the end. If you \\nwere a sculptor, you’d rough out the general shape before you started polishing indi-\\nvidual features. Premature optimization wastes time because you spend time polish-\\ning sections of code that don’t need to be polished. You might polish sections that are \\nsmall enough and fast enough as they are, you might polish code that you later throw \\naway, and you might fail to throw away bad code because you’ve already spent time \\npolishing it. Always be thinking, “Am I doing this in the right order? Would changing \\nthe order make a difference?” Consciously follow a good process.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 877}, page_content='34.3 Write Programs for People First, Computers Second 841\\nCross-Reference For details \\non iteration, see Section \\n34.8, “Iterate, Repeatedly, \\nAgain and Again,” later in \\nthis chapter.\\nLow-level processes matter, too. If you follow the process of writing pseudocode and \\nthen filling in the code around the pseudocode, you reap the benefits of designing \\nfrom the top down. You’re also guaranteed to have comments in the code without hav-\\ning to put them in later.\\nObserving large processes and small processes means pausing to pay attention to how \\nyou create software. It’s time well spent. Saying that “code is what matters; you have to \\nfocus on how good the code is, not some abstract process” is shortsighted and ignores \\nmountains of experimental and practical evidence to the contrary. Software development \\nis a creative exercise. If you don’t understand the creative process, you’re not getting the \\nmost out of the primary tool you use to create software—your brain. A bad process wastes \\nyour brain cycles. A good process leverages them to maximum advantage.\\n34.3 Write Programs for People First, Computers Second\\nyour program n. A maze of non sequiturs littered with clever-clever tricks and \\nirrelevant comments. Compare MY PROGRAM.\\nmy program n. A gem of algoristic precision, offering the most sublime balance \\nbetween compact, efficient coding on the one hand and fully commented legibil-\\nity for posterity on the other. Compare YOUR PROGRAM.\\n—Stan Kelly-Bootle\\nAnother theme that runs throughout this book is an emphasis on code readability. \\nCommunication with other people is the motivation behind the quest for the Holy \\nGrail of self-documenting code.\\nThe computer doesn’t care whether your code is readable. It’s better at reading binary \\nmachine instructions than it is at reading high-level-language statements. You write \\nreadable code because it helps other people to read your code. Readability has a posi-\\ntive effect on all these aspects of a program:\\n■ Comprehensibility\\n■ Reviewability\\n■ Error rate\\n■ Debugging\\n■ Modifiability\\n■ Development time—a consequence of all of the above\\n■ External quality—a consequence of all of the above'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 878}, page_content='842 Chapter 34: Themes in Software Craftsmanship\\nIn the early years of pro-\\ngramming, a program was \\nregarded as the private \\nproperty of the programmer. \\nOne would no more think of \\nreading a colleague’s pro-\\ngram unbidden than of pick-\\ning up a love letter and \\nreading it. This is essentially \\nwhat a program was, a love \\nletter from the programmer \\nto the hardware, full of the \\nintimate details known only \\nto partners in an affair. Con-\\nsequently, programs became \\nlarded with the pet names \\nand verbal shorthand so \\npopular with lovers who live \\nin the blissful abstraction \\nthat assumes that theirs is \\nthe only existence in the uni-\\nverse. Such programs are \\nunintelligible to those out-\\nside the partnership.  \\n—Michael Marcotty\\nReadable code doesn’t take any longer to write than confusing code does, at least not in \\nthe long run. It’s easier to be sure your code works if you can easily read what you wrote. \\nThat should be a sufficient reason to write readable code. But code is also read during \\nreviews. It’s read when you or someone else fixes an error. It’s read when the code is \\nmodified. It’s read when someone tries to use part of your code in a similar program.\\nMaking code readable is not an optional part of the development process, and favor-\\ning write-time convenience over read-time convenience is a false economy. You should \\ngo to the effort of writing good code, which you can do once, rather than the effort of \\nreading bad code, which you’d have to do again and again.\\n“What if I’m just writing code for myself? Why should I make it readable?” Because a \\nweek or two from now you’re going to be working on another program and think, \\n“Hey! I already wrote this class last week. I’ll just drop in my old tested, debugged \\ncode and save some time.” If the code isn’t readable, good luck!\\nThe idea of writing unreadable code because you’re the only person working on a \\nproject sets a dangerous precedent. Your mother used to say, “What if your face froze \\nin that expression?” And your dad used to say, “You play how you practice.” Habits \\naffect all your work; you can’t turn them on and off at will, so be sure that what you’re \\ndoing is something you want to become a habit. A professional programmer writes \\nreadable code, period.\\nIt’s also good to recognize that whether a piece of code ever belongs exclusively to you \\nis debatable. Douglas Comer came up with a useful distinction between private and \\npublic programs (Comer 1981): “Private programs” are programs for a programmer’s \\nown use. They aren’t used by others. They aren’t modified by others. Others don’t even \\nknow the programs exist. They are usually trivial, and they are the rare exception. “Pub-\\nlic programs” are programs used or modified by someone other than the author.\\nStandards for public and for private programs can be different. Private programs can \\nbe sloppily written and full of limitations without affecting anyone but the author. \\nPublic programs must be written more carefully: their limitations should be docu-\\nmented, they should be reliable, and they should be modifiable. Beware of a private \\nprogram’s becoming public, as private programs often do. You need to convert the \\nprogram to a public program before it goes into general circulation. Part of making a \\nprivate program public is making it readable.\\nEven if you think you’re the only one who will read your code, in the real world \\nchances are good that someone else will need to modify your code. One study found \\nthat 10 generations of maintenance programmers work on an average program before \\nit gets rewritten (Thomas 1984). Maintenance programmers spend 50 to 60 percent \\nof their time trying to understand the code they have to maintain, and they appreciate \\nthe time you put into documenting it (Parikh and Zvegintzov 1983).\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 879}, page_content='34.4 Program into Your Language, Not in It 843\\nEarlier chapters in this book examined the techniques that help you achieve readabil-\\nity: good class, routine, and variable names, careful formatting, small routines, hiding \\ncomplex boolean tests in boolean functions, assigning intermediate results to vari-\\nables for clarity in complicated calculations, and so on. No individual application of a \\ntechnique can make the difference between a readable program and an illegible one, \\nbut the accumulation of many small readability improvements will be significant.\\nIf you think you don’t need to make your code readable because no one else ever \\nlooks at it, make sure you’re not confusing cause and effect.\\n34.4 Program into Your Language, Not in It\\nDon’t limit your programming thinking only to the concepts that are supported auto-\\nmatically by your language. The best programmers think of what they want to do, and \\nthen they assess how to accomplish their objectives with the programming tools at \\ntheir disposal.\\nShould you use a class member routine that’s inconsistent with the class’s abstraction \\njust because it’s more convenient than using one that provides more consistency? You \\nshould write code in a way that preserves the abstraction represented by the class’s \\ninterface as much as possible. You don’t need to use global data or gotos just because \\nyour language supports them. You can choose not to use those hazardous program-\\nming capabilities and instead use programming conventions to make up for weak-\\nnesses of the language. Programming using the most obvious path amounts to \\nprogramming in a language rather than programming into a language; it’s the pro-\\ngrammer’s equivalent of “If Freddie jumped off a bridge, would you jump off a bridge, \\ntoo?” Think about your technical goals, and then decide how best to accomplish those \\ngoals by programming into your language.\\nYour language doesn’t support assertions? Write your own assert() routine. It might \\nnot function exactly the same as a built-in assert(), but you can still realize most of \\nassert()’s benefits by writing your own routine. Your language doesn’t support enu-\\nmerated types or named constants? That’s fine; you can define your own enumera-\\ntions and named constants with a disciplined use of global variables supported by \\nclear naming conventions.\\nIn extreme cases, especially in new-technology environments, your tools might be so \\nprimitive that you’re forced to change your desired programming approach signifi-\\ncantly. In such cases, you might have to balance your desire to program into the lan-\\nguage with the accidental difficulties that are created when the language makes your \\ndesired approach too cumbersome. But in such cases, you’ll benefit even more from \\nprogramming conventions that help you steer clear of those environments’ most haz-\\nardous features. In more typical cases, the gap between what you want to do and what \\nyour tools will readily support will require you to make only relatively minor conces-\\nsions to your environment.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 880}, page_content='844 Chapter 34: Themes in Software Craftsmanship\\n34.5 Focus Your Attention with the Help of Conventions\\nCross-Reference For an \\nanalysis of the value of con-\\nventions as they apply to \\nprogram layout, see “How \\nMuch Is Good Layout \\nWorth?” and “Objectives of \\nGood Layout” in Section \\n31.1.\\nA set of conventions is one of the intellectual tools used to manage complexity. Earlier \\nchapters talk about specific conventions. This section lays out the benefits of conven-\\ntions with many examples.\\nMany of the details of programming are somewhat arbitrary. How many spaces do \\nyou indent a loop? How do you format a comment? How should you order class rou-\\ntines? Most of the questions like these have several correct answers. The specific way \\nin which such a question is answered is less important than that it be answered con-\\nsistently each time. Conventions save programmers the trouble of answering the same \\nquestions—making the same arbitrary deci sions—again and again. On projects with \\nmany programmers, using conventions prevents the confusion that results when dif-\\nferent programmers make the arbitrary decisions differently.\\nA convention conveys important information concisely. In naming conventions, a sin-\\ngle character can differentiate among local, class, and global variables; capitalization \\ncan concisely differentiate among types, named constants, and variables. Indentation \\nconventions can concisely show the logical structure of a program. Alignment conven-\\ntions can indicate concisely that statements are related.\\nConventions protect against known hazards. You can establish conventions to elimi-\\nnate the use of dangerous practices, to restrict such practices to cases in which they’re \\nneeded, or to compensate for their known hazards. You could eliminate a dangerous \\npractice, for example, by prohibiting global variables or prohibiting multiple state-\\nments on a line. You could compensate for a hazardous practice by requiring paren-\\ntheses around complicated expressions or requiring pointers to be set to NULL \\nimmediately after they’re deleted to help prevent dangling pointers.\\nConventions add predictability to low-level tasks. Having conventional ways of han-\\ndling memory requests, error processing, input/output, and class interfaces adds a \\nmeaningful structure to your code and makes it easier for another programmer to fig-\\nure out—as long as the programmer knows your conventions. As mentioned in an ear-\\nlier chapter, one of the biggest benefits of eliminating global data is that you eliminate \\npotential interactions among different classes and subsystems. A reader knows \\nroughly what to expect from local and class data. But it’s hard to tell when changing \\nglobal data will break some bit of code four subsystems away. Global data increases \\nthe reader’s uncertainty. With good conventions, you and your readers can take more \\nfor granted. The amount of detail that has to be assimilated will be reduced, and that \\nin turn will improve program comprehension.\\nConventions can compensate for language weaknesses. In languages that don’t sup-\\nport named constants (such as Python, Perl, UNIX shell script, and so on), a conven-\\ntion can differentiate between variables intended to be both read and written and'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 881}, page_content='34.6 Program in Terms of the Problem Domain 845\\nthose that are intended to emulate read-only constants. Conventions for the disci-\\nplined use of global data and pointers are other examples of compensating for lan-\\nguage weaknesses with conventions.\\nProgrammers on large projects sometimes go overboard with conventions. They \\nestablish so many standards and guidelines that remembering them becomes a full-\\ntime job. But programmers on small projects tend to go “underboard,” not realizing \\nthe full benefits of intelligently conceived conventions. You should understand their \\nreal value and take advantage of them; you should use them to provide structure in \\nareas in which structure is needed.\\n34.6 Program in Terms of the Problem Domain\\nAnother specific method of dealing with complexity is to work at the highest possible \\nlevel of abstraction. One way of working at a high level of abstraction is to work in \\nterms of the programming problem rather than the computer-science solution.\\nTop-level code shouldn’t be filled with details about files and stacks and queues and \\narrays and characters whose parents couldn’t think of better names for them than i, j, \\nand k. Top-level code should describe the problem that’s being solved. It should be \\npacked with descriptive class names and routine calls that indicate exactly what the \\nprogram is doing, not cluttered with details about opening a file as “read only.” Top-\\nlevel code shouldn’t contain clumps of comments that say “i is a variable that repre-\\nsents the index of the record from the employee file here, and then a little later it’s \\nused to index the client account file there.”\\nThat’s clumsy programming practice. At the top level of the program, you don’t need \\nto know that the employee data comes as records or that it’s stored as a file. Informa-\\ntion at that level of detail should be hidden. At the highest level, you shouldn’t have \\nany idea how the data is stored. Nor do you need to read a comment that explains \\nwhat i means and that it’s used for two purposes. You should see different variable \\nnames for the two purposes instead, and they should also have distinctive names such \\nas employeeIndex and clientIndex.\\nSeparating a Program into Levels of Abstraction\\nObviously, you have to work in implementation-level terms at some level, but you can \\nisolate the part of the program that works in implementation-level terms from the part \\nthat works in problem-domain terms. If you’re designing a program, consider the lev-\\nels of abstraction shown in Figure 34-1.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 882}, page_content='846 Chapter 34: Themes in Software Craftsmanship\\nFigure 34-1 Programs can be divided into levels of abstraction. A good design will allow \\nyou to spend much of your time focusing on only the upper layers and ignoring the lower \\nlayers.\\nLevel 0: Operating-System Operations and Machine Instructions\\nIf you’re working in a high-level language, you don’t have to worry about the lowest \\nlevel—your language takes care of it automatically. If you’re working in a low-level lan-\\nguage, you should try to create higher layers for yourself to work in, even though many \\nprogrammers don’t do that.\\nLevel 1: Programming-Language Structures and Tools\\nProgramming-language structures are the language’s primitive data types, control struc-\\ntures, and so on. Most common languages also provide additional libraries, access to \\noperating system calls, and so on. Using these structures and tools comes naturally \\nsince you can’t program without them. Many programmers never work above this level \\nof abstraction, which makes their lives much harder than they need to be.\\nLevel 2: Low-Level Implementation Structures\\nLow-level implementation structures are slightly higher-level structures than those \\nprovided by the language itself. They tend to be the operations and data types you \\nlearn about in college courses in algorithms and data types: stacks, queues, linked \\nlists, trees, indexed files, sequential files, sort algorithms, search algorithms, and so \\non. If your program consists entirely of code written at this level, you’ll be awash in \\ntoo much detail to win the battle against complexity.\\nLevel 3: Low-Level Problem-Domain Terms\\nAt this level, you have the primitives you need to work in terms of the problem \\ndomain. It’s a glue layer between the computer-science structures below and the high-\\nlevel problem-domain code above. To write code at this level, you need to figure out \\n4\\nHigh-level problem-domain terms\\n3\\nLow-level problem-domain terms\\n2\\nLow-level implementation structures\\n1\\nProgramming-language structures and tools \\n0\\nOperating-system operations and machine instructions'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 883}, page_content='34.6 Program in Terms of the Problem Domain 847\\nthe vocabulary of the problem area and create building blocks you can use to work \\nwith the problem the program solves. In many applications, this will be the business \\nobjects layer or a services layer. Classes at this level provide the vocabulary and the \\nbuilding blocks. The classes might be too primitive to be used to solve the problem \\ndirectly at this level, but they provide a framework that higher-level classes can use to \\nbuild a solution to the problem.\\nLevel 4: High-Level Problem-Domain Terms\\nThis level provides the abstractive power to work with a problem on its own terms. \\nYour code at this level should be somewhat readable by someone who’s not a com-\\nputer-science whiz, perhaps even by your nontechnical customer. Code at this level \\nwon’t depend much on the specific features of your programming language because \\nyou’ll have built your own set of tools to work with the problem. Consequently, at this \\nlevel your code depends more on the tools you’ve built for yourself at Level 3 than on \\nthe capabilities of the language you’re using.\\nImplementation details should be hidden two layers below this one, in a layer of com-\\nputer-science structures, so that changes in hardware or the operating system don’t \\naffect this layer at all. Embody the user’s view of the world in the program at this level \\nbecause when the program changes, it will change in terms of the user’s view. \\nChanges in the problem domain should affect this layer a lot, but they should be easy \\nto accommodate by programming in the problem-domain building blocks from the \\nlayer below.\\nIn addition to these conceptual layers, many programmers find it useful to break a \\nprogram up into other “layers” that cut across the layers described here. For example, \\nthe typical three-tier architecture cuts across the levels described here and provides \\nfurther tools for making the design and code intellectually manageable.\\nLow-Level Techniques for Working in the Problem Domain\\nEven without a complete, architectural approach to working in the problem area’s \\nvocabulary, you can use many of the techniques in this book to work in terms of the \\nreal-world problem rather than the computer-science solution:\\n■ Use classes to implement structures that are meaningful in problem-domain \\nterms.\\n■ Hide information about the low-level data types and their implementation \\ndetails.\\n■ Use named constants to document the meanings of strings and of numeric literals.\\n■ Assign intermediate variables to document the results of intermediate calculations.\\n■ Use boolean functions to clarify complex boolean tests.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 884}, page_content='848 Chapter 34: Themes in Software Craftsmanship\\n34.7 Watch for Falling Rocks\\nProgramming is neither fully an art nor fully a science. As it’s typically practiced, it’s a \\n“craft” that’s somewhere between art and science. At its best, it’s an engineering discipline \\nthat arises from the synergistic fusion of art and science (McConnell 2004). Whether art, \\nscience, craft, or engineering, it still takes plenty of individual judgment to create a work-\\ning software product. And part of having good judgment in computer programming is \\nbeing sensitive to a wide array of warning signs, subtle indications of problems in your \\nprogram. Warning signs in programming alert you to the possibility of problems, but \\nthey’re usually not as blatant as a road sign that says “Watch for falling rocks.”\\nWhen you or someone else says “This is really tricky code,” that’s a warning sign, usu-\\nally of poor code. “Tricky code” is a code phrase for “bad code.” If you think code is \\ntricky, think about rewriting it so that it’s not.\\nA class’s having more errors than average is a warning sign. A few error-prone classes \\ntend to be the most expensive part of a program. If you have a class that has had more \\nerrors than average, it will probably continue to have more errors than average. Think \\nabout rewriting it.\\nIf programming were a science, each warning sign would imply a specific, well-\\ndefined corrective action. Because programming is still a craft, however, a warning \\nsign merely points to an issue that you should consider. You can’t necessarily rewrite \\ntricky code or improve an error-prone class.\\nJust as an abnormal number of defects in a class warns you that the class has low qual-\\nity, an abnormal number of defects in a program implies that your process is defective. \\nA good process wouldn’t allow error-prone code to be developed. It would include the \\nchecks and balances of architecture followed by architecture reviews, design followed \\nby design reviews, and code followed by code reviews. By the time the code was ready \\nfor testing, most errors would have been eliminated. Exceptional performance \\nrequires working smart in addition to working hard. Lots of debugging on a project is \\na warning sign that implies people aren’t working smart. Writing a lot of code in a day \\nand then spending two weeks debugging it is not working smart.\\nYou can use design metrics as another kind of warning sign. Most design metrics are \\nheuristics that give an indication of the quality of a design. The fact that a class con-\\ntains more than seven members doesn’t necessarily mean that it’s poorly designed, \\nbut it’s a warning that the class is complicated. Similarly, more than about 10 decision \\npoints in a routine, more than three levels of logical nesting, an unusual number of \\nvariables, high coupling to other classes, or low class or routine cohesion should raise \\na warning flag. None of these signs necessarily means that a class is poorly designed, \\nbut the presence of any of them should cause you to look at the class skeptically.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 885}, page_content='34.7 Watch for Falling Rocks 849\\nAny warning sign should cause you to doubt the quality of your program. As Charles \\nSaunders Peirce says, “Doubt is an uneasy and dissatisfied state from which we strug-\\ngle to free ourselves and pass into the state of belief.” Treat a warning sign as an “irri-\\ntation of doubt” that prompts you to look for the more satisfied state of belief.\\nIf you find yourself working on repetitious code or making similar modifications in \\nseveral areas, you should feel “uneasy and dissatisfied,” doubting that control has \\nbeen adequately centralized in classes or routines. If you find it hard to create scaffold-\\ning for test cases because you can’t use an individual class easily, you should feel the \\n“irritation of doubt” and ask whether the class is coupled too tightly to other classes. \\nIf you can’t reuse code in other programs because some classes are too interdepen-\\ndent, that’s another warning sign that  the classes are coupled too tightly.\\nWhen you’re deep into a program, pay attention to warning signs that indicate that \\npart of the program design isn’t defined well enough to code. Difficulties in writing \\ncomments, naming variables, and decomposing the problem into cohesive classes \\nwith clear interfaces all indicate that you need to think harder about the design before \\ncoding. Wishy-washy names and difficulty in describing sections of code in concise \\ncomments are other signs of trouble. When the design is clear in your mind, the low-\\nlevel details come easily.\\nBe sensitive to indications that your program is hard to understand. Any discomfort is \\na clue. If it’s hard for you, it will be even harder for the next programmers. They’ll \\nappreciate the extra effort you make to improve it. If you’re figuring out code instead \\nof reading it, it’s too complicated. If it’s hard, it’s wrong. Make it simpler.\\nIf you want to take full advantage of warning signs, program in such a way that you \\ncreate your own warnings. This is useful because even after you know what the signs \\nare, it’s surprisingly easy to overlook them. Glenford Myers conducted a study of \\ndefect correction in which he found that the single most common cause of not finding \\nerrors was simply overlooking them. The errors were visible on test output but not \\nnoticed (Myers 1978b).\\nMake it hard to overlook problems in your program. One example is setting pointers \\nto null after you free them so that they’ll cause ugly problems if you mistakenly use \\none. A freed pointer might point to a valid memory location even after it’s been freed. \\nSetting it to null guarantees that it points to an invalid location, making the error \\nharder to overlook.\\nCompiler warnings are literal warning signs that are often overlooked. If your pro-\\ngram generates warnings or errors, fix it so that it doesn’t. You don’t have much \\nchance of noticing subtle warning signs when you’re ignoring those that have \\n“WARNING” printed directly on them.\\n1\\n2\\n3\\nHARD DATA'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 886}, page_content='850 Chapter 34: Themes in Software Craftsmanship\\nWhy is paying attention to intellectual warning signs especially important in software \\ndevelopment? The quality of the thinking that goes into a program largely determines \\nthe quality of the program, so paying attention to warnings about the quality of think-\\ning directly affects the final product.\\n34.8 Iterate, Repeatedly, Again and Again\\nIteration is appropriate for many software-development activities. During your initial \\nspecification of a system, you work with the user through several versions of require-\\nments until you’re sure you agree on them. That’s an iterative process. When you \\nbuild flexibility into your process by building and delivering a system in several incre-\\nments, that’s an iterative process. If you use prototyping to develop several alternative \\nsolutions quickly and cheaply before crafting the final product, that’s another form of \\niteration. Iterating on requirements is perhaps as important as any other aspect of the \\nsoftware-development process. Projects fail because they commit themselves to a solu-\\ntion before exploring alternatives. Iteration provides a way to learn about a product \\nbefore you build it.\\nAs Chapter 28, “Managing Construction,” points out, schedule estimates during ini-\\ntial project planning can vary greatly depending on the estimation technique you use. \\nUsing an iterative approach for estimation produces a more accurate estimate than \\nrelying on a single technique.\\nSoftware design is a heuristic process and, like all heuristic processes, is subject to iter-\\native revision and improvement. Software tends to be validated rather than proven, \\nwhich means that it’s tested and developed iteratively until it answers questions cor-\\nrectly. Both high-level and low-level design attempts should be repeated. A first \\nattempt might produce a solution that works, but it’s unlikely to produce the best \\nsolution. Taking several repeated and different approaches produces insight into the \\nproblem that’s unlikely with a single approach.\\nThe idea of iteration appears again in code tuning. Once the software is operational, \\nyou can rewrite small parts of it to greatly improve overall system performance. Many \\nof the attempts at optimization, however, hurt the code more than they help it. It’s not \\nan intuitive process, and some techniques that seem likely to make a system smaller \\nand faster actually make it larger and slower. The uncertainty about the effect of any \\noptimization technique creates a need for tuning, measuring, and tuning again. If a \\nbottleneck is critical to system performance, you can tune the code several times, and \\nseveral of your later attempts may be more successful than your first.\\nReviews cut across the grain of the development process, inserting iterations at any \\nstage in which they’re conducted. The purpose of a review is to check the quality of \\nthe work at a particular point. If the product fails the review, it’s sent back for rework. \\nIf it succeeds, it doesn’t need further iteration.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 887}, page_content='34.9 Thou Shalt Rend Software and Religion Asunder 851\\nOne definition of engineering is to do for a dime what anyone can do for a dollar. Iter-\\nating in the late stages is doing for two dollars what anyone can do for one dollar. Fred \\nBrooks suggested that you “build one to throw away; you will, anyhow” (Brooks \\n1995). The trick of software engineering is to build the disposable parts as quickly \\nand inexpensively as possible, which is the point of iterating in the early stages.\\n34.9 Thou Shalt Rend Software and Religion Asunder\\nReligion appears in software development in numerous incarnations—as dogmatic \\nadherence to a single design method, as unswerving belief in a specific formatting or \\ncommenting style, or as a zealous avoidance of global data. Whatever the case, it’s \\nalways inappropriate.\\nSoftware Oracles\\nCross-Reference For details \\non handling programming \\nreligion as a manager, see \\n“Religious Issues” in Section \\n28.5.\\nUnfortunately, the zealous attitude is decreed from on high by some of the more \\nprominent people in the profession. It’s important to publicize innovations so that \\npractitioners can try out promising new methods. Methods have to be tried before \\nthey can be fully proven or disproved. The dissemination of research results to practi-\\ntioners is called “technology transfer” and is important for advancing the state of the \\npractice of software development. There’s a difference, however, between disseminat-\\ning a new methodology and selling software snake oil. The idea of technology transfer \\nis poorly served by dogmatic methodology peddlers who try to convince you that \\ntheir new one-size-fits-all, high-tech cow pies will solve all your problems. Forget \\neverything you’ve already learned because this new method is so great it will improve \\nyour productivity 100 percent in everything!\\nRather than latching on to the latest miracle fad, use a mixture of methods. Experi-\\nment with the exciting, recent methods, but bank on the old and dependable ones.\\nEclecticism\\nCross-Reference For more \\non the difference between \\nalgorithmic and heuristic \\napproaches, see Section 2.2, \\n“How to Use Software Meta-\\nphors.” For information on \\neclecticism in design, see \\n“Iterate” in Section 5.4.\\nBlind faith in one method precludes the selectivity you need if you’re to find the most \\neffective solutions to programming problems. If software development were a deter-\\nministic, algorithmic process, you could follow a rigid methodology to your solution. \\nBut software development isn’t a deterministic process; it’s heuristic, which means \\nthat rigid processes are inappropriate and have little hope of success. In design, for \\nexample, sometimes top-down decomposition works well. Sometimes an object-ori-\\nented approach, a bottom-up composition, or a data-structure approach works better. \\nYou have to be willing to try several approaches, knowing that some will fail and some \\nwill succeed but not knowing which ones will work until after you try them. You have \\nto be eclectic.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 888}, page_content='852 Chapter 34: Themes in Software Craftsmanship\\nAdherence to a single method is also harmful in that it makes you force-fit the problem \\nto the solution. If you decide on the solution method before you fully understand the \\nproblem, you act prematurely. Over-constrain the set of possible solutions, and you \\nmight rule out the most effective solution.\\nYou’ll be uncomfortable with any new methodology initially, and the advice that you \\navoid religion in programming isn’t meant to suggest that you should stop using a \\nnew method as soon as you have a little trouble solving a problem with it. Give the \\nnew method a fair shake, but give the old methods their fair shakes, too.\\nCross-Reference For a more \\ndetailed description of the \\ntoolbox metaphor, see \\n“Applying Software Tech-\\nniques: The Intellectual Tool-\\nbox” in Section 2.3.\\nEclecticism is a useful attitude to bring to the techniques presented in this book as \\nmuch as to techniques described in other sources. Discussions of several topics pre-\\nsented here have advanced alternative approaches that you can’t use at the same time. \\nYou have to choose one or the other for each specific problem. You have to treat the \\ntechniques as tools in a toolbox and use your own judgment to select the best tool for \\nthe job. Most of the time, the tool choice doesn’t matter very much. You can use a box \\nwrench, vise-grip pliers, or a crescent wrench. In some cases, however, the tool selec-\\ntion matters a lot, so you should always make your selection carefully. Engineering is \\nin part a discipline of making tradeoffs among competing techniques. You can’t make \\na tradeoff if you’ve prematurely limited your choices to a single tool.\\nThe toolbox metaphor is useful because it makes the abstract idea of eclecticism con-\\ncrete. Suppose you were a general contractor and your buddy Simple Simon always \\nused vise-grip pliers. Suppose he refused to use a box wrench or a crescent wrench. \\nYou’d probably think he was odd because he wouldn’t use all the tools at his disposal. \\nThe same is true in software development. At a high level, you have alternative design \\nmethods. At a more detailed level, you can choose one of several data types to repre-\\nsent any given design. At an even more detailed level, you can choose several different \\nschemes for formatting and commenting code, naming variables, defining class inter-\\nfaces, and passing routine parameters.\\nA dogmatic stance conflicts with the eclectic  toolbox approach to software construc-\\ntion. It’s incompatible with the attitude needed to build high-quality software.\\nExperimentation\\nEclecticism has a close relative in experimentation. You need to experiment through-\\nout the development process, but zealous inflexibility hobbles the impulse. To exper-\\niment effectively, you must be willing to change your beliefs based on the results of the \\nexperiment. If you’re not willing, experimentation is a gratuitous waste of time.\\nMany of the inflexible approaches to software development are based on a fear of \\nmaking mistakes. A blanket attempt to avoid mistakes is the biggest mistake of all. \\nDesign is a process of carefully planning small mistakes in order to avoid making big \\nones. Experimentation in software development is a process of setting up tests so that'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 889}, page_content='Key Points 853\\nyou learn whether an approach fails or succeeds—the experiment itself is a success as \\nlong as it resolves the issue.\\nExperimentation is appropriate at as many levels as eclecticism is. At each level at \\nwhich you are ready to make an eclectic choice, you can probably come up with a cor-\\nresponding experiment to determine which approach works best. At the architectural-\\ndesign level, an experiment might consist of sketching software architectures using \\nthree different design approaches. At the detailed-design level, an experiment might \\nconsist of following the implications of a higher-level architecture using three different \\nlow-level design approaches. At the programming-language level, an experiment \\nmight consist of writing a short experimental program to exercise the operation of a \\npart of the language you’re not completely familiar with. The experiment might con-\\nsist of tuning a piece of code and benchmarking it to verify that it’s really smaller or \\nfaster. At the overall software-development-process level, an experiment might consist \\nof collecting quality and productivity data so that you can see whether inspections \\nreally find more errors than walk-throughs.\\nThe point is that you have to keep an open mind about all aspects of software devel-\\nopment. You have to get technical about your process as well as your product. Open-\\nminded experimentation and religious adherence to a predefined approach don’t mix.\\nKey Points\\n■ One primary goal of programming is managing complexity.\\n■ The programming process significantly affects the final product.\\n■ Team programming is more an exercise in communicating with people than in \\ncommunicating with a computer. Individual programming is more an exercise \\nin communicating with yourself than with a computer.\\n■ When abused, a programming convention can be a cure that’s worse than the \\ndisease. Used thoughtfully, a convention adds valuable structure to the develop-\\nment environment and helps with managing complexity and communication.\\n■ Programming in terms of the problem rather than the solution helps to manage \\ncomplexity.\\n■ Paying attention to intellectual warning signs like the “irritation of doubt” is \\nespecially important in programming because programming is almost purely a \\nmental activity.\\n■ The more you iterate in each development activity, the better the product of that \\nactivity will be.\\n■ Dogmatic methodologies and high-quality software development don’t mix. Fill \\nyour intellectual toolbox with programming alternatives, and improve your skill \\nat choosing the right tool for the job.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 891}, page_content='855\\nChapter 35\\nWhere to Find More \\nInformation\\ncc2e.com/3560 Contents\\n■ 35.1 Information About Software Construction: page 856\\n■ 35.2 Topics Beyond Construction: page 857\\n■ 35.3 Periodicals: page 859\\n■ 35.4 A Software Developer’s Reading Plan: page 860\\n■ 35.5 Joining a Professional Organization: page 862\\nRelated Topics\\n■ Web resources: www.cc2e.com\\nIf you’ve read this far, you already know that a lot has been written about effective soft-\\nware-development practices. Much more information is available than most people \\nrealize. People have already made all the mistakes that you’re making now, and unless \\nyou’re a glutton for punishment, you’ll prefer reading their books and avoiding their \\nmistakes to inventing new versions of old problems.\\nBecause this book describes hundreds of other books and articles that contain infor-\\nmation on software development, it’s hard to know what to read first. A software-\\ndevelopment library is made up of several kinds of information. A core of program-\\nming books explains fundamental concepts of effective programming. Related books \\nexplain the larger technical, management, and intellectual contexts within which pro-\\ngramming goes on. And detailed references on languages, operating systems, environ-\\nments, and hardware contain information that’s useful for specific projects.\\ncc2e.com/3581 Books in the last category generally have a life span of about one project; they’re more or \\nless temporary and aren’t discussed here. Of the other kinds of books, it’s useful to have \\na core set that discusses each of the major software-development activities in depth: \\nbooks on requirements, design, construction, management, testing, and so on. The fol-\\nlowing sections describe construction resources in depth and then provide an overview \\nof materials available in other software knowledge areas. Section 35.4 wraps these \\nresources into a neat package by defining a software developer’s reading program.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 892}, page_content='856 Chapter 35: Where to Find More Information\\n35.1 Information About Software Construction\\ncc2e.com/3588 I originally wrote this book because I couldn’t find a thorough discussion of software \\nconstruction. In the years since I published the first edition, several good books have \\nappeared.\\nPragmatic Programmer (Hunt and Thomas 2000) focuses on the activities most closely \\nassociated with coding, including testing, debugging, use of assertions, and so on. It \\ndoes not dive deeply into code itself but contains numerous principles related to cre-\\nating good code.\\nJon Bentley’s Programming Pearls, 2d ed. (Bentley 2000) discusses the art and science \\nof software design in the small. The book is organized as a set of essays that are very \\nwell written and express a great deal of insight into effective construction techniques \\nas well as genuine enthusiasm for software construction. I use something I learned \\nfrom Bentley’s essays nearly every day that I program.\\nCross-Reference For more in \\nthe economics of Extreme \\nProgramming and agile pro-\\ngramming, see cc2e.com/\\n3545.\\nKent Beck’s Extreme Programming Explained: Embrace Change (Beck 2000) defines a \\nconstruction-centric approach to software development. As Section 3.1 (“Importance \\nof Prerequisites”) explained, the book’s assertions about the economics of Extreme \\nProgramming are not borne out by industry research, but many of its recommenda-\\ntions are useful during construction regardless of whether a team is using Extreme \\nProgramming or some other approach.\\nA more specialized book is Steve Maguire’s Writing Solid Code – Microsoft’s Techniques \\nfor Developing Bug-Free C Software (Maguire 1993). It focuses on construction practices \\nfor commercial-quality software applications, mostly based on the author’s experi-\\nences working on Microsoft’s Office applications. It focuses on techniques applicable \\nin C. It is largely oblivious to object-oriented programming issues, but most of the top-\\nics it addresses are relevant in any environment.\\nAnother more specialized book is The Practice of Programming, by Brian Kernighan and \\nRob Pike (Kernighan and Pike 1999). This book focuses on nitty-gritty, practical \\naspects of programming, bridging the gap between academic computer-science \\nknowledge and hands-on lessons. It includes discussions of programming style, \\ndesign, debugging, and testing. It assumes familiarity with C/C++.\\ncc2e.com/3549 Although it’s out of print and hard to find, Programmers at Work, by Susan Lammers \\n(1986), is worth the search. It contains interviews with the industry’s high-profile pro-\\ngrammers. The interviews explore their personalities, work habits, and programming \\nphilosophies. The luminaries interviewed include Bill Gates (founder of Microsoft), John \\nWarnock (founder of Adobe), Andy Hertzfeld (principal developer of the Macintosh \\noperating system), Butler Lampson (a senior engineer at DEC, now at Microsoft), Wayne \\nRatliff (inventor of dBase), Dan Bricklin (inventor of VisiCalc), and a dozen others.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 893}, page_content='35.2 Topics Beyond Construction 857\\n35.2 Topics Beyond Construction\\nBeyond the core books described in the previous section, here are some books that \\nrange further afield from the topic of software construction.\\nOverview Material\\ncc2e.com/3595 The following books provide software-development overviews from a variety of van-\\ntage points:\\nRobert L. Glass’s Facts and Fallacies of Software Engineering (2003) provides a readable \\nintroduction to the conventional wisdom of software development dos and don’ts. \\nThe book is well researched and provides numerous pointers to additional resources.\\nMy own Professional Sofware Development (2004) surveys the field of software develop-\\nment as it is practiced now and as it could be if it were routinely practiced at its best.\\nThe Swebok: Guide to the Software Engineering Body of Knowledge (Abran 2001) pro-\\nvides a detailed decomposition of the software-engineering body of knowledge. This \\nbook has dived into detail in the software-construction area. The Guide to the Swebok \\nshows just how much more knowledge exists in the field.\\nGerald Weinberg’s The Psychology of Computer Programming (Weinberg 1998) is \\npacked with fascinating anecdotes about programming. It’s far-ranging because it was \\nwritten at a time when anything related to software was considered to be about pro-\\ngramming. The advice in the original review of the book in the ACM Computing \\nReviews is as good today as it was when the review was written:\\nEvery manager of programmers should have his own copy. He should read it, \\ntake it to heart, act on the precepts, and leave the copy on his desk to be stolen \\nby his programmers. He should continue replacing the stolen copies until equi-\\nlibrium is established (Weiss 1972).\\nIf you can’t find The Psychology of Computer Programming, look for The Mythical Man-\\nMonth (Brooks 1995) or PeopleWare (DeMarco and Lister 1999). They both drive \\nhome the theme that programming is first and foremost something done by people \\nand only secondarily something that happens to involve computers.\\nA final excellent overview of issues in software development is Software Creativity \\n(Glass 1995). This book should have been a breakthrough book on software creativity \\nthe way that Peopleware was on software teams. Glass discusses creativity versus disci-\\npline, theory versus practice, heuristics versus methodology, process versus product, \\nand many of the other dichotomies that defi ne the software field. After years of dis-\\ncussing this book with programmers who work for me, I have concluded that the'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 894}, page_content='858 Chapter 35: Where to Find More Information\\ndifficulty with the book is that it is a collection of essays edited by Glass but not \\nentirely written by him. For some readers, this gives the book an unfinished feel. \\nNonetheless, I still require every developer in my company to read it. The book is \\nout of print and hard to find but worth the effort if you are able to find it.\\nSoftware-Engineering Overviews\\nEvery practicing computer programmer or software engineer should have a high-level \\nreference on software engineering. Such books survey the methodological landscape \\nrather than painting specific features in detail. They provide an overview of effective \\nsoftware-engineering practices and capsule descriptions of specific software-engineer-\\ning techniques. The capsule descriptions aren’t detailed enough to train you in the \\ntechniques, but a single book would have to be several thousand pages long to do \\nthat. They provide enough information so that you can learn how the techniques fit \\ntogether and can choose techniques for further investigation.\\nRoger S. Pressman’s Software Engineering: A Practitioner’s Approach, 6th ed. (Pressman \\n2004), is a balanced treatment of requirements, design, quality validation, and man-\\nagement. Its 900 pages pay little attention to programming practices, but that’s a \\nminor limitation, especially if you already have a book on construction such as the \\none you’re reading.\\nThe sixth edition of Ian Sommerville’s Software Engineering (Sommerville 2000) is \\ncomparable to Pressman’s book, and it also provides a good high-level overview of the \\nsoftware-development process.\\nOther Annotated Bibliographies\\ncc2e.com/3502 Good computing bibliographies are rare. Here are a few that justify the effort it takes \\nto obtain them:\\nACM Computing Reviews is a special-interest publication of the Association for Com-\\nputing Machinery (ACM) that’s dedicated to reviewing books about all aspects of \\ncomputers and computer programming. The reviews are organized according to an \\nextensive classification scheme, making it easy to find books in your area of interest. \\nFor information on this publication and on membership in the ACM, see \\nwww.acm.org.\\ncc2e.com/3509 Construx Software’s Professional Development Ladder (www.construx.com/ladder/). \\nThis website provides recommended reading programs for software developers, tes-\\nters, and managers.\\nC35619670.fm  Page 858  Tuesday, April 12, 2011  3:45 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 895}, page_content='35.3 Periodicals 859\\n35.3 Periodicals\\nLowbrow Programmer Magazines\\nThese magazines are often available at local newsstands:\\ncc2e.com/3516 Software Development. www.sdmagazine.com. This magazine focuses on programming \\nissues—less on tips for specific environments than on the general issues you face as a \\nprofessional programmer. The quality of the articles is quite good. It also includes \\nproduct reviews.\\ncc2e.com/3523 Dr. Dobb’s Journal. www.ddj.com. This magazine is oriented toward hard-core program-\\nmers. Its articles tend to deal with detailed issues and include lots of code.\\nIf you can’t find these magazines at your local newsstand, many publishers will send \\nyou a complimentary issue, and many articles are available online.\\nHighbrow Programmer Journals\\nYou don’t usually buy these magazines at the newsstand. You usually have to go to a \\nmajor university library or subscribe to them for yourself or your company:\\ncc2e.com/3530 IEEE Software. www.computer.org/software/. This bimonthly magazine focuses on soft-\\nware construction, management, requirements, design and other leading-edge soft-\\nware topics. Its mission is to “build the community of leading software practitioners.” \\nIn 1993, I wrote that it’s “the most valuable magazine a programmer can subscribe to.” \\nSince I wrote that, I’ve been Editor in Chief of the magazine, and I still believe it’s the \\nbest periodical available for a serious software practitioner.\\ncc2e.com/3537 IEEE Computer. www.computer.org/computer/. This monthly magazine is the flagship \\npublication of the IEEE (Institute of Electrical and Electronics Engineers) Computer \\nSociety. It publishes articles on a wide spectrum of computer topics and has scrupu-\\nlous review standards to ensure the quality of the articles it publishes. Because of its \\nbreadth, you’ll probably find fewer articles that interest you than you will in IEEE Soft-\\nware.\\ncc2e.com/3544 Communications of the ACM. www.acm.org/cacm/. This magazine is one of the oldest \\nand most respected computer publications available. It has the broad charter of pub-\\nlishing about the length and breadth of computerology, a subject that’s much vaster \\nthan it was even a few years ago. As with IEEE Computer, because of its breadth, you’ll \\nprobably find that many of the articles are outside your area of interest. The magazine \\ntends to have an academic flavor, which has both a bad side and a good side. The bad \\nside is that some of the authors write in an obfuscatory academic style. The good side \\nis that it contains leading-edge information that won’t filter down to the lowbrow mag-\\nazines for years.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 896}, page_content='860 Chapter 35: Where to Find More Information\\nSpecial-Interest Publications\\nSeveral publications provide in-depth coverage of specialized topics.\\nProfessional Publications\\ncc2e.com/3551 The IEEE Computer Society publishes specialized journals on software engineering, \\nsecurity and privacy, computer graphics and animation, internet development, multi-\\nmedia, intelligent systems, the history of computing, and other topics. See www.com-\\nputer.org for more details.\\ncc2e.com/3558 The ACM also publishes special-interest publications in artificial intelligence, comput-\\ners and human interaction, databases, embedded systems, graphics, programming \\nlanguages, mathematical software, networking, software engineering, and other top-\\nics. See www.acm.org for more information.\\nPopular-Market Publications\\ncc2e.com/3565 These magazines all cover what their names suggest they cover.\\nThe C/C++ Users Journal. www.cuj.com.\\nJava Developer’s Journal. www.sys-con.com/java/.\\nEmbedded Systems Programming. www.embedded.com.\\nLinux Journal. www.linuxjournal.com.\\nUnix Review. www.unixreview.com.\\nWindows Developer’s Network. www.wd-mag.com.\\n35.4 A Software Developer’s Reading Plan\\ncc2e.com/3507 This section describes the reading program that a software developer needs to work \\nthrough to achieve full professional standing at my company, Construx Software. The \\nplan described is a generic baseline plan for a software professional who wants to \\nfocus on development. Our mentoring program provides for further tailoring of the \\ngeneric plan to support an individual’s interests, and within Construx this reading is \\nalso supplemented with training and directed professional experiences.\\nIntroductory Level\\nTo move beyond “introductory” level at Construx, a developer must read the follow-\\ning books:\\nAdams, James L. Conceptual Blockbusting: A Guide to Better Ideas, 4th ed. Cambridge, \\nMA: Perseus Publishing, 2001.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 897}, page_content='35.4 A Software Developer’s Reading Plan 861\\nBentley, Jon. Programming Pearls, 2d ed. Reading, MA: Addison-Wesley, 2000.\\nGlass, Robert L. Facts and Fallacies of Software Engineering . Boston, MA: Addison-\\nWesley, 2003.\\nMcConnell, Steve. Software Project Survival Guide. Redmond, WA: Microsoft Press, 1998.\\nMcConnell, Steve. Code Complete, 2d ed. Redmond, WA: Microsoft Press, 2004.\\nPractitioner Level \\nTo achieve “intermediate” status at Construx, a programmer needs to read the follow-\\ning additional materials:\\nBerczuk, Stephen P. and Brad Appleton. Software Configuration Management Patterns: \\nEffective Teamwork, Practical Integration. Boston, MA: Addison-Wesley, 2003.\\nFowler, Martin. UML Distilled: A Brief Guide to the Standard Object Modeling Language, \\n3d ed. Boston, MA: Addison-Wesley, 2003.\\nGlass, Robert L. Software Creativity. Reading, MA: Addison-Wesley, 1995.\\nKaner, Cem, Jack Falk, Hung Q. Nguyen. Testing Computer Software, 2d ed. New York, \\nNY: John Wiley & Sons, 1999.\\nLarman, Craig. Applying UML and Patterns: An Introduction to Object-Oriented Analysis \\nand Design and the Unified Process, 2d ed. Englewood Cliffs, NJ: Prentice Hall, 2001.\\nMcConnell, Steve. Rapid Development. Redmond, WA: Microsoft Press, 1996.\\nWiegers, Karl. Software Requirements, 2d ed. Redmond, WA: Microsoft Press, 2003.\\ncc2e.com/3514 “Manager’s Handbook for Software Development,” NASA Goddard Space Flight Cen-\\nter. Downloadable from sel.gsfc.nasa.gov/website/documents/online-doc.htm.\\nProfessional Level\\nA software developer must read the following materials to achieve full professional \\nstanding at Construx (“leadership” level). Additional requirements are tailored to \\neach individual developer; this section describes the generic requirements.\\nBass, Len, Paul Clements, and Rick Kazman. Software Architecture in Practice, 2d ed. \\nBoston, MA: Addison-Wesley, 2003.\\nFowler, Martin. Refactoring: Improving the Design of Existing Code. Reading, MA: Addi-\\nson-Wesley, 1999.\\nGamma, Erich, et al. Design Patterns. Reading, MA: Addison-Wesley, 1995.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 898}, page_content='862 Chapter 35: Where to Find More Information\\nGilb, Tom. Principles of Software Engineering Management. Wokingham, England: Add-\\nison-Wesley, 1988.\\nMaguire, Steve. Writing Solid Code. Redmond, WA: Microsoft Press, 1993.\\nMeyer, Bertrand. Object-Oriented Software Construction, 2d ed. New York, NY: Prentice \\nHall PTR, 1997.\\ncc2e.com/3521 “Software Measurement Guidebook,” NASA Goddard Space Flight Center. Available \\nfrom sel.gsfc.nasa.gov/website/documents/online-doc.htm.\\ncc2e.com/3528 For more details on this professional development program, as well as for up-to-\\ndate reading lists, see our professional developme nt website at www.construx.com\\n/professionaldev/ .\\n35.5 Joining a Professional Organization\\ncc2e.com/3535 One of the best ways to learn more about programming is to get in touch with other \\nprogrammers who are as dedicated to the profession as you are. Local user groups for \\nspecific hardware and language products are one kind of group. Other kinds are \\nnational and international professional organizations. The most practitioner-oriented \\norganization is the IEEE Computer Society, which publishes the IEEE Computer and \\nIEEE Software magazines. For membership information, see www.computer.org.\\ncc2e.com/3542 The original professional organization was the ACM, which publishes Communications \\nof the ACM and many special-interest magazines. It tends to be somewhat more aca-\\ndemically oriented than the IEEE Computer Society. For membership information, \\nsee www.acm.org.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 899}, page_content='863\\nBibliography\\n“A C Coding Standard.” 1991. Unix Review\\n9, no. 9 (September): 42–43.\\nAbdel-Hamid, Tarek K. 1989. “The Dynam-\\nics of Software Project Staffing: A System\\nDynamics Based Simulation Approach.”\\nIEEE Transactions on Software Engineer-\\ning SE-15, no. 2 (February): 109–19.\\nAbran, Alain, et al. 2001. Swebok: Guide to\\nthe Software Engineering Body of Knowl-\\nedge: Trial Version 1.00-May 2001 . Los\\nAlamitos, CA: IEEE Computer Society\\nPress.\\nAbrash, Michael. 1992. “Flooring It: The\\nOptimization Challenge.” PC Techniques\\n2, no. 6 (February/March): 82–88.\\nAckerman, A. Frank, Lynne S. Buchwald,\\nand Frank H. Lewski. 1989. “Software\\nInspections: An Effective Verification\\nProcess.” IEEE Software , May/June\\n1989, 31–36.\\nAdams, James L. 2001. Conceptual Block-\\nbusting: A Guide to Better Ideas , 4th ed.\\nCambridge, MA: Perseus Publishing.\\nAho, Alfred V., Brian W. Kernighan, and\\nPeter J. Weinberg. 1977. The AWK Pro-\\ngramming Language. Reading, MA:\\nAddison-Wesley.\\nAho, Alfred V., John E. Hopcroft, and Jef-\\nfrey D. Ullman. 1983. Data Structures\\nand Algorithms . Reading, MA: Addison-\\nWesley.\\nAlbrecht, Allan J. 1979. “Measuring Appli-\\ncation Development Productivity.” Pro-\\nceedings of the Joint SHARE/GUIDE/IBM\\nApplication Development Symposium, Oc-\\ntober 1979: 83–92.\\nAmbler, Scott. 2003. Agile Database Tech-\\nniques. New York, NY: John Wiley &\\nSons.\\nAnand, N. 1988. “Clarify Function!” ACM\\nSigplan Notices 23, no. 6 (June): 69–79.\\nAristotle. The Ethics of Aristotle: The Nicoma-\\nchean Ethics. Trans. by J.A.K. Thomson.\\nRev. by Hugh Tredennick. Harmond-\\nsworth, Middlesex, England: Penguin,\\n1976.\\nArmenise, Pasquale. 1989. “A Structured\\nApproach to Program Optimization.”\\nIEEE Transactions on Software Engineer-\\ning SE-15, no. 2 (February): 101–8.\\nArnold, Ken, James Gosling, and David\\nHolmes. 2000. The Java Programming\\nLanguage, 3d ed. Boston, MA: Addison-\\nWesley.\\nArthur, Lowell J. 1988. Software Evolution:\\nThe Software Maintenance Challenge. New\\nYork, NY: John Wiley & Sons.\\nAugustine, N. R. 1979. “Augustine’s Laws\\nand Major System Development Pro-\\ngrams.” Defense Systems Management\\nReview: 50–76.\\nBabich, W. 1986. Software Configuration\\nManagement. Reading, MA: Addison-\\nWesley.\\nBachman, Charles W. 1973. “The Program-\\nmer as Navigator.” Turing Award Lec-\\nture. Communications of the ACM 16, no.\\n11 (November): 653.\\nBaecker, Ronald M., and Aaron Marcus.\\n1990. Human Factors and Typography for\\nMore Readable Programs . Reading, MA:\\nAddison-Wesley.\\nBairdain, E. F. 1964. “Research Studies of\\nProgrammers and Programming.” Un-\\npublished studies reported in Boehm\\n1981.\\nBaker, F. Terry, and Harlan D. Mills. 1973.\\n“Chief Programmer Teams.” Datamation\\n19, no. 12 (December): 58–61.\\nBarbour, Ian G. 1966. Issues in Science and\\nReligion. New York, NY: Harper & Row.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 900}, page_content='864 Bibliography\\nBarbour, Ian G. 1974. Myths, Models, and\\nParadigms: A Comparative Study in Sci-\\nence and Religion. New York, NY: Harper\\n& Row.\\nBarwell, Fred, et al. 2002. Professional\\nVB.NET, 2d ed. Birmingham, UK: Wrox.\\nBasili, V. R., and B. T. Perricone. 1984. “Soft-\\nware Errors and Complexity: An Empiri-\\ncal Investigation.” Communications of the\\nACM 27, no. 1 (January): 42–52.\\nBasili, Victor R., and Albert J. Turner. 1975.\\n“Iterative Enhancement: A Practical\\nTechnique for Software Development.”\\nIEEE Transactions on Software Engineer-\\ning SE-1, no. 4 (December): 390–96.\\nBasili, Victor R., and David M. Weiss. 1984.\\n“A Methodology for Collecting Valid\\nSoftware Engineering Data.” IEEE Trans-\\nactions on Software Engineering SE-10, no.\\n6 (November): 728–38.\\nBasili, Victor R., and Richard W. Selby.\\n1987. “Comparing the Effectiveness of\\nSoftware Testing Strategies.” IEEE Trans-\\nactions on Software Engineering SE-13, no.\\n12 (December): 1278–96.\\nBasili, Victor R., et al. 2002. “Lessons\\nlearned from 25 years of process im-\\nprovement: The Rise and Fall of the\\nNASA Software Engi neering Laborato-\\nry,” Proceedings of the 24th International\\nConference on Software Engineering ,\\nOrlando, FL.\\nBasili, Victor R., Richard W. Selby, and Dav-\\nid H. Hutchens. 1986. “Experimentation\\nin Software Engineering.” IEEE Transac-\\ntions on Software Engineering SE-12, no. 7\\n(July): 733–43.\\nBasili, Victor, L. Briand, and W.L. Melo.\\n1996. “A Validation of Object-Oriented\\nDesign Metrics as Quality Indicators,”\\nIEEE Transactions on Software Engineer-\\ning, October 1996, 751–761.\\nBass, Len, Paul Clements, and Rick Ka-\\nzman. 2003. Software Architecture in\\nPractice, 2d ed. Boston, MA: Addison-\\nWesley.\\nBastani, Farokh, and Sitharama Iyengar.\\n1987. “The Effect of Data Structures on\\nthe Logical Complexity of Programs.”\\nCommunications of the ACM 30, no. 3\\n(March): 250–59.\\nBays, Michael. 1999. Software Release Meth-\\nodology. Englewood Cliffs, NJ: Prentice\\nHall.\\nBeck, Kent. 2000. Extreme Programming Ex-\\nplained: Embrace Change. Reading, MA:\\nAddison-Wesley.\\nBeck, Kent. 2003. Test-Driven Development:\\nBy Example. Boston, MA: Addison-Wes-\\nley.\\nBeck, Kent. 1991. “Think Like An Object.”\\nUnix Review 9, no. 10 (October): 39–43.\\nBeck, Leland L., and Thomas E. Perkins.\\n1983. “A Survey of Software Engineering\\nPractice: Tools, Methods, and Results.”\\nIEEE Transactions on Software Engineer-\\ning SE-9, no. 5 (September): 541–61.\\nBeizer, Boris. 1990. Software Testing Tech-\\nniques, 2d ed. New York, NY: Van Nos-\\ntrand Reinhold.\\nBentley, Jon, and Donald Knuth. 1986. “Lit-\\nerate Programming.” Communications of\\nthe ACM 29, no. 5 (May): 364–69.\\nBentley, Jon, Donald Knuth, and Doug\\nMcIlroy. 1986. “A Literate Program.”\\nCommunications of the ACM  29, no. 5\\n(May): 471–83.\\nBentley, Jon. 1982. Writing Efficient Pro-\\ngrams. Englewood Cliffs, NJ: Prentice\\nHall.\\nBentley, Jon. 1988. More Programming\\nPearls: Confessions of a Coder . Reading,\\nMA: Addison-Wesley.\\nBentley, Jon. 1991. “Software Exploratori-\\num: Writing Efficient C Programs.” Unix\\nReview 9, no. 8 (August): 62–73.\\nBentley, Jon. 2000. Programming Pearls, 2d\\ned. Reading, MA: Addison-Wesley.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 901}, page_content='Bibliography 865\\nBerczuk, Stephen P. and Brad Appleton.\\n2003. Software Configuration Manage-\\nment Patterns: Effective Teamwork, Practi-\\ncal Integration. Boston, MA: Addison-\\nWesley.\\nBerry, R. E., and B. A. E. Meekings. 1985. “A\\nStyle Analysis of C Programs.” Communi-\\ncations of the ACM 28, no. 1 (January):\\n80–88.\\nBersoff, Edward H. 1984. “Elements of\\nSoftware Configuration Management.”\\nIEEE Transactions on Software Engineer-\\ning SE-10, no. 1 (January): 79–87.\\nBersoff, Edward H., and Alan M. Davis.\\n1991. “Impacts of Life Cycle Models on\\nSoftware Configuration Management.”\\nCommunications of the ACM  34, no. 8\\n(August): 104–18.\\nBersoff, Edward H., et al. 1980. Software\\nConfiguration Management . Englewood\\nCliffs, NJ: Prentice Hall.\\nBirrell, N. D., and M. A. Ould. 1985. A Prac-\\ntical Handbook for Software Development .\\nCambridge, England: Cambridge Uni-\\nversity Press.\\nBloch, Joshua. 2001. Effective Java Program-\\nming Language Guide. Boston, MA: Addi-\\nson-Wesley.\\nBLS 2002. Occupational Outlook Hand-\\nbook 2002-03 Edition , Bureau of Labor\\nStatistics.\\nBLS 2004. Occupational Outlook Handbook\\n2004-05 Edition, Bureau of Labor Statistics.\\nBlum, Bruce I. 1989. “A Software Environ-\\nment: Some Surprising Empirical Re-\\nsults.” Proceedings of the Fourteenth\\nAnnual Software Engineering Workshop,\\nNovember 29, 1989. Greenbelt, MD: God-\\ndard Space Flight Center. Document\\nSEL-89-007.\\nBoddie, John. 1987. Crunch Mode . New\\nYork, NY: Yourdon Press.\\nBoehm, Barry and Richard Turner. 2004.\\nBalancing Agility and Discipline: A Guide\\nfor the Perplexed. Boston, MA: Addison-\\nWesley.\\nBoehm, Barry W. 1981. Software Engineering\\nEconomics. Englewood Cliffs, NJ: Pren-\\ntice Hall.\\nBoehm, Barry W. 1984. “Software Engineer-\\ning Economics.” IEEE Transactions on\\nSoftware Engineering SE-10, no. 1 (Janu-\\nary): 4–21.\\nBoehm, Barry W. 1987a. “Improving Soft-\\nware Productivity.” IEEE Computer, Sep-\\ntember, 43–57.\\nBoehm, Barry W. 1987b. “Industrial Soft-\\nware Metrics Top 10 List.” IEEE Software\\n4, no. 9 (September): 84–85.\\nBoehm, Barry W. 1988. “A Spiral Model of\\nSoftware Development and Enhance-\\nment.” Computer, May, 61–72.\\nBoehm, Barry W., and Philip N. Papaccio.\\n1988. “Understanding and Controlling\\nSoftware Costs.” IEEE Transactions on\\nSoftware Engineering SE-14, no. 10 (Octo-\\nber): 1462–77.\\nBoehm, Barry W., ed. 1989. Tutorial: Soft-\\nware Risk Management. Washington, DC:\\nIEEE Computer Society Press.\\nBoehm, Barry W., et al. 1978. Characteristics\\nof Software Quality . New York, NY:\\nNorth-Holland.\\nBoehm, Barry W., et al. 1984. “A Software\\nDevelopment Environment for Improv-\\ning Productivity.” Computer, June, 30–\\n44.\\nBoehm, Barry W., T. E. Gray, and T. See-\\nwaldt. 1984. “Prototyping Versus Speci-\\nfying: A Multiproject Experiment.” IEEE\\nTransactions on Software Engineering  SE-\\n10, no. 3 (May): 290–303. Also in Jones\\n1986b.\\nBoehm, Barry, et al. 2000a. Software Cost Es-\\ntimation with Cocomo II. Boston, MA: Ad-\\ndison-Wesley.\\nBoehm, Barry. 2000b. “Unifying Software\\nEngineering and Systems Engineering,”\\nIEEE Computer, March 2000, 114–116.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 902}, page_content='866 Bibliography\\nBoehm-Davis, Deborah, Sylvia Sheppard,\\nand John Bailey. 1987. “Program Design\\nLanguages: How Much Detail Should\\nThey Include?” International Journal of\\nMan-Machine Studies 27, no. 4: 337–47.\\nBöhm, C., and G. Jacopini. 1966. “Flow Di-\\nagrams, Turing Mach ines and Languag-\\nes with Only Two Formation Rules.”\\nCommunications of the ACM  9, no. 5\\n(May): 366–71.\\nBooch, Grady. 1987. Software Engineering\\nwith Ada , 2d ed. Menlo Park, CA: Ben-\\njamin/Cummings.\\nBooch, Grady. 1994. Object Oriented Analy-\\nsis and Design with Applications , 2d ed.\\nBoston, MA: Addison-Wesley.\\nBooth, Rick. 1997. Inner Loops : A Source-\\nbook for Fast 32-bit Software Development.\\nBoston, MA: Addison-Wesley.\\nBoundy, David. 1991. “A Taxonomy of Pro-\\ngrammers.” ACM SIGSOFT Software En-\\ngineering Notes 16, no. 4 (October): 23–\\n30.\\nBrand, Stewart. 1995. How Buildings Learn:\\nWhat Happens After They’re Built. Pen-\\nguin USA.\\nBranstad, Martha A., John C. Cherniavsky,\\nand W. Richards Adrion. 1980. “Valida-\\ntion, Verification, and Testing for the In-\\ndividual Programmer.” Computer,\\nDecember, 24–30.\\nBrockmann, R. John. 1990. Writing Better\\nComputer User Documentation: From Pa-\\nper to Hypertext: Version 2.0. New York,\\nNY: John Wiley & Sons.\\nBrooks, Frederick P., Jr. 1987. “No Silver\\nBullets—Essence and Accidents of Soft-\\nware Engineering.” Computer, April, 10–\\n19.\\nBrooks, Frederick P., Jr. 1995. The Mythical\\nMan-Month: Essays on Software Engineer-\\ning, Anniversary Edition (2d ed.). Read-\\ning, MA: Addison-Wesley.\\nBrooks, Ruven. 1977. “Towards a Theory of\\nthe Cognitive Processes in Computer\\nProgramming.” International Journal of\\nMan-Machine Studies 9:737–51.\\nBrooks, W. Douglas. 1981. “Software Tech-\\nnology Payoff—Some Statistical Evi-\\ndence.” The Journal of Systems and\\nSoftware 2:3–9.\\nB r o w n ,  A .  R . ,  a n d  W .  A .  S a m p s o n .  1 9 7 3 .\\nProgram Debugging. New York, NY:\\nAmerican Elsevier.\\nBuschman, Frank, et al. 1996. Pattern-Ori-\\nented Software Architecture, Volume 1: A\\nSystem of Patterns. New York, NY: John\\nWiley & Sons.\\nBush, Marilyn, and John Kelly. 1989. “The\\nJet Propulsion Laboratory’s Experience\\nwith Formal Inspections.” Proceedings of\\nthe Fourteenth Annual Software Engineer-\\ning Workshop, November 29, 1989. Green-\\nbelt, MD: Goddard Space Flight Center.\\nDocument SEL-89-007.\\nCaine, S. H., and E. K. Gordon. 1975.\\n“PDL—A Tool for Software Design.”\\nAFIPS Proceedings of the 1975 National\\nComputer Conference 44. Montvale, NJ:\\nAFIPS Press, 271–76.\\nCard, David N. 1987. “A Software Technol-\\nogy Evaluation Program.” Information\\nand Software Technology  29, no. 6 (July/\\nAugust): 291–300.\\nCard, David N., Frank E. McGarry, and Ger-\\nald T. Page. 1987. “Evaluating Software\\nEngineering Technologies.” IEEE Trans-\\nactions on Software Engineering SE-13, no.\\n7 (July): 845–51.\\nCard, David N., Victor E. Church, and Will-\\niam W. Agresti. 1986. “An Empirical\\nStudy of Software Design Practices.”\\nIEEE Transactions on Software Engineer-\\ning SE-12, no. 2 (February): 264–71.\\nCard, David N., with Robert L. Glass. 1990.\\nMeasuring Software Design Quality . En-\\nglewood Cliffs, NJ: Prentice Hall.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 903}, page_content='Bibliography 867\\nCard, David, Gerald Page, and Frank Mc-\\nGarry. 1985. “Criteria for Software Mod-\\nularization.” Proceedings of the 8th\\nInternational Conference on Software Engi-\\nneering. Washington, DC: IEEE Comput-\\ner Society Press, 372–77.\\nCarnegie, Dale. 1981. How to Win Friends\\nand Influence People , Revised Edition.\\nNew York, NY: Pocket Books.\\nChase, William G., and Herbert A. Simon.\\n1973. “Perception in Chess.” Cognitive\\nPsychology 4:55–81.\\nClark, R. Lawrence. 1973. “A Linguistic\\nContribution of GOTO-less Program-\\nming,” Datamation, December 1973.\\nClements, Paul, ed. 2003. Documenting Soft-\\nware Architectures: Views and Beyond .\\nBoston, MA: Addison-Wesley.\\nClements, Paul, Rick Kazman, and Mark\\nKlein. 2002. Evaluating Software Architec-\\ntures: Methods and Case Studies . Boston,\\nMA: Addison-Wesley.\\nCoad, Peter, and Edward Yourdon. 1991.\\nObject-Oriented Design. Englewood\\nCliffs, NJ: Yourdon Press.\\nCobb, Richard H., and Harlan D. Mills.\\n1990. “Engineering Software Under Sta-\\ntistical Quality Control.” IEEE Software 7,\\nno. 6 (November): 45–54.\\nCockburn, Alistair. 2000. Writing Effective\\nUse Cases. Boston, MA: Addison-Wesley.\\nCockburn, Alistair. 2002. Agile Software De-\\nvelopment. Boston, MA: Addison-Wesley.\\nCollofello, Jim, and Scott Woodfield. 1989.\\n“Evaluating the Effectiveness of Reliabil-\\nity Assurance Techniques.” Journal of\\nSystems and Software 9, no. 3 (March).\\nComer, Douglas. 1981. “Principles of Pro-\\ngram Design Induced from Experience\\nwith Small Public Programs.” IEEE\\nTransactions on Software Engineering  SE-\\n7, no. 2 (March): 169–74.\\nConstantine, Larry L. 1990a. “Comments\\non ‘On Criteria for Module Interfaces.’”\\nIEEE Transactions on Software Engineer-\\ning SE-16, no. 12 (December): 1440.\\nConstantine, Larry L. 1990b. “Objects,\\nFunctions, and Program Extensibility.”\\nComputer Language, January, 34–56.\\nConte, S. D., H. E. Dunsmore, and V. Y.\\nShen. 1986. Software Engineering Metrics\\nand Models. Menlo Park, CA: Benjamin/\\nCummings.\\nCooper, Doug, and Michael Clancy. 1982.\\nOh! Pascal!  2d ed. New York, NY:\\nNorton.\\nCooper, Kenneth G. and Thomas W.\\nMullen. 1993. “Swords and Plowshares:\\nThe Rework Cycles of Defense and Com-\\nmercial Software Development\\nProjects,” American Programmer , May\\n1993, 41–51.\\nCorbató, Fernando J. 1991. “On Building\\nSystems That Will Fail.” 1991 Turing\\nAward Lecture. Communications of the\\nACM 34, no. 9 (September): 72–81.\\nCornell, Gary and Jonathan Morrison.\\n2002. Programming VB .NET: A Guide for\\nExperienced Programmers , Berkeley, CA:\\nApress.\\nCorwin, Al. 1991. Private communication.\\nCSTB 1990. “Scaling Up: A Research Agen-\\nda for Software Engineering.” Excerpts\\nfrom a report by the Computer Science\\nand Technology Board. Communications\\nof the ACM 33, no. 3 (March): 281–93.\\nCurtis, Bill, ed. 1985. Tutorial: Human Fac-\\ntors in Software Development . Los Ange-\\nles, CA: IEEE Computer Society Press.\\nCurtis, Bill, et al. 1986. “Software Psycholo-\\ngy: The Need for an Interdisciplinary\\nProgram.” Proceedings of the IEEE 74, no.\\n8: 1092–1106.\\nCurtis, Bill, et al. 1989. “Experimentation of\\nSoftware Documentation Formats.” Jour-\\nnal of Systems and Software 9, no. 2 (Feb-\\nruary): 167–207.\\nCurtis, Bill, H. Krasner, and N. Iscoe. 1988.\\n“A Field Study of the Software Design\\nProcess for Large Systems.” Communica-\\ntions of the ACM 31, no. 11 (November):\\n1268–87.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 904}, page_content='868 Bibliography\\nCurtis, Bill. 1981. “Substantiating Program-\\nmer Variability.” Proceedings of the IEEE\\n69, no. 7: 846.\\nCusumano, Michael and Richard W. Selby.\\n1995. Microsoft Secrets . New York, NY:\\nThe Free Press.\\nCusumano, Michael, et al. 2003. “Software\\nDevelopment Worldwide: The State of\\nthe Practice,” IEEE Software, November/\\nDecember 2003, 28–34.\\nDahl, O. J., E. W. Dijkstra, and C. A. R.\\nHoare. 1972. Structured Programming .\\nNew York, NY: Academic Press.\\nDate, Chris. 1977. An Introduction to Data-\\nbase Systems . Reading, MA: Addison-\\nWesley.\\nDavidson, Jack W., and Anne M. Holler.\\n1992. “Subprogram Inlining: A Study of\\nIts Effects on Program Execution Time.”\\nIEEE Transactions on Software Engineer-\\ning SE-18, no. 2 (February): 89–102.\\nDavis, P. J. 1972. “Fidelity in Mathematical\\nDiscourse: Is One and One Really Two?”\\nAmerican Mathematical Monthly , March,\\n252–63.\\nDeGrace, Peter, and Leslie Stahl. 1990.\\nWicked Problems, Righteous Solutions: A\\nCatalogue of Modern Software Engineering\\nParadigms. Englewood Cliffs, NJ: Your-\\ndon Press.\\nDeMarco, Tom and Timothy Lister. 1999.\\nPeopleware: Productive Projects and\\nTeams, 2d ed. New York, NY: Dorset\\nHouse.\\nDeMarco, Tom, and Timothy Lister. 1985.\\n“Programmer Performance and the Ef-\\nfects of the Workplace.” Proceedings of\\nthe 8th International Conference on Soft -\\nware Engineering. Washington, DC: IEEE\\nComputer Society Press, 268–72.\\nDeMarco, Tom. 1979. Structured Analysis\\nand Systems Specification: Tools and Tech-\\nniques. Englewood Cliffs, NJ: Prentice\\nHall.\\nDeMarco, Tom. 1982. Controlling Software\\nProjects. New York, NY: Yourdon Press.\\nDeMillo, Richard A., Richard J. Lipton, and\\nAlan J. Perlis. 1979. “Social Processes\\nand Proofs of Theorems and Programs.”\\nCommunications of the ACM 22, no. 5\\n(May): 271–80.\\nDijkstra, Edsger. 1965. “Programming Con-\\nsidered as a Human Activity.” Proceed-\\nings of the 1965 IFIP Congress.\\nAmsterdam: North-Holland, 213–17. Re-\\nprinted in Yourdon 1982.\\nDijkstra, Edsger. 1968. “Go To Statement\\nConsidered Harmful.” Communications\\nof the ACM 11, no. 3 (March): 147–48.\\nDijkstra, Edsger. 1969. “Structured Pro-\\ngramming.” Reprinted in Yourdon 1979.\\nDijkstra, Edsger. 1972. “The Humble Pro-\\ngrammer.” Communications of the ACM\\n15, no. 10 (October): 859–66.\\nDijkstra, Edsger. 1985. “Fruits of Misun-\\nderstanding.” Datamation, February 15,\\n86–87.\\nDijkstra, Edsger. 1989. “On the Cruelty of\\nReally Teaching Computer Science.”\\nCommunications of the ACM 32, no. 12\\n(December): 1397–1414.\\nDunn, Robert H. 1984. Software Defect Re-\\nmoval. New York, NY: McGraw-Hill.\\nEllis, Margaret A., and Bjarne Stroustrup.\\n1990. The Annotated C++ Reference Man-\\nual. Boston, MA: Addison-Wesley.\\nElmasri, Ramez, and Shamkant B. Navathe.\\n1989. Fundamentals of Database Systems.\\nRedwood City, CA: Benjamin/Cummings.\\nElshoff, James L. 1976. “An Analysis of\\nSome Commercial PL/I Programs.” IEEE\\nTransactions on Software Engineering  SE-\\n2, no. 2 (June): 113–20.\\nElshoff, James L. 1977. “The Influence of\\nStructured Programming on PL/I Pro-\\ngram Profiles.” IEEE Transactions on Soft-\\nware Engineering  SE-3, no. 5\\n(September): 364–68.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 905}, page_content='Bibliography 869\\nElshoff, James L., and Michael Marcotty.\\n1982. “Improving Computer Program\\nReadability to Aid Modification.” Com-\\nmunications of the ACM 25, no. 8 (Au-\\ngust): 512–21.\\nEndres, Albert. 1975. “An Analysis of Errors\\nand Their Causes in System Programs.”\\nIEEE Transactions on Software Engineer-\\ning SE-1, no. 2 (June): 140–49.\\nEvangelist, Michael. 1984. “Program Com-\\nplexity and Programming Style.” Pro-\\nceedings of the First International\\nConference on Data Engineering. New\\nYork, NY: IEEE Computer Society Press,\\n534–41.\\nFagan, Michael E. 1976. “Design and Code\\nInspections to Reduce Errors in Program\\nDevelopment.” IBM Systems Journal  15,\\nno. 3: 182–211.\\nFagan, Michael E. 1986. “Advances in Soft-\\nware Inspections.” IEEE Transactions on\\nSoftware Engineering SE-12, no. 7 (July):\\n744–51.\\nFederal Software Management Support\\nCenter. 1986. Programmers Work-bench\\nHandbook. Falls Church, VA: Office of\\nSoftware Development and Information\\nTechnology.\\nFeiman, J., and M. Driver. 2002. “Leading\\nProgramming Languages for IT Portfolio\\nPlanning,” Gartner Research report SPA-\\n17-6636, September 27, 2002.\\nFetzer, James H. 1988. “Program Verifica-\\ntion: The Very Idea.” Communications of\\nthe ACM 31, no. 9 (September): 1048–\\n63.\\nFIPS PUB 38, Guidelines for Documentation\\nof Computer Programs and Automated\\nData Systems. 1976. U.S. Department of\\nCommerce. National Bureau of Stan-\\ndards. Washington, DC: U.S. Govern-\\nment Printing Office, Feb. 15.\\nFishman, Charles. 1996. “They Write the\\nRight Stuff,” Fast Company , December\\n1996.\\nFjelstad, R. K., and W. T. Hamlen. 1979.\\n“Applications Program Maintenance\\nStudy: Report to our Respondents.” Pro-\\nceedings Guide 48, Philadelphia. Reprint-\\ned in Tutorial on Software Maintenance ,\\nG. Parikh and N. Zvegintzov, eds. Los\\nAlamitos, CA: CS Press, 1983: 13–27.\\nFloyd, Robert. 1979. “The Paradigms of\\nProgramming.” Communications of the\\nACM 22, no. 8 (August): 455–60.\\nFowler, Martin. 1999. Refactoring: Improv-\\ning the Design of Existing Code . Reading,\\nMA: Addison-Wesley.\\nFowler, Martin. 2002. Patterns of Enterprise\\nApplication Architecture. Boston, MA: Ad-\\ndison-Wesley.\\nFowler, Martin. 2003. UML Distilled: A Brief\\nGuide to the Standard Object Modeling\\nLanguage, 3d ed. Boston, MA: Addison-\\nWesley.\\nFowler, Martin. 2004. UML Distilled, 3d ed.\\nBoston, MA: Addison-Wesley.\\nFowler, Priscilla J. 1986. “In-Process Inspec-\\ntions of Work Products at AT&T.” AT&T\\nTechnical Journal, March/April, 102–12.\\nFoxall, James. 2003. Practical Standards for\\nMicrosoft Visual Basic .NET . Redmond,\\nWA: Microsoft Press.\\nFreedman, Daniel P., and Gerald M. Wein-\\nberg. 1990. Handbook of Walkthroughs,\\nInspections and Technical Reviews , 3d ed.\\nNew York, NY: Dorset House.\\nFreeman, Peter, and Anthony I. Wasser-\\nman, eds. 1983. Tutorial on Software De-\\nsign Techniques , 4th ed. Silver Spring,\\nMD: IEEE Computer Society Press.\\nGamma, Erich, et al. 1995. Design Patterns.\\nReading, MA: Addison-Wesley.\\nGerber, Richard. 2002. Software Optimiza-\\ntion Cookbook: High-Performance Recipes\\nfor the Intel Architecture. Intel Press.\\nGibson, Elizabeth. 1990. “Objects—Born\\nand Bred.” BYTE, October, 245–54.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 906}, page_content='870 Bibliography\\nGilb, Tom, and Dorothy Graham. 1993.\\nSoftware Inspection . Wokingham, En-\\ngland: Addison-Wesley.\\nGilb, Tom. 1977. Software Metrics . Cam-\\nbridge, MA: Winthrop.\\nGilb, Tom. 1988. Principles of Software Engi-\\nneering Management . Wokingham, En-\\ngland: Addison-Wesley.\\nGilb, Tom. 2004. Competitive Engineering .\\nBoston, MA: Addison-Wesley. Down-\\nloadable from www.result-planning.com.\\nGinac, Frank P. 1998. Customer Oriented\\nSoftware Quality Assurance . Englewood\\nCliffs, NJ: Prentice Hall.\\nGlass, Robert L. 1982. Modern Programming\\nPractices: A Report from Industry . Engle-\\nwood Cliffs, NJ: Prentice Hall.\\nGlass, Robert L. 1988. Software Communica-\\ntion Skills. Englewood Cliffs, NJ: Prentice\\nHall.\\nGlass, Robert L. 1991. Software Conflict: Es-\\nsays on the Art and Science of Software En-\\ngineering. Englewood Cliffs, NJ: Yourdon\\nPress.\\nGlass, Robert L. 1995. Software Creativity.\\nReading, MA: Addison-Wesley.\\nGlass, Robert L. 1999. “Inspections—Some\\nSurprising Findings,” Communications of\\nthe ACM, April 1999, 17–19.\\nGlass, Robert L. 1999. “The realities of soft-\\nware technology payoffs,” Communica-\\ntions of the ACM, February 1999, 74–79.\\nGlass, Robert L. 2003. Facts and Fallacies of\\nSoftware Engineering. Boston, MA: Addi-\\nson-Wesley.\\nGlass, Robert L., and Ronald A. Noiseux.\\n1981. Software Maintenance Guidebook .\\nEnglewood Cliffs, NJ: Prentice Hall.\\nGordon, Ronald D. 1979. “Measuring Im-\\nprovements in Program Clarity.” IEEE\\nTransactions on Software Engineering  SE-\\n5, no. 2 (March): 79–90.\\nGordon, Scott V., and James M. Bieman.\\n1991. “Rapid Prototyping and Software\\nQuality: Lessons from Industry.” Ninth\\nAnnual Pacific Northwest Software Quality\\nConference, October 7–8. Oregon Con-\\nvention Center, Portland, OR.\\nGorla, N., A. C. Benander, and B. A.\\nBenander. 1990. “Debugging Effort Esti-\\nmation Using Software Metrics.” IEEE\\nTransactions on Software Engineering  SE-\\n16, no. 2 (February): 223–31.\\nGould, John D. 1975. “Some Psychological\\nEvidence on How People Debug Com-\\nputer Programs.” International Journal of\\nMan-Machine Studies 7:151–82.\\nGrady, Robert B. 1987. “Measuring and\\nManaging Software Maintenance.” IEEE\\nSoftware 4, no. 9 (September): 34–45.\\nGrady, Robert B. 1993. “Practical Rules of\\nThumb for Software Managers.” The Soft-\\nware Practitioner 3, no. 1 (January/Feb-\\nruary): 4–6.\\nGrady, Robert B. 1999. “An Economic Re-\\nlease Decision Model: Insights into Soft-\\nware Project Management.” In\\nProceedings of the Applications of Software\\nMeasurement Conference, 227–239. Or-\\nange Park, FL: Software Quality Engi-\\nneering.\\nGrady, Robert B., and Tom Van Slack. 1994.\\n“Key Lessons in Achieving Widespread\\nInspection Use,” IEEE Software , July\\n1994.\\nGrady, Robert B. 1992. Practical Software\\nMetrics For Project Management And Pro-\\ncess Improvement. Englewood Cliffs, NJ:\\nPrentice Hall.\\nGrady, Robert B., and Deborah L. Caswell.\\n1987. Software Metrics: Establishing a\\nCompany-Wide Program. Englewood\\nCliffs, NJ: Prentice Hall.\\nGreen, Paul. 1987. “Human Factors in\\nComputer Systems, Some Useful Read-\\nings.” Sigchi Bulletin 19, no. 2: 15–20.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 907}, page_content='Bibliography 871\\nGremillion, Lee L. 1984. “Determinants of\\nProgram Repair Maintenance Require-\\nments.” Communications of the ACM  27,\\nno. 8 (August): 826–32.\\nGries, David. 1981. The Science of Program-\\nming. New York, NY: Springer-Verlag.\\nGrove, Andrew S. 1983. High Output Man-\\nagement. New York, NY: Random House.\\nHaley, Thomas J. 1996. “Software Process\\nImprovement at Raytheon.” IEEE Soft-\\nware, November 1996.\\nHansen, John C., and Roger Yim. 1987. “In-\\ndentation Styles in C.” SIGSMALL/PC\\nNotes 13, no. 3 (August): 20–23.\\nHanson, Dines. 1984. Up and Running. New\\nYork, NY: Yourdon Press.\\nHarrison, Warren, and Curtis Cook. 1986.\\n“Are Deeply Nested Conditionals Less\\nReadable?” Journal of Systems and Soft-\\nware 6, no. 4 (November): 335–42.\\nHasan, Jeffrey and Kenneth Tu. 2003. Per-\\nformance Tuning and Optimizing\\nASP.NET Applications. Apress.\\nHass, Anne Mette Jonassen. 2003. Configu-\\nration Management Principles and Practic-\\nes, Boston, MA: Addison-Wesley.\\nHatley, Derek J., and Imtiaz A. Pirbhai. 1988.\\nStrategies for Real-Time System Specifica-\\ntion. New York, NY: Dorset House.\\nHecht, Alan. 1990. “Cute Object-oriented\\nAcronyms Consid ered FOOlish.” Soft-\\nware Engineering Notes, January, 48.\\nHeckel, Paul. 1994. The Elements of Friendly\\nSoftware Design. Alameda, CA: Sybex.\\nHecker, Daniel E. 2001. “Occupational Em-\\nployment Projections to 2010.” Monthly\\nLabor Review, November 2001.\\nHecker, Daniel E. 2004. \"Occupational Em-\\nployment Projections to 2012.\" Monthly\\nLabor Review, February 2004, Vol. 127,\\nNo. 2, pp. 80-105. \\nHenry, Sallie, and Dennis Kafura. 1984.\\n“The Evaluation of Software Systems’\\nStructure Using Quantitative Software\\nMetrics.” Software—Practice and Experi-\\nence 14, no. 6 (June): 561–73.\\nHetzel, Bill. 1988. The Complete Guide to\\nSoftware Testing , 2d ed. Wellesley, MA:\\nQED Information Systems.\\nHighsmith, James A., III. 2000. Adaptive\\nSoftware Development: A Collaborative Ap-\\nproach to Managing Complex Systems.\\nNew York, NY: Dorset House.\\nHighsmith, Jim. 2002. Agile Software Devel-\\nopment Ecosystems . Boston, MA: Addi-\\nson-Wesley.\\nHildebrand, J. D. 1989. “An Engineer’s Ap-\\nproach.” Computer Language, October,\\n5–7.\\nHoare, Charles Anthony Richard, 1981. “The\\nEmperor’s Old Clothes.” Communications\\nof the ACM, February 1981, 75–83.\\nHollocker, Charles P. 1990. Software Re-\\nviews and Audits Handbook . New York,\\nNY: John Wiley & Sons.\\nHoughton, Raymond C. 1990. “An Office\\nLibrary for Software Engineering Profes-\\nsionals.” Software Engineering: Tools,\\nTechniques, Practice, May/June, 35–38.\\nHoward, Michael, and David LeBlanc.\\n2003. Writing Secure Code,  2d ed. Red-\\nmond, WA: Microsoft Press.\\nHughes, Charles E., Charles P. Pfleeger, and\\nLawrence L. Rose. 1978. Advanced Pro-\\ngramming Techniques: A Second Course in\\nProgramming Using Fortran. New York,\\nNY: John Wiley & Sons.\\nHumphrey, Watts S. 1989. Managing the\\nSoftware Process. Reading, MA: Addison-\\nWesley.\\nHumphrey, Watts S. 1995. A Discipline for\\nSoftware Engineering. Reading, MA: Addi-\\nson-Wesley.\\nHumphrey, Watts S., Terry R. Snyder, and\\nRonald R. Willis. 1991. “Software Pro-\\ncess Improvement at Hughes Aircraft.”\\nIEEE Software 8, no. 4 (July): 11–23.\\nHumphrey, Watts. 1997. Introduction to the\\nPersonal Software Process . Reading, MA:\\nAddison-Wesley.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 908}, page_content='872 Bibliography\\nHumphrey, Watts. 2002. Winning with Soft-\\nware: An Executive Strategy . Boston, MA:\\nAddison-Wesley.\\nHunt, Andrew, and David Thomas. 2000.\\nThe Pragmatic Programmer . Boston, MA:\\nAddison-Wesley.\\nIchbiah, Jean D., et al. 1986. Rationale for\\nDesign of the Ada Programming Language.\\nMinneapolis, MN: Honeywell Systems\\nand Research Center.\\nIEEE Software 7, no. 3 (May 1990).\\nIEEE Std 1008-1987 (R1993), Standard for\\nSoftware Unit Testing\\nIEEE Std 1016-1998, Recommended Practice\\nfor Software Design Descriptions\\nIEEE Std 1028-1997, Standard for Software\\nReviews\\nIEEE Std 1045-1992, Standard for Software\\nProductivity Metrics\\nIEEE Std 1058-1998, Standard for Software\\nProject Management Plans\\nIEEE Std 1061-1998, Standard for a Software\\nQuality Metrics Methodology\\nIEEE Std 1062-1998, Recommended Practice\\nfor Software Acquisition\\nIEEE Std 1063-2001, Standard for Software\\nUser Documentation\\nIEEE Std 1074-1997, Standard for Developing\\nSoftware Life Cycle Processes\\nIEEE Std 1219-1998, Standard for Software\\nMaintenance\\nIEEE Std 1233-1998, Guide for Developing\\nSystem Requirements Specifications\\nIEEE Std 1233-1998. IEEE Guide for Develop-\\ning System Requirements Specifications\\nIEEE Std 1471-2000. Recommended Practice\\nfor Architectural Description of Software\\nIntensive Systems \\nIEEE Std 1490-1998, Guide - Adoption of PMI\\nStandard - A Guide to the Project Manage-\\nment Body of Knowledge\\nIEEE Std 1540-2001, Standard for Software\\nLife Cycle Processes - Risk Management\\nIEEE Std 730-2002, Standard for Software\\nQuality Assurance Plans\\nIEEE Std 828-1998, Standard for Software\\nConfiguration Management Plans\\nIEEE Std 829-1998, Standard for Software\\nTest Documentation\\nIEEE Std 830-1998, Recommended Practice\\nfor Software Requirements Specifications\\nIEEE Std 830-1998. IEEE Recommended Prac-\\ntice for Software Requirements Specifica-\\ntions. Los Alamitos, CA: IEEE Computer\\nSociety Press.\\nIEEE, 1991. IEEE Software Engineering Stan-\\ndards Collection, Spring 1991 Edition .\\nNew York, NY: Institute of Electrical and\\nElectronics Engineers.\\nIEEE, 1992. “Rear Adm. Grace Hopper dies\\nat 85.” IEEE Computer, February, 84.\\nIngrassia, Frank S. 1976. “The Unit Devel-\\nopment Folder (UDF): An Effective\\nManagement Tool for Software Develop-\\nment.” TRW Technical Report TRW-SS-\\n76-11. Also reprinted in Reifer 1986,\\n366–79.\\nIngrassia, Frank S. 1987. “The Unit Devel-\\nopment Folder (UDF): A Ten-Year Per-\\nspective.” Tutorial: Software Engineering\\nProject Management , ed. Richard H.\\nThayer. Los Alamitos, CA: IEEE Comput-\\ner Society Press, 405–15.\\nJackson, Michael A. 1975. Principles of Pro-\\ngram Design . New York, NY: Academic\\nPress.\\nJacobson, Ivar, Grady Booch, and James\\nRumbaugh. 1999. The Unified Software\\nDevelopment Process. Reading, MA: Addi-\\nson-Wesley.\\nJohnson, Jim. 1999. “Turning Chaos into\\nSuccess,” Software Magazine, December\\n1999, 30–39.\\nJohnson, Mark. 1994a. “Dr. Boris Beizer\\non Software Testing: An Interview Part\\n1,” The Software QA Quarterly , Spring\\n1994, 7–13.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 909}, page_content='Bibliography 873\\nJohnson, Mark. 1994b. “Dr. Boris Beizer on\\nSoftware Testing: An Interview Part 2,”\\nThe Software QA Quarterly , Summer\\n1994, 41–45.\\nJohnson, Walter L. 1987. “Some Comments\\non Coding Practice.” ACM SIGSOFT Soft-\\nware Engineering Notes 12, no. 2 (April):\\n32–35.\\nJones, T. Capers. 1977. “Program Quality\\nand Programmer Productivity.” IBM\\nTechnical Report TR 02.764, January, 42–\\n78. Also in Jones 1986b.\\nJones, Capers. 1986a. Programming Produc-\\ntivity. New York, NY: McGraw-Hill.\\nJones, T. Capers, ed. 1986b. Tutorial: Pro-\\ngramming Productivity: Issues for the\\nEighties, 2d ed. Los Angeles, CA: IEEE\\nComputer Society Press.\\nJones, Capers. 1996. “Software Defect-Re-\\nmoval Efficiency,” IEEE Computer , April\\n1996.\\nJones, Capers. 1997. Applied Software Mea-\\nsurement: Assuring Productivity and Qual-\\nity, 2d ed. New York, NY: McGraw-Hill.\\nJones, Capers. 1998. Estimating Software\\nCosts. New York, NY: McGraw-Hill.\\nJones, Capers. 2000. Software Assessments,\\nBenchmarks, and Best Practices . Reading,\\nMA: Addison-Wesley.\\nJones, Capers. 2003. “V ariations in Soft-\\nware Development Practices,” IEEE Soft-\\nware, November/December 2003, 22–\\n27.\\nJonsson, Dan. 1989. “Next: The Elimina-\\ntion of GoTo-Patches?” ACM Sigplan No-\\ntices 24, no. 3 (March): 85–92.\\nKaelbling, Michael. 1988. “Programming\\nLanguages Should NOT Have Comment\\nStatements.” ACM Sigplan Notices 23, no.\\n10 (October): 59–60.\\nKaner, Cem, Jack Falk, and Hung Q. Nguy-\\nen. 1999. Testing Computer Software , 2d\\ned. New York, NY: John Wiley & Sons.\\nKaner, Cem, James Bach, and Bret Pettichord.\\n2002. Lessons Learned in Software Testing.\\nNew York, NY: John Wiley & Sons.\\nKeller, Daniel. 1990. “A Guide to Natural\\nNaming.” ACM Sigplan Notices 25, no. 5\\n(May): 95–102.\\nKelly, John C. 1987. “A Comparison of Four\\nDesign Methods for Real-Time Systems.”\\nProceedings of the Ninth International Con-\\nference on Software Engineering. 238–52.\\nKelly-Bootle, Stan. 1981. The Devil’s DP Dic-\\ntionary. New York, NY: McGraw-Hill.\\nKernighan, Brian W., and Rob Pike. 1999.\\nThe Practice of Programming . Reading,\\nMA: Addison-Wesley.\\nKernighan, Brian W., and P. J. Plauger.\\n1976. Software Tools. Reading, MA: Addi-\\nson-Wesley.\\nKernighan, Brian W., and P. J. Plauger.\\n1978. The Elements of Programming Style.\\n2d ed. New York, NY: McGraw-Hill.\\nKernighan, Brian W., and P. J. Plauger.\\n1981. Software Tools in Pascal . Reading,\\nMA: Addison-Wesley.\\nKernighan, Brian W., and Dennis M. Ritch-\\nie. 1988. The C Programming Language ,\\n2d ed. Englewood Cliffs, NJ: Prentice\\nHall.\\nKillelea, Patrick. 2002. Web Performance\\nTuning, 2d ed. Sebastopol, CA: O’Reilly\\n& Associates.\\nKing, David. 1988. Creating Effective Soft-\\nware: Computer Program Design Using the\\nJackson Methodology . New York, NY:\\nYourdon Press.\\nKnuth, Donald. 1971. “An Empirical Study\\nof FORTRAN programs,” Software—Prac-\\ntice and Experience 1:105–33.\\nKnuth, Donald. 1974. “Structured Pro-\\ngramming with go to Statements.” In\\nClassics in Software Engineering, edited by\\nEdward Yourdon. Englewood Cliffs, NJ:\\nYourdon Press, 1979.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 910}, page_content='874 Bibliography\\nKnuth, Donald. 1986. Computers and Type-\\ns e t t i n g ,  V o l u m e  B ,  T E X :  T h e  P r o g r a m.\\nReading, MA: Addison-Wesley.\\nKnuth, Donald. 1997a. The Art of Computer\\nProgramming, vol. 1, Fundamental Algo -\\nrithms, 3d ed. Reading, MA: Addison-\\nWesley.\\nKnuth, Donald. 1997b. The Art of Computer\\nProgramming, vol. 2, Seminumerical Algo-\\nrithms, 3d ed. Reading, MA: Addison-\\nWesley.\\nKnuth, Donald. 1998. The Art of Computer\\nProgramming, vol. 3, Sorting and Searching,\\n2d ed. Reading, MA: Addison-Wesley.\\nKnuth, Donald. 2001. Literate Program-\\nming. Cambridge University Press.\\nKorson, Timothy D., and Vijay K. Vaishnavi.\\n1986. “An Empirical Study of Modulari-\\nty on Program Modifiability.” In Soloway\\nand Iyengar 1986: 168–86.\\nKouchakdjian, Ara, Scott Green, and Victor\\nBasili. 1989. “Evaluation of the Clean-\\nroom Methodology in the Software Engi-\\nneering Laboratory.” Proceedings of the\\nFourteenth Annual Software Engineering\\nWorkshop, November 29, 1989. Green-\\nbelt, MD: Goddard Space Flight Center.\\nDocument SEL-89-007.\\nKovitz, Benjamin, L. 1998 Practical Software\\nRequirements: A Manual of Content and\\nStyle, Manning Publications Company.\\nKreitzberg, C. B., and B. Shneiderman.\\n1972. The Elements of Fortran Style. New\\nYork, NY: Harcourt Brace Jovanovich.\\nKruchten, Philippe B. “The 4+1 View Model\\nof Architecture.” IEEE Software , pages\\n42–50, November 1995.\\nKruchten, Philippe. 2000. The Rational Uni-\\nfied Process: An Introduction, 2d Ed.,\\nReading, MA: Addison-Wesley.\\nKuhn, Thomas S. 1996. The Structure of Sci-\\nentific Revolutions, 3d ed. Chicago: Uni-\\nversity of Chicago Press.\\nLammers, Susan. 1986. Programmers at\\nWork. Redmond, WA: Microsoft Press.\\nLampson, Butler. 1984. “Hints for Comput-\\ner System Design.” IEEE Software 1, no. 1\\n(January): 11–28.\\nLarman, Craig and Rhett Guthrie. 2000.\\nJava 2 Performance and Idiom Guide . En-\\nglewood Cliffs, NJ: Prentice Hall.\\nLarman, Craig. 2001. Applying UML and\\nPatterns: An Introduction to Object-Orient-\\ned Analysis and Design and the Unified\\nProcess, 2d ed. Englewood Cliffs, NJ:\\nPrentice Hall.\\nLarman, Craig. 2004. Agile and Iterative De-\\nvelopment: A Manager’s Guide . Boston,\\nMA: Addison-Wesley, 2004.\\nLauesen, Soren. Software Requirements:\\nStyles and Techniques. Boston, MA: Addi-\\nson-Wesley, 2002.\\nLaurel, Brenda, ed. 1990. The Art of Human-\\nComputer Interface Design . Reading, MA:\\nAddison-Wesley.\\nLedgard, Henry F., with John Tauer. 1987a.\\nC With Excellence: Programming Proverbs.\\nIndianapolis: Hayden Books.\\nLedgard, Henry F., with John Tauer. 1987b.\\nProfessional Software, vol. 2, Programming\\nPractice. Indianapolis: Hayden Books.\\nLedgard, Henry, and Michael Marcotty.\\n1986. The Programming Language Land-\\nscape: Syntax, Semantics, and Implementa-\\ntion, 2d ed. Chicago: Science Research\\nAssociates.\\nLedgard, Henry. 1985. “Programmers: The\\nAmateur vs. the Professional.” Abacus 2,\\nno. 4 (Summer): 29–35.\\nLeffingwell, Dean. 1997. “Calculating the\\nReturn on Investment from More Effec-\\ntive Requirements Management,” Ameri-\\ncan Programmer, 10(4):13–16.\\nLewis, Daniel W. 1979. “A Review of Ap-\\nproaches to Teaching Fortran.” IEEE\\nTransactions on Education, E-22, no. 1:\\n23–25.\\nLewis, William E. 2000. Software Testing and\\nContinuous Quality Improvement, 2d ed.\\nAuerbach Publishing.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 911}, page_content='Bibliography 875\\nLieberherr, Karl J. and Ian Holland. 1989.\\n“Assuring Good Style for Object-Orient-\\ned Programs.” IEEE Software, September\\n1989, pp. 38f.\\nLientz, B. P., and E. B. Swanson. 1980. Soft-\\nware Maintenance Management. Reading,\\nMA: Addison-Wesley.\\nLind, Randy K., and K. Vairavan. 1989. “An\\nExperimental Investigation of Software\\nMetrics and Their Relationship to Soft-\\nware Development Effort.” IEEE Transac-\\ntions on Software Engineering SE-15, no. 5\\n(May): 649–53.\\nLinger, Richard C., Harlan D. Mills, and Ber-\\nnard I. Witt. 1979. Structured Program-\\nming: Theory and Practice . Reading, MA:\\nAddison-Wesley.\\nLinn, Marcia C., and Michael J. Clancy.\\n1992. “The Case for Case Studies of Pro-\\ngramming Problems.” Communications\\nof the ACM 35, no. 3 (March): 121–32.\\nLiskov, Barbara, and Stephen Zilles. 1974.\\n“Programming with Abstract Data Types.”\\nACM Sigplan Notices 9, no. 4: 50–59.\\nLiskov, Barbara. “Data Abstraction and Hi-\\nerarchy,” ACM SIGPLAN Not ices, May\\n1988.\\nLittman, David C., et al. 1986. “Mental\\nModels and Software Maintenance.” In\\nSoloway and Iyengar 1986: 80–98.\\nLongstreet, David H., ed. 1990. Software\\nMaintenance and Computers . Los Alami-\\ntos, CA: IEEE Computer Society Press.\\nLoy, Patrick H. 1990. “A Comparison of Ob-\\nject-Oriented and Structured Develop-\\nment Methods.” Software Engineering\\nNotes 15, no. 1 (January): 44–48.\\nMackinnon, Tim, Steve Freeman, and Philip\\nCraig. 2000. “Endo-Testing: Unit Testing\\nwith Mock Objects,” eXtreme Program-\\nming and Flexible Processes Software En-\\ngineering - XP2000 Conference.\\nMaguire, Steve. 1993. Writing Solid Code .\\nRedmond, WA: Microsoft Press.\\nMannino, P. 1987. “A Presentation and\\nComparison of Four Information Sys-\\ntem Development Methodologies.” Soft-\\nware Engineering Notes 12, no. 2 (April):\\n26–29.\\nManzo, John. 2002. “Odyssey and Other\\nCode Science Success Stories.” Crosstalk,\\nOctober 2002.\\nMarca, David. 1981. “Some Pascal Style\\nGuidelines.” ACM Sigplan Notices 16, no.\\n4 (April): 70–80.\\nMarch, Steve. 1999. “Learning from Path-\\nfinder’s Bumpy Start.” Software Testing\\nand Quality Engineering , September/Oc-\\ntober 1999, pp. 10f.\\nMarcotty, Michael. 1991. Software Imple-\\nmentation. New York, NY: Prentice Hall.\\nMartin, Robert C. 2003. Agile Software\\nDevelopment: Principles, Patterns, and\\nPractices. Upper Saddle River, NJ:\\nPearson Education.\\nMcCabe, Tom. 1976. “A Complexity Mea-\\nsure.” IEEE Transactions on Software Engi-\\nneering, SE-2, no. 4 (December): 308–20.\\nMcCarthy, Jim. 1995. Dynamics of Software\\nDevelopment. Redmond, WA: Microsoft\\nPress.\\nMcConnell, Steve. 1996. Rapid Develop-\\nment. Redmond, WA: Microsoft Press.\\nMcConnell, Steve. 1997a. “The Program-\\nmer Writing,” IEEE Software , July/Au-\\ngust 1997.\\nMcConnell, Steve. 1997b. “Achieving Lean-\\ner Software,” IEEE Software, November/\\nDecember 1997.\\nMcConnell, Steve. 1998a. Software Project\\nSurvival Guide. Redmond, WA: Microsoft\\nPress.\\nMcConnell, Steve. 1998b. “Why You\\nShould Use Routines, Routinely,” IEEE\\nSoftware, Vol. 15, No. 4, July/August\\n1998.\\nMcConnell, Steve. 1999. “Brooks Law Re-\\npealed?” IEEE Software , November/De-\\ncember 1999.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 912}, page_content='876 Bibliography\\nMcConnell, Steve. 2004. Professional Soft-\\nware Development. Boston, MA: Addison-\\nWesley.\\nMcCue, Gerald M. 1978. “IBM’s Santa Tere-\\nsa Laboratory—Architectural Design for\\nProgram Development.” IBM Systems\\nJournal 17, no. 1:4–25.\\nMcGarry, Frank, and Rose Pajerski. 1990.\\n“Towards Understanding Software—15\\nYears in the SEL.” Proceedings of the Fif-\\nteenth Annual Software Engineering Work-\\nshop, November 28–29, 1990 . Greenbelt,\\nMD: Goddard Space Flight Center. Doc-\\nument SEL-90-006.\\nMcGarry, Frank, Sharon Waligora, and Tim\\nMcDermott. 1989. “Experiences in the\\nSoftware Engineering Laboratory (SEL)\\nApplying Software Measurement.” Pro-\\nceedings of the Fourteenth Annual Software\\nEngineering Workshop, November 29,\\n1989. Greenbelt, MD: Goddard Space\\nFlight Center. Document SEL-89-007.\\nMcGarry, John, et al. 2001. Practical Soft-\\nware Measurement: Objective Information\\nfor Decision Makers. Boston, MA: Addi-\\nson-Wesley.\\nMcKeithen, Katherine B., et al. 1981.\\n“Knowledge Organization and Skill Dif-\\nferences in Computer Programmers.”\\nCognitive Psychology 13:307–25.\\nMetzger, Philip W., and John Boddie. 1996.\\nManaging a Programming Project: Process-\\nes and People , 3d ed. Englewood Cliffs,\\nNJ: Prentice Hall, 1996.\\nMeyer, Bertrand. 1997. Object-Oriented Soft-\\nware Construction, 2d ed. New York, NY:\\nPrentice Hall.\\nMeyers, Scott. 1996. More Effective C++: 35\\nNew Ways to Improve Your Programs and\\nDesigns. Reading, MA: Addison-Wesley.\\nMeyers, Scott. 1998. Effective C++: 50 Specif-\\nic Ways to Improve Your Programs and De-\\nsigns, 2d ed. Reading, MA: Addison-\\nWesley.\\nMiaria, Richard J., et al. 1983. “Program In-\\ndentation and Comprehensibility.” Com-\\nmunications of the ACM  26, no. 11\\n(November): 861–67.\\nMichalewicz, Zbigniew, and David B. Fogel.\\n2000. How to Solve It: Modern Heuristics .\\nBerlin: Springer-Verlag.\\nMiller, G. A. 1956. “The Magical Number\\nSeven, Plus or Minus Two: Some Limits\\non Our Capacity for Processing Informa-\\ntion.” The Psychological Review 63, no. 2\\n(March): 81–97.\\nMills, Harlan D. 1983. Software Productivity.\\nBoston, MA: Little, Brown.\\nMills, Harlan D. 1986. “Structured Pro-\\ngramming: Retrospect and Prospect.”\\nIEEE Software, November, 58–66.\\nMills, Harlan D., and Richard C. Linger.\\n1986. “Data Structured Programming:\\nProgram Design Without Arrays and\\nPointers.” IEEE Transactions on Software\\nEngineering SE-12, no. 2 (February):\\n192–97.\\nMills, Harlan D., Michael Dyer, and Richard\\nC. Linger. 1987. “Cleanroom Software\\nEngineering.” IEEE Software, September,\\n19–25.\\nMisfeldt, Trevor, Gr eg Bumgardner, and\\nAndrew Gray. 2004. The Elements of C++\\nStyle. Cambridge University Press.\\nMitchell, Jeffrey, Joseph Urban, and Robert\\nMcDonald. 1987. “The Effect of Abstract\\nData Types on Program Development.”\\nIEEE Computer  20, no. 9 (September):\\n85–88.\\nMody, R. P. 1991. “C in Education and Soft-\\nware Engineering.” SIGCSE Bulletin  23,\\nno. 3 (September): 45–56.\\nMoore, Dave. 1992. Private communication.\\nMoore, James W. 1997. Software Engineer-\\ning Standards: A User’s Road Map . Los\\nAlamitos, CA: IEEE Computer Society\\nPress.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 913}, page_content='Bibliography 877\\nMorales, Alexandra Weber. 2003. “The\\nConsummate Coach: Watts Humphrey,\\nFather of Cmm and Author of Winning\\nwith Software, Explains How to Get Bet-\\nter at What You Do,” SD Show Daily, Sep-\\ntember 16, 2003.\\nMyers, Glenford J. 1976. Software Reliabili-\\nty. New York, NY: John Wiley & Sons.\\nMyers, Glenford J. 1978a. Composite/Struc-\\ntural Design . New York, NY: Van Nos-\\ntrand Reinhold.\\nMyers, Glenford J. 1978b. “A Controlled\\nExperiment in Program Testing and\\nCode Walkthroughs/Inspections.” Com-\\nmunications of the ACM  21, no. 9 (Sep-\\ntember): 760–68.\\nMyers, Glenford J. 1979. The Art of Software\\nTesting. New York, NY: John Wiley &\\nSons.\\nMyers, Ware. 1992. “Good Software Practic-\\nes Pay Off—Or Do They?” IEEE Software,\\nMarch, 96–97.\\nNaisbitt, John. 1982. Megatrends. New\\nYork, NY: Warner Books.\\nNASA Software Engineering Laboratory,\\n1994. Software Measurement Guidebook ,\\nJune 1995, NASA-GB-001-94. Available\\nfrom http://sel.gsfc.nasa.gov/website\\n/documents/online-doc/94-102.pdf .\\nNCES 2002. National Center for Education\\nStatistics, 2001 Digest of Educational Sta-\\ntistics, Document Number NCES\\n2002130, April 2002.\\nNevison, John M. 1978. The Little Book of BA-\\nSIC Style. Reading, MA: Addison-Wesley.\\nNewcomer, Joseph M. 2000. “Optimization:\\nYour Worst Enemy,” May 2000,\\nwww.flounder.com/optimization.htm.\\nNorcio, A. F. 1982. “Indentation, Documen-\\ntation and Programmer Comprehen-\\nsion.” Proceedings: Human Factors in\\nComputer Systems, March 15–17, 1982,\\nGaithersburg, MD: 118–20.\\nNorman, Donald A. 1988. The Psychology of\\nEveryday Things . New York, NY: Basic\\nBooks. (Also published in paperback as\\nThe Design of Everyday Things. New York,\\nNY: Doubleday, 1990.)\\nOman, Paul and Shari Lawrence Pfleeger,\\neds. 1996. Applying Software Metrics. Los\\nAlamitos, CA: IEEE Computer Society\\nPress.\\nOman, Paul W., and Curtis R. Cook. 1990a.\\n“The Book Paradigm for Improved Main-\\ntenance.” IEEE Software, January, 39–45.\\nOman, Paul W., and Curtis R. Cook. 1990b.\\n“Typographic Style Is More Than Cos-\\nmetic.” Communications of the ACM  33,\\nno. 5 (May): 506–20.\\nOstrand, Thomas J., and Elaine J. Weyuker.\\n1984. “Collecting and Categorizing Soft-\\nware Error Data in an Industrial Envi-\\nronment.” Journal of Systems and Software\\n4, no. 4 (November): 289–300.\\nPage-Jones, Meilir. 2000. Fundamentals of\\nObject-Oriented Design in UML . Boston,\\nMA: Addison-Wesley.\\nPage-Jones, Meilir. 1988. The Practical Guide\\nto Structured Systems Design . Englewood\\nCliffs, NJ: Yourdon Press.\\nParikh, G., and N. Zvegintzov, eds. 1983.\\nTutorial on Software Maintenance . Los\\nAlamitos, CA: IEEE Computer Society\\nPress.\\nParikh, Girish. 1986. Handbook of Software\\nMaintenance. New York, NY: John Wiley\\n& Sons.\\nParnas, David L. 1972. “On the Criteria to\\nBe Used in Decomposing Systems into\\nModules.” Communications of the ACM 5,\\nno. 12 (December): 1053–58.\\nParnas, David L. 1976. “On the Design and\\nDevelopment of Program Families.”\\nIEEE Transactions on Software Engineer-\\ning SE-2, 1 (March): 1–9.\\nParnas, David L. 1979. “Designing Software\\nfor Ease of Extension and Contraction.”\\nIEEE Transactions on Software Engineer-\\ning SE-5, no. 2 (March): 128–38.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 914}, page_content='878 Bibliography\\nParnas, David L. 1999. ACM Fellow Profile:\\nDavid Lorge Parnas,” ACM Software Engi-\\nneering Notes, May 1999, 10–14.\\nParnas, David L., and Paul C. Clements.\\n1986. “A Rational Design Process: How\\nand Why to Fake It.” IEEE Transactions\\non Software Engineering  SE-12, no. 2\\n(February): 251–57.\\nParnas, David L., Paul C. Clements, and D.\\nM. Weiss. 1985. “The Modular Structure\\nof Complex Systems.” IEEE Transactions\\non Software Engineering  SE-11, no. 3\\n(March): 259–66.\\nPerrott, Pamela. 2004. Private communi-\\ncation.\\nPeters, L. J., and L. L. Tripp. 1976. “Is Soft-\\nware Design Wicked” Datamation, Vol.\\n22, No. 5 (May 1976), 127–136.\\nPeters, Lawrence J. 1981. Handbook of Soft-\\nware Design: Methods and Techniques .\\nNew York, NY: Yourdon Press.\\nPeters, Lawrence J., and Leonard L. Tripp.\\n1977. “Comparing Software Design\\nMethodologies.” Datamation, Novem-\\nber, 89–94.\\nPeters, Tom. 1987. Thriving on Chaos: Hand-\\nbook for a Management Revolution. New\\nYork, NY: Knopf.\\nPetroski, Henry. 1994. Design Paradigms:\\nCase Histories of Error and Judgment in\\nEngineering. Cambridge, U.K.: Cam-\\nbridge University Press.\\nPietrasanta, Alfred M.  1990. “Alfred M. Pi-\\netrasanta on Improving the Software\\nProcess.” Software Engineering: Tools,\\nTechniques, Practices  1, no. 1 (May/\\nJune): 29–34.\\nPietrasanta, Alfred M. 1991a. “A Strategy for\\nSoftware Process Improvement.” Ninth\\nAnnual Pacific Northwest Software Quality\\nConference, October 7–8, 1991 . Oregon\\nConvention Center, Portland, OR\\nPietrasanta, Alfred M. 1991b. “Implement-\\ning Software Engineering in IBM.” Key-\\nnote address. Ninth Annual Pacific\\nNorthwest Software Quality Conference,\\nOctober 7–8, 1991. Oregon Convention\\nCenter, Portland, OR.\\nPigoski, Thomas M. 1997. Practical Software\\nMaintenance. New York, NY: John Wiley\\n& Sons.\\nPirsig, Robert M. 1974. Zen and the Art of\\nMotorcycle Maintenance: An Inquiry into\\nValues. William Morrow.\\nPlauger, P. J. 1988. “A Designer’s Bibliogra-\\nphy.” Computer Language, July, 17–22.\\nPlauger, P. J. 1993. Programming on Purpose:\\nEssays on Software Design. New York, NY:\\nPrentice Hall.\\nPlum, Thomas. 1984. C Programming\\nGuidelines. Cardiff, NJ: Plum Hall.\\nPolya, G. 1957. How to Solve It: A New Aspect\\nof Mathematical Method , 2d ed. Prince-\\nton, NJ: Princeton University Press.\\nPost, Ed. 1983. “Real Programmers Don’t\\nUse Pascal,” Datamation, July 1983,\\n263–265.\\nPrechelt, Lutz. 2000. “An Empirical Compar-\\nison of Seven Programming Languages,”\\nIEEE Computer, October 2000, 23–29.\\nPressman, Roger S. 1987. Software Engineer-\\ning: A Practitioner’s Approach. New York,\\nNY: McGraw-Hill.\\nPressman, Roger S. 1988. Making Software\\nEngineering Happen: A Guide for Institut-\\ning the Technology. Englewood Cliffs, NJ:\\nPrentice Hall.\\nPutnam, Lawrence H. 2000. “Familiar Met-\\nric Management – Effort, Development\\nTime, and Defects Interact.” Download-\\nable from www.qsm.com.\\nPutnam, Lawrence H., and Ware Myers.\\n1992. Measures for Excellence: Reliable\\nSoftware On Time, Within Budget . Engle-\\nwood Cliffs, NJ: Yourdon Press, 1992.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 915}, page_content='Bibliography 879\\nPutnam, Lawrence H., and Ware Myers.\\n1997. Industrial Strength Software: Effec-\\ntive Management Using Measurement .\\nWashington, DC: IEEE Computer Soci-\\nety Press.\\nPutnam, Lawrence H., and Ware Myers.\\n2000. “What We Have Learned.” Down-\\nloadable from www.qsm.com, June 2000.\\nRaghavan, Sridhar A., and Donald R. Chand.\\n1989. “Diffusing Software-Engineering\\nMethods.” IEEE Software, July, 81–90.\\nRamsey, H. Rudy, Michael E. Atwood, and\\nJames R. Van Doren. 1983. “Flowcharts\\nVersus Program Design Languages: An\\nExperimental Comparison.” Communica-\\ntions of the ACM 26, no. 6 (June): 445–49.\\nRatliff, Wayne. 1987. Interview in Solution\\nSystem.\\nRaymond, E. S.  2000. “The Cathedral and\\nthe Bazaar,” www.catb.org/~esr/writings\\n/cathedral-bazaar.\\nRaymond, Eric S. 2004. The Art of Unix Pro-\\ngramming. Boston, MA: Addison-Wesley.\\nRees, Michael J. 1982.  “Automatic Assess-\\nment Aids for Pascal Programs.” ACM Sig-\\nplan Notices 17, no. 10 (October): 33–42.\\nReifer, Donald. 2002. “How to Get the Most\\nOut of Extreme Programming/Agile\\nMethods,” Proceedings, XP/Agile Uni-\\nverse 2002 . New York, NY: Springer;\\n185–196.\\nReingold, Edward M., and Wilfred J. Hans-\\nen. 1983. Data Structures . Boston, MA:\\nLittle, Brown.\\nRettig, Marc. 1991. “Testing Made Palat-\\nable.” Communications of the ACM 34, no.\\n5 (May): 25–29.\\nRiel, Arthur J. 1996. Object-Oriented Design\\nHeuristics. Reading, MA: Addison-Wesley.\\nRittel, Horst, and Melvin Webber. 1973.\\n“Dilemmas in a General Theory of Plan-\\nning.” Policy Sciences 4:155–69.\\nRobertson, Suzanne, and James Robertson,\\n1999. Mastering the Requirements Process.\\nReading, MA: Addison-Wesley.\\nRogers, Everett M. 1995. Diffusion of Innova-\\ntions, 4th ed. New York, NY: The Free\\nPress.\\nRombach, H. Dieter. 1990. “Design Mea-\\nsurements: Some Lessons Learned.”\\nIEEE Software, March, 17–25.\\nRubin, Frank. 1987. “‘GOTO Considered\\nHarmful’ Considered Harmful.” Letter\\nto the editor. Communications of the ACM\\n30, no. 3 (March): 195–96. Follow-up\\nletters in 30, no. 5 (May 1987): 351–55;\\n30, no. 6 (June 1987): 475–78; 30, no. 7\\n(July 1987): 632–34; 30, no. 8 (August\\n1987): 659–62; 30, no. 12 (December\\n1987): 997, 1085.\\nSackman, H., W. J. Erikson, and E. E. Grant.\\n1968. “Exploratory Experimental Studies\\nComparing Online and Offline Program-\\nming Performance.” Communications of\\nthe ACM 11, no. 1 (January): 3–11.\\nSchneider, G. Michael, Johnny Martin, and\\nW. T. Tsai. 1992. “An Experimental\\nStudy of Fault Detection in User Re-\\nquirements Documents,” ACM Transac-\\ntions on Software Engineering and\\nMethodology, vol 1, no. 2, 188–204.\\nSchulmeyer, G. Gordon. 1990. Zero Defect\\nSoftware. New York, NY: McGraw-Hill.\\nSedgewick, Robert. 1997. Algorithms in C,\\nParts 1-4 , 3d ed. Boston, MA: Addison-\\nWesley.\\nSedgewick, Robert. 2001. Algorithms in C,\\nPart 5 , 3d ed. Boston, MA: Addison-\\nWesley.\\nSedgewick, Robert. 1998. Algorithms in C++,\\nParts 1-4 , 3d ed. Boston, MA: Addison-\\nWesley.\\nSedgewick, Robert. 2002. Algorithms in\\nC++, Part 5, 3d ed. Boston, MA: Addison-\\nWesley.\\nSedgewick, Robert. 2002. Algorithms in Java,\\nParts 1-4 , 3d ed. Boston, MA: Addison-\\nWesley.\\nSedgewick, Robert. 2003. Algorithms in Java,\\nPart 5 , 3d ed. Boston, MA: Addison-\\nWesley.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 916}, page_content='880 Bibliography\\nSEI 1995. The Capability Maturity Model:\\nGuidelines for Improving the Software Pro-\\ncess, Software Engineering Institute,\\nReading, MA: Addison-Wesley, 1995.\\nSEI, 2003. “Process Maturity Profile: Soft-\\nware CMM®, CBA IPI and SPA Appraisal\\nResults: 2002 Year End Update,” Soft-\\nware Engineering Institute, April 2003.  \\nSelby, Richard W., and Victor R. Basili.\\n1991. “Analyzing Error-Prone System\\nStructure.” IEEE Transactions on Software\\nEngineering SE-17, no. 2 (February):\\n141–52.\\nSEN 1990. “Subsection on Telephone Sys-\\ntems,” Software Engineering Notes , April\\n1990, 11–14.\\nShalloway, Alan, and James R. Trott. 2002.\\nDesign Patterns Explained . Boston, MA:\\nAddison-Wesley.\\nSheil, B. A. 1981. “The Psychological Study\\nof Programming.” Computing Surveys 13,\\nno. 1 (March): 101–20.\\nShen, Vincent Y., et al. 1985. “Identifying\\nError-Prone Software—An Empirical\\nStudy.” IEEE Transactions on Software En-\\ngineering SE-11, no. 4 (April): 317–24.\\nSheppard, S. B., et al. 1978. “Predicting Pro-\\ngrammers’ Ability to Modify Software.”\\nTR 78-388100-3, General Electric Com-\\npany, May.\\nSheppard, S. B., et al. 1979. “Modern Cod-\\ning Practices and Programmer Perfor-\\nmance.” IEEE Computer  12, no. 12\\n(December): 41–49.\\nShepperd, M., and D. Ince. 1989. “Metrics,\\nOutlier Analysis and the Software De-\\nsign Process.” Information and Software\\nTechnology 31, no. 2 (March): 91–98.\\nShirazi, Jack. 2000. Java Performance Tun-\\ning. Sebastopol, CA: O’Reilly & Associ-\\nates.\\nShlaer, Sally, and Stephen J. Mellor. 1988.\\nObject Oriented Systems Analysis—Model-\\ning the World in Data . Englewood Cliffs,\\nNJ: Prentice Hall.\\nShneiderman, Ben, and Richard Mayer.\\n1979. “Syntactic/Semantic Interactions\\nin Programmer Behavior: A Model and\\nExperimental Results.” International\\nJournal of Computer and Information Sci-\\nences 8, no. 3: 219–38.\\nShneiderman, Ben. 1976. “Exploratory Ex-\\nperiments in Programmer Behavior.” In-\\nternational Journal of Computing and\\nInformation Science 5:123–43.\\nShneiderman, Ben. 1980. Software Psychol-\\nogy: Human Factors in Computer and\\nInformation Systems. Cambridge, MA:\\nWinthrop.\\nShneiderman, Ben. 1987. Designing the User\\nInterface: Strategies for Effective Human-\\nComputer Interaction. Reading, MA: Add-\\nison-Wesley.\\nShull, et al. 2002. “What We Have Learned\\nAbout Fighting Defects,” Proceedings,\\nMetrics 2002. IEEE; 249–258.\\nSimon, Herbert. 1996. The Sciences of the Ar-\\ntificial, 3d ed. Cambridge, MA: MIT\\nPress.\\nSimon, Herbert. The Shape of Automation for\\nMen and Management. Harper and Row,\\n1965.\\nSimonyi, Charles, and Martin Heller. 1991.\\n“The Hungarian Revolution.” BYTE , Au-\\ngust, 131–38.\\nSmith, Connie U., and Lloyd G. Williams.\\n2002. Performance Solutions: A Practical\\nGuide to Creating Responsive, Scalable\\nSoftware. Boston, MA: Addison-Wesley.\\nSoftware Productivity Consortium. 1989.\\nAda Quality and Style: Guidelines for Pro-\\nfessional Programmers. New York, NY:\\nVan Nostrand Reinhold.\\nSoloway, Elliot, and Kate Ehrlich. 1984.\\n“Empirical Studies of Programming\\nKnowledge.” IEEE Transactions on Soft-\\nware Engineering  SE-10, no. 5 (Septem-\\nber): 595–609.\\nSoloway, Elliot, and Sitharama Iyengar, eds.\\n1986. Empirical Studies of Programmers .\\nNorwood, NJ: Ablex.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 917}, page_content='Bibliography 881\\nSoloway, Elliot, Jeffrey Bonar, and Kate Ehr-\\nlich. 1983. “Cognitive Strategies and\\nLooping Constructs: An Empirical\\nStudy.” Communications of the ACM  26,\\nno. 11 (November): 853–60.\\nSolution Systems. 1987. World-Class Pro-\\ngrammers’ Editing Techniques: Interviews\\nwith Seven Programmers. South Wey-\\nmouth, MA: Solution Systems.\\nSommerville, Ian. 1989. Software Engineer-\\ning, 3d ed. Reading, MA: Addison-Wesley.\\nSpier, Michael J. 1976. “Software Malprac-\\ntice—A Distasteful Experience.” Soft-\\nware—Practice and Experience 6:293–99.\\nSpinellis, Diomidis. 2003. Code Reading:\\nThe Open Source Perspective. Boston, MA:\\nAddison-Wesley.\\nSPMN. 1998. Little Book of Configuration\\nManagement. Arlington, VA; Software\\nProgram Managers Network.\\nStarr, Daniel. 2003. “What Supports the\\nRoof?” Software Development. July 2003,\\n38–41.\\nStephens, Matt. 2003. “Emergent Design vs.\\nEarly Prototyping,” May 26, 2003,\\nwww.softwarereality.com/design/early_\\nprototyping.jsp.\\nStevens, Scott M. 1989. “Intelligent Interac-\\ntive Video Simulation of a Code Inspec-\\ntion.” Communications of the ACM 32, no.\\n7 (July): 832–43.\\nStevens, W., G. Myers, and L. Constantine.\\n1974. “Structured Design.” IBM Systems\\nJournal 13, no. 2 (May): 115–39.\\nStevens, Wayne. 1981. Using Structured De-\\nsign. New York, NY: John Wiley & Sons.\\nStroustrup, Bjarne. 1997. The C++ Program-\\nming Language, 3d ed. Reading, MA: Ad-\\ndison-Wesley.\\nStrunk, William, and E. B. White. 2000. Ele-\\nments of Style, 4th ed. Pearson.\\nSun Microsystems, Inc. 2000. “How to Write\\nDoc Comments for the Javadoc Tool,”\\n2000. Available from http://java.sun.com\\n/j2se/javadoc/writingdoccomments/.\\nSutter, Herb. 2000. Exceptional C++: 47 En-\\ngineering Puzzles, Programming Problems,\\nand Solutions. Boston, MA: Addison-\\nWesley.\\nTackett, Buford D., III, and Buddy Van\\nDoren. 1999. “Process Control for Error\\nFree Software: A Software Success Sto-\\nry,” IEEE Software, May 1999.\\nTenner, Edward. 1997. Why Things Bite\\nBack: Technology and the Revenge of Unin-\\ntended Consequences. Vintage Books.\\nTenny, Ted. 1988. “Program Readability:\\nProcedures versus Comments.” IEEE\\nTransactions on Software Engineering  SE-\\n14, no. 9 (September): 1271–79.\\nThayer, Richard H., ed. 1990. Tutorial: Soft-\\nware Engineering Project Management .\\nLos Alamitos, CA: IEEE Computer Soci-\\nety Press.\\nThimbleby, Harold. 1988. “Delaying Com-\\nmitment.” IEEE Software, May, 78–86.\\nThomas, Dave, and Andy Hunt. 2002.\\n“Mock Objects,” IEEE Software , May/\\nJune 2002.\\nThomas, Edward J., and Paul W. Oman.\\n1990. “A Bibliography of Programming\\nStyle.” ACM Sigplan Notices 25, no. 2\\n(February): 7–16.\\nThomas, Richard A. 1984. “Using Com-\\nments to Aid Program Maintenance.”\\nBYTE, May, 415–22.\\nTripp, Leonard L., William F. Struck, and\\nBryan K. Pflug. 1991. “The Application\\nof Multiple Team Inspections on a Safe-\\nty-Critical Software Standard,” Proceed-\\nings of the 4th Software Engineering\\nStandards Application Workshop , Los\\nAlamitos, CA: IEEE Computer Society\\nPress.\\nU.S. Department of Labor. 1990. “The\\n1990–91 Job Outlook in Brief.” Occupa-\\ntional Outlook Quarterly, Spring . U.S.\\nGovernment Printing Office. Document\\n1990-282-086/20007.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 918}, page_content='882 Bibliography\\nValett, J., and F. E. McGarry. 1989. “A Sum-\\nmary of Software Measurement Experi-\\nences in the Software Engineering\\nLaboratory.” Journal of Systems and Soft -\\nware 9, no. 2 (February): 137–48.\\nVan Genuchten, Michiel. 1991. “Why Is\\nSoftware Late? An Empirical Study of\\nReasons for Delay in Software Develop-\\nment.” IEEE Transactions on Software En-\\ngineering SE-17, no. 6 (June): 582–90.\\nVan Tassel, Dennie. 1978. Program Style,\\nDesign, Efficiency, Debugging, and Testing,\\n2d ed. Englewood Cliffs, NJ: Prentice\\nHall.\\nVaughn-Nichols, Steven. 2003. “Building\\nBetter Software with Better Tools,” IEEE\\nComputer, September 2003, 12–14.\\nVermeulen, Allan, et al. 2000. The Elements\\nof Java Style . Cambridge University\\nPress.\\nVessey, Iris, Sirkka L. Jarvenpaa, and Noam\\nTractinsky. 1992. “Evaluation of Vendor\\nProducts: CASE Tools as Methodologi-\\ncal Companions.” Communications of the\\nACM 35, no. 4 (April): 91–105.\\nVessey, Iris. 1986. “Expertise in Debugging\\nComputer Programs: An Analysis of the\\nContent of Verbal Protocols.” IEEE\\nTransactions on Systems, Man, and Cyber-\\nnetics SMC-16, no. 5 (September/Octo-\\nber): 621–37.\\nVotta, Lawrence G., et al. 1991. “Investigat-\\ning the Application of Capture-Recap-\\nture Techniques to Requirements and\\nDesign Reviews.” Proceedings of the Six -\\nteenth Annual Software Engineering Work-\\nshop, December 4–5, 1991. Greenbelt,\\nMD: Goddard Space Flight Center. Doc-\\nument SEL-91-006.\\nWalston, C. E., and C. P. Felix. 1977. “A\\nMethod of Programming Measurement\\nand Estimation.” IBM Systems Journal 16,\\nno. 1: 54–73.\\nWard, Robert. 1989. A Programmer’s Intro-\\nduction to Debugging C . Lawrence, KS: R\\n& D Publications.\\nWard, William T. 1989. “Software Defect\\nPrevention Using McCabe’s Complexity\\nMetric.” Hewlett-Packard Journal, April,\\n64–68.\\nWebster, Dallas E. 1988. “Mapping the De-\\nsign Information Representation Ter-\\nrain.” IEEE Computer, December, 8–23.\\nWeeks, Kevin. 1992. “Is Your Code Done\\nYet?” Computer Language, April, 63–72.\\nWeiland, Richard J. 1983. The Programmer’s\\nCraft: Program Construction, Computer\\nArchitecture, and Data Management. Re-\\nston, VA: Reston Publishing.\\nWeinberg, Gerald M. 1983. “Kill That\\nCode!” Infosystems, August, 48–49.\\nWeinberg, Gerald M. 1998. The Psychology\\nof Computer Programming: Silver Anniver-\\nsary Edition. New York, NY: Dorset\\nHouse.\\nWeinberg, Gerald M., and Edward L. Schul-\\nman. 1974. “Goals and Performance in\\nComputer Programming.” Human Fac-\\ntors 16, no. 1 (February): 70–77.\\nWeinberg, Gerald. 1988. Rethinking Systems\\nAnalysis and Design. New York, NY: Dor-\\nset House.\\nWeisfeld, Matt. 2004. The Object-Oriented\\nThought Process, 2d ed. SAMS, 2004.\\nWeiss, David M. 1975. “Evaluating Soft-\\nware Development by Error Analysis:\\nThe Data from the Architecture Research\\nFacility.” Journal of Systems and Software\\n1, no. 2 (June): 57–70.\\nWeiss, Eric A. 1972. “Review of The Psychol-\\nogy of Computer Programming, by Gerald\\nM. Weinberg.” ACM Computing Reviews\\n13, no. 4 (April): 175–76.\\nWheeler, David, Bill Brykczynski, and Regi-\\nnald Meeson. 1996. Software Inspection:\\nAn Industry Best Practice. Los Alamitos,\\nCA: IEEE Computer Society Press.\\nWhittaker, James A. 2000 “What Is Soft-\\nware Testing? And Why Is It So Hard?”\\nIEEE Software, January 2000, 70–79.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 919}, page_content='Bibliography 883\\nWhittaker, James A. 2002. How to Break\\nSoftware: A Practical Guide to Testing. Bos-\\nton, MA: Addison-Wesley.\\nWhorf, Benjamin. 1956. Language, Thought\\nand Reality. Cambridge, MA: MIT Press.\\nWiegers, Karl. 2002. Peer Reviews in Soft-\\nware: A Practical Guide. Boston, MA: Ad-\\ndison-Wesley.\\nWiegers, Karl. 2003. Software Requirements,\\n2d ed. Redmond, WA: Microsoft Press.\\nWilliams, Laurie, and Robert Kessler. 2002.\\nPair Programming Illuminated . Boston,\\nMA: Addison-Wesley.\\nWillis, Ron R., et al. 1998. “Hughes Air-\\ncraft’s Widespread Deployment of a\\nContinuously Improving Software Pro-\\ncess,” Software Engineering Institute/\\nCarnegie Mellon University, CMU/SEI-\\n98-TR-006, May 1998.\\nWilson, Steve, and Jeff Kesselman. 2000.\\nJava Platform Performance: Strategies and\\nTactics. Boston, MA: Addison-Wesley.\\nWirth, Niklaus. 1995. “A Plea for Lean Soft-\\nware,” IEEE Computer, February 1995.\\nWirth, Niklaus. 1971. “Program Develop-\\nment by Stepwise Refinement.” Commu-\\nnications of the ACM 14, no. 4 (April):\\n221–27.\\nWirth, Niklaus. 1986. Algorithms and Data\\nStructures. Englewood Cliffs, NJ: Prentice\\nHall.\\nWoodcock, Jim, and Martin Loomes. 1988.\\nSoftware Engineering Mathematics. Read-\\ning, MA: Addison-Wesley.\\nWoodfield, S. N., H. E. Dunsmore, and V. Y.\\nShen. 1981. “The Effect of Modulariza-\\ntion and Comments on Program Com-\\nprehension.” Proceedings of the Fifth\\nInternational Conference on Software Engi-\\nneering, March 1981, 215–23.\\nWulf, W. A. 1972. “A Case Against the GO-\\nTO.” Proceedings of the 25th National\\nACM Conference, August 1972, 791–97.\\nYoungs, Edward A. 1974. “Human Errors in\\nProgramming.” International Journal of\\nMan-Machine Studies 6:361–76.\\nYourdon, Edward, and Larry L. Constan-\\ntine. 1979. Structured Design: Fundamen-\\ntals of a Discipline of Computer Program\\nand Systems Design. Englewood Cliffs,\\nNJ: Yourdon Press.\\nYourdon, Edward, ed. 1979. Classics in Soft-\\nware Engineering. Englewood Cliffs, NJ:\\nYourdon Press.\\nYourdon, Edward, ed. 1982. Writings of the\\nRevolution: Selected Readings on Software\\nEngineering. New York, NY: Yourdon\\nPress.\\nYourdon, Edward. 1986a. Managing the\\nStructured Techniques: Strategies for Soft-\\nware Development in the 1990s , 3d ed.\\nNew York, NY: Yourdon Press.\\nYourdon, Edward. 1986b. Nations at Risk .\\nNew York, NY: Yourdon Press.\\nYourdon, Edward. 1988. “The 63 Greatest\\nSoftware Books.” American Programmer ,\\nSeptember.\\nYourdon, Edward. 1989a. Modern Struc-\\ntured Analysis. New York, NY: Yourdon\\nPress.\\nYourdon, Edward. 1989b. Structured Walk-\\nThroughs, 4th ed. New York, NY: Your-\\ndon Press.\\nYourdon, Edward. 1992. Decline & Fall of\\nthe American Programmer . Englewood\\nCliffs, NJ: Yourdon Press.\\nZachary, Pascal. 1994. Showstopper! The\\nFree Press.\\nZahniser, Richard A. 1992. “A Massively\\nParallel Software Development Ap-\\nproach.” American Programmer, January,\\n34–41.'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 921}, page_content='885\\nIndex\\nSymbols and Numbers\\n* (pointer declaration symbol), 332, \\n334–335, 763\\n& (pointer reference symbol), 332\\n–> (pointer symbol), 328\\n80/20 rule, 592\\nA\\nabbreviation of names, 283–285\\nabstract data types. See ADTs\\nAbstract Factory pattern, 104\\nabstraction\\naccess routines for, 340–342\\nADTs for. See ADTs\\nair lock analogy, 136\\nchecklist, 157\\nclasses for, 152, 157\\ncohesion with, 138\\ncomplexity, for handling, 839\\nconsistent level for class \\ninterfaces, 135–136\\ndefined, 89\\nerosion under modification \\nproblem, 138\\nevaluating, 135\\nexactness goal, 136–137\\nforming consistently, 89–90\\ngood example for class interfaces, \\n133–134\\nguidelines for creating class \\ninterfaces, 135–138\\nhigh-level problem domain terms, \\n847\\nimplementation structures, \\nlow-level, 846\\ninconsistent, 135–136, 138\\ninterfaces, goals for, 133–138\\nlevels of, 845–847\\nopposites, pairs of, 137\\nOS level, 846\\npatterns for, 103\\nplacing items in inheritance trees, \\n146\\npoor example for class interfaces, \\n134–135\\nproblem domain terms, low-level, \\n846\\nprogramming-language level, 846\\nroutines for, 164\\naccess routines\\nabstraction benefit, 340\\nabstraction, level of, 341–342\\nadvantages of, 339–340\\nbarricaded variables benefit, 339\\ncentralized control from, 339\\ncreating, 340\\ng_ prefix guideline, 340\\ninformation hiding benefit, 340\\nlack of support for, overcoming, \\n340–342\\nlocking, 341\\nparallelism from, 342\\nrequiring, 340\\naccidental problems, 77–78\\naccreting a system metaphor, 15–16\\naccuracy, 464\\nAda\\ndescription of, 63\\nparameter order, 174–175\\nadaptability, 464\\nAdapter pattern, 104\\naddition, dangers of, 295\\nADTs (abstract data types)\\nabstraction with, 130\\naccess routines, 339–342\\nbenefits of, 126–129\\nchanges not propagating benefit, \\n128\\nclasses based on, 133\\ncooling system example, 129–130\\ndata, meaning of, 126\\ndefined, 126\\ndocumentation benefit, 128\\nexplicit instancing, 132\\nfiles as, 130\\nguidelines, 130–131\\nhiding information with, 127\\ninstancing, 132\\nimplicit instancing, 132\\ninterfaces, making more \\ninformative, 128\\nlow-level data types as, 130\\nmedia independence with, 131\\nmultiple instances, handling, \\n131–133\\nneed for, example of, 126–127\\nnon-object-oriented languages \\nwith, 131–133\\nobjects as, 130\\noperations examples, table of, \\n129–130\\npassing of data, minimization of, \\n128\\nperformance improvements with, \\n128\\npurpose of, 126\\nr\\neal-world entities, working with, \\n128–129\\nrepresentation question, 130\\nsimple items as, 131\\nverification of code benefit, 128\\nagile development, 58, 658\\nalgebraic identities, 630\\nalgorithms\\ncommenting, 809\\nheuristics compared to, 12\\nmetaphors serving as, 11–12\\nresources on, 607\\nroutines, planning for, 223\\naliasing, 311-316\\nanalysis skills development, 823\\napproaches to development\\nagile development, 58, 658\\nbottom-up approaches, 112–113, \\n697–698\\nExtreme Programming, 58, \\n471–472, 482, 708, 856\\nimportance of, 839–841\\niterative approach. See iteration in \\ndevelopment\\npremature optimization problem, \\n840\\nquality control, 840. See also \\nquality of software\\nresources for, 58–59\\nsequential approach, 35–36\\nteam processes, 839–840\\ntop-down approaches, 111–113, \\n694–696\\narchitecture\\nbuilding block definition, 45\\nbusiness rules, 46\\nbuying vs. building components, \\n51\\nchanges, 44, 52\\nchecklist for, 54–55\\nclass design, 46\\ncommitment delay strategy, 52\\nconceptual integrity of, 52\\nZ02I619670.fm  Page 885  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 922}, page_content='886 first top-level entry\\narchitecture, continued\\ndata design, 46\\ndefined, 43\\nerror handling, 49–50\\nfault tolerance, 50\\nGUIs, 47\\nimportance of, 44\\ninput/output, 49\\ninternationalization planning, 48\\ninteroperability, 48\\nkey point for, 60\\nlocalization planning, 48\\nmachine independence, 53\\noverengineering, 51\\npercent of total activity, by size of \\nproject, 654–655\\nperformance goals, 48\\nperformance-oriented, 590\\nprerequisite nature of, 44\\nprogram organization, 45–46\\nquality, 52–53, 55\\nresource management, 47\\nresources on developing, 57\\nreuse decisions, 52\\nrisky areas, identifying, 53\\nscalability, 48\\nsecurity design, 47\\ntechnical feasibility, 51\\ntime allowed for, 56\\nuser interface design, 47\\nvalidation design, 50\\narithmetic expressions\\nmisleading precedence example, \\n733\\nmagnitudes, greatly different, 295\\nmultiplication, changing to \\naddition, 623–624\\nrounding errors, 297\\narrays\\nC language macro for, 311\\nchecklist, 317\\ncontainers as an alternative, 310\\ncosts of operations, 602\\ncross-talk, 311\\ndefined, 310\\ndimensions, minimizing, \\n625–626\\nend points, checking, 310\\nforeach loops with, 372\\nindexes of, 310–311\\nlayout of references, 754\\nloops with, 387–388\\nmultidimensional, 310\\nnaming conventions for, 280–281\\nperformance tuning, 593–594, \\n603–604\\nrefactoring, 572\\nreferences, minimizing, 626–627\\nsemantic prefixes for, 280–281\\nsentinel tests for loops, 621–623\\nsequential access guideline, 310\\nassembly language\\ndescription of, 63\\nlisting tools, 720\\nrecoding to, 640–642\\nassertions\\naborting program recommended, \\n206\\narguments for, 189\\nassumptions to check, list of, 190\\nbarricades, relation to, 205\\nbenefits of, 189\\nbuilding your own mechanism \\nfor, 191\\nC++ example, 191\\ndangerous use of example, 192\\ndefined, 189\\ndependencies, checking for, 350\\nerror handling with, 191, 193–194\\nexecutable code in, 191–192\\nguidelines for, 191–193\\nJava example of, 190\\npostcondition verification, \\n192–193\\nprecondition verification, \\n192–193\\nremoving from code, 190\\nresources for, 212\\nVisual Basic examples, 192–194\\nassignment statements, 249, 758\\nauthor role in inspections, 486\\nauto_ptrs, 333\\nautomated testing, 528–529\\nB\\nbackup plans, 669, 670\\nbad data, testing for, 514–515\\nbarricades\\nassertions, relation to, 205\\nclass-level, 204\\ninput data conversions, 204\\ninterfaces as boundaries, 203\\noperating room analogy, 204\\npurpose of, 203\\nbase classes\\nabstract overridable routines, 145\\nabstraction aspect of, 89\\ncoupling, too tight, 143\\nLiskov Substitution Principle, \\n144–145\\noverridable vs. non-overridable \\nroutines, 145–146\\nprotected data, 143\\nroutines overridden to do \\nnothing, 146–147\\nsingle classes from, 146\\nBasic, 65. See also Visual Basic\\nbasis testing, structured, 503, \\n505–509\\nBCD (binary coded decimal) type, \\n297\\nBDUF (big design up front), 119\\nbeauty, 80\\nbegin-end pairs, 742–743\\nbibliographies, software, 858\\nbig-bang integration, 691\\nbig design up front (BDUF), 119\\nbinary searches, 428\\nbinding\\nin code, 252\\ncompile time, 252–253\\nheuristic design with, 107\\njust in time, 253\\nkey point, 258\\nload time, 253\\nrun time, 253\\nvariables, timing of, 252–254\\nblack-box testing, 500\\nblank lines for formatting, 747–748, \\n765–766\\nblocks\\nbraces writing rule, 443\\ncomments on, 795–796\\nconditionals, clarifying, 443\\ndefined, 443\\nemulated pure layout style, \\n740–743\\npure, layout style, 738–740\\nsingle statements, 748–749\\nBook Paradigm, 812–813\\nboolean expressions\\n0, comparisons to, 441–442\\n0s and 1s as values, 432\\nbreaking into partial tests, 433\\nC languages syntax, 442–443\\ncharacters, comparisons to zero, \\n441\\nchecklist for, 459\\nconstants in comparisons, \\n442–443\\ndecision tables, moving to, 435\\nDeMorgan’s Theorems, applying, \\n436–437\\narithmetic expressions\\nZ02I619670.fm  Page 886  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 923}, page_content='last top-level entry 887\\nevaluation guidelines, 438–440\\nfunctions, moving to, 434–435\\nidentifiers for, 431–433\\nif statements, negatives in, \\n435–436\\nimplicit comparisons, 433\\nJava syntax, 439, 443\\nlayout guidelines, 749–750\\nlogical identities, 630\\nnegatives in, 435–437\\nnumeric, structuring, 440–441\\nparentheses for clarifying, \\n437–438\\npointers, comparisons with, 441\\npositive form recommended, \\n435–437\\nrefactoring, 572\\nshort circuit evaluation, 438–440\\nsimplifying, 433–435\\nvariables in. See boolean variables\\nzero, comparisons to, 441–442\\nboolean functions\\ncreating from expressions, \\n434–435\\nif statements, used in, 359\\nboolean tests\\nbreaking into partial tests, 433\\nhiding with routines, 165\\nsimplifying, 301–302\\nzero, comparisons to, 441–442\\nboolean variables\\n0s and 1s as values, 432\\nC, creating data type, 302–303\\nchecklist, 317\\ndocumentation with, 301\\nenumerated types as alternative, \\n304\\nexpressions with. See boolean \\nexpressions\\nidentifiers for, 431–433\\nnaming, 268–269\\nsimplifying tests with, 301–302\\nzeros and ones as values, 432\\nboss readiness test on prerequisites, \\n30–31\\nbottom-up approach to design, \\n112–113\\nbottom-up integration, 697–698\\nboundary analysis, 513–514\\nbraces\\nblock layout with, 740–743\\nstyles compared, 734\\nbreak statements\\nC++ loops, 371–372\\ncaution about, 381\\nguidelines, 379–380\\nlabeled, 381\\nmultiple in one loop, 380\\nnested-if simplification with, \\n446–447\\nwhile loops with, 379\\nbridge failure, Tacoma Narrows, 74\\nBridge pattern, 104\\nbrute-force debugging, 548–549\\nbuffer overruns, 196\\nbugs. See debugging; defects in code; \\nerrors\\nbuild tools, 716–717. See also \\ncompilers\\nbuilding metaphor, 16–19\\nbuilding vs. buying components, 18\\nbuilds, daily. See daily build and \\nsmoke tests\\nbusiness rules\\narchitecture prerequisites, 46\\nchange, identifying areas of, 98\\ngood practices table for, 31–32\\nsubsystem design, 85\\nbuying components, 18, 51\\nC\\nC language\\nADTs with, 131\\nboolean expression syntax, \\n442–443\\ndescription of, 64\\nnaming conventions for, 275, 278\\npointers, 334–335\\nstring data types, 299–301, 317\\nstring index errors, 299–300\\nC#, 64\\nC++\\nassertion example, 191\\nboolean expression syntax, \\n442–443\\ndebugging stubs with, 208–209\\ndescription of, 64\\nDoNothing() macros, 444–445\\nexceptions in, 198–199\\ninline routines, 184–185\\ninterface considerations, 139–141\\nlayout recommended, 745\\nmacro routines, 182–184\\nnaming conventions for, 275–277\\nnull statements, 444–445\\nparameters, by reference vs. by \\nvalue, 333\\npointers, 325, 328–334, 763\\npreprocessors, excluding debug \\ncode, 207–208\\nresources for, 159\\nside effects, 759–761\\nsource files, layout in, 773\\ncaching, code tuning with, 628–629\\nCapability Maturity Model (CMM), \\n491\\ncapturing design work, 117–118\\nCardinal Rule of Software Evolution, \\n565\\nCASE (computer-aided software \\nengineering) tools, 710\\ncase statements\\nalpha ordering, 361\\nchecklist, 365\\ndebugging, 206\\ndefault clauses, 363\\ndrop-throughs, 363–365\\nend of case statements, 363–365\\nendline layout, 751–752\\nerror detection in, 363\\nfrequency of execution ordering, \\n361, 612–613\\nif statements, comparing \\nperformance with, 614\\nkey points, 366\\nlanguage support for, 361\\nnested ifs, converting from, \\n448–449, 451\\nnormal case first rule, 361\\nnumeric ordering, 361\\nordering cases, 361\\nparallel modifications to, 566\\nphony variables, 361–362\\npolymorphism preferable to, \\n147–148\\nredesigning, 453\\nrefactoring, 566, 573\\nsimple action guideline, 361\\ntable-driven methods using, \\n421–422\\nchange control. See configuration \\nmanagement\\ncharacter arrays, 299–300. See also \\nstring data types\\ncharacter data types\\narrays vs. string pointers, 299\\nC language, 299–301\\ncharacter sets, 298\\nchecklist, 316–317\\nconversion strategies, 299\\nmagic (literal) characters, \\n297–298\\nUnicode, 298, 299\\ncharacter, personal\\nanalysis skills, 823\\ncommunication skills, 828\\ncharacter, personal\\nZ02I619670.fm  Page 887  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 924}, page_content='888 first top-level entry\\ncharacter, personal, continued\\ncompiler messages, treatment of, \\n826–827\\ncomputer-science graduates, 829\\ncooperation skills, 828\\ncreativity, 829, 857\\ncuriosity, 822–825\\ndevelopment process awareness, \\n822\\ndiscipline, 829\\nestimations, 827–828\\nexperience, 831–832\\nexperimentation, 822–823\\ngonzo programming, 832\\nhabits, 833–834\\nhumility, 821, 826, 834\\nimportance of, 819–820\\nintellectual honesty, 826–828\\nintelligence, 821\\njudgment, 848\\nkey points, 835\\nlaziness, 830\\nmistakes, admitting to, 826\\npersistence, 831\\npractices compensating for \\nweakness, 821\\nproblem solving, 823\\nprofessional development, \\n824–825\\nreading, 824\\nreligion in programming, harmful \\neffects of, 851–853\\nresources on, 834–835\\nstatus reporting, 827\\nsuccessful projects, learning from, \\n823–824\\nchecklists\\nabstraction, 157\\narchitecture, 54–55\\narrays, 317\\nbackups, 670\\nboolean expressions, 459\\ncase statements, 365\\ncharacter data types, 316–317\\nclasses, 157–158, 233–234, \\n578–579, 774, 780\\ncoding practices, 69\\ncode tuning, 607–608, 642–643\\ncomments, 774, 816–817\\nconditional statements, 365\\nconfiguration management, \\n669–670\\nconstants, 317\\nconstruction practices, 69–70\\ncontrol structures, 459, 773, 780\\ndaily build and smoke tests, 707\\ndata organization, 780\\ndata types, 316–318\\ndebugging, 559–561\\ndefects, 489, 559–560\\ndefensive programming, 211–212\\ndesign, 122–123, 781\\ndocumentation, 780–781, \\n816–817\\nencapsulation, 158\\nenumerated types, 317\\nfixing defects, 560\\nformal inspections, 489, 491–492\\nformatting, 773–774\\ngoto statements, 410\\nif statements, 365\\ninheritance, 158\\ninitialization, 257\\nintegration, 707\\ninterfaces, 579\\nlayout, 773–774\\nlist of, xxix–xxx\\nloops, 388–389\\nnames, 288–289, 780\\npair programming, 484\\nparameters, 185\\nperformance tuning, 607–608\\npointers, 344\\nprerequisites, 59\\npseudocoding, 233–234\\nprogramming tools, 724–725\\nquality assurance, 42–43, 70, 476\\nrefactoring, 570, 577–579, 584\\nrequirements, 40, 42–43\\nroutines, 185, 774, 780\\nspeed, tuning for, 642–643\\nstatements, 774\\nstraight-line code, 353\\nstrings, 316–317\\nstructures, 343\\ntable-driven methods, 429\\ntesting, 503, 532\\ntools, 70\\ntype creation, 318\\nvariables, 257–258, 288–289, \\n343–344\\ncircular dependencies, 95\\nclasses\\nabstract data types. See ADTs\\nabstract objects, modeling, 1\\n52\\nabstraction checklist, 157\\nalternates to PPP, 232–233\\narchitecture prerequisites, 46\\nassumptions about users, 141\\nbase. See base classes\\nbidirectional associations, 577\\ncalls to, refactoring, 575\\ncase statements vs. inheritance, \\n147–148\\ncentralizing control with, 153\\nchanges, limiting effects of, 153\\nchecklists, 157–158, 774, 780\\ncoding routines from \\npseudocode, 225–229\\ncohesion as refactoring indicator, \\n566\\ncomplexity issues, 152–153\\nconstant values returned, 574\\nconstructors, 151–152\\ncontainment, 143–144\\ncoupling considerations, \\n100–102, 142–143\\ndata-free, 155\\ndeep inheritance trees, 147\\ndefined, 125\\ndelegation vs. inheritance, \\nrefactoring, 576\\ndescendants, refactoring indicator \\nfor, 567\\ndesigning, 86, 216, 220–225, 233\\ndisallowing functions and \\noperators, 150\\ndocumenting, 780, 810\\nencapsulation, 139–143, 158\\nextension, refactoring with, 576\\nfactoring, benefit of, 154\\nfiles containing, 771–772\\nforeign routines, refactoring with, \\n576\\nformalizing contracts for \\ninterfaces, 106\\nformatting, 768–771\\nfriend, encapsulation violation \\nconcern, 141\\nfunctions in. See functions; \\nroutines\\nglobal data, hiding, 153\\ngod classes, 155\\nhacking approach to, 233\\nhiding implementation details, \\n153\\nimplementation checklist, 158\\nindirect calls to other classes, 150\\ninformation hiding, 92–93\\ninheritance, 144–149, 158\\ninitializing members, 243\\nintegration, 691, 694, 697\\nirrelevant classes, 155\\nis a relationships, 144\\nkey points for, 160, 234\\nchecklists\\nZ02I619670.fm  Page 888  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 925}, page_content='last top-level entry 889\\nlanguage-specific issues, 156\\nlayout of, 768–771\\nlimiting collaboration, 150\\nLiskov Substitution Principle, \\n144–145\\nmember variables, naming, 273, \\n279\\nmethods of. See routines\\nminimizing accessibility rule, 139\\nmixins, 149\\nmodeling real-world objects, 152\\nmultiple per file, layout of, \\n769–770\\nnaming, 277, 278\\nnumber of members, 143\\nnumber of routines, 150\\nobject names, differentiating from, \\n272–273\\nobjects, contrasted with, 86\\noverformatting, 770\\noverriding routines, 145–146, 156\\npackages, 155–157\\nparallel modifications refactoring \\nindicator, 566\\nplanning for program families, \\n154\\nprivate vs. protected data, 148\\nprivate, declaring members as, \\n150\\nprocedures in. See routines\\nprotected data, 148\\npseudocode for designing, \\n232–234\\npublic members, 139, 141, 576\\nread-time convenience rule, 141\\nreasons for creating, 152–156\\nrefactoring, 155, 574–576, \\n578–579, 582\\nresources, 159\\nreusability benefit of, 154\\nreview and test step, 217\\nroutine construction step, 217\\nroutines in. See routines\\nroutines, unused, 146–147, 576\\nsemantic violations of \\nencapsulation, 141–142\\nSet() routines, unnecessary, 576\\nsimilar sub and superclasses, 576\\nsingle-instance, 146\\nsingleton property, enforcing, 151\\nsteps in creating, 216–217\\nstreamlining parameter passing, \\n153\\nsubclasses, 165, 575\\nsuperclasses for common code, \\n575\\ntest-first development, 233\\ntesting with stub objects, 523\\nunidirectional associations, 577\\nvisibility of, 93\\nwarning signs for, 848, 849\\nclass-hierarchy generators, 713\\ncleanup steps, PPP, 232\\ncleanroom development, 521\\nCMM (Capability Maturity Model), \\n491\\nCobol, 64\\ncode coverage testing, 506\\ncode libraries, 222, 717\\ncode quality analysis tools, 713–714\\ncode reading method, 494\\ncode tuning\\n80/20 rule, 592\\nadvantages from, 591\\nalgebraic identities, 630\\nappeal of, 591–592\\narrays, 593–594, 603–604, \\n625–627\\nassembler, listing tools, 720\\nassembler, recoding to, 640–642\\nbottleneck identification, 594\\ncaching data, 628–629\\nchecklists, 607–608, 642–643\\ncomparing logic structures, 614\\ncompeting objectives dilemma, \\n595\\ncompiler considerations, 590, \\n596–597\\nconverting data types, 635\\ncorrectness, importance of, \\n595–596\\ndata transformations, 624–629\\ndata type choices, 635\\ndatabase indexing, 601\\ndefects in code, 601\\ndefined, 591\\nDES example, 605–606\\ndesign view, 589–590\\ndisadvant\\nages of, 591\\ndisassemblers, 720\\nexecution profiler tools, 720\\nexpressions, 630–639\\nfeature specific, 595\\nfrequency, testing in order of, \\n612–613\\nfrequently used code spots, 592\\nhardware considerations, 591\\nimprovements possible, 605\\nindexing data, 627–628\\ninefficiency, sources of, 598–601\\ninitializing at compile time, \\n632–633\\ninline routines, 639–640\\ninput/output, 598–599\\nintegers preferred to floating, 625\\ninterpreted vs. compiled \\nlanguages, 592, 600–601\\niteration of, 608, 850\\njamming loops, 617–618\\nkey points, 608, 645\\nlanguage specificity, 644\\nlazy evaluation, 615–616\\nlines of code, minimizing number \\nof, 593–594\\nlogic manipulation guidelines, \\n610–616\\nlookup tables for, 614–615, 635\\nloops, 616–624\\nlow-level language, recoding to, \\n640–642\\nmeasurement to locate hot spots, \\n603–604, 644\\nmemory vs. file operations, \\n598–599\\nminimizing work inside loops, \\n620–621\\nmultiplication, changing to \\naddition, 623–624\\nnested loop order, 623\\nold wives’ tales, 593–596\\noperating system considerations, \\n590\\noperation speeds, presumptions \\nabout, 594\\noperations, costs of common, \\n601–603\\noptimizing as you go, 594–595\\noverview of, 643–644\\npaging operations, 599\\nPareto Principle, 592\\nprecomputing results, 635–638\\nprogram requirements view of, \\n589\\nrefactoring, compared to, 609\\nresource goals, 590\\nresources on, 606–607, 644–645\\nright shifting, 634\\nroutines, 590, 639–640\\nsentinel tests for loops, 621–623\\nshort-circuit evaluation, 610\\nspeed, importance of, 595–596\\nstrength reduction, 623–624, \\n630–632\\ncode tuning\\nZ02I619670.fm  Page 889  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 926}, page_content='890 first top-level entry\\ncode tuning, continued\\nsubexpression elimination, \\n638–639\\nsummary of approach for, 606\\nsystem calls, 599–600, 633–634\\ntools, 720\\nunrolling loops, 618–620\\nunswitching loops, 616–617\\nvariations in environments for, \\n594\\nwhen to tune, 596\\ncode-generation wizards, 718\\ncoding. See also construction; \\nsoftware construction overview\\nconventions. See conventions, \\ncoding\\npractices checklist, 69\\nsequential. See straight-line code\\nsoftware construction as, 5\\nstyle. See layout\\ncohesion\\ninterfaces, class, 138\\nroutines, designing with, 168–171\\nstrength reduction, 623–624, \\n630–632\\ncoincidental cohesion, 170\\ncollaboration\\ncode reading, 494\\ncollective ownership benefits, 482\\ncomparisons of techniques, table \\nof, 495–496\\ncost advantage, 480–481\\ndefined, 479, 480\\ndesign phase, 115\\ndevelopment time benefit, 480\\ndog-and-pony shows, 495\\nextending beyond construction, \\n483\\nExtreme Programming method, \\n482\\nformal inspections. See formal \\ninspections\\nGeneral Principle of Software \\nQuality, 481\\ninspections. See formal \\ninspections\\nkey points, 497\\nmentoring aspect of, 482\\npair programming. See pair \\nprogramming\\npurpose of, 480\\nstandards, IEEE, 497\\ntesting, compared to, 481\\nwalk-throughs, 492–493\\ncollections, refactoring, 572\\ncollective ownership, 482. See also \\ncollaboration\\ncomments. See also documentation\\n/* vs. //, 790\\nabbreviations in, 799\\nalgorithms, 809\\nargument against, 782\\nauthorship, 811\\nbad code, on, 568\\nblank lines around, 765–766\\nBook Paradigm for, 812–813\\ncategories of, 786–788\\nchecklists, 774, 816–817\\nclasses, 810\\ncoded meanings, 802–803\\ncontrol structures, 804–805, 817\\ndeclarations with, 794, 802–803, \\n816\\ndescriptions of code intent, 787\\ndistance to code guideline, 806\\nefficient creation of, 788–791\\nendline comments, 793–795\\nerrors, marking workarounds, \\n800\\nexplanatory, 786\\nfiles, 810–811\\nflags, bit level, 803\\nglobal variables, 803, 809\\nindentation guidelines, 764–765\\nindividual lines with, 792–795\\nin\\nput data, 803, 808\\nintegrating into development, 791\\ninterfaces, class, 810\\ninterfaces, routine, 808\\nJavadoc, 807, 815\\nkey points, 817\\nlayout guidelines, 763–766\\nlegal notices, 811\\nlength of descriptions, 806\\nlevel of code intent, 795–796\\nloops, 804–805\\nmaintenance of, 220, 788–791, \\n794\\nmajor vs. minor, 799–800\\nmarkers, 787\\nnon-code essential information, \\n788\\nnumerical data, 802\\noptimum density of, 792\\noutput data, 808\\nparagraphs of code with, \\n795–801, 816\\nparameter declarations, 806–807\\nparts of programs, 809\\nperformance considerations, 791\\npreceding code rule, 798\\nproportionality of, 806\\npseudocode, deriving from, 220, \\n784, 791\\npurpose of, 782\\nrepeating code with, 786\\nresources on, 815\\nroutines with, 805–809, 817\\nself-commenting code, 796–797\\nSocratic dialog about, 781–785\\nstandards, IEEE, 813–814\\nstyle differences, managing, 683\\nstyle violations, 801\\nsummaries of code, 787\\nsurprises, 798\\ntricky code, 798, 801\\nundocumented features, 800\\nvariables, 803\\nversion control, 811\\nwhy vs. how, 797–798\\nworkarounds, 800\\ncommitment delay strategy, 52\\ncommunication skills, importance \\nof, 828\\ncommunicational cohesion, 169\\ncommunications, development \\nteam, 650\\ncomparisons\\nboolean. See boolean tests\\nfloating-point equality, 295–296\\nmixed data types, 293\\ncompilers\\nbinding during compilation, \\n252–253\\nbroken builds, 703\\ndata type warnings, 293\\ndebugging tools, as, 557, 827\\nerrors, finding in routines, \\n230–231\\nline numbers, debugging with, \\n549\\nmessages, treatment of, 549, \\n826–827\\nmultiple error messages, 550\\noptimizations by, 596–597\\nperformance tuning \\nconsiderations, 590\\nproject-wide standards for, 557\\nspeeds from optimization, table \\nof, 597\\ntools for, 716\\ntricky code optimization, 597\\nvalidators with, 231\\nwarnings, 293, 557\\ncode-generation wizards\\nZ02I619670.fm  Page 890  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 927}, page_content='last top-level entry 891\\ncompleteness of requirements \\nchecklist, 43\\ncomplex data types. See structures\\ncomplexity\\nabstraction for handling, 839\\nclasses for reducing, 152\\ncoding conventions for reducing, \\n839\\ncontrol structure contributions to, \\n456–459\\nconventions for managing,\\n 844–845\\ndecision points, counting, 458\\nimportance of, 457\\nisolation, classes for, 153\\nlive time, 459\\nmanagement, 77–79, 844–845\\nMcCabe’s metric, 457–458\\nmental objects held, measure of, \\n457\\nmethods for handling, 837–839\\nminimization goal, 80\\npatterns, reducing with, 103\\nproblem domain, working at, 845\\nreliability correlated with, 457\\nroutines for reducing, 164\\nsize of projects, effect on, \\n656–657\\nspan, 459\\ncomponent testing, 499\\ncomponents, buying, 18, 51\\nComposite pattern, 104\\ncompound boundaries, 514\\ncompound statements. See blocks\\ncomputed-value qualifiers of \\nvariable names, 263–264\\ncomputer-aided software \\nengineering (CASE) tools, 710\\nconditional statements\\nboolean function calls with, 359\\nboolean variables recommended, \\n301–302\\ncase statements. See case \\nstatements\\nchained if-then-else statements, \\n358–360\\nchecklist, 365\\ncommon cases first guideline, \\n359–360\\ncomparing performance of, 614\\ncovering all cases, 360\\ndefined, 355\\neliminating testing redundancy, \\n610–611\\nelse clauses, 358–360\\nequality, branching on, 355\\nerror processing examples, \\n356–357\\nfrequency, testing in order of, \\n612–613\\nif statements. See if statements\\nkey points, 366\\nlookup tables, substituting, \\n614–615\\nlooping, conditional. See loops\\nnormal case first guideline, \\n356–357\\nnormal path first guideline, 355\\nnull if clauses, 357\\nplain if-then statements, 355–357\\nrefactoring, 573\\nshort-circuit evaluation, 610\\nswitch statements. See case \\nstatements\\nconfessional debugging, 547–548\\nconfiguration management\\narchitectural anticipation of \\nchange, 52\\nbackup plans, 669, 670\\nboards, change-control, 667\\nbureaucratic considerations, 667\\nchecklist, 669–670\\ncode changes, 667–668\\ncost, estimating, 666\\ndefined, 664\\ndesign changes, 666–667\\nestimating change costs, 666\\ngrouping change requests, 666\\nhigh change volumes, 666\\nidentifying areas of change, 97–99\\nmachine configurations, \\nr\\neproducing, 668\\npurpose of, 664–665\\nrequirements changes, 41, 664, \\n666–667\\nresources on, 670\\nSCM, 665\\ntool version control, 668\\nversion-control software, 668\\nconst keyword, C++, 176, 177, 243, \\n274, 333\\nconstants\\nchecklist, 317\\nconsistency rule, 309\\ndeclarations using, 308\\ndefined, 307\\nemulation by global variables, 338\\ninitializing, 243\\nliterals, avoiding with, 308–309\\nnaming, 270, 273, 277–279\\npurpose of, 307\\nrefactoring, 571\\nsimulating in languages lacking, \\n309\\nconstruction. See also software \\nconstruction overview\\ncollaborative. See collaboration\\ndecisions. See construction \\ndecisions\\nguidelines, 66\\nmanaging. See managing \\nconstruction\\npercent of total activity, by size of \\nproject, 654–655\\nprerequisites. See prerequisites, \\nupstream\\nquality of. See quality of software\\nresources on, 856\\nschedules, estimating. See \\nconstruction schedules, \\nestimating\\nsize of projects, effects on. See size \\nof projects\\ntools for. See programming tools\\nconstruction decisions\\nchecklist of major construction \\npractices, 69–70\\ncoding practices checklist, 69\\nearly-wave environments, 67\\nkey points for, 70\\nmajor construction practices, \\nselecting, 69–70\\nmature technology environments, \\n67\\nprogramming conventions, 66–66\\nprogramming into languages, \\n68–69\\nprogramming languages. See \\nprogramming language choice\\nquality assurance checklist, 70\\nteamwork checklist, 69\\ntechnology waves, determining \\nyour location in, 66–69\\ntools checklist, 70\\nconstruction schedules, estimating\\napproaches to, list of, 671\\ncatching up from behind, \\n675–676\\ncontrolling vs. estimating, 675\\nfactors influencing, 674–675\\nlevel of detail for, 672\\nmultiple techniques with \\ncomparisons, 672\\nobjectives, establishing, 671\\noptimism, 675\\nconstruction schedules, estimating\\nZ02I619670.fm  Page 891  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 928}, page_content='892 first top-level entry\\nconstruction schedules, estimating, \\ncontinued\\noverview, 671\\nplanning estimation time, 671\\nreduction of scope, 676\\nreestimating, 672\\nrequirements specification, 672\\nresources for, 677\\nteams, expanding, 676\\nconstructors\\ndeep vs. shallow copies, 151–152\\nexceptions with, 199\\nguidelines for, 151–152\\ninitializing data members, 151\\nrefactoring, 577\\nsingleton property, enforcing, 151\\ncontainer classes, 310\\ncontainment, 88, 143\\ncontinuation lines, 754–758\\ncontinue statements, 379, 380, 381\\ncontinuous integration, 706\\ncontrol structures\\nboolean expressions in. See \\nboolean expressions\\ncase. See case statements\\nchecklists, 459, 773, 780\\ncommenting, 804–805, 817\\ncomplexity, contributions to, \\n456–459\\ncompound statements, 443\\nconditional flow. See conditional \\nstatements\\ncontinuation lines in, 757\\ndata types, relationship to, \\n254–255\\ndocumentation, 780\\ndouble indented begin-end pairs, \\n746–747\\ngotos. See goto statements\\nif statements. See if statements\\niteration, 255, 456\\nkey points, 460\\nlayout styles, 745–752\\nloops. See loops\\nmultiple returns from routines, \\n391–393\\nnull statements, 444–445\\nrecursive. See recursion\\nreliability correlated with \\ncomplexity, 457\\nreturns as. See return statements\\nselective data with, 254\\nsequential data with, 254\\nstructured programming, \\n454–455\\nunindented begin-end pairs, 746\\nunusual, overview of, 408\\nconventions, coding\\nbenefits of, 844–845\\nchecklist, 69\\nformatting. See layout\\nhazards, avoiding with, 844\\npredictability benefit, 844\\nconverting data types, 635\\ncooperation skills, importance of, \\n828\\ncorrectness, 197, 463\\ncosts. See also performance tuning\\nchange estimates, 666\\ncollaboration benefits, 480–481\\ndebugging, time consumed by, \\n474–475\\ndefects contributing to, 519–520\\ndetection of defects, 472\\nerror-prone routines, 518\\nestimating, 658, 828\\nfixing of defects, 472–473, 519\\nGeneral Principle of Software \\nQuality, 474–475, 522\\npair programming vs. inspections, \\n480–481\\nresources on, 658\\ncounted loops. See fo r loops\\ncoupling\\nbase classes to derived classes, \\n143\\nclasses, too tightly, 142–143\\ndesign considerations, 100–102\\nflexibility of, 100–101\\ngoals of, 100\\nloose, 80, 100–102\\nobject-parameter type, 101\\nsemantic type, 102\\nsimple-data-parameter type, 101\\nsimple-object type, 101\\nsize of, 100\\nvisibility of, 100\\ncoverage\\nmonitoring tools, 526\\nstructured basis testing, 505–509\\nCRC (Class, Responsibility, \\nCollaboration) cards, 118\\ncreativity, importance of, 829, 857\\ncross-reference tools, 713\\ncuriosity, role in character, 822–825\\nCurrency data types, 297\\ncustomization, building metaphor \\nfor, 18\\nD\\ndaily build and smoke tests\\nautomation of, 704\\nbenefits of, 702\\nbroken builds, 703, 705\\nbuild groups, 704\\nchecklist, 707\\ndefined, 702\\ndiagnosis benefit, 702\\nholding area for additions, \\n704–705\\nimportance of, 706\\nmorning releases, 705\\npressure, 706\\npretest requirement, 704\\nrevisions, 704\\nsmoke tests, 703\\nunsurfaced work, 702\\ndata\\narchitecture prerequisites, 46\\nbad classes, testing for, 514–515\\nchange, identifying areas of, 99\\ncode tuning. See data \\ntransformations for code \\ntuning\\ncombined states, 509–510\\ndefined state, 509–510\\ndefined-used paths, testing, \\n510–512\\ndesign, 46\\nentered state, 509\\nexited state, 509\\ngood classes, testing, 515–516\\nkilled state, 509–510\\nlegacy, compatibility with, 516\\nnominal case errors, 515\\ntest, generators for, 524–525\\ntypes. See data types\\nused state, 509–510\\ndata dictionaries, 715\\ndata flow testing, 509–512\\ndata literacy test, 238–239\\ndata recorder tools, 526\\ndata structures. See structures\\ndata transformations for code \\ntuning\\narray dimension minimization, \\n625–626\\narray reference minimization, \\n626–627\\ncaching data, 628–629\\nfloating point to integers, 625\\nindexing data, 627–628\\npurpose of, 624\\nconstructors\\nZ02I619670.fm  Page 892  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 929}, page_content='last top-level entry 893\\ndata types\\n“a” prefix convention, 272\\nabstract data types. See ADTs\\narrays. See arrays\\nBCD, 297\\nboolean. See boolean variables\\nchange, identifying areas of, 99\\ncharacters. See character data \\ntypes\\nchecklist, 316–318\\ncomplex. See structures\\ncontrol structures, relationship to, \\n254–255\\ncreating. See type creation\\nCurrency, 297\\ndefinitions, 278\\nenumerated types. See \\nenumerated types\\nfloating-point. See floating-point \\ndata types\\nintegers. See integer data types\\niterative data, 255\\nkey points for, 318\\nnaming, 273, 277, 278\\nnumeric. See numeric data types\\noverloaded primitives, 567\\npointers. See pointers\\nrefactoring to classes, 567, 572\\nresources on, 239\\nselective data, 254\\nsequential data, 254\\nstrings. See string data types\\nstructures. See structures\\nt_ prefix convention, 272\\nuser-defined. See type creation\\nvariables of, differentiating from, \\n272–273\\ndatabases\\nperformance issues, 601\\nSQL, 65\\nsubsystem design, 85\\ndata-level refactoring, 571–572, 577\\ndays-in-month, determining, \\n413–414\\ndeallocation\\ngoto statements for, 399\\npointers, of, 326, 330, 332\\nDebug.Assert statements, 191–193\\ndebugging\\naids to. See debugging aids\\nbinary searches of code, 546\\nblindness, sources of, 554–555\\nbreakpoints, 558\\nbreaks, taking, 548\\nbrute-force, 548–549\\nchanges, recent, 547\\nchecklist, 559–561\\ncomments, misplaced, 550\\ncommon defects lists, 547\\ncompilers as tools for, 549, 557\\nconfessional debugging, 547–548\\ncosts of, 29–30, 474–475\\ndebugger tools, 526–527, 545, \\n556–559, 719. See also \\ndebugging aids\\ndefects as opportunities, 537–538\\ndefensive. See debugging aids\\ndefined, 535\\nDiff tool, 556\\nexecution profilers for, 557–558\\nexpanding suspicious regions, \\n547\\nexperience of pr\\nogrammers, \\neffects of, 537\\nfinding defects, 540, 559–560\\nfixing defects, 550–554\\nguessing, 539\\nhistory of, 535–536\\nhypothesis testing, 543–544, 546\\nincremental approach, 547\\nineffective approach to, 539–540\\nkey points, 562\\nline numbers from compilers, 549\\nlint tool, 557\\nlisting possibilities, 546\\nlocating error sources, 543–544\\nlogic checking tools, 557\\nmultiple compiler messages, 550\\nnarrowing code searches, 546\\nobvious fixes, 539\\nperformance variations, 536–537\\nproject-wide compilers settings, \\n557\\npsychological considerations, \\n554–556\\nquality of software, role in, 536\\nquotation marks, misplaced, 550\\nreadability improvements, 538\\nrecommended approach, 541\\nreexamining defect-prone code, \\n547\\nresources for, 561\\nSatan’s helpers, 539–540\\nscaffolding for, 558\\nscientific method of, 540–544\\nself-knowledge from, 538\\nsource-code comparators, 556\\nstabilizing errors, 542–543\\nsuperstitious approaches, \\n539–540\\nsymbolic debuggers, 526–527\\nsyntax checking, 549–550, 557, \\n560\\nsystem debuggers, 558\\ntest case creation, 544\\ntesting, compared to, 500\\ntime for, setting maximums, 549\\ntools for, 526–527, 545, 556–559, \\n719. See also debugging aids\\nunderstanding the problems, 539\\nunit tests, 545\\nvarying test cases, 545\\nwarnings, treating as errors, 557\\ndebugging aids\\nC++ preprocessors, 207–208\\ncase statements, 206\\nearly introduction recommended, \\n206\\noffensive programming, 206\\nplanning removal of, 206–209\\npointers, checking, 208–209\\npreprocessors, 207–208\\nproduction constraints in \\ndevelopment versions, 205\\npurpose of, 205\\nstubs, 208–209\\nversion control tools, 207\\ndecision tables. See table-driven \\nmethods\\ndeclarations\\ncommenting, 794, 802–803, 816\\nconst recommended, 243\\ndeclare and define near first use \\nrule, 242–243\\ndefine near first use rule, \\n242–243\\nfinal recommended, 243\\nformatting, 761–763\\nimplicit declarations, 239–240\\nmultiple on one line, 761–762\\nnaming. See naming conventions\\nnumerical data, commenting, 802\\norder of, 762\\nplacement of, 762\\npointers, 325–326, 763\\nusing all declared, 257\\nDecorator pattern, 104\\ndefects in code\\nclasses prone to error, 517–518\\nclassifications of, 518–520\\nclerical errors (typos), 519\\nCode Complete example, \\n490–491\\nconstruction, proportion \\nresulting from, 520–521\\ndefects in code'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 929}, page_content='classes prone to error, 517–518\\nclassifications of, 518–520\\nclerical errors (typos), 519\\nCode Complete example, \\n490–491\\nconstruction, proportion \\nresulting from, 520–521\\ndefects in code\\nZ02I619670.fm  Page 893  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 930}, page_content='894 first top-level entry\\ndefects in code, continued\\ncost of detection, 472\\ncost of fixing, 472–473\\ndatabases of, 527\\ndetection by various techniques, \\ntable of, 470\\ndistribution of, 517–518\\nease of fixing defects, 519\\nerror checklists, 489\\nexpected rate of, 521–522\\nfinding, checklist, 559–560\\nfixing. See debugging; fixing \\ndefects\\nformal inspections for detecting. \\nSee formal inspections\\nintermittent, 542–543\\nmisunderstood designs as sources \\nfor, 519\\nopportunities presented by, \\n537–538\\noutside of construction domain, \\n519\\npercentage of, measurement, \\n469–472\\nperformance issues, 601\\nprogrammers at fault for, 519\\nreadability improvements, 538\\nrefactoring after fixing, 582\\nscope of, 519\\nself-knowledge from, 538\\nsize of projects, effects on, \\n651–653\\nsources of, table, 518\\nstabilizing, 542–543\\ndefensive programming\\nassertions, 189–194\\nassumptions to check, list of, 190\\nbarricades, 203–205\\nchecklist, 211–212\\ndebugging aids, 205–209\\ndefined, 187\\nerror handling for, 194–197\\nexceptions, 198–203, 211\\nfriendly messages guideline, 210\\ngraceful crashing guideline, 210\\nguidelines for production code, \\n209–210\\nhard crash errors guideline, 209\\nimportant errors guideline, 209\\nkey points for, 213\\nlogging guideline, 210\\nproblems caused by, 210\\nquality improvement techniques, \\nother, 188\\nrobustness vs. correctness, 197\\nsecurity issues, 212\\ntrivial errors guideline, 209\\nvalidating input, 188\\ndefined data state, 509–510\\ndefining variables. See declarations\\nDelphi, recoding to assembler, \\n640–642\\nDeMorgan’s Theorems, applying, \\n436–437\\ndependencies, code-ordering\\nchecker tools, 716\\ncircular, 95\\nclarifying, 348–350\\nconcept of, 347\\ndocumentation, 350\\nerror checking, 350\\nhidden, 348\\ninitialization order, 348\\nnaming routines, 348–349\\nnon-obvious, 348\\norganization of code, 348\\nparameters, effective, 349\\ndesign\\nabstractions, forming consistent, \\n89–90\\naccidental problems, 77–78\\nBDUF, 119\\nbeauty, 80\\nbottom-up approach to design, \\n112–113\\nbusiness logic subsystem, 85\\ncapturing work, 117–118\\ncentral points of control, 107\\nchange, identifying areas of, \\n97–99\\nchanges, management of, \\n666–667\\ncharacteristics of high quality, \\n80–81\\nchecklists, 122–123, 781\\nclasses, division into, 86\\ncollaboration, 115\\ncommunications among \\nsubsystems, 83–84\\ncom\\npletion of, determining, \\n115–117\\ncomplexity management, 77–80\\nconstruction activity, as, 73–74\\ncontract, by, 233\\ncoupling considerations, 100–102\\ndatabase access subsystem, 85\\ndefined, 74\\ndiagrams, drawing, 107\\ndiscussion, summarizing, 117\\ndivide and conquer technique, \\n111\\ndocumentation, as, 781\\ndocumentation overkill, 117\\nemergent nature of, 76\\nencapsulation, 90–91\\nenough, determining, 118–119\\nessential problems, 77–78\\nextensibility goal, 80\\nformality of, determining, \\n115–117\\nformalizing class contracts, 106\\ngoals checklist, 122–123\\ngood practices table for, 31–32\\nheuristic. See heuristic design\\nhierarchies for, 105–106\\nhigh fan-in goal, 80\\nIEEE standards, 122\\ninformation hiding, 92–97, 120\\ninheritance, 91–92\\niteration practice, 111–117\\nkey points, 123\\nleanness goal, 81\\nlevel of detail needed, 115–117\\nlevels of, 82–87\\nloose coupling goal, 80\\nlow-to-medium fan-out goal, 81\\nmaintenance goals, 80\\nmental limitations of humans, 79\\nmetrics, warning signs from, 848\\nnondeterministic nature of, 76, 87\\nobject-oriented, resource for, 119\\nobjects, real world, finding, 87–89\\npackages level, 82–85\\npatterns, common. See patterns\\nperformance tuning \\nconsiderations, 589–590\\nportability goal, 81\\npractice heuristics. See heuristic \\ndesign\\npractices, 110–118, 122\\nprioritizing during, 76\\nprototyping, 114–115\\nresources for, 119–121\\nrestrictive nature of, 76\\nreusability goal, 80\\nroutines, of, 86–87\\nsloppy process nature of, 75–76\\nsoftware system level, 82\\nstandard techniques goal, 81\\nstandards, IEEE, 122\\nstratification goal, 81\\nstrong cohesion, 105\\nsubsystem level, 82–85\\ndefensive programming\\nZ02I619670.fm  Page 894  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 931}, page_content='last top-level entry 895\\nsystem dependencies subsystem, \\n85\\ntesting for implementation, 503\\ntools for, 710\\ntop-down approach, 111–113\\ntradeoffs, 76\\nUML diagrams, 118\\nuser interface subsystem, 85\\nvisual documentation of, 118\\nwicked problem nature of, 74–75\\nWikis, capturing on, 117\\ndestructors, exceptions with, 199\\ndetailed-design documents, 778\\ndeveloper testing. See testing\\ndevelopment processes. See \\napproaches to development\\ndevelopment standards, IEEE, 813\\ndiagrams\\nheuristic design use of, 107\\nUML, 118\\nDiff tools, 556, 712\\ndirect access tables\\nadvantages of, 420\\narrays for, 414\\ncase statement approach, \\n421–422\\ndays-in-month example, 413–414\\ndefined, 413\\ndesign method for, 420\\nflexible-message-format example, \\n416–423\\nfudging keys for, 423–424\\ninsurance rates example, 415–416\\nkeys for, 423–424\\nobject approach, 422–423\\ntransforming keys, 424\\ndisassemblers, 720\\ndiscipline, importance of, 829\\ndiscourse rules, 733\\ndisposing of objects, 206\\ndivide and conquer technique, 111\\ndivision, 292–293\\nDo loops, 369–370. See also loops\\ndocumentation\\nabbreviation of names, 284–285\\nADTs for, 128\\nbad code, of, 568\\nBook Paradigm for, 812–813\\ncapturing work, 117–118\\nchecklists, 780–781, 816–817\\nclasses, 780\\ncomments. See comments\\ncontrol structures, 780\\nCRC cards for, 118\\ndependencies, clarifying, 350\\ndesign as, 117, 781\\ndetailed-design documents, 778\\nexternal, 777–778\\nJavadoc, 807, 815\\nkey points, 817\\nnames as, 284–285, 778–779, \\n780\\norganization of data, 780\\nparameter assumptions, 178\\npseudocode, deriving from, 220\\nresources on, 815\\nroutine parameter assumptions, \\n178\\nroutines, 780\\nSDFs, 778\\nself-documenting code, 778–781\\nsize of projects, effects of, 657\\nsource code as, 7\\nstandards, IEEE, 813–814\\nstyle differences, managing, 683\\nUDFs, 778\\nvisual, of designs, 118\\nwhy vs. how, 797–798\\ndog-and-pony shows, 495\\ndog tag fields, 326–327\\nDoNothing() macros, 444–445\\nDRY (Don’t Repeat Yourself) \\nprinciple, 565\\nduplication\\navoiding with routines, 164–165\\ncode as refactoring indicator, 565\\nE\\nearly-wave environments, 67\\nease of maintenance design goal, 80\\neclecticism, 851–852\\nediting tools\\nbeautifiers, 712\\nclass-hierarchy generators, 713\\ncross-reference tools, 713\\nDiff tools, 712\\ngrep, 711\\nIDEs, 710–711\\ninterface documentation, 713\\nmerge tools, 712\\nmultiple-file string searches, \\n711–712\\ntemplates, 713\\nefficiency, 464\\neighty/twenty (80/20) rule, 592\\nelse clauses\\nboolean function calls with, 359\\ncase statements instead of, 360\\nchains, in, 358–360\\ncommon cases first guideline, \\n359–360\\ncorrectness testing, 358\\ndefault for covering all cases, 360\\ngotos with, 406–407\\nnull, 358\\nembedded life-critical systems, \\n31–32\\nemergent nature of design process, \\n76\\nemulated pure blocks layout style, \\n740–743\\nencapsulation\\nassumptions about users, 141\\nchecklist, 158\\nclasses, role for, 139–143\\ncoupling classes too tightly, \\n142–143\\ndowncast objects, 574\\nfriend class concern, 141\\nheuristic design with, 90–91\\nminimizing accessibility, 139\\nprivate details in class interfaces, \\n139–141\\npublic data members, 567\\npublic members of classes, 139\\npublic routines in interfaces \\nconcern, 141\\nsemantic violations of, 141–142\\nweak, 567\\nendless loops, 367, 374\\nendline comments, 793–795\\nendline layout, 743–745, 751–752, \\n767\\nenumerated types\\nbenefits of, 303\\nbooleans, alternative to, 304\\nC++, 303–304, 306\\nchanges benefit, 304\\nchecklist, 317\\ncomments substituting for, \\n802–803\\ncreating for Java, 307\\ndefined, 303\\nemulation by global variables, 338\\nexplicit value pitfalls, 306\\nfirst entry invalid trick, 305–306\\niterating through, 305\\nJava, creating for, 307\\nlanguages available in, 303\\nloop limits with, 305\\nnaming, 269, 274, 277–279\\nparameters using, 303\\nreadability from, 303\\nreliability benefit, 304\\nenumerated types\\nZ02I619670.fm  Page 895  Wednesday, May 12, 2004  12:23 PM\\nDownload from Wow! eBook <www.wowebook.com>'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 932}, page_content='896 first top-level entry\\nenumerated types, continued\\nstandard for, 306\\nvalidation with, 304–305\\nVisual Basic, 303–306\\nequality, floating-point, 295–296\\nequivalence partitioning, 512\\nerror codes, 195\\nerror detection, doing early, 29–30\\nerror guessing, 513\\nerror handling. See also exceptions\\narchitecture prerequisites, 49–50\\nassertions, compared to, 191\\nbarricades, 203–205\\nbuffer overruns compromising, \\n196\\nclosest legal value, 195\\ndefensive programming, \\ntechniques for, 194–197\\nerror codes, returning, 195\\nerror-processing routines, calling, \\n196\\nhigh-level design implication, 197\\nlocal handling, 196\\nlogging warning messages, 195\\nmessages, 49, 195–196, 210\\nnext valid data, returning, 195\\nprevious answers, reusing, 195\\npropagation design, 49\\nrefactoring, 577\\nreturning neutral values, 194\\nrobustness, 51, 197\\nroutines, designing along with, \\n222\\nshutting down, 196\\nvalidation design, 50\\nerror messages\\ncodes, returning, 195\\ndesign, 49\\ndisplaying, 196\\nfriendly messages guideline, 210\\nerrors. See also defects in code; \\nexceptions\\nclassifications of, 518–520\\ncoding. See defects in code\\ndog tag fields, 326–327\\nexceptions. See exceptions\\nhandling. See error handling\\ngoto statements for processing, \\n401–402\\nsources of, table, 518\\nessential problems, 77–78\\nestimating schedules\\napproaches to, list of, 671\\nchange costs, 666\\ncontrol, compared to, 675\\nfactors influencing, 674–675\\nlevel of detail for, 672\\ninaccuracy, character-based, \\n827–828\\nmultiple techniques with \\ncomparisons, 672\\nobjectives, establishing, 671\\noptimism, 675\\noverview, 671\\nplanning for estimation time, 671\\nredoing periodically, 672\\nreduction of scope, 676\\nrequirements specification, 672\\nresources for, 677\\nteams, expanding, 676\\nevent handlers, 170\\nevolution. See software evolution\\nEvolutionary Delivery. See \\nincremental development \\nmetaphor\\nexceptions. See also error handling\\nabstraction issues, 199–200\\nalternatives to, 203\\nbase classes for, project specific, \\n203\\nC++, 198–199\\ncentralized reporters, 201–202\\nconstructors with, 199\\ndefensive programming checklist, \\n211\\ndestructors with, 199\\nempty catch blocks rule, 201\\nencapsulation, breaking, 200\\nfull information rule, 200\\nJava, 198–201\\nlanguag\\nes, table comparing, \\n198–199\\nlevel of abstraction rule, 199–200\\nlibrary code generation of, 201\\nlocal handling rule, 199\\nnon-exceptional conditions, 199\\npurpose of, 198, 199\\nreadability of code using, 199\\nrefactoring, 577\\nresources for, 212–213\\nstandardizing use of, 202–203\\nVisual Basic, 198–199, 202\\nexecution profilers, 557–558, 720\\nexecutable-code tools\\nbuild tools, 716–717\\ncode libraries, 717\\ncode-generation wizards, 718\\ncompilers. See compilers\\ninstallation tools, 718\\nlinkers, 716\\npreprocessors, 718–719\\nsetup tools, 718\\nExit Function, 391. See also return \\nstatements\\nExit statements. See break \\nstatements\\nExit Sub, 392–393. See also return \\nstatements\\nexiting loops, 369–372, 377–381\\nexperience, personal, 831–832\\nexperimental prototyping, 114–115\\nexperimentation as learning, \\n822–823, 852–853\\nexponential expressions, 631–632\\nexpressions\\nboolean. See boolean expressions\\nconstants, data types for, 635\\ninitializing at compile time, \\n632–633\\nlayout guidelines, 749–750\\nprecomputing results, 635–638\\nright shifting, 634\\nstrength reduction, 630–632\\nsubexpression elimination, \\n638–639\\nsystem calls, performance of, \\n633–634\\nextensibility design goal, 80\\nexternal audits, 467\\nexternal documentation, 777–778\\nExtreme Programming\\ncollaboration component of, 482\\ndefect detection, 471–472\\ndefined, 58\\nresources on, 708, 856\\nF\\nFacade pattern, 104\\nfactorials, 397–398\\nfactoring, 154. See also refactoring\\nfactory methods\\nFactory Method pattern, 103–104\\nnested ifs refactoring example, \\n452–453\\nrefactoring to, 577\\nfan-in, 80\\nfan-out, 81\\nfarming metaphor, 14–15\\nfault tolerance, 50\\nfeature-oriented integration, \\n700–701\\nFibonacci numbers, 397–398\\nfigures, list of, xxxiii\\nequality, floating-point\\nZ02I619670.fm  Page 896  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 933}, page_content='last top-level entry 897\\nfiles\\nADTs, treating as, 130\\nauthorship records for, 811\\nC++ source file order, 773\\ndeleting multiple example, \\n401–402\\ndocumenting, 810–811\\nlayout within, 771–773\\nnaming, 772, 811\\nroutines in, 772\\nfinal keyword, Java, 243\\nfinally statements, 404–405\\nfixing defects\\nchecking fixes, 553\\nchecklist, 560\\ndiagnosis confirmation, 551\\nhurrying, impact of, 551\\ninitialization defects, 553\\nmaintenance issues, 553\\none change at a time rule, 553\\nreasoning for changes, 553\\nsaving unfixed code, 552\\nsimilar defects, looking for, 554\\nspecial cases, 553\\nsymptoms, fixing instead of \\nproblems, 552–553\\nunderstand first guideline, \\n550–551\\nunit tests for, 554\\nflags\\nchange, identifying areas of, \\n98–99\\ncomments for bit-level meanings, \\n803\\nenumerated types for, 266–267\\ngotos, rewriting with, 403–404\\nnames for, 266–267\\nsemantic coupling with, 102\\nflexibility\\ncoupling criteria for, 100–101\\ndefined, 464\\nfloating-point data types\\naccuracy limitations, 295\\nBCD, 297\\nchecklist, 316\\ncosts of operations, 602\\nequality comparisons, 295–296\\nmagnitudes, greatly different, \\noperations with, 295\\nrounding errors, 297\\nVisual Basic types, 297\\nfor loops\\nadvantages of, 374\\nformatting, 732–733, 746–747\\nindexes, 377–378\\npurpose of, 372\\nforeach loops, 367, 372\\nformal inspections\\nauthor role, 486\\nbenefit summary, 491\\nblame game, 490\\nchecklist, 491–492\\nCMM, 491\\nCode Complete example, \\n490–491\\ncompared to other collaboration, \\n495–496\\ndefined, 485\\negos in, 490\\nerror checklists, 489\\nexpected results from, 485–486\\nfine-tuning, 489\\nfollow-up stage, 489\\ninspection meetings, 488\\nkey points, 497\\nmanagement role, 486–487\\nmoderator role, 486\\noverview stage, 487\\nperformance appraisals from, 487\\nplanning stage, 487\\npreparation stage, 487–488\\nprocedure for, 487–489\\nrate of code review, 488\\nreports, 488–489\\nresources for, 496–497\\nreviewer role, 486\\nreviews, compared to, 485\\nrework stage, 489\\nroles in, 486–487\\nscenarios approach, 488\\nscribe role, 486\\nstages of, 487–489\\nthree-hour solutions meeting, 489\\nformal technical reviews, 467\\nformatting code. See layout\\nFortran, 64\\nfunctional cohesion, 168–169\\nfunctional specification. See \\nrequirements\\nfunctions. See also routines\\ncalculations conv\\nerted to \\nexample, 166–167\\ndefined, 181\\ndisallowing, 150\\nkey point for, 186\\nnaming conventions for, 172, 181\\nprivate, overriding, 146\\nreturn values, setting, 182\\nstatus as return value, 181\\nwhen to use, 181–182\\nFundamental Theorem of \\nFormatting, 732\\nG\\nGeneral Principle of Software \\nQuality\\ncollaboration effects, 481\\ncosts, 522\\ndebugging, 537\\ndefined, 474–475\\nglobal variables\\naccess routines for. See access \\nroutines\\naliasing problems with, 336–337\\nalternatives to, 339–342\\nannotating, 343\\nchanges to, inadvertent, 336\\nchecklist for, 343–344\\nclass variable alternatives, 339\\ncode reuse problems, 337\\ncommenting, 803, 809\\nenumerated types emulation by, \\n338\\ng_ prefix guideline, 340\\nhiding implementation in classes, \\n153\\ninformation hiding problems \\nwith, 95–96\\ninitialization problems, 337\\nintermediate results, avoiding, \\n343\\nkey points, 344\\nlocal first guideline, 339\\nlocking, 341\\nmodularity damaged by, 337–338\\nnamed constants emulation by, \\n338\\nnaming, 263, 273, 277, 278, 279, \\n342\\nobjects for, monster, 343\\noverview of, 335–336\\npersistence of, 251\\npreservation of values with, 338\\nre-entrant code problems, 337\\nrefactoring, 568\\nrisk reduction strategies, 342–343\\nroutines using as parameters, 336\\nsemantic coupling with, 102\\nstreamlining data use with, 338\\ntramp data, eliminating with, 338\\ngod classes, 155\\ngonzo programming, 832\\ngood data, testing, 515–516\\ngoto statements\\nAda, inclusion in, 399\\nadvantages of, 399\\nalternatives compared with, 405\\nchecklist, 410\\ngoto statements\\nZ02I619670.fm  Page 897  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 934}, page_content='898 first top-level entry\\ngoto statements, continued\\ndeallocation with, 399\\ndisadvantages of, 398–399\\nduplicate code, eliminating with, \\n399\\nelse clauses with, 406–407\\nerror processing with, 401–402\\nFortran’s use of, 399\\nforward direction guideline, 408\\nguidelines, 407–408\\nindentation problem with, 398\\nkey points, 410\\nlayout guidelines, 750–751\\nlegitimate uses of, 407–408\\noptimization problem with, 398\\nphony debating about, 400–401\\nreadability issue, 398\\nresources for, 409–410\\nrewritten with nested ifs, \\n402–403\\nrewritten with status variables, \\n403–404\\nrewritten with try-finally, \\n404–405\\ntrivial rewrite example, 400–401\\nunused labels, 408\\ngraphical design tools, 710\\ngrep, 711\\ngrowing a system metaphor, 14–15\\nGUIs (graphical user interfaces)\\narchitecture prerequisites, 47\\nrefactoring data from, 576\\nsubsystem design, 85\\nH\\nhabits of programmers, 833–834\\nhacking approach to design, 233\\nhardware\\ndependencies, changing, 98\\nperformance enhancement with, \\n591\\nhas a relationships, 143\\nheuristic design\\nabstractions, forming consistent, \\n89–90\\nalternatives from patterns, 103\\navoiding failure, 106–107\\nbinding time considerations, 107\\nbottom-up approach to design, \\n112–113\\nbrute force, 107\\ncapturing work, 117–118\\ncentral points of control, 107\\nchange, identifying areas of, \\n97–99\\nchecklist for, 122–123\\ncollaboration, 115\\ncommunications benefit from \\npatterns, 104\\ncompletion of, determining, \\n115–117\\ncoupling considerations, 100–102\\ndiagrams, drawing, 107\\ndivide and conquer technique, \\n111\\nencapsulation, 90–91\\nerror reduction with patterns, 103\\nformality of, determining, \\n115–117\\nformalizing class contracts, 106\\ngoals checklist, 122–123\\nguidelines for using, 109–110\\nhierarchies for, 105–106\\ninformation hiding, 92–97, 120\\ninheritance, 91–92\\ninterfaces, formalizing as \\ncontracts, 106\\niteration practice, 111–117\\nkey points, 123\\nlevel of detail needed, 115–117\\nmodularity, 107\\nmultiple approach suggestion, \\n110\\nnature of design process, 76\\nnondeterministic basis for, 87\\nobject-oriented, resource for, 119\\nobjects, real world, finding, 87–89\\npatterns, 103–105, 120\\npractices, 110–118, 122\\nprototyping, 114–115\\nresources for, 121\\nresponsibilities, assigning to \\nobjects, 106\\nstrong cohesion, 105\\nsummary list of rules, 108\\ntesting, anticipating, 106\\ntop-down approach, 111–112, 113\\nheuristics\\nalgorithms compared to, 12\\ndesign with. See heuristic design\\nerror guessing, 513\\nhiding. See information hiding\\nhierarchies, benefits of, 105–106\\nhigh fan-in design goal, 80\\nhuman aspects of software \\ndevelopment. See character, \\npersonal\\nhumility, role in character, 821, 826, \\n834\\nHungarian naming convention, 279\\nhybrid coupling of variables, \\n256–257\\nI\\nI/O (input/output)\\narchitecture prerequisites, 49\\nchange, identifying areas of, 98\\nperformance considerations, \\n598–599\\nIDEs (Integrated Development \\nEnvironments), 710–711\\nIEEE (Institute for Electric and \\nElectrical Engineers), 813\\nif statements\\nboolean function calls with, 359\\nbreak blocks, simplification with, \\n446–447\\ncase statements, compared to, \\n360, 614\\ncase statements, converting to, \\n448–449, 451\\nchains of, 358–360\\nchecklist, 365\\ncommon cases first guideline, \\n359–360\\ncontinuation lines in, 757\\ncovering all cases, 360\\nelse clauses, 358–360, 406–407\\nequality, branching on, 355\\nerror processing examples, \\n356–357\\nfactoring to routines, 449–451\\nflipped, 358\\nfrequency, testing in order of, \\n612–613\\ngotos rewritten with, 402–403, \\n406–407\\nif-then-else statements, converting \\nto, 447–448\\nkey points, 366\\nlookup tables, substituting, \\n614–615\\nmultiple returns nested in, \\n392–393\\nnegatives in, making positive, \\n435–436\\nnested. See nested if statements\\nnormal case first guideline, \\n356–357\\nnormal path first guideline, 355\\nnull if clauses, 357\\ngraphical design tools\\nZ02I619670.fm  Page 898  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 935}, page_content='last top-level entry 899\\nplain if-then statements, 355–357\\nrefactoring, 573\\nsimplification, 445–447\\nsingle-statement layout, 748–749\\ntables, replacing with, 413–414\\ntypes of, 355\\nimplicit declarations, 239–240\\nimplicit instancing, 132\\nin keyword, creating, 175–176\\nincomplete preparation, causes of, \\n25–27\\nincremental development metaphor, \\n15–16\\nincremental integration\\nbenefits of, 693–694\\nbottom-up strategy, 697–698\\nclasses, 694, 697\\ncustomer relations benefit, 694\\ndefined, 692\\ndisadvantages of top-down \\nstrategy, 695–696\\nerrors, locating, 693\\nfeature-oriented integration, \\n700–701\\ninterface specification, 695, 697\\nprogress monitoring benefit, 693\\nresources on, 708\\nresults, early, 693\\nrisk-oriented integration, 699\\nsandwich strategy, 698–699\\nscheduling benefits, 694\\nslices approach, 698\\nsteps in, 692\\nstrategies for, overview, 694\\nstubs, 694, 696\\nsummary of approaches, 702\\ntest drivers, 697\\ntop-down strategy for, 694–696\\nT-shaped integration, 701\\nvertical-slice approach, 696\\nindentation, 737, 764–768\\nindexed access tables, 425–426, \\n428–429\\nindexes, supplementing data types \\nwith, 627–628\\nindexes, loop\\nalterations, 377\\nchecklist, 389\\nenumerated types for, 305\\nfinal values, 377–378\\nscope of, 383–384\\nvariable names, 265\\ninfinite loops, 367, 374\\ninformal reviews, 467, 492–493\\ninformation hiding\\naccess routines for, 340\\nADTs for, 127\\nbarriers to, 95–96\\ncategories of secrets, 94\\ncircular dependencies problem, \\n95\\nclass data mistaken for global \\ndata, 95–96\\nclass design considerations, 93\\nclass implementation details, 153\\nexample, 93–94\\nexcessive distribution problem, \\n95\\nimportance of, 92\\ninterfaces, class, 93\\nperformance issues, 96\\nprivacy rights of classes, 92–93\\nresources for, 120\\nsecrets concept, 92\\ntype creation for, 313–314\\ninheritance\\naccess privileges from, 148\\ncase statements, 147–148\\nchecklist, 158\\ncontainment compared to, 143\\ndecisions involved in, 144\\ndeep trees, 147\\ndefined, 144\\ndesign rule for, 144\\nfunctions, private, overriding, 146\\nguidelines, list of, 149\\nheuristic design with, 91–92\\nidentifying as a design step, 88\\nis a relationships, 144\\nkey points for, 160\\nLiskov Substitution Principle, \\n144–145\\nmain goal of, 136\\nmixins, 149\\nmultiple, 148–149\\noverridable vs. non-overridable \\nroutines, 145–146\\nparallel modifications refactoring \\nindicator, 566\\nplacement of common items in \\ntree, 146\\nprivate vs. protected data, 148\\nprivate, avoiding, 143\\nrecommended bias against, 149\\nr\\noutines overridden to do \\nnothing, 146–147\\nsingle-instance classes, 146\\nsimilar sub and super classes, 576\\ninitializing variables\\naccumulators, 243\\nat declaration guideline, 241\\nC++ example, 241\\nchecklist for, 257\\nclass members, 243\\ncompiler settings, 243\\nconsequences of failing to, 240\\nconst recommended, 243\\nconstants, 243\\ncounters, 243\\ndeclare and define near first use \\nrule, 242–243\\nfinal recommended, 243\\nfirst use guideline, 241–242\\nfixing defects, 553\\nglobal variables, 337\\nimportance of, 240–241\\nJava example, 242–243\\nkey point, 258\\nloops, variables used in, 249\\nparameter validity, 244\\npointer problems, 241, 244, \\n325–326\\nPrinciple of Proximity, 242\\nreinitialization, 243\\nstrings, 300\\nsystem perturbers, testing with, \\n527\\nVisual Basic examples, 241–242\\ninitializing working memory, 244\\ninline routines, 184–185\\ninput parameters, 274\\ninput/output. See I/O\\ninspections. See formal inspections\\ninstallation tools, 718\\ninstancing objects\\nADTs, 132\\nfactory method, 103–104\\nsingleton, 104, 151\\ninteger data types\\nchecklist, 316\\ncosts of operations, 602\\ndivision considerations, 293\\noverflows, 293–295\\nranges of, 294\\nIntegrated Development \\nEnvironments (IDEs), 710–711\\nintegration\\nbenefits of, 690–691, 693–694\\nbig-bang, 691\\nbottom-up strategy, 697–698\\nbroken builds, 703\\nchecklist, 707\\nintegration\\nZ02I619670.fm  Page 899  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 936}, page_content='900 first top-level entry\\nintegration, continued\\nclasses, 691, 694, 697\\ncontinuous, 706\\ncustomer relations, 694\\ndaily build and smoke test, \\n702–706\\ndefined, 689\\ndisadvantages of top-down \\nstrategy, 695–696\\nerrors, locating, 693\\nfeature-oriented strategy, 700–701\\nimportance of approach methods, \\n689–691\\nincremental. See incremental \\nintegration\\ninterface specification, 695, 697\\nkey points, 708\\nmonitoring, 693\\nphased, 691–692\\nresources on, 707–708\\nrisk-oriented strategy, 699\\nsandwich strategy, 698–699\\nscheduling, 694\\nslices approach, 698\\nsmoke tests, 703\\nstrategies for, overview, 694\\nstubs, 694, 696\\nsummary of approaches, 702\\ntesting, 499, 697\\ntop-down strategy for, 694–696\\nT-shaped integration, 701\\nunsurfaced work, 702\\nvertical-slice approach, 696\\nintegrity, 464\\nintellectual honesty, 826–828\\nintellectual toolbox approach, 20\\nintelligence, role in character, 821\\ninterfaces, class\\nabstraction aspect of, 89, \\n133–138, 566\\ncalls to classes, refactoring, 575\\ncohesion, 138\\nconsistent level of abstraction, \\n135–136\\ndelegation vs. inheritance, \\nrefactoring, 576\\ndocumenting, 713, 810\\nerosion under modification \\nproblem, 138\\nevaluating abstraction of, 135\\nextension classes, refactoring \\nwith, 576\\nformalizing as contracts, 106\\ngood abstraction example, \\n133–134\\nguidelines for creating, 135–138\\nforeign routines, refactoring with, \\n576\\ninconsistency with members \\nproblem, 138\\ninconsistent abstraction, example \\nof, 135–136\\ninformation hiding role, 93\\nintegration, specification during, \\n695, 697\\nkey points for, 160\\nlayout of, 768\\nmixins, 149\\nobjects, designing for, 89\\nopposites, pairs of, 137\\npoor abstraction example, \\n134–135\\nprivate details in, 139–141\\nprogrammatic preferred to \\nsemantic, 137\\npublic routines in interfaces \\nconcern, 141\\nread-time convenience rule, 141\\nrefactoring, 575–576, 579\\nroutines, moving to refactor, 575\\nroutines, unused, 576\\nsemantic violations of \\nencapsulation, 141–142\\nunrelated information, handling, \\n137\\ninterfaces, graphic. See GUIs\\ninterfaces, routine. See also \\nparameters of routines\\ncommenting, 808\\nforeign routines, refactoring with, \\n576\\npseudocode for, 226\\npublic member variables, 576\\nroutines, hiding, 576\\nroutines, moving to refactor, 575\\ninternationalization, 48\\ninter\\noperability, 48\\ninterpreted languages, performance \\nof, 600–601\\ninvalid input. See validation\\niteration, code. See also loops\\nforeach loops, 367, 372\\niterative data, 255\\niterator loops, defined, 367\\nIterator pattern, 104\\nstructured programming concept \\nof, 456\\niteration in development\\nchoosing, reasons for, 35–36\\ncode tuning, 850\\ndesign practice, 111–117\\nExtreme Programming, 58\\nimportance of, 850–851\\nprerequisites, 28, 33–34\\nsequential approach compared, \\n33–34\\npseudocode component of, 219\\nJ\\njamming loops, 617–618\\nJava\\nassertion example in, 190\\nboolean expression syntax, 443\\ndescription of, 65\\nexceptions, 198–201\\nlayout recommended, 745\\nlive time examples, 247–248\\nnaming conventions for, 276, 277\\nparameters example, 176–177\\npersistence of variables, 251\\nresources for, 159\\nJavadoc, 807, 815\\nJavaScript, 65\\nJUnit, 531\\njust in time binding, 253\\nK\\nkey construction decisions. See \\nconstruction decisions\\nkilled data state, 509–510\\nkinds of software projects, 31–33\\nL\\nlanguages, programming. See \\nprogramming language choice\\nLaw of Demeter, 150\\nlayout\\narray references, 754\\nassignment statement \\ncontinuations, 758\\nbegin-end pairs, 742–743\\nblank lines, 737, 747–748\\nblock style, 738–743\\nbrace styles, 734, 740–743\\nC++ side effects, 759–761\\nchecklist, 773–774\\nclasses, 768–771\\nclosely related statement \\nelements, 755–756\\ncomments, 763–766\\ncomplicated expressions, \\n749–750\\nconsistency requirement, 735\\nintegrity\\nZ02I619670.fm  Page 900  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 937}, page_content='last top-level entry 901\\ncontinuing statements, 754–758\\ncontrol statement continuations, \\n757\\ncontrol structure styles, 745–752\\ndeclarations, 761–763\\ndiscourse rules, 733\\ndocumentation in code, 763–766\\ndouble indented begin-end pairs, \\n746–747\\nemulating pure blocks, 740–743\\nendline layout, 743–745, 751–752\\nends of continuations, 756–757\\nfiles, within, 771–773\\nFundamental Theorem of \\nFormatting, 732\\ngotos, 750–751\\nincomplete statements, 754–755\\nindentation, 737\\ninterfaces, 768\\nkey points, 775\\nlanguage-specific guidelines, 745\\nlogical expressions, 753\\nlogical structure, reflecting, 732, \\n735\\nmediocre example, 731–732\\nmisleading indentation example, \\n732–733\\nmisleading precedence, 733\\nmodifications guideline, 736\\nmultiple statements per line, \\n758–761\\nnegative examples, 730–731\\nobjectives of, 735–736\\nparentheses for, 738\\npointers, C++, 763\\npure blocks style, 738–740\\nreadability goal, 735\\nreligious aspects of, 735\\nresources on, 774–775\\nroutine arguments, 754\\nroutine call continuations, 756\\nroutine guidelines, 766–768\\nself-documenting code, 778–781\\nsingle-statement blocks, 748–749\\nstatement continuation, 754–758\\nstatement length, 753\\nstructures, importance of, \\n733–734\\nstyles overview, 738\\nunindented begin-end pairs, 746\\nviolations of, commenting, 801\\nVisual Basic blocking style, 738\\nwhite space, 732, 736–737, \\n753–754\\nlaziness, 830\\nlazy evaluation, 615–616\\nleanness design goal, 81\\nlegal notices, 811\\nlength of variable names, optimum, \\n262\\nlevels of design\\nbusiness logic subsystem, 85\\nclasses, divisions into, 86\\ndatabase access subsystem, 85\\noverview of, 82\\npackages, 82–85\\nroutines, 86–87\\nsoftware system, 82\\nsubsystems, 82–85\\nsystem dependencies subsystem, \\n85\\nuser interface subsystem, 85\\nlibraries, code\\npurpose of, 717\\nusing functionality from, 222\\nlibraries, book. See software-\\ndevelopment libraries\\nlife-cycle models\\ngood practices table for, 31–32\\ndevelopment standard, 813\\nlinked lists\\ndeleting pointers, 330\\nnode insertion, 327–329\\npointers, isolating operations of, \\n325\\nlinkers, 716\\nlint tool, 557\\nLiskov Substitution Principle (LSP), \\n144–145\\nlists\\nof checklists, xxix–xxx\\nof figures, xxxiii\\nof tables, xxxi–xxxii\\nliteral data, 297–298, 308–309\\nliterate programs, 13\\nlive time of variables, 246–248, 459\\nload time, binding during, 253\\nlocalization\\narchitecture prerequisites, 48\\nstring data types, 298\\nlocking global data, 341\\nlogarithms, 632–634\\nlogging\\ndefensive programming guideline, \\n210\\nto\\nols for testing, 526\\nlogic coverage testing, 506\\nlogical cohesion, 170\\nlogical expressions. See also boolean \\nexpressions\\ncode tuning, 610–616\\ncomparing performance of, 614\\neliminating testing redundancy, \\n610–611\\nfrequency, testing in order of, \\n612–613\\nidentities, 630\\nlayout of, 753\\nlazy evaluation, 615–616\\nlookup tables, substituting, \\n614–615\\nshort-circuit evaluation, 610\\nloops\\nabnormal, 371\\narrays with, 387–388\\nbodies of, processing, 375–376, \\n388\\nbrackets recommended, 375\\nbreak statements, 371–372, \\n379–380, 381\\nchecklist, 388–389\\ncode tuning, 616–624\\ncommenting, 804–805\\ncompletion tests, location of, 368\\ncompound, simplifying, 621–623\\ncontinuously evaluated loops, \\n367. See also while loops\\ncontinuation lines in, 757\\ncontinue statements, 379, 380, \\n381\\ncounted loops, 367. See also for \\nloops\\ncross talk, 383\\ndefined, 367\\ndesigning, process for, 385–387\\ndo loops, 369–370\\nempty, avoiding, 375–376\\nendless loops, 367, 374\\nendpoint considerations, \\n381–382\\nentering, guidelines for, 373–375, \\n388\\nenumerated types for, 305\\nexit guidelines, 369–372, \\n377–381, 389\\nfor loops, 372, 374–378, \\n732–733, 746–747\\nforeach loops, 367, 372\\nfusion of, 617–618\\ngoto with, 371\\nhousekeeping statements, 376\\nindex alterations, 377\\nindex checklist, 389\\nindex final values, 377–378\\nindex variable names, 265\\nindex scope, 383-384\\ninfinite loops, 367, 374\\nloops\\nZ02I619670.fm  Page 901  Wednesday, May 12, 2004  12:23 PM\\nDownload from Wow! eBook <www.wowebook.com>'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 938}, page_content='902 first top-level entry\\nloops, continued\\ninitialization code for, 373, 374\\niterative data structures with, 255\\niterator loops, 367, 456\\njamming, 617–618\\nkey points, 389\\nkinds of, generalized, 367–368\\nlabeled break statements, 381\\nlanguage-specific, table of, 368\\nlength of, 385\\nminimizing work inside, 620–621\\nmultiple break statements, 380\\nnaming variables, 382–383\\nnested, 382–383, 385, 623\\nnull statements, rewriting, 445\\noff-by-one errors, 381–382\\none-function guideline, 376\\norder of nesting, 623\\nperformance considerations, 599\\npointers inside, 620\\nproblems with, overview of, 373\\npseudocode method, 385–387\\nrefactoring, 565, 573\\nrepeat until clauses, 377\\nroutines in, 385\\nsafety counters with, 378–379\\nscope of indexes, 383–384\\nsentinel tests for, 621–623\\nsize as refactoring indicator, 565\\nstrength reduction, 623–624\\nswitching, 616\\ntermination, making obvious, 377\\ntesting redundancy, eliminating, \\n610–611\\nunrolling, 618–620\\nunswitching, 616–617\\nvariable guidelines, 382–384\\nvariable initializations, 249\\nvariables checklist, 389\\nverifying termination, 377\\nwhile loops, 368–369\\nloose coupling\\ndesign goal, as, 80\\nstrategies for, 100–102\\nlow-to-medium fan-out design goal, \\n81\\nLSP (Liskov Substitution Principle), \\n144–145\\nM\\nMacintosh naming conventions, 275\\nmacro routines. See also routines\\nalternatives for, 184\\nlimitations on, 184\\nmultiple statements in, 183\\nnaming, 183, 277–278\\nparentheses with, 182–183\\nmagazines on programming, \\n859–860\\nmagic variables, avoiding, 292, \\n297–298, 308–309\\nmaintenance\\ncomments requiring, 788–791\\ndesign goal for, 80\\nerror-prone routines, prioritizing \\nfor, 518\\nfixing defects, problems from, 553\\nmaintainability defined, 464\\nreadability benefit for, 842\\nstructures for reducing, 323\\nmajor construction practices \\nchecklist, 69–70\\nmanaging construction\\napproaches. See approaches to \\ndevelopment\\nchange control. See configuration \\nmanagement\\ncode ownership attitudes, 663\\ncomplexity, 77–79\\nconfiguration management. See \\nconfiguration management\\ngood coding, encouraging, \\n662–664\\ninspections, management role in, \\n486–487\\nkey points, 688\\nmanagers, 686\\nmeasurements, 677–680\\nprogrammers, treatment of, \\n680–686\\nreadability standard, 664\\nresources on, 687\\nreviewing all code, 663\\nrewarding good practices, 664\\nschedules, estimating, 671–677\\nsigning off on code, 663\\nsize of projects, effects of. See size \\nof projects\\nstandards, authority to set, 662\\nstandards, IEEE, 687, 814\\ntwo-person teams, 662\\nmarkers, defects from, 787\\nmatrices. See arrays\\nmature technology environments, \\n67\\nmaximum normal configurations, \\n515\\nmaze recursion example, 394–396\\nMcCabe’s complexity metric, 457, \\n458\\nmeasure twice, cut once, 23\\nmeasurement\\nadvantages of, 677\\narguing against, 678\\ngoals for, 679\\noutlier identification, 679\\nresources for, 679–680\\nside effects of, 678\\ntable of useful types of, 678–679\\nmemory\\nallocation, error detection for, 206\\ncorruption by pointers, 325\\nfillers, 244\\ninitializing working, 244\\npaging operation performance \\nimpact, 599\\npointers, corruption by, 325\\ntools for, 527\\nmentoring, 482\\nmerge tools, 712\\nmetaphors, software\\naccreting a system, 15–16\\nalgorithmic use of, 11, 12\\nbuilding metaphor, 16–19\\nbuilding vs. buying components, \\n18\\ncombining, 20\\ncomputer-centric vs. data-centric \\nviews, 11\\ncustomization, 18\\ndiscoveries based on, 9–10\\near\\nth centric vs. sun centric views, \\n10–11\\nexamples of, 13–20\\nfarming, 14–15\\ngrowing a system, 14–15\\nheuristic use of, 12\\nimportance of, 9–11\\nincremental development, 15–16\\nkey points for, 21\\nmodeling use for, 9\\noverextension of, 10\\noyster farming, 15–16\\npendulum example, 10\\npower of, 10\\nreadability, 13\\nrelative merits of, 10, 11\\nsimple vs. complex structures, \\n16–17\\nsize of projects, 19\\nthrowing one away, 13–14\\ntoolbox approach, 20\\nusing, 11–12\\nwriting code example, 13–14\\nmethodologies, 657–659. See also \\napproaches to development\\nmethods. See routines\\nloose coupling\\nZ02I619670.fm  Page 902  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 939}, page_content='last top-level entry 903\\nmetrics reporters, 714\\nminimum normal configurations, \\n515\\nmission-critical systems, 31–32\\nmixed-language environments, 276\\nmixins, 149\\nmock objects, 523\\nmodeling, metaphors as. See \\nmetaphors, software\\nmoderator role in inspections, 486\\nmodularity\\ndesign goal of, 107\\nglobal variables, damage from, \\n337–338\\nmodules, coupling considerations, \\n100–102\\nmultiple inheritance, 148–149\\nmultiple returns from routines, \\n391–393\\nmultiple-file string search capability, \\n711–712\\nN\\nnamed constants. See constants\\nnaming conventions\\n“a” prefix convention, 272\\nabbreviating names, 282–285\\nabbreviation guidelines, 282\\narrays, 280–281\\nbenefits of, 270–271\\nC language, 275, 278\\nC++, 275–277\\ncapitalization, 274, 286\\ncase-insensitive languages, 273\\ncharacters, hard to read, 287\\nchecklist, 288–289, 780\\nclass member variables, 273\\nclass vs. object names, 272–273\\ncommon operations, for, 172–173\\nconstants, 273–274\\ncross-project benefits, 270\\ndescriptiveness guideline, 171\\ndocumentation, 284–285, \\n778–780\\nenumerated types, 269, 274, \\n277–279\\nformality, degrees of, 271\\nfiles, 811\\nfunction return values, 172\\nglobal variables, 273, 342\\nhomonyms, 286\\nHungarian, 279\\ninformal, 272–279\\ninput parameters, 274\\nJava, 276, 277\\nkey points, 289\\nkinds of information in names, \\n277\\nlanguage-independence \\nguidelines, 272–274\\nlength, not limiting, 171\\nMacintosh, 275\\nmeanings in names, too similar, \\n285\\nmisleading names, 285\\nmisspelled words, 286\\nmixed-language considerations, \\n276\\nmultiple natural languages, 287\\nnumbers, differentiating solely by, \\n171\\nnumerals, 286\\nopposites, use of, 172\\nparameters, 178\\nphonic abbreviations, 283\\nprefix standardization, 279–281\\nprocedure descriptions, 172\\nproliferation reduction benefit, \\n270\\npronunciation guideline, 283\\npurpose of, 270–271\\nreadability, 274\\nrelationships, emphasis of, 271\\nreserved names, 287\\nroutines, 171–173, 222\\nsemantic prefixes, 280–281\\nshort names, 282–285, 288–289\\nsimilarity of names, too much, \\n285\\nspacing characters, 274\\nt_ prefix convention, 272\\nthesaurus, using, 283\\ntypes vs. variables names, \\n272–273\\nUDT abbreviations, 279–280\\nvariables, for. See variable names\\nVisual Basic, 278–279\\nwhen to use, 271\\nnested if statements\\ncase statements, converting to, \\n448–449, 451\\nconverting to if-then-else \\nstatements, 447–448\\nfactoring to routines, 449–451\\nfactory method approach, \\nconverting to, 452–453\\nfunctional decomposition of, \\n450–451\\nobject-oriented approach, \\nconverting to, 452–453\\nredesigning, 453\\nsimplification by retesting \\nconditions, 445–446\\nsimplification with break blocks, \\n446–447\\nsummary of techniques for \\nreducing, 453–454\\ntoo many levels of, 445–454\\nnested loops\\ndesigning, 382–383, 385\\nordering for performance, 623\\nnondeterministic nature of design \\nprocess, 76, 87\\nnonst\\nandard language features, 98\\nnull objects, refactoring, 573\\nnull statements, 444–445\\nnumbers, literal, 292\\nnumeric data types\\nBCD, 297\\nchecklist, 316\\ncompiler warnings, 293\\ncomparisons, 440–442\\nconversions, showing, 293\\ncosts of operations, 602\\ndeclarations, commenting, 802\\nfloating-point types, 295–297, \\n316, 602\\nhard coded 0s and 1s, 292\\nintegers, 293–295\\nliteral numbers, avoiding, 292\\nmagic numbers, avoiding, 292\\nmagnitudes, greatly different, \\noperations with, 295\\nmixed-type comparisons, 293\\noverflows, 293–295\\nranges of integers, 294\\nzero, dividing by, 292\\nO\\nobjectives, software quality, 466, \\n468–469\\nobject-oriented programming\\nhiding information. See \\ninformation hiding\\ninheritance. See inheritance\\nobjects. See classes; objects\\npolymorphism. See \\npolymorphism\\nresources for, 119, 159\\nobject-parameter coupling, 101\\nobjects\\nADTs as, 130\\nattribute identification, 88\\nobjects\\nZ02I619670.fm  Page 903  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 940}, page_content='904 first top-level entry\\nobjects, continued\\nclass names, differentiating from, \\n272–273\\nclasses, contrasted to, 86\\ncontainment, identifying, 88\\ndeleting objects, 206\\nfactory methods, 103–104, \\n452–453, 577\\nidentifying, 88\\ninheritance, identifying, 88. See \\nalso inheritance\\ninterfaces, designing, 89. See also \\ninterfaces, class\\noperations, identifying, 88\\nparameters, using as, 179, 574\\nprotected interfaces, designing, \\n89\\npublic vs. private members, \\ndesigning, 89\\nreal world, finding, 87–89\\nrefactoring, 574–576\\nreference objects, 574\\nresponsibilities, assigning to, 106\\nsingleton property, enforcing, 151\\nsteps in designing, 87–89\\nObserver pattern, 104\\noff-by-one errors\\nboundary analysis, 513–514\\nfixing, approaches to, 553\\noffensive programming, 206\\none-in, one-out control constructs, \\n454\\noperating systems, 590\\noperations, costs of common, \\n601–603\\nopposites for variable names, 264\\noptimization, premature, 840. See \\nalso performance tuning\\noracles, software, 851\\nout keyword creation, 175–176\\noverengineering, 51\\noverflows, integer, 293–295\\noverlay linkers, 716\\noverridable routines, 145–146, 156\\noyster farming metaphor, 15–16\\nP\\npackages, 156–157\\npaging operations, 599\\npair programming\\nbenefits of, 484\\nchecklist, 484\\ncoding standards support for, 483\\ncompared to other collaboration, \\n495–496\\ndefined, 483\\ninexperienced pairs, 484\\nkey points, 497\\npace, matching, 483\\npersonality conflicts, 484\\nresources, 496\\nrotating pairs, 483\\nteam leaders, 484\\nvisibility of monitor, 484\\nwatching, 483\\nwhen not to use, 483\\nparameters of routines\\nabstraction and object \\nparameters, 179\\nactual, matching to formal, 180\\nasterisk (*) rule for pointers, \\n334–335\\nbehavior dependence on, 574\\nby reference vs. by value, 333\\nchecklist for, 185\\nC-library order, 175\\ncommenting, 806–807\\nconst prefix, 176, 177, 274\\ndependencies, clarifying, 349\\ndocumentation, 178\\nenumerated types for, 303\\nerror variables, 176\\nformal, matching to actual, 180\\nglobal variables for, 336\\nguidelines for use in routines, \\n174–180\\nin keyword creation, 175–176\\ninput-modify-output order, \\n174–175\\nJava, 176–177\\nlist size as refactoring indicator, \\n566\\nmatching actual to formal, 180\\nnaming, 178, 180, 274, 277, 278, \\n279\\nnumber of, limiting, 178\\nobjects, passing, 179\\norder for, 174–176\\nout keyword creation, 175–176\\npassing, types of, 333\\nrefactoring, 571, 573\\nstatus, 176\\nstructures as, 322\\nusing all of rule, 176\\nvariables, using as, 176–177\\nVisual Basic, 180\\nparentheses\\nbalancing technique, 437–438\\nlayout with, 738\\nPareto Principle, 592\\npassing parameters, 333\\npatterns\\nadvantages of, 103–104\\nalternatives suggested by, 103\\ncommunications benefit, 104\\ncomplexity reduction with, 103\\ndisadvantages of, 105\\nerror reduction benefit, 103\\nFactory Method, 103–104\\nresource for, 120\\ntable of, 104\\npeople first theme. See readability\\nperformance appraisals, 487\\nperformance tuning\\nalgorithm choice, 590\\narchitecture prerequisites, 48\\narrays, 593–594, 603–604\\nchecklist, 607–608\\ncode tuning for. See code tuning\\ncomments, effects on, 791\\ncompeting objectives dilemma, \\n595, 605\\ncompiler considerations, 590, \\n596–597\\ncorrectness, importance of, \\n595–596\\ndatabase indexing, 601\\ndefects in code, 601\\nDES example, 605–606\\ndesign view, 589–590\\nfeature specific, 595\\nhardware considerations, 591\\ninefficiency, sources of, 598–601\\ninformation hiding \\nconsiderations of, 96\\ninput/output, 598–599\\ninterpreted vs. compiled \\nlanguages, 600–601\\nkey points, 608\\nlines of code, minimizing number \\nof, 593–594\\nmeasur\\nement of, 603–604\\nmemory vs. file operations, \\n598–599\\nold wives’ tales, 593–596\\noperating system considerations, \\n590\\noperations, costs of common, \\n601–603\\noverview of, 643–644\\npaging operations, 599\\npremature optimization, 840\\nprogram requirements view of, \\n589\\npurpose of, 587\\nObserver pattern\\nZ02I619670.fm  Page 904  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 941}, page_content='last top-level entry 905\\nquality of code, impact on, 588\\nresource goals, 590\\nresources, 606–607\\nroutine design, 165, 222–223, \\n590\\nspeed, importance of, 595–596\\nsummary of approach for, 606\\nsystem calls, 599–600\\ntiming issues, 604\\nuser view of coding, 588\\nwhen to tune, 596\\nperiodicals on programming, \\n859-860\\nPerl, 65\\npersistence of variables, 251–252, \\n831\\npersonal character. See character, \\npersonal\\nperturbers. See system perturbers\\nphased integration, 691–692\\nphonic abbreviations of names, 283\\nPHP (PHP Hypertext Processor), 65, \\n600\\nphysical environment for \\nprogrammers, 684–685\\nplanning\\nanalogy argument for, 27–28\\nbuilding metaphor for, 18–19\\ndata arguing for, 28–30\\ngood practices table for, 31–32\\nlogical argument for, 27\\npointers\\n* (pointer declaration symbol), \\n332, 334–335, 763\\n& (pointer reference symbol), 332 \\n–> (pointer symbol), 328\\naddress of, 323, 326\\nallocation of, 326, 330, 331\\nalternatives to, 332\\nas function return values, 182\\nasterisk (*) rule, 334–335\\nauto_ptrs, 333\\nbounds checking tools, 527\\nC language, 334–335\\nC++ examples, 325, 328–334\\nC++ guidelines, 332–334\\nchecking before using, 326, 331\\nchecklist for, 344\\ncomparisons with, 441\\ncontents, interpretation of, \\n324–325\\ncover routines for, 331–332\\ndangers of, 323, 325\\ndata types pointed to, 324–325\\ndeallocation of, 326, 330, 332\\ndebugging aids, 208–209\\ndeclaring, 325–326, 763\\ndeleting, 330–331, 332\\ndiagramming, 329\\ndog tag fields, 326–327\\nexplicit typing of, 334\\nexplicitly redundant fields, 327\\nextra variables for clarity, \\n327–329\\nhiding operations with routines, \\n165\\ninitializing, 241, 244, 325–326\\ninterpretation of address \\ncontents, 324–325\\nisolating operations of, 325\\nkey points, 344\\nlanguages not providing, 323\\nlinked lists, deleting in, 330\\nlocation in memory, 323\\nmemory corruption by, 325–327\\nmemory parachutes, 330\\nnull, setting to after deleting, 330\\nnull, using as warnings, 849\\noverwriting memory with junk, \\n330\\nparts of, 323\\npassing by reference, 333\\nreferences, C++, 332\\nresources for, 343\\nSAFE_ routines for, 331–332\\nsimplifying complicated \\nexpressions, 329\\nsizeof(), 335\\nsmart, 334\\nstring operations in C, 299\\ntype casting, avoiding, 334\\nvariables referenced by, checking, \\n326\\npolymorphism\\ncase statements, replacing with, \\n147–148\\ndefined, 92\\nlanguage-specific rules, 156\\nnested ifs, converting to, 452–453\\npolynomial expressions, 631–632\\nportability\\ndat\\na types, defining for, 315–316\\ndefined, 464\\nroutines for, 165\\npostconditions\\nroutine design with, 221\\nverification, 192–193\\nPPP (Pseudocode Programming \\nProcess)\\nalgorithms, researching, 223\\nalternates to, 232–233\\nchecking for errors, 230–231\\nchecklist for, 233–234\\ncleanup steps, 232\\ncoding below comments, \\n227–229\\ncoding routines from, 225–229\\ndata structure for routines, 224\\ndeclarations from, 226\\ndefined, 218\\ndesigning routines, 220–225\\nerror handling considerations, \\n222\\nexample for routines, 224\\nfunctionality from libraries, 222\\nheader comments for routines, \\n223\\nhigh-level comments from, \\n226–227\\niterating, 225\\nkey points for, 234\\nnaming routines, 222\\nperformance considerations, \\n222–223\\nprerequisites, 221\\nproblem definition, 221\\nrefactoring, 229\\nremoving errors, 231\\nrepeating steps, 232\\nreviewing pseudocode, 224–225\\nstepping through code, 231\\ntesting the code, 222, 231\\nwriting pseudocode step, \\n223–224\\nprecedence, misleading, 733\\npreconditions\\nroutine design with, 221\\nverification, 192–193\\nprefixes, standardization of, \\n279–281\\npremature optimization, 840\\npreparation. See prerequisites, \\nupstream\\npreprocessors\\nC++, 207–208\\ndebugging aids, removing with, \\n207–208\\npurpose of, 718–719\\nwriting, 208\\nprerequisites, upstream\\nanalogy argument for, 27–28\\narchitectural. See architecture\\nboss readiness test, 30–31\\nchecklist for, 59\\nprerequisites, upstream\\nZ02I619670.fm  Page 905  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 942}, page_content='906 first top-level entry\\nprerequisites, upstream, continued\\nchoosing between iterative and \\nsequential approaches, 35–36\\ncoding too early mistake, 25\\ncompelling argument for, 27–31\\ndata arguing for, 28–30\\nerror detection, doing early, \\n29–30\\ngoal of, 25\\ngood practices table for, 31–32\\nimportance of, 24\\nincomplete preparation, causes of, \\n25–27\\niterative and sequential mixes, \\n34–35\\niterative methods with, 28, 33–34\\nkey points for, 59–60\\nkinds of projects, 31–33\\nlogical argument for, 27\\nmanager ignorance problem, 26\\nproblem definition, 36–38\\nrequirements development. See \\nrequirements\\nrisk reduction goal, 25\\nskills required for success, 25\\ntime allowed for, 55–56\\nWIMP syndrome, 26\\nWISCA syndrome, 26\\nPrinciple of Proximity, 242, 351\\nprivate data, 148\\nproblem-definition prerequisites, \\n36–38\\nproblem domain, programming at, \\n845–847\\nproblem-solving skills development, \\n823\\nprocedural cohesion, 170\\nprocedures. See also routines\\nnaming guidelines for, 172\\nwhen to use, 181–182\\nprocesses, development. See \\napproaches to development\\nproductivity\\neffects of good construction \\npractice, 7\\nindustry average, 474\\nsize of projects, effects on, 653\\nprofessional development, 824–825\\nprofessional organizations, 862\\nprogram flow\\ncontrol of. See control structures\\nsequential. See straight-line code\\nprogram organization prerequisite, \\n45–46\\nprogram size. See size of projects\\nprogrammers, character of. See \\ncharacter, personal\\nprogrammers, treatment of. See also \\nteams\\noverview, 680\\nphysical environment, 684–685\\nprivacy of offices, 684\\nreligious issues, 683–684\\nresources on, 685–686\\nstyle issues, 683–684\\ntime allocations, 681\\nvariations in performance, \\n681–683\\nprogramming conventions\\nchoosing, 66\\ncoding practices checklist, 69\\nformatting rules. See layout\\nprogramming into languages, \\n68–69, 843\\nprogramming language choice\\nAda, 63\\nassembly language, 63\\nBasic, 65\\nC, 64\\nC#, 64\\nC++, 64\\nCobol, 64\\nexpressiveness of concepts, 63\\nfamiliar vs. unfamiliar languages, \\n62\\nFo\\nrtran, 64\\nhigher- vs. lower-level language \\nproductivity, 62\\nimportance of, 61–63\\nJava, 65\\nJavaScript, 65\\nPerl, 65\\nPHP, 65\\nproductivity from, 62\\nprogramming into languages, \\n68–69, 843\\nPython, 65\\nratio of statements compared to C \\ncode, table of, 62\\nSQL, 65\\nthinking, effects on, 63\\nVisual Basic, 65\\nprogramming tools\\nassembler listing tools, 720\\nbeautifiers, 712\\nbuild tools, 716–717\\nbuilding your own, 721–722\\nCASE tools, 710\\nchecklist, 724–725\\nclass-hierarchy generators, 713\\ncode libraries, 717\\ncode tuning, 720\\ncode-generation wizards, 718\\ncompilers, 716\\ncross-reference tools, 713\\ndata dictionaries, 715\\ndebugging tools, 526–527, 545, \\n558–559, 719\\ndependency checkers, 716\\ndesign tools, 710\\nDiff tools, 712\\ndisassemblers, 720\\nediting tools, 710–713\\nexecutable-code tools, 716–720\\nexecution profiler tools, 720\\nfantasyland, 722–723\\ngraphical design tools, 710\\ngrep, 711\\nIDEs, 710–711\\ninterface documentation, 713\\nkey points, 725\\nlinkers, 716\\nmerge tools, 712\\nmetrics reporters, 714\\nmultiple-file string searches, \\n711–712\\npreprocessors, 718–719\\nproject-specific tools, 721–722\\npurpose of, 709\\nquality analysis, 713–714\\nrefactoring tools, 714–715\\nresources on, 724\\nrestructuring tools, 715\\nscripts, 722\\nsemantics checkers, 713–714\\nsource-code tools, 710–715\\nsyntax checkers, 713–714\\ntemplates, 713\\ntesting tools, 719\\ntool-oriented environments, \\n720–721\\ntranslators, 715\\nversion control tools, 715\\nproject types, prerequisites \\ncorresponding to, 31–33\\nprotected data, 148\\nprototyping, 114–115, 468\\nProximity, Principle of, 242, 351\\npseudocode\\nalgorithms, researching, 223\\nbad, example of, 218–219\\nbenefits from, 219–220\\nchanging, efficiency of, 220\\nchecking for errors, 230–231\\nchecklist for PPP, 233–234\\nPrinciple of Proximity\\nZ02I619670.fm  Page 906  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 943}, page_content='last top-level entry 907\\nclasses, steps in creating, 216–217\\ncoding below comments, \\n227–229\\ncoding from, 225–229\\ncomments from, 220, 791\\ndata structure for routines, 224\\ndeclarations from, 226\\ndefined, 218\\ndesigning routines, 220–225\\nerror handling considerations, \\n222\\nexample for routines, 224\\nfunctionality from libraries, 222\\ngood, example of, 219\\nguidelines for effective use, 218\\nheader comments for routines, \\n223\\nhigh-level comments from, \\n226–227\\niterative refinement, 219, 225\\nkey points for creating, 234\\nloop design, 385–387\\nnaming routines, 222\\nperformance considerations, \\n222–223\\nPPP. See PPP\\nprerequisites, 221\\nproblem definition, 221\\nrefactoring, 229\\nreviewing, 224–225\\nroutines, steps in creating, 217, \\n223–224\\ntesting, planning for, 222\\nPseudocode Programming Process. \\nSee PPP\\npsychological distance, 556\\npsychological set, 554–555\\npsychological factors. See character, \\npersonal\\npublic data members, 567\\npure blocks layout style, 738–740\\nPython\\ndescription of, 65\\nperformance issues, 600\\nQ\\nquality assurance. See also quality of \\nsoftware\\nchecklist, 70\\ngood practices table for, 31–32\\nprerequisites role in, 24\\nrequirements checklist, 42–43\\nquality gates, 467\\nquality of software\\naccuracy, 464\\nadaptability, 464\\nchange-control procedures, 468\\nchecklist for, 476\\ncollaborative construction. See \\ncollaboration\\ncorrectness, 463\\ncosts of finding defects, 472\\ncosts of fixing defects, 472–473\\ndebugging, role of, 474–475, 536\\ndetection of defects by various \\ntechniques, table of, 470\\ndevelopment process assurance \\nactivities, 467–468\\nefficiency, 464\\nengineering guidelines, 467\\nexplicit activity for, 466\\nexternal audits, 467\\nexternal characteristics of, \\n463–464\\nExtreme Programming, 471–472\\nflexibility, 464\\ngates, 467\\nGeneral Principle of Software \\nQuality, 474–475\\nintegrity, 464\\ninternal characteristics, 464–465\\nkey points, 477\\nmaintainability, 464\\nmeasurement of results, 468\\nmultiple defect detection \\ntechniques recommended, \\n470–471\\nobjectives, setting, 466, 468–469\\noptimization conflicts, 465–466\\npercentage of defects \\nmeasurement, 469–472\\nportability, 464\\nprogrammer performance, \\nobjectives based, 468–469\\nprototyping, 468\\nreadability, 464\\nrecommended combination for, \\n473\\nrelationships of characteristics, \\n465–466\\nreliability, 464\\nresources for, 476\\nreusability, 464\\nreviews, 467\\nrobustness, 464\\nstandards, IEEE, 477, 814\\ntesting, 465, 467, 500–502\\nunderstandability, 465\\nusability, 463\\nwhen to do assurance of, 473\\nR\\nrandom-data generators, 525\\nreadability\\nas management standard, 664\\ndefects exposing lack of, 538\\ndefined, 464\\nformatting for. See layout\\nimportance of, 13, 841–843\\nmaintenance benefit from, 842\\nnaming variables for. See naming \\nconventions; variable names\\npositive effects from, 841\\nprivate vs. public programs, 842\\nprofessional development, \\nimportance to, 825\\nstructures, importance of, \\n733–734\\nwarning sign, as a, 849\\nreading as a skill, 824\\nreading plan for software \\ndevelopers, 860–862\\nrecords, refactoring, 572\\nrecursion\\nalternatives to, 398\\nchecklist, 410\\ndefined, 393\\nfactorials using, 397–398\\nFibonacci numbers using, \\n397–398\\nguidelines for, 394\\nkey points, 410\\nmaze example, 394–396\\nsafety counters for, 396\\nsingle routine guideline, 396\\nsorting example, 393–394\\nstack space concerns, 397\\nterminating, 396\\nrefactoring\\n80/20 rule, 582\\nadding routines, 582\\nalgorithms, 573\\narrays, 572\\nbacking up old code, 579\\nbidirectional class associations, \\n577\\nboolean expressions, 572\\ncase statements, 573\\nchecklists for, 570, 577–579\\ncheckpoints for, 580\\nrefactoring\\nZ02I619670.fm  Page 907  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 944}, page_content='908 first top-level entry\\nrefactoring, continued\\nclass cohesion indicator, 566\\nclass interfaces, 575–576\\nclasses, 566–567, 574–576, \\n578–579, 582\\ncode tuning, compared to, 609\\ncollections, 572\\ncomments on bad code, 568\\ncomplex modules, 583\\nconditional expressions, 573\\nconstant values varying among \\nsubclass, 574\\nconstructors to factory methods, \\n577\\ndata from uncontrolled sources, \\n576\\ndata sets, related, as indicator, 566\\ndata types to classes, 572\\ndata-level, 571–572, 577\\ndefects, fixes of, 582\\ndefined, 565\\ndesigning code for future needs, \\n569–570\\nDon’t Repeat Yourself principle, \\n565\\nduplicate code indicator, 565\\nerror-prone modules, 582\\nexpressions, 571\\nglobal variables, 568\\nGUI data, 576\\nif statements, 573\\ninterfaces, 566, 575–576, 579\\nkey points, 585\\nlisting planned steps, 580\\nliteral constants, 571\\nloops, 565, 573\\nmaintenance triggering, 583\\nmiddleman classes, 567\\nmisuse of, 582\\nnull objects, 573\\nobjects, 574–576\\none-at-a-time rule, 580\\noverloaded primitive data types, \\n567\\nparallel modifications required \\nindicator, 566\\nparameters, 566, 571, 573\\nPPP coding step, 229\\npublic data members, 567\\nqueries, 574\\nreasons not to, 571\\nrecords, 572\\nredesigning instead of, 582\\nreference objects, 574\\nresources on, 585\\nreviews of, 580–581\\nrisk levels of, 581\\nroutines, 565–567, 573–574, 578, \\n582\\nsafety guidelines, 579–581, 584\\nsetup code, 568–569\\nsize guideline, 580\\nstatement-level, 572–573, \\n577–578\\nstrategies for, 582–584\\nsubclasses, 567, 575\\nsuperclasses, 575\\nsystem-level, 576–577, 579\\ntakedown code, 568–569\\ntesting, 580\\nto do lists for, 580\\ntools for, 714–715\\ntramp data, 567\\nugly code, interfaces to, 583–584\\nunidirectional class associations, \\n577\\nunit tests for, 580\\nvariables, 571\\nwarnings, compiler, 580\\nreferences (&), C++, 332\\nregression testing\\ndiff tools for, 524\\ndefined, 500\\npurpose of, 528\\nreliability\\ncohesive routines, 168\\ndefined, 464\\nreligious attitude toward \\nprogramming\\neclecticism, 851–852\\nexperimentation compared to, \\n852–853\\nharmful effects of, 851–853\\nlayout styles becoming, 735\\nmanaging people, 683–684\\nsoftware oracles, 851\\nreports. See formal inspections\\nrequirements\\nbenefits of, 38–39\\nbusiness cases for, 41\\nchange-control procedures, 40–41\\nchecklists for, 40, 42–43\\ncoding without, 26\\ncommunicating chang\\nes in, 40–41\\ncompleteness, checklist, 43\\nconfiguration management of, \\n664, 666–667\\ndefined, 38\\ndevelopment approaches with, 41\\ndevelopment process effects on, \\n40\\ndumping projects, 41\\nerrors in, effects of, 38–39\\nfunctional, checklist, 42\\ngood practices table for, 31–32\\nimportance of, 38–39\\nkey point for, 60\\nnonfunctional, checklist, 42\\nperformance tuning, 589\\nquality, checklist, 42–43\\nrate of change, typical, 563\\nresources on developing, 56–57\\nstability of, 39–40, 840\\ntesting for, 503\\ntime allowed for, 55–56\\nresource management\\narchitecture for, 47\\ncleanup example, 401–402\\nrestrictive nature of design, 76\\nrestructuring tools, 715\\nretesting. See regression testing\\nreturn statements\\nchecklist, 410\\nguard clauses, 392–393\\nkey points, 410\\nmultiple, from one routine, \\n391–393\\nreadability, 391–392\\nresources for, 408\\nreusability\\ndefined, 464\\narchitecture prerequisites, 52\\nreviewer role in inspections, 486\\nreviews\\ncode reading, 494\\ndog-and-pony shows, 495\\neducational aspect of, 482\\nevery line of code rule, 663\\nformal inspections, compared to, \\n485\\nformal, quality from, 467\\ninformal, defined, 467\\niteration process, place in, 850\\nrefactoring conducting after, \\n580–581\\nwalk-throughs, 492–493\\nright shifting, 634\\nrisk-oriented integration, 699\\nrobustness\\narchitecture prerequisites, 51\\nassertions with error handling, \\n193–194\\ncorrectness, balanced against, 197\\ndefined, 197, 464\\nreferences (&), C+ +\\nZ02I619670.fm  Page 908  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 945}, page_content='last top-level entry 909\\nrounding errors, 297\\nroutines\\nabstract overridable, 145\\nabstraction benefit, 164\\nabstraction with object \\nparameters, 179, 574\\naccess. See access routines\\nalgorithm selection for, 223, 573\\nalternates to PPP, 232–233\\nblack-box testing of, 502\\nblank lines in, 766\\nboolean test benefit, 165\\ncalculation to function example, \\n166–167\\ncalls, costs of, 601\\nchecking for errors, 230–231\\nchecklists, 185, 774, 780\\nclasses, converting to, criteria for, \\n573\\ncleanup steps, 232\\ncode tuning, 639–640\\ncoding from pseudocode, \\n225–229\\ncohesion, 168–171\\ncoincidental cohesion, 170\\ncommenting, 805–809, 817\\ncommunicational cohesion, 169\\ncompiling for errors, 230–231\\ncomplexity metric, 458\\ncomplexity reduction benefit, 164\\nconstruction step for classes, 217\\ncontinuations in call lines, 756\\ncoupling considerations, 100–102\\ndata states, 509\\ndata structures for, 224\\ndeclarations, 226\\ndefined, 161\\ndescriptiveness guideline for \\nnaming, 171\\ndesign by contract, 233\\ndesigning, 86, 220–225\\ndocumentation, 178, 780\\ndowncast objects, 574\\nduplication benefit, 164–165\\nendline layout, 767\\nerror handling considerations, \\n222\\nerrors in, relation to length of, 173\\nevent handlers, 170\\nfields of objects, passing to, 574\\nfiles, layout in, 772\\nfunctional cohesion, 168–169\\nfunctionality from libraries, 222\\nfunctions, special considerations \\nfor, 181–182\\nhacking approach to, 233\\nheader comments for, 223\\nhigh quality, counterexample, \\n161–163\\nhigh-level comments from \\npseudocode, 226–227\\nimportance of, 163\\nin keyword creation, 175–176\\nindentation of, 766–768\\ninternal design, 87\\ninline, 184–185\\ninput-modify-output parameter \\norder, 174–175\\ninterface statements, 226\\niterating pseudocode, 225\\nkey points for, 186, 234\\nlayout of, 754, 766–768\\nlength of, guideline for, 173–174\\nlimitations, documenting, 808\\nlogical cohesion, 170\\nlow-quality example, 161–163\\nmacro. See macro routines\\nmentally checking for errors, 230\\nmultiple returns from, 391–393\\nnamed parameters in, 180\\nnaming, 171–173, 222, 277–278, \\n567\\nnested deeply, 164\\nobjects, passing to, 179, 574\\nout keyword creation, 175–176\\noverridable vs. non-overridable \\nroutines, 145–146\\noverridden to do nothing, \\n146–147\\noverriding, 156\\nparameters. See parameters of \\nroutines\\nperformance considerations, 165, \\n222–223\\npointer hiding benefit, 165\\nportability benefit, 165\\npostconditions, 221\\nPPP checklist f\\nor, 233–234\\npreconditions, 221\\nprerequisites, 221\\nproblem definition, 221\\nprocedural cohesion, 170\\nprocedure naming guideline, 172\\npseudocode writing step, \\n223–224\\npublic, using in interfaces \\nconcern, 141\\nqueries, refactoring, 574\\nreasons for creating, list of, 167\\nrefactoring, 229, 573–575, 578, \\n582\\nreliability from cohesiveness, 168\\nremoving errors, 231\\nrepeating steps, 232\\nreturns from, multiple, 391–393\\nreviewing pseudocode, 224–225\\nsequence hiding benefit, 165\\nsequential cohesion, 168\\nsetup code for, refactoring, \\n568–569\\nsimilar parameters, order for, 176\\nsimilar, refactoring, 574\\nsimple, usefulness of, 166–167\\nsize as refactoring indicator, \\n565–566\\nsmall vs. large, 166, 173–174\\nspecification example, 221\\nstepping through code, 231\\nstrength, 168\\nsubclassing benefit, 165\\ntemporal cohesion, 169\\ntest-first development, 233\\ntesting, 222, 231, 523\\ntramp data in, 567\\nunused, refactoring, 576\\nvalid reasons for creating, \\n164–167\\nvariable names, differentiating \\nfrom, 272\\nwrong class, indicator for, 566\\nrun time, binding during, 253\\nS\\nsafety counters in loops, 378–379\\nsandwich integration, 698–699\\nscaffolding\\ndebugging with, 558\\ntesting, 523–524, 531\\nscalability, 48. See also size of \\nprojects\\nscientific method, classic steps in, \\n540\\nSCM (software configuration \\nmanagement), 665. See also \\nconfiguration management\\nschedules, estimating. See estimating \\nschedules\\nscope of variables\\nconvenience argument, 250\\ndefined, 244\\nglobal scope, problems with, 251\\nscope of variables\\nZ02I619670.fm  Page 909  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 946}, page_content='910 first top-level entry\\nscope of variables, continued\\ngrouping related statements, \\n249–250\\nkey point, 258\\nlanguage differences, 244\\nlive time, minimizing, 246–248\\nlocalizing references to variables, \\n245\\nloop initializations, 249\\nmanageability argument, 251\\nminimizing, guidelines for, \\n249–251\\nrestrict and expand tactic, 250\\nspan of variables, 245\\nvalue assignments, 249\\nvariable names, effects on, \\n262–263\\nscribe role in inspections, 486\\nscripts\\nprogramming tools, as, 722\\nslowness of, 600-601\\nSDFs (software development \\nfolders), 778\\nsecurity, 47\\nselections, code, 455\\nselective data, 254\\nself-documenting code, 778–781, \\n796–797\\nsemantic coupling, 102\\nsemantic prefixes, 280–281\\nsemantics checkers, 713–714\\nsentinel tests for loops, 621–623\\nsequences, code. See also blocks\\nhiding with routines, 165\\norder of. See dependencies, \\ncode-ordering\\nstructured programming concept \\nof, 454\\nsequential approach, 33–36\\nsequential cohesion, 168\\nSet() routines, 576\\nsetup code, refactoring, 568–569\\nsetup tools, 718\\nshort-circuit evaluation, 438–440, \\n610\\nside effects, C++, 759–761\\nsigning off on code, 663\\nsimple-data-parameter coupling, 101\\nsimple-object coupling, 101\\nsingle points of control, 308\\nsingle-statement blocks, 748–749\\nsingleton property, enforcing, 104, \\n151\\nsize of projects\\nactivities, list of fastest growing, \\n655\\nactivity types, effects on, 654–655\\nbuilding metaphor for, 19\\ncommunications between people, \\n650\\ncomplexity, effect of, 656–657\\ndefects created, effects on, \\n651–653\\ndocumentation requirements, \\n657\\nestimation errors, 656–657\\nformality requirements, 657\\nkey points, 659\\nmethodology considerations, \\n657–658\\noverview, 649\\nproductivity, effects on, 653\\nranges in, 651\\nresources on, 658–659\\nsingle product, multiple users, \\n656\\nsingle program, single user, 656\\nsystem products, 656\\nsystems, 656\\nsizeof(), 335\\nsloppy processes, 75–76\\nsmart pointers, 334\\nsmoke tests, 703\\nsoftware accretion metaphor, 15–16\\nsoftware construction overview\\nactivities excluded from, 6\\nactivities in, list of, 3\\ncentralness to development \\nprocess, 7\\ndefined, 3–6\\ndocumentation by source code, 7\\nguaranteed done nature of, 7\\nimportance of, 6–7\\nkey points for, 8\\nmain activities of, 4\\npercent of total development \\nprocess, 7\\nproductivity, importance in, 7\\npr\\nogramming as, 5\\nprogramming vs., 4\\nsource code as documentation, 7\\ntasks in, list of, 5\\nsoftware design. See design\\nsoftware development folders \\n(SDFs), 778\\nsoftware engineering overview of \\nresources, 858\\nsoftware evolution\\nbackground for, 563–564\\nCardinal Rule of, 565\\nconstruction vs. maintenance, \\n564\\nimproving vs. degrading direction \\nof, 564\\nphilosophy of, 564–565\\nsoftware metaphors. See metaphors, \\nsoftware\\nsoftware oracles, 851\\nsoftware quality. See quality of \\nsoftware\\nSoftware’s Primary Technical \\nImperative, 92\\nsoftware-development libraries\\nbibliographies, 858\\nconstruction, 856\\nmagazines, 859–860\\noverview, 855, 857–858\\nreading plan, 860–862\\nsoftware engineering overviews, \\n858\\nsoftware-engineering guidelines, \\n467\\nsorting, recursive algorithm for, \\n393–394\\nsource code\\ndocumentation aspect of, 7\\nresource for, 815\\nsource-code tools\\nanalyzing quality, 713–714\\nbeautifiers, 712\\nclass-hierarchy generators, 713\\ncomparators, 556\\ncross-reference tools, 713\\ndata dictionaries, 715\\nDiff tools, 712\\nediting tools, 710–713\\ngrep, 711\\nIDEs, 710–711\\ninterface documentation, 713\\nmerge tools, 712\\nmetrics reporters, 714\\nmultiple-file string searches, \\n711–712\\nrefactoring tools, 714–715\\nrestructuring tools, 715\\nsemantics checkers, 713–714\\nsyntax checkers, 713–714\\ntemplates, 713\\ntranslators, 715\\nversion control tools, 715\\nspan, 245, 459\\nscribe role in inspections\\nZ02I619670.fm  Page 910  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 947}, page_content='last top-level entry 911\\nspecific functional requirements \\nchecklist, 42\\nspecific nonfunctional requirements \\nchecklist, 42\\nspecification. See requirements\\nspeed improvement checklist, \\n642–643. See also code tuning; \\nperformance tuning\\nSQL, 65\\nstabilizing errors, 542–543\\nstair-step access tables, 426–429\\nstandards, overview of, 814\\nstate variables. See status variables\\nstatements\\nchecklist, 774\\nclosely-related elements, 755–756\\ncontinuation layout, 754–758\\nends of continuations, 756–757\\nincomplete, 754–755\\nlength of, 753\\nrefactoring, 572–573, 577–578\\nsequential. See straight-line code\\nstatus reporting, 827\\nstatus variables\\nbit-level meanings, 803\\nchange, identifying areas of, \\n98–99\\nenumerated types for, 266–267\\ngotos rewritten with, 403–404\\nnames for, 266–267\\nsemantic coupling of, 102\\nstraight-line code\\nchecklist, 353\\nclarifying dependencies, 348–350\\ndependencies concept, 347\\ndocumentation, 350\\nerror checking, 350\\ngrouping related statements, \\n352–353\\nhidden dependencies, 348\\ninitialization order, 348\\nnaming routines, 348–349\\nnon-obvious dependencies, 348\\norganization to show \\ndependencies, 348\\nparameters, effective, 349\\nproximity principle, 351\\nspecific order, required, 347–350\\ntop to bottom readability \\nguideline, 351–352\\nStrategy pattern, 104\\nstratification design goal, 81\\nstrcpy(), 301\\nstreams, 206\\nstrength. See cohesion\\nstring data types\\nC language, 299–301\\ncharacter sets, 298\\nchecklist, 316–317\\nconversion strategies, 299\\nindexes, 298, 299–300, 627\\ninitializing, 300\\nlocalization, 298\\nmagic (literal) strings, 297–298\\nmemory concerns, 298, 300\\npointers vs. character arrays, 299\\nUnicode, 298, 299\\nstring pointers, 299\\nstrncpy(), 301\\nstrong cohesion, 105\\nstructs. See structures\\nstructured basis testing\\nrecommended, 503\\ntheory of, 505–509\\nstructured programming\\ncore thesis of, 456\\niteration, 456\\noverview, 454\\nselections, 455\\nsequences, 454\\nstructures\\nblocks of data, operations on, \\n320–322\\nchecklist for, 343\\nclarifying data relationships with, \\n320\\nclasses performing as, 319\\ndefined, 319\\nkey points, 344\\nmaintenance reduction with, 323\\noverdoing, 322\\nparameter simplification with, \\n322\\nrelationships, clear example of, \\n320\\nr\\noutine calls with, 322\\nsimplifying data operations with, \\n320–322\\nswapping data, 321–322\\nunstructured data example, 320\\nVisual Basic examples, 320–322\\nstub objects, testing with, 523\\nstubs as integration aids, 694, 696\\nstubs with debugging aids, 208–209\\nstyle issues\\nformatting. See layout\\nself-documenting code, 778–781\\nhuman aspects of, 683–684\\nsub procedures, 161. See also \\nroutines\\nsubsystem design level, 82–85\\nsubtraction, 295\\nswapping data using structures, \\n321–322\\nswitch statements. See case \\nstatements\\nsymbolic debuggers, 526–527\\nsyntax, errors in, 549–550, 560, \\n713–714\\nsystem architecture. See architecture\\nsystem calls\\ncode tuning, 633–634\\nperformance issues, 599–600\\nsystem dependencies, 85\\nsystem perturbers, 527\\nsystem testing, 500\\nsystem-level refactoring, 576–577, \\n579\\nT\\ntable-driven methods\\nadvantages of, 420\\nbinary searches with, 428\\ncase statement approach, \\n421–422\\nchecklist, 429\\ncode-tuning with, 614–615\\ncreating from expressions, 435\\ndays-in-month example, 413–414\\ndefined, 411\\ndesign method, 420\\ndirect access. See direct access \\ntables\\nendpoints of ranges, 428\\nflexible-message-format example, \\n416–423\\nfudging keys for, 423–424\\nindexed access tables, 425–426, \\n428–429\\ninsurance rates example, 415–416\\nissues in, 412–413\\nkey points, 430\\nkeys for, 423–424\\nlookup issue, 412\\nmiscellaneous examples, 429\\nobject approach, 422–423\\nprecomputing calculations, 635\\npurpose of, 411–412\\nstair-step access tables, 426–429\\nstorage issue, 413\\ntransforming keys, 424\\nTacoma Narrows bridge, 74\\ntakedown code, refactoring, \\n568–569\\nTeam Software Process (TSP), 521\\nTeam Software Process\\nZ02I619670.fm  Page 911  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 948}, page_content='912 first top-level entry\\nteams. See also managing \\nconstruction\\nbuild groups, 704\\nchecklist, 69\\ndevelopment processes used by, \\n840\\nexpanding to meet schedules, 676\\nmanagers, 686\\nphysical environment, 684–685\\nprivacy of offices, 684\\nprocess, importance to, 839–840\\nreligious issues, 683–684\\nresources on, 685–686\\nsize of projects, effects of, 650–653\\nstyle issues, 683–684\\ntime allocations, 681\\nvariations in performance, \\n681–683\\ntechnology waves, determining your \\nlocation in, 66–69\\nTemplate Method pattern, 104\\ntemplate tools, 713\\ntemporal cohesion, 169\\ntemporary variables, 267–268\\ntestability\\ndefined, 465\\nstrategies for, 467\\ntest-data generators, 524–525\\ntest-first development, 233\\ntesting\\nautomated testing, 528–529\\nbad data classes, 514–515\\nblack-box testing, 500\\nboundary analysis, 513–514\\nbounds checking tools, 527\\ncases, creating, 506–508, \\n522–525, 532\\ncharacteristics of, troublesome, \\n501\\nchecklist, 532\\nclasses prone to error, 517–518\\nclassifications of errors, 518–520\\nclean test limitation, 504\\nclerical errors (typos), 519\\ncode coverage testing, 506\\ncomponent testing, 499\\ncompound boundaries, 514\\nconstruction defects, proportion \\nof, 520–521\\ncoverage of code, 505–509, 526\\ndata flow testing, 509–512\\ndata generators for, 524–525\\ndata recorder tools, 526\\ndebuggers, 526–527\\ndebugging, compared to, 500\\ndefined-used data paths, 510–512\\ndesign concerns, 503\\ndesigns, misunderstanding, 519\\ndeveloper-view limitations, 504\\ndeveloping tests, 522\\ndiff tools for, 524\\ndriver routines, 523\\ndummy classes, 523\\ndummy files for, 524\\nduring construction, 502–503\\nease of fixing defects, 519\\nequivalence partitioning, 512\\nerror checklists for, 503\\nerror databases, 527\\nerror guessing, 513\\nerror presence assumption, 501\\nerrors in testing itself, 522\\nexpected defect rate, 521–522\\nfirst or last recommendation, \\n503–504, 531\\nframeworks for, 522, 524\\ngoals of, 501\\ngood data classes, 515–516\\nintegration testing, 499\\nJUnit for, 531\\nkey points, 533\\nlimitations on developer testing, \\n504\\nlogging tools for, 526\\nlogic coverage testing, 506\\nmaximum normal configurations, \\n515\\nmeasurement of, 520, 529\\nmemory tools, 527\\nminimum normal configurations, \\n515\\nmock objects, 523\\nnominal case errors, 515\\nold data, compatibility with, 516\\noptimistic programmers \\nlimitation, 504\\noutside of construction domain \\ndefects, 519\\nplanning for, 528\\nprioritizing coverage, 505\\nprovability of correctness, 501, \\n505\\nquality not affected by, 501\\nrandom-data generators, 525\\nre\\ncommended approach to, \\n503–504\\nrecord keeping for, 529–530\\nregression testing, 500, 528\\nrequirements, 503\\nresources for, 530–531\\nresults, uses for, 502\\nrole in software quality assurance, \\n500–502\\nroutines, black-box testing of, 502\\nscaffolding, 523–524, 531\\nscope of defects, 519\\nselecting cases for convenience, \\n516\\nstabilizing errors, 542\\nstandards, IEEE, 532\\nstructured basis testing, 503, \\n505–509\\nstub objects, 523\\nsymbolic debuggers, 526–527\\nsystem perturbers, 527\\nsystem testing, 500\\ntestability, 465, 467\\ntest case errors, 522\\ntime commitment to, 501–502\\ntest-first development, 233\\ntools, list of, 719\\nunit testing, 499, 545\\nvarying cases, 545\\nwhite-box testing, 500, 502\\nthreading, 337\\nthrowaway code, 114\\nthrowing one away metaphor, 13–14\\ntime allowances, 55–56\\ntool version control, 668\\ntoolbox approach, 20\\ntools\\nchecklist, 70\\ndebugging. See debugging\\nediting. See editing tools\\nprogramming. See programming \\ntools\\nsource code. See source-code tools\\ntop-down approach to design, \\n111–113\\ntop-down integration, 694–696\\ntranscendental functions, 602, 634\\ntranslator tools, 715\\ntry-finally statements, 404–405\\nT-shaped integration, 701\\ntype casting, avoiding, 334\\ntype creation\\nC++, 312\\ncentralization benefit, 314\\nchecklist, 318\\nclasses, compared to, 316\\nexample of, 313–315\\nguidelines for, 315–316\\ninformation hiding aspect of, \\n313–314\\nteams\\nZ02I619670.fm  Page 912  Wednesday, May 12, 2004  12:23 PM\\nDownload from Wow! eBook <www.wowebook.com>'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 949}, page_content='last top-level entry 913\\nlanguages with, evaluation of, \\n314–315\\nmodification benefit, 314\\nnaming conventions, 315\\nPascal example, 312–313\\nportability benefit, 315–316\\npredefined types, avoiding, 315\\npurpose of, 311–312\\nreasons for, 314\\nredefining predefined, 315\\nreliability benefit, 314\\nvalidation benefit, 314\\ntype definitions, 278\\nU\\nUDFs (unit development folders), \\n778\\nUDT (user-defined type) \\nabbreviations, 279–280\\nUML diagrams, 118, 120\\nunderstandability, 465. See also \\nreadability\\nUnicode, 288–299\\nunit development folders (UDFs), \\n778\\nunit testing, 499\\nUNIX programming environment, \\n720\\nunrolling loops, 618–620\\nunswitching loops, 616–617\\nupstream prerequisites. See \\nprerequisites, upstream\\nusability, 463\\nused data state, 509–510\\nuser-defined type (UDT) \\nabbreviations, 279–280\\nuser interfaces\\narchitecture prerequisites, 47\\nrefactoring data from, 576\\nsubsystem design, 85\\nV\\nvalidation\\nassumptions to check, list of, 190\\ndata types, suspicious, 188\\nenumerated types for, 304–305\\nexternal data sources rule, 188\\ninput parameters rule, 188\\nvariable names\\nabbreviation guidelines, 282\\naccurate description rule, \\n260–261\\nbad names, examples of, \\n259–260, 261\\nboolean variables, 268–269\\nC language, 275, 278\\nC++, 263, 275–277\\ncapitalization, 286\\ncharacters, hard to read, 287\\nchecklist, 288–289\\nclass member variables, 273\\ncomputed-value qualifiers, \\n263–264\\nconstants, 270\\nenumerated types, 269\\nfull description rule, 260–261\\nglobal, qualifiers for, 263\\ngood names, examples of, 260, \\n261\\nhomonyms, 286\\nJava conventions, 277\\nkey points, 289\\nkinds of information in, 277\\nlength, optimum, 262\\nloop indexes, 265\\nmisspelled words, 286\\nmultiple natural languages, 287\\nnamespaces, 263\\nnumerals in, 286\\nopposite pairs for, 264\\nphonic abbreviations, 283\\nproblem orientation rule, 261\\npsychological distance, 556\\npurpose of, 240\\nreserved names, 287\\nroutine names, differentiating \\nfrom, 272\\nscope, effects of, 262–263\\nsimilarity of names, too much, \\n285\\nspecificity rule, 261\\nstatus variables, 266–267\\ntemporary variables, 267–268\\ntype names, differentiating from, \\n272–273\\nVisual Basic, 279\\nvariables\\nbinding time for, 252–254\\nchange, identifying areas of, \\n98–99\\nchecklist for using, 257–258\\ncomments for, 803\\ncounters, 243\\ndata literacy test, 238–239\\ndata type relationship to control \\nstructures, 254–255\\ndeclaring. See declarations\\nglobal. See global variables\\nhidden meanings, avoiding, \\n256–257\\nhybrid coupling, 256–257\\nimplicit declarations, 239–240\\ninitializing, 240–244, 257\\niterative data, 255\\nkey points, 258\\nlive time, 246–248, 459\\nlocalizing references to, 245\\nlooping, 382–384\\nnaming. See variable names\\npersistence of, 251–252\\nPrinciple of Proximity, 242\\npublic class members, 576\\nrefactoring, 571, 576\\nreusing, 255–257\\nscope of. See scope of variables\\nselective data, 254\\nsequential data, 254\\nspan of, 245\\ntypes of. See data types\\nusing all declared, 257\\nversion control\\ncommenting, 811\\ndebugging aid removal, 207\\ntools for, 668, 715\\nvisibility\\n. See also scope of variables\\ncoupling criteria for, 100\\nclasses, of, 93\\nvision statement prerequisites. See \\nproblem definition \\nprerequisites\\nVisual Basic\\nassertion examples, 192–194\\nblocking style, 738\\ncase-insensitivity, 273\\ndescription of, 65\\nenumerated types, 303–306\\nexceptions in, 198–199, 202\\nimplicit declarations, turning off, \\n240\\nlayout recommended, 745\\nnaming conventions for, 278–279\\nparameters example, 180\\nresources for, 159\\nstructures, 320–322\\nVisual Basic\\nZ02I619670.fm  Page 913  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 950}, page_content='914 first top-level entry\\nW\\nwalk-throughs, 492–493, 495–496\\nwarning signs, 848–850\\nwhile loops\\nadvantages of, 374–375\\nbreak statements, 379\\ndo-while loops, 369\\nexits in, 369–372\\ninfinite loops, 374\\nmisconception of evaluation, 554\\nnull statements with, 444\\npurpose of, 368\\ntests, position of, 369\\nwhite space\\nblank lines, 737, 747–748\\ndefined, 732\\ngrouping with, 737\\nimportance of, 736\\nindentation, 737\\nindividual statements with, \\n753–754\\nwhite-box testing, 500, 502\\nwicked problems, 74–75\\nWikis, 117\\nWIMP syndrome, 26\\nWISCA syndrome, 26\\nworkarounds, documenting, 800\\nwriting metaphor for coding, 13–14\\nZ\\nzero, dividing by, 292\\nwalk-throughs\\nZ02I619670.fm  Page 914  Wednesday, May 12, 2004  12:23 PM'),\n",
              " Document(metadata={'source': '/content/Steve McConnell - Code Complete (2nd edition).pdf', 'page': 951}, page_content='Steve McConnell\\nSteve McConnell is Chief Software Engineer at Construx Soft-\\nware where he oversees Construx’s software engineering prac-\\ntices. Steve is the lead for the Construction Knowledge Area of \\nthe Software Engineering Body of Knowledge (SWEBOK) \\nproject. Steve has worked on software projects at Microsoft, Boe-\\ning, and other Seattle-area companies. \\nSteve is the author of Rapid Development (1996), Software Project \\nSurvival Guide (1998), and Professional Software Development \\n(2004). His books have twice won Software Development  maga-\\nzine’s Jolt Excellence award for outstanding software develop-\\nment book of the year. Steve was also the lead developer of SPC \\nEstimate Professional, winner of a Software Development Pro-\\nductivity award. In 1998, readers of Software Development magazine named Steve one of the \\nthree most influential people in the software industry, along with Bill Gates and Linus Tor-\\nvalds. \\nSteve earned a Bachelor’s degree from Whitman College and a Master’s degree in software \\nengineering from Seattle University. He lives in Bellevue, Washington.\\nIf you have any comments or questions about this book, please contact Steve at \\nstevemcc@construx.com or via www.stevemcconnell.com.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitter:"
      ],
      "metadata": {
        "id": "SZu8rfuh3WfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-text-splitters"
      ],
      "metadata": {
        "id": "WnhiYJqT3cRZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "txt_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 200,\n",
        "    chunk_overlap = 20,\n",
        "    length_function = len,\n",
        "    is_separator_regex=False\n",
        ")"
      ],
      "metadata": {
        "id": "cEe7n5Ln4Jp0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_list = []\n",
        "for page in pages:\n",
        "  chunks = txt_splitter.split_text(page.page_content)\n",
        "  for chunk in chunks:\n",
        "    chunk_list.append(chunk)\n",
        "  print(len(chunk_list))"
      ],
      "metadata": {
        "id": "XOKCcouo7wID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431ac000-db91-4e81-f7d6-6388338e74e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "18\n",
            "32\n",
            "45\n",
            "46\n",
            "63\n",
            "78\n",
            "104\n",
            "134\n",
            "166\n",
            "183\n",
            "212\n",
            "239\n",
            "267\n",
            "294\n",
            "304\n",
            "318\n",
            "334\n",
            "347\n",
            "364\n",
            "379\n",
            "399\n",
            "406\n",
            "423\n",
            "427\n",
            "432\n",
            "433\n",
            "443\n",
            "445\n",
            "458\n",
            "474\n",
            "488\n",
            "502\n",
            "514\n",
            "517\n",
            "525\n",
            "536\n",
            "547\n",
            "560\n",
            "578\n",
            "586\n",
            "597\n",
            "617\n",
            "637\n",
            "655\n",
            "672\n",
            "689\n",
            "704\n",
            "720\n",
            "732\n",
            "745\n",
            "764\n",
            "781\n",
            "786\n",
            "796\n",
            "813\n",
            "831\n",
            "851\n",
            "867\n",
            "882\n",
            "897\n",
            "908\n",
            "919\n",
            "930\n",
            "944\n",
            "958\n",
            "965\n",
            "981\n",
            "994\n",
            "1006\n",
            "1020\n",
            "1036\n",
            "1056\n",
            "1070\n",
            "1083\n",
            "1096\n",
            "1115\n",
            "1132\n",
            "1148\n",
            "1166\n",
            "1183\n",
            "1201\n",
            "1217\n",
            "1237\n",
            "1256\n",
            "1269\n",
            "1283\n",
            "1301\n",
            "1314\n",
            "1332\n",
            "1345\n",
            "1350\n",
            "1362\n",
            "1378\n",
            "1394\n",
            "1409\n",
            "1423\n",
            "1441\n",
            "1462\n",
            "1480\n",
            "1495\n",
            "1507\n",
            "1511\n",
            "1523\n",
            "1540\n",
            "1549\n",
            "1566\n",
            "1583\n",
            "1601\n",
            "1618\n",
            "1634\n",
            "1649\n",
            "1657\n",
            "1667\n",
            "1680\n",
            "1697\n",
            "1717\n",
            "1734\n",
            "1748\n",
            "1766\n",
            "1779\n",
            "1792\n",
            "1809\n",
            "1819\n",
            "1836\n",
            "1855\n",
            "1875\n",
            "1893\n",
            "1913\n",
            "1932\n",
            "1951\n",
            "1969\n",
            "1985\n",
            "2004\n",
            "2021\n",
            "2038\n",
            "2055\n",
            "2072\n",
            "2080\n",
            "2098\n",
            "2114\n",
            "2131\n",
            "2148\n",
            "2164\n",
            "2183\n",
            "2198\n",
            "2211\n",
            "2231\n",
            "2248\n",
            "2266\n",
            "2281\n",
            "2300\n",
            "2311\n",
            "2318\n",
            "2330\n",
            "2347\n",
            "2360\n",
            "2378\n",
            "2390\n",
            "2405\n",
            "2420\n",
            "2435\n",
            "2449\n",
            "2459\n",
            "2472\n",
            "2487\n",
            "2507\n",
            "2522\n",
            "2539\n",
            "2548\n",
            "2566\n",
            "2583\n",
            "2599\n",
            "2617\n",
            "2632\n",
            "2652\n",
            "2667\n",
            "2678\n",
            "2696\n",
            "2715\n",
            "2730\n",
            "2749\n",
            "2768\n",
            "2786\n",
            "2800\n",
            "2813\n",
            "2828\n",
            "2837\n",
            "2849\n",
            "2853\n",
            "2865\n",
            "2878\n",
            "2897\n",
            "2912\n",
            "2932\n",
            "2946\n",
            "2953\n",
            "2972\n",
            "2989\n",
            "3010\n",
            "3028\n",
            "3047\n",
            "3063\n",
            "3082\n",
            "3091\n",
            "3110\n",
            "3125\n",
            "3141\n",
            "3157\n",
            "3172\n",
            "3189\n",
            "3204\n",
            "3216\n",
            "3229\n",
            "3242\n",
            "3249\n",
            "3260\n",
            "3279\n",
            "3289\n",
            "3301\n",
            "3315\n",
            "3330\n",
            "3347\n",
            "3361\n",
            "3380\n",
            "3399\n",
            "3416\n",
            "3428\n",
            "3448\n",
            "3461\n",
            "3474\n",
            "3485\n",
            "3502\n",
            "3517\n",
            "3531\n",
            "3546\n",
            "3559\n",
            "3575\n",
            "3590\n",
            "3607\n",
            "3617\n",
            "3627\n",
            "3639\n",
            "3649\n",
            "3658\n",
            "3668\n",
            "3683\n",
            "3697\n",
            "3712\n",
            "3729\n",
            "3750\n",
            "3768\n",
            "3784\n",
            "3795\n",
            "3809\n",
            "3825\n",
            "3839\n",
            "3856\n",
            "3876\n",
            "3896\n",
            "3911\n",
            "3928\n",
            "3938\n",
            "3941\n",
            "3951\n",
            "3960\n",
            "3975\n",
            "3994\n",
            "4006\n",
            "4019\n",
            "4036\n",
            "4055\n",
            "4068\n",
            "4077\n",
            "4091\n",
            "4102\n",
            "4117\n",
            "4134\n",
            "4153\n",
            "4169\n",
            "4182\n",
            "4196\n",
            "4204\n",
            "4217\n",
            "4232\n",
            "4239\n",
            "4250\n",
            "4264\n",
            "4279\n",
            "4293\n",
            "4307\n",
            "4319\n",
            "4332\n",
            "4344\n",
            "4358\n",
            "4375\n",
            "4387\n",
            "4400\n",
            "4417\n",
            "4429\n",
            "4448\n",
            "4468\n",
            "4480\n",
            "4494\n",
            "4507\n",
            "4520\n",
            "4534\n",
            "4544\n",
            "4559\n",
            "4572\n",
            "4588\n",
            "4603\n",
            "4620\n",
            "4636\n",
            "4653\n",
            "4663\n",
            "4674\n",
            "4682\n",
            "4695\n",
            "4709\n",
            "4725\n",
            "4742\n",
            "4753\n",
            "4773\n",
            "4790\n",
            "4806\n",
            "4821\n",
            "4837\n",
            "4849\n",
            "4858\n",
            "4873\n",
            "4884\n",
            "4894\n",
            "4909\n",
            "4923\n",
            "4936\n",
            "4955\n",
            "4970\n",
            "4982\n",
            "4994\n",
            "5008\n",
            "5027\n",
            "5041\n",
            "5050\n",
            "5056\n",
            "5067\n",
            "5081\n",
            "5090\n",
            "5105\n",
            "5122\n",
            "5134\n",
            "5151\n",
            "5168\n",
            "5182\n",
            "5192\n",
            "5205\n",
            "5222\n",
            "5237\n",
            "5253\n",
            "5271\n",
            "5287\n",
            "5302\n",
            "5316\n",
            "5334\n",
            "5352\n",
            "5369\n",
            "5390\n",
            "5408\n",
            "5428\n",
            "5442\n",
            "5453\n",
            "5457\n",
            "5466\n",
            "5482\n",
            "5497\n",
            "5512\n",
            "5525\n",
            "5536\n",
            "5544\n",
            "5554\n",
            "5569\n",
            "5582\n",
            "5595\n",
            "5607\n",
            "5621\n",
            "5637\n",
            "5650\n",
            "5664\n",
            "5677\n",
            "5685\n",
            "5689\n",
            "5699\n",
            "5712\n",
            "5724\n",
            "5736\n",
            "5750\n",
            "5762\n",
            "5780\n",
            "5799\n",
            "5809\n",
            "5822\n",
            "5835\n",
            "5845\n",
            "5859\n",
            "5871\n",
            "5884\n",
            "5899\n",
            "5913\n",
            "5927\n",
            "5943\n",
            "5956\n",
            "5969\n",
            "5978\n",
            "5985\n",
            "5995\n",
            "6006\n",
            "6019\n",
            "6031\n",
            "6041\n",
            "6056\n",
            "6069\n",
            "6087\n",
            "6108\n",
            "6121\n",
            "6133\n",
            "6147\n",
            "6163\n",
            "6179\n",
            "6195\n",
            "6206\n",
            "6223\n",
            "6238\n",
            "6255\n",
            "6265\n",
            "6276\n",
            "6289\n",
            "6299\n",
            "6308\n",
            "6318\n",
            "6330\n",
            "6338\n",
            "6353\n",
            "6364\n",
            "6377\n",
            "6389\n",
            "6401\n",
            "6419\n",
            "6435\n",
            "6445\n",
            "6459\n",
            "6473\n",
            "6490\n",
            "6504\n",
            "6508\n",
            "6518\n",
            "6532\n",
            "6546\n",
            "6560\n",
            "6572\n",
            "6585\n",
            "6599\n",
            "6613\n",
            "6626\n",
            "6639\n",
            "6650\n",
            "6663\n",
            "6677\n",
            "6691\n",
            "6705\n",
            "6716\n",
            "6724\n",
            "6734\n",
            "6751\n",
            "6764\n",
            "6775\n",
            "6787\n",
            "6799\n",
            "6813\n",
            "6822\n",
            "6834\n",
            "6853\n",
            "6866\n",
            "6878\n",
            "6881\n",
            "6886\n",
            "6895\n",
            "6911\n",
            "6927\n",
            "6940\n",
            "6962\n",
            "6980\n",
            "6993\n",
            "7006\n",
            "7024\n",
            "7039\n",
            "7056\n",
            "7073\n",
            "7085\n",
            "7096\n",
            "7105\n",
            "7115\n",
            "7132\n",
            "7149\n",
            "7169\n",
            "7185\n",
            "7199\n",
            "7215\n",
            "7232\n",
            "7250\n",
            "7269\n",
            "7286\n",
            "7306\n",
            "7319\n",
            "7333\n",
            "7350\n",
            "7367\n",
            "7379\n",
            "7394\n",
            "7406\n",
            "7417\n",
            "7436\n",
            "7455\n",
            "7471\n",
            "7488\n",
            "7505\n",
            "7521\n",
            "7534\n",
            "7544\n",
            "7558\n",
            "7571\n",
            "7587\n",
            "7597\n",
            "7614\n",
            "7628\n",
            "7643\n",
            "7655\n",
            "7671\n",
            "7685\n",
            "7700\n",
            "7719\n",
            "7735\n",
            "7749\n",
            "7767\n",
            "7781\n",
            "7800\n",
            "7817\n",
            "7834\n",
            "7851\n",
            "7868\n",
            "7881\n",
            "7895\n",
            "7911\n",
            "7921\n",
            "7932\n",
            "7944\n",
            "7952\n",
            "7969\n",
            "7987\n",
            "8003\n",
            "8017\n",
            "8028\n",
            "8045\n",
            "8060\n",
            "8077\n",
            "8091\n",
            "8108\n",
            "8128\n",
            "8141\n",
            "8158\n",
            "8177\n",
            "8196\n",
            "8209\n",
            "8229\n",
            "8244\n",
            "8258\n",
            "8272\n",
            "8289\n",
            "8306\n",
            "8319\n",
            "8326\n",
            "8337\n",
            "8343\n",
            "8355\n",
            "8372\n",
            "8389\n",
            "8406\n",
            "8425\n",
            "8440\n",
            "8457\n",
            "8466\n",
            "8481\n",
            "8495\n",
            "8511\n",
            "8527\n",
            "8540\n",
            "8556\n",
            "8566\n",
            "8574\n",
            "8584\n",
            "8601\n",
            "8612\n",
            "8626\n",
            "8636\n",
            "8647\n",
            "8658\n",
            "8669\n",
            "8686\n",
            "8700\n",
            "8718\n",
            "8735\n",
            "8752\n",
            "8766\n",
            "8786\n",
            "8805\n",
            "8823\n",
            "8837\n",
            "8850\n",
            "8865\n",
            "8881\n",
            "8894\n",
            "8903\n",
            "8917\n",
            "8937\n",
            "8951\n",
            "8963\n",
            "8978\n",
            "8990\n",
            "9000\n",
            "9016\n",
            "9031\n",
            "9042\n",
            "9054\n",
            "9065\n",
            "9077\n",
            "9088\n",
            "9100\n",
            "9112\n",
            "9123\n",
            "9134\n",
            "9144\n",
            "9155\n",
            "9168\n",
            "9182\n",
            "9192\n",
            "9204\n",
            "9217\n",
            "9231\n",
            "9241\n",
            "9253\n",
            "9265\n",
            "9276\n",
            "9286\n",
            "9298\n",
            "9309\n",
            "9323\n",
            "9336\n",
            "9347\n",
            "9360\n",
            "9377\n",
            "9387\n",
            "9400\n",
            "9410\n",
            "9427\n",
            "9438\n",
            "9442\n",
            "9454\n",
            "9465\n",
            "9477\n",
            "9490\n",
            "9507\n",
            "9521\n",
            "9533\n",
            "9552\n",
            "9571\n",
            "9588\n",
            "9600\n",
            "9608\n",
            "9625\n",
            "9646\n",
            "9663\n",
            "9682\n",
            "9703\n",
            "9722\n",
            "9738\n",
            "9752\n",
            "9767\n",
            "9783\n",
            "9801\n",
            "9810\n",
            "9822\n",
            "9834\n",
            "9853\n",
            "9870\n",
            "9886\n",
            "9901\n",
            "9916\n",
            "9930\n",
            "9948\n",
            "9960\n",
            "9976\n",
            "9994\n",
            "10011\n",
            "10028\n",
            "10034\n",
            "10044\n",
            "10054\n",
            "10066\n",
            "10080\n",
            "10103\n",
            "10118\n",
            "10136\n",
            "10150\n",
            "10164\n",
            "10178\n",
            "10186\n",
            "10197\n",
            "10211\n",
            "10223\n",
            "10241\n",
            "10259\n",
            "10277\n",
            "10296\n",
            "10314\n",
            "10325\n",
            "10341\n",
            "10353\n",
            "10368\n",
            "10381\n",
            "10399\n",
            "10412\n",
            "10428\n",
            "10442\n",
            "10457\n",
            "10468\n",
            "10484\n",
            "10494\n",
            "10509\n",
            "10525\n",
            "10542\n",
            "10560\n",
            "10574\n",
            "10581\n",
            "10584\n",
            "10596\n",
            "10613\n",
            "10627\n",
            "10642\n",
            "10660\n",
            "10675\n",
            "10691\n",
            "10706\n",
            "10722\n",
            "10734\n",
            "10741\n",
            "10752\n",
            "10758\n",
            "10768\n",
            "10778\n",
            "10792\n",
            "10808\n",
            "10819\n",
            "10831\n",
            "10847\n",
            "10861\n",
            "10878\n",
            "10891\n",
            "10902\n",
            "10914\n",
            "10930\n",
            "10944\n",
            "10957\n",
            "10971\n",
            "10986\n",
            "11003\n",
            "11017\n",
            "11034\n",
            "11049\n",
            "11062\n",
            "11074\n",
            "11087\n",
            "11101\n",
            "11115\n",
            "11125\n",
            "11138\n",
            "11152\n",
            "11165\n",
            "11179\n",
            "11188\n",
            "11198\n",
            "11211\n",
            "11221\n",
            "11237\n",
            "11249\n",
            "11260\n",
            "11269\n",
            "11284\n",
            "11302\n",
            "11319\n",
            "11330\n",
            "11342\n",
            "11355\n",
            "11371\n",
            "11388\n",
            "11403\n",
            "11421\n",
            "11436\n",
            "11451\n",
            "11466\n",
            "11479\n",
            "11495\n",
            "11509\n",
            "11525\n",
            "11540\n",
            "11553\n",
            "11567\n",
            "11586\n",
            "11604\n",
            "11618\n",
            "11632\n",
            "11649\n",
            "11666\n",
            "11686\n",
            "11702\n",
            "11718\n",
            "11731\n",
            "11750\n",
            "11765\n",
            "11778\n",
            "11797\n",
            "11806\n",
            "11816\n",
            "11827\n",
            "11843\n",
            "11862\n",
            "11881\n",
            "11899\n",
            "11917\n",
            "11936\n",
            "11952\n",
            "11973\n",
            "11991\n",
            "12010\n",
            "12026\n",
            "12045\n",
            "12061\n",
            "12080\n",
            "12099\n",
            "12109\n",
            "12120\n",
            "12136\n",
            "12153\n",
            "12177\n",
            "12190\n",
            "12213\n",
            "12231\n",
            "12251\n",
            "12267\n",
            "12280\n",
            "12297\n",
            "12315\n",
            "12333\n",
            "12352\n",
            "12371\n",
            "12391\n",
            "12408\n",
            "12420\n",
            "12438\n",
            "12454\n",
            "12469\n",
            "12485\n",
            "12497\n",
            "12509\n",
            "12518\n",
            "12534\n",
            "12552\n",
            "12569\n",
            "12587\n",
            "12606\n",
            "12623\n",
            "12641\n",
            "12659\n",
            "12677\n",
            "12694\n",
            "12711\n",
            "12729\n",
            "12747\n",
            "12764\n",
            "12782\n",
            "12799\n",
            "12817\n",
            "12835\n",
            "12853\n",
            "12871\n",
            "12887\n",
            "12906\n",
            "12927\n",
            "12949\n",
            "12970\n",
            "12992\n",
            "13013\n",
            "13035\n",
            "13056\n",
            "13079\n",
            "13081\n",
            "13103\n",
            "13124\n",
            "13146\n",
            "13166\n",
            "13188\n",
            "13209\n",
            "13230\n",
            "13252\n",
            "13274\n",
            "13295\n",
            "13316\n",
            "13337\n",
            "13358\n",
            "13379\n",
            "13400\n",
            "13422\n",
            "13443\n",
            "13465\n",
            "13487\n",
            "13506\n",
            "13510\n",
            "13518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_list[100]"
      ],
      "metadata": {
        "id": "pshqeOktKb5u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "93a1ad43-5c5f-448f-dcca-82b72590d7b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.1 Choice of Programming Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metadata Preprocessing:"
      ],
      "metadata": {
        "id": "rk6CNbejIUqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document"
      ],
      "metadata": {
        "id": "UGH3xIEHIY8R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_list = []\n",
        "\n",
        "for page in pages:\n",
        "  pag_split = txt_splitter.split_text(page.page_content)\n",
        "\n",
        "  for pag_sub_split in pag_split:\n",
        "    metadata = {\"source\": \"Book\", \"page_no\": page.metadata.get('page', 0) + 1}\n",
        "    doc_string = Document(page_content= pag_sub_split, metadata=metadata)\n",
        "    doc_list.append(doc_string)\n"
      ],
      "metadata": {
        "id": "aPp00FLJIniu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_list[26]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSaCBGUIL40B",
        "outputId": "a3eca9ea-1f16-4305-bb9f-cf5bddcd272c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'Book', 'page_no': 4}, page_content='Subtitled ‘A Practical Handbook of Software Construction,’ this 850-page book is exactly \\nthat. Its stated goal is to narrow the gap between the knowledge of ‘industry gurus and pro-')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VClEb4FNMGuc",
        "outputId": "2f1f12f7-47aa-422d-c584-a6d728887bb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13518"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embeddings:"
      ],
      "metadata": {
        "id": "IKtUhLIDKlJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers langchain_huggingface"
      ],
      "metadata": {
        "id": "jc7Rmln7KjpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "2385c456-a617-4e07-d3e2-0f9db380a213"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.3.29)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.2.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.2.2)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
      ],
      "metadata": {
        "id": "gylHdxPbLwTl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'BAAI/bge-small-en'\n",
        "embed_model = HuggingFaceBgeEmbeddings(model_name=model_name)"
      ],
      "metadata": {
        "id": "I3wMr_GNL6D_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534,
          "referenced_widgets": [
            "73a791bac3a145f9be91af1fc7f91261",
            "68d98e182d664e3c9cb7fa4eeb752f7f",
            "6d123e170fdf4e3d9af898132cafd0ef",
            "3e0f98e483254b74937329a50fb4a8f6",
            "b883e6eeb8d6428d9bac9b852d17713e",
            "21d16b2d720f4d259d7dbf3d4ce34347",
            "df4b795e84b347ec91d5082a7bf1ba6e",
            "0d1b8b96009a44578ceea774e87aa997",
            "9bad6be03aa8497fb1e7d7dedf7e7b00",
            "7b500dea7aef473e8eab00fc1bd0ca2d",
            "2fa94ea7a1814789a7c82781f0811117",
            "35d358ee658e40f9835efaa94d1bef59",
            "585da3866ca3467e981052a294e971ab",
            "ca64cdd7acfc4de8b5d520d7213558b8",
            "e0919e03c18644829ef00ead8b7f1b89",
            "264e80dca4cc4cc785911a1f4f4c9adb",
            "3f1dc7e1caf74b3ba118f031fd7f93d7",
            "155e16b4696f429caa0a5d0e352cd2d9",
            "b229290bd03e491988ad2b3936cc3232",
            "7d47421504464c79a53cf70bd41da69c",
            "b1af69ce2dcd420a8a74bb8b729d619d",
            "640b91c236ba4e0094919077f76f7554",
            "f67f63773aed429ab6756e52f8e740a5",
            "5470a6145b244f79929fdfe237967157",
            "52f799d3a80f4c4fad19613f8edf2a88",
            "f743ae87ba3c489cbc9b42193fa7d433",
            "2a100750ec8449f6974e58f554a2e919",
            "f0233ba554d04e6d952e6860fff7a8dd",
            "521ffa9ce0c547c5951c7bdf96911a1d",
            "33d105481adb43459ae095f2bdc7a77b",
            "e9eed2441dca4f2cb9f3c39bc379de78",
            "a35dd4d4466e4905af3ac25a0cd22490",
            "3837338226504d3199e679f8d9e49d54",
            "5cb14a0818a94e219c4d9f076aaf69bc",
            "d627f6d073254bf6b3bb26573ca33e18",
            "2fca0fc034964ee78d18bc90c73a5147",
            "319d5cb7911b424c9ea5bb1fb458fd8e",
            "95a8a346a6a94fce81194c2b63a2f0fb",
            "c10539ac70af47c6857b927eaf15e8a5",
            "83798f23433542be8e84e895204b29d6",
            "6eabce3df59348cc95f686ccbd0897e5",
            "b0a466e871104182becc301d80d14487",
            "e98af947ca1b46a28020a40da73986c3",
            "ebda46e3c7704e909ad43ab60c6c69c6",
            "9cf453de9be8434d81d4def587a25fd8",
            "4aa43aa6720f44bea7184deb5d069f97",
            "c54da21129e740129f2cc6eb609e1971",
            "12d248a8609b4f47b44f3588ca9ef8cc",
            "3ad6b605c9f245ae8150561d41c737a5",
            "63e236de967742d8a243d58ef3a491ed",
            "dbcf99f5ee39422a8a8d3c774b08fc09",
            "0a062e06fe1d4623a29d2c15d2a33ebc",
            "4ab727032f3f4d92bf7164aecb949a98",
            "5a7ff2c3747d4f7d9b7196e786db9295",
            "21118120ce37454ab635d04a67782f11",
            "eca50dbb727845798cb245fbe37a8788",
            "c3f8684107d2422a8d195e23f10fae8e",
            "4145394e98ea4058afa4e34240fad08f",
            "8fde85f3865c4625b271f3519f7f88aa",
            "5ff7f491fe8d446da32b3b0b107dd682",
            "667d49f0e8d94b2b9b9347c9fa408146",
            "6fa8c99f119a434ba141f3582ed4392d",
            "b000c676279f42f1881881dc24bf7801",
            "42019e625903477da0250a86e803d46f",
            "dec18b00d69e44dab894104cb2dc4996",
            "49f8b59baf134d488d48cf087cdc07f4",
            "e01535535a8c4c1a90f82f953d99c04a",
            "943e60adc33049cca17bcccbee7539e4",
            "aaa01e878d4e4ba98bbde56794e07b88",
            "62b7c563ba014e0d9028af838f0a01e9",
            "c566fda5cb5746aba4b9a3abb9ace2ae",
            "7559dfb657b242f291bd057d72317c23",
            "a9dba276ad924fcdb5a27c04d36f37f9",
            "ec94637cec684245b1b96a04e8aca3b8",
            "51cfd9d5e05245779d8d4e6be61e80ef",
            "b17978e524634ac38ab0e72c7039e34e",
            "06a16e526ea545ee9bc73376bcde2fc5",
            "2c1831679935415ca79ecb05a342c7f3",
            "41b2b6f8d1194851a098ab5cb91d00d2",
            "ba5d273634384e87a6f18177b4e3e4d6",
            "bb7ca2868bf745249980ac34edf6a1da",
            "417c7c2bfe014a94b6c1efa37d679906",
            "d50a1bceac424836a2d3d514613166f8",
            "7cd2eb162aa74b929735da4441448e85",
            "c4b7a67827634effa663471b7e50273a",
            "137e0917c2b34b5b857d4c1c068fbcdf",
            "f34202830c654a5d9b4bf5cc955dcfc0",
            "63db7001ce514f0a890b5aa81dde918c",
            "af600747b25042a5b4f37e8aa2209ebd",
            "cb5f85fa412c4803adf854d21471e2e9",
            "0c52e4ff871b4e53a37b2dcc2b819194",
            "4d7721728a074b78ba166811f132e84f",
            "e69e41ab6d734f9e9974486f9f123f88",
            "832fce08921e4abb9c7231c9e1d4b7e3",
            "04098c319a2945e7bb33d67163f4ea41",
            "25ba56af6d42471687571987d0924a4f",
            "4bfa72d10bc24e0abd38b8407b225397",
            "3410212cb61246968ffdf4536f238feb",
            "76d4c42ec93d423b90ec1e8bef91a768",
            "1cc2f3d6e91f48a3ba7dd628076c3e46",
            "4b4ca00530ed41729383f3bac13b1878",
            "ce1f20c592c54641aaee425399d720d7",
            "e6bb55c70ffc4d0ab3fd9cccb71fb7b4",
            "d1b1556f578e4145894248528953eb80",
            "af3fe298ae2f45e19dacf6ceb8935ecf",
            "91d537a0f2c94368a5fa6c54f8778405",
            "a46d5ce753bf48e6913cac32eab95a6b",
            "dc98aa38c43649169f969bd7e31ddef0",
            "25958817b176497596e061c5c9a41716",
            "cf090b1b278f49bcac441597ce6c60a8",
            "09195407eea9424ba9361a1ec94bc081",
            "ff857e90e0054fb1a28830d4196069ad",
            "7745873979844dd9a8589ff9b6d2ec0d",
            "da8ac054b6c64333a78f3957d04ae70c",
            "e6cefb1f11f948059c33f811bafed2ab",
            "a5f70bf0f78047b6acd2a17a6c4f4cfd",
            "68de20ef66c44dcfac0017b23166ba97",
            "9658e296bd1641cfb482ebaa82a07a5f",
            "7b76db09b41841d897a3f236048d157f",
            "d7982e441c444a2d8934510cf317ed66",
            "1c832d121e6641df9a7645835fdd19bd"
          ]
        },
        "outputId": "473eedb6-52d5-4ac6-cf42-0f97c275a847"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-7e779377dc83>:2: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embed_model = HuggingFaceBgeEmbeddings(model_name=model_name)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73a791bac3a145f9be91af1fc7f91261"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35d358ee658e40f9835efaa94d1bef59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/90.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f67f63773aed429ab6756e52f8e740a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cb14a0818a94e219c4d9f076aaf69bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cf453de9be8434d81d4def587a25fd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eca50dbb727845798cb245fbe37a8788"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e01535535a8c4c1a90f82f953d99c04a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c1831679935415ca79ecb05a342c7f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af600747b25042a5b4f37e8aa2209ebd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc2f3d6e91f48a3ba7dd628076c3e46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09195407eea9424ba9361a1ec94bc081"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Qdrant Vectore Store:**"
      ],
      "metadata": {
        "id": "j_YlCqhrN4aI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Qdrant Credentials:"
      ],
      "metadata": {
        "id": "gBzssD8VN9wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qdrant_client langchain-qdrant"
      ],
      "metadata": {
        "id": "ALMWMQNfQB8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b58bc674-8dae-46f6-8922-e45f03ec8593"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qdrant_client\n",
            "  Downloading qdrant_client-1.12.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-qdrant\n",
            "  Downloading langchain_qdrant-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.68.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n",
            "  Downloading grpcio_tools-1.69.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (1.26.4)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.10.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant_client) (2.2.3)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.10/dist-packages (from langchain-qdrant) (0.3.29)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant_client)\n",
            "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting grpcio>=1.41.0 (from qdrant_client)\n",
            "  Downloading grpcio-1.69.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant_client) (2.27.1)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-qdrant) (3.4.0)\n",
            "Downloading qdrant_client-1.12.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_qdrant-0.2.0-py3-none-any.whl (23 kB)\n",
            "Downloading grpcio_tools-1.69.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.69.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: protobuf, portalocker, hyperframe, hpack, grpcio, h2, grpcio-tools, qdrant_client, langchain-qdrant\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.68.1\n",
            "    Uninstalling grpcio-1.68.1:\n",
            "      Successfully uninstalled grpcio-1.68.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.69.0 grpcio-tools-1.69.0 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 langchain-qdrant-0.2.0 portalocker-2.10.1 protobuf-5.29.2 qdrant_client-1.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant_url=\"https://d0413-ae37-8001e4736ed5.europe-west3-0.gcp.3541\"\n",
        "qdrant_key=\"74qTUBZqABCj-JLgrV_U2654FXQ-Rg\"\n",
        "groq_api_key=\"gsk_qTkwehjf\"\n",
        "\n",
        "collection_name = 'Steve_McConnel_code_book'"
      ],
      "metadata": {
        "id": "nYeNn5ZdN4Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import qdrant_client\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "qdrant = QdrantVectorStore.from_documents(\n",
        "    doc_list,\n",
        "    embed_model,\n",
        "    url=qdrant_url,\n",
        "    api_key=qdrant_key,\n",
        "    collection_name=collection_name\n",
        ")"
      ],
      "metadata": {
        "id": "T4YxxKckSoa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # Q/A Chain"
      ],
      "metadata": {
        "id": "CRtMKlgi5Zto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq"
      ],
      "metadata": {
        "id": "gMyg5UpL-EEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "cbc97bc2-5926-42d9-ad36-3e0fb82f4f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.3.28)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (2.2.3)\n",
            "Downloading langchain_groq-0.2.2-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.13.1-py3-none-any.whl (109 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.13.1 langchain-groq-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough"
      ],
      "metadata": {
        "id": "BN4hrx2-3Xo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrievers:"
      ],
      "metadata": {
        "id": "wdmPKvymnRlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = qdrant.as_retriever()"
      ],
      "metadata": {
        "id": "ajN767mvnRXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_results = retriever.invoke(\"What is a good sofware architecture?\")\n",
        "print(retriever_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r-fPW88vB6u",
        "outputId": "98720a8a-c24b-4ff8-c687-59f2a4ac3c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'Book', 'page_no': 84, '_id': 'd816206c-000e-403b-8e87-b91910834cbc', '_collection_name': 'Steve_McConnel_code_book'}, page_content='ified in the software architecture. The architecture should specify major elements of \\nWeb page formats, GUIs, command line interfaces, and so on. Careful architecture of'), Document(metadata={'source': 'Book', 'page_no': 84, '_id': '63d6e7e1-7c43-4822-b342-5a2708e936a3', '_collection_name': 'Steve_McConnel_code_book'}, page_content='ified in the software architecture. The architecture should specify major elements of \\nWeb page formats, GUIs, command line interfaces, and so on. Careful architecture of'), Document(metadata={'source': 'Book', 'page_no': 84, '_id': '827efe7e-d1ca-4128-93a9-ad1f9f30963a', '_collection_name': 'Steve_McConnel_code_book'}, page_content='ified in the software architecture. The architecture should specify major elements of \\nWeb page formats, GUIs, command line interfaces, and so on. Careful architecture of'), Document(metadata={'source': 'Book', 'page_no': 84, '_id': '741f225e-e0c2-4e19-b28c-a1d61bd19ddd', '_collection_name': 'Steve_McConnel_code_book'}, page_content='ified in the software architecture. The architecture should specify major elements of \\nWeb page formats, GUIs, command line interfaces, and so on. Careful architecture of')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_str = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "Question : {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
        "\n",
        "def doc2str(docs):\n",
        "  return '\\n\\n'.join(doc.page_content for doc in docs)\n",
        "\n",
        "llm = ChatGroq(model_name=\"mixtral-8x7b-32768\", temperature=0, groq_api_key=groq_api_key)\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        'context': retriever | doc2str, \"question\": RunnablePassthrough()\n",
        "        }\n",
        "    | prompt | llm | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "vysv6WaEsnQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"What is a good sofware architecture?\"\n",
        "\n",
        "response = rag_chain.invoke(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24hX_OQ8ujXp",
        "outputId": "01af2a01-26d1-4cc6-b802-aa34b53529bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A good software architecture is one that carefully specifies major elements of Web page formats, graphical user interfaces (GUIs), command line interfaces, and so on. It provides a clear structure for the software system, enabling effective organization, development, and maintenance of the software. A well-designed architecture ensures that the system's components interact efficiently, are modular, reusable, and adaptable to changing requirements.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73a791bac3a145f9be91af1fc7f91261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68d98e182d664e3c9cb7fa4eeb752f7f",
              "IPY_MODEL_6d123e170fdf4e3d9af898132cafd0ef",
              "IPY_MODEL_3e0f98e483254b74937329a50fb4a8f6"
            ],
            "layout": "IPY_MODEL_b883e6eeb8d6428d9bac9b852d17713e"
          }
        },
        "68d98e182d664e3c9cb7fa4eeb752f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d16b2d720f4d259d7dbf3d4ce34347",
            "placeholder": "​",
            "style": "IPY_MODEL_df4b795e84b347ec91d5082a7bf1ba6e",
            "value": "modules.json: 100%"
          }
        },
        "6d123e170fdf4e3d9af898132cafd0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1b8b96009a44578ceea774e87aa997",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bad6be03aa8497fb1e7d7dedf7e7b00",
            "value": 349
          }
        },
        "3e0f98e483254b74937329a50fb4a8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b500dea7aef473e8eab00fc1bd0ca2d",
            "placeholder": "​",
            "style": "IPY_MODEL_2fa94ea7a1814789a7c82781f0811117",
            "value": " 349/349 [00:00&lt;00:00, 24.9kB/s]"
          }
        },
        "b883e6eeb8d6428d9bac9b852d17713e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d16b2d720f4d259d7dbf3d4ce34347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4b795e84b347ec91d5082a7bf1ba6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d1b8b96009a44578ceea774e87aa997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bad6be03aa8497fb1e7d7dedf7e7b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b500dea7aef473e8eab00fc1bd0ca2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fa94ea7a1814789a7c82781f0811117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35d358ee658e40f9835efaa94d1bef59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_585da3866ca3467e981052a294e971ab",
              "IPY_MODEL_ca64cdd7acfc4de8b5d520d7213558b8",
              "IPY_MODEL_e0919e03c18644829ef00ead8b7f1b89"
            ],
            "layout": "IPY_MODEL_264e80dca4cc4cc785911a1f4f4c9adb"
          }
        },
        "585da3866ca3467e981052a294e971ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1dc7e1caf74b3ba118f031fd7f93d7",
            "placeholder": "​",
            "style": "IPY_MODEL_155e16b4696f429caa0a5d0e352cd2d9",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "ca64cdd7acfc4de8b5d520d7213558b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b229290bd03e491988ad2b3936cc3232",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d47421504464c79a53cf70bd41da69c",
            "value": 124
          }
        },
        "e0919e03c18644829ef00ead8b7f1b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1af69ce2dcd420a8a74bb8b729d619d",
            "placeholder": "​",
            "style": "IPY_MODEL_640b91c236ba4e0094919077f76f7554",
            "value": " 124/124 [00:00&lt;00:00, 9.14kB/s]"
          }
        },
        "264e80dca4cc4cc785911a1f4f4c9adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1dc7e1caf74b3ba118f031fd7f93d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155e16b4696f429caa0a5d0e352cd2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b229290bd03e491988ad2b3936cc3232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d47421504464c79a53cf70bd41da69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1af69ce2dcd420a8a74bb8b729d619d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640b91c236ba4e0094919077f76f7554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f67f63773aed429ab6756e52f8e740a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5470a6145b244f79929fdfe237967157",
              "IPY_MODEL_52f799d3a80f4c4fad19613f8edf2a88",
              "IPY_MODEL_f743ae87ba3c489cbc9b42193fa7d433"
            ],
            "layout": "IPY_MODEL_2a100750ec8449f6974e58f554a2e919"
          }
        },
        "5470a6145b244f79929fdfe237967157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0233ba554d04e6d952e6860fff7a8dd",
            "placeholder": "​",
            "style": "IPY_MODEL_521ffa9ce0c547c5951c7bdf96911a1d",
            "value": "README.md: 100%"
          }
        },
        "52f799d3a80f4c4fad19613f8edf2a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d105481adb43459ae095f2bdc7a77b",
            "max": 90797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9eed2441dca4f2cb9f3c39bc379de78",
            "value": 90797
          }
        },
        "f743ae87ba3c489cbc9b42193fa7d433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a35dd4d4466e4905af3ac25a0cd22490",
            "placeholder": "​",
            "style": "IPY_MODEL_3837338226504d3199e679f8d9e49d54",
            "value": " 90.8k/90.8k [00:00&lt;00:00, 5.23MB/s]"
          }
        },
        "2a100750ec8449f6974e58f554a2e919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0233ba554d04e6d952e6860fff7a8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "521ffa9ce0c547c5951c7bdf96911a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d105481adb43459ae095f2bdc7a77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9eed2441dca4f2cb9f3c39bc379de78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a35dd4d4466e4905af3ac25a0cd22490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3837338226504d3199e679f8d9e49d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cb14a0818a94e219c4d9f076aaf69bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d627f6d073254bf6b3bb26573ca33e18",
              "IPY_MODEL_2fca0fc034964ee78d18bc90c73a5147",
              "IPY_MODEL_319d5cb7911b424c9ea5bb1fb458fd8e"
            ],
            "layout": "IPY_MODEL_95a8a346a6a94fce81194c2b63a2f0fb"
          }
        },
        "d627f6d073254bf6b3bb26573ca33e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c10539ac70af47c6857b927eaf15e8a5",
            "placeholder": "​",
            "style": "IPY_MODEL_83798f23433542be8e84e895204b29d6",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "2fca0fc034964ee78d18bc90c73a5147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eabce3df59348cc95f686ccbd0897e5",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0a466e871104182becc301d80d14487",
            "value": 52
          }
        },
        "319d5cb7911b424c9ea5bb1fb458fd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e98af947ca1b46a28020a40da73986c3",
            "placeholder": "​",
            "style": "IPY_MODEL_ebda46e3c7704e909ad43ab60c6c69c6",
            "value": " 52.0/52.0 [00:00&lt;00:00, 2.97kB/s]"
          }
        },
        "95a8a346a6a94fce81194c2b63a2f0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c10539ac70af47c6857b927eaf15e8a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83798f23433542be8e84e895204b29d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eabce3df59348cc95f686ccbd0897e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a466e871104182becc301d80d14487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e98af947ca1b46a28020a40da73986c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebda46e3c7704e909ad43ab60c6c69c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cf453de9be8434d81d4def587a25fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aa43aa6720f44bea7184deb5d069f97",
              "IPY_MODEL_c54da21129e740129f2cc6eb609e1971",
              "IPY_MODEL_12d248a8609b4f47b44f3588ca9ef8cc"
            ],
            "layout": "IPY_MODEL_3ad6b605c9f245ae8150561d41c737a5"
          }
        },
        "4aa43aa6720f44bea7184deb5d069f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e236de967742d8a243d58ef3a491ed",
            "placeholder": "​",
            "style": "IPY_MODEL_dbcf99f5ee39422a8a8d3c774b08fc09",
            "value": "config.json: 100%"
          }
        },
        "c54da21129e740129f2cc6eb609e1971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a062e06fe1d4623a29d2c15d2a33ebc",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ab727032f3f4d92bf7164aecb949a98",
            "value": 684
          }
        },
        "12d248a8609b4f47b44f3588ca9ef8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7ff2c3747d4f7d9b7196e786db9295",
            "placeholder": "​",
            "style": "IPY_MODEL_21118120ce37454ab635d04a67782f11",
            "value": " 684/684 [00:00&lt;00:00, 43.4kB/s]"
          }
        },
        "3ad6b605c9f245ae8150561d41c737a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e236de967742d8a243d58ef3a491ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbcf99f5ee39422a8a8d3c774b08fc09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a062e06fe1d4623a29d2c15d2a33ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab727032f3f4d92bf7164aecb949a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a7ff2c3747d4f7d9b7196e786db9295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21118120ce37454ab635d04a67782f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eca50dbb727845798cb245fbe37a8788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3f8684107d2422a8d195e23f10fae8e",
              "IPY_MODEL_4145394e98ea4058afa4e34240fad08f",
              "IPY_MODEL_8fde85f3865c4625b271f3519f7f88aa"
            ],
            "layout": "IPY_MODEL_5ff7f491fe8d446da32b3b0b107dd682"
          }
        },
        "c3f8684107d2422a8d195e23f10fae8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667d49f0e8d94b2b9b9347c9fa408146",
            "placeholder": "​",
            "style": "IPY_MODEL_6fa8c99f119a434ba141f3582ed4392d",
            "value": "model.safetensors: 100%"
          }
        },
        "4145394e98ea4058afa4e34240fad08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b000c676279f42f1881881dc24bf7801",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42019e625903477da0250a86e803d46f",
            "value": 133466304
          }
        },
        "8fde85f3865c4625b271f3519f7f88aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec18b00d69e44dab894104cb2dc4996",
            "placeholder": "​",
            "style": "IPY_MODEL_49f8b59baf134d488d48cf087cdc07f4",
            "value": " 133M/133M [00:00&lt;00:00, 171MB/s]"
          }
        },
        "5ff7f491fe8d446da32b3b0b107dd682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667d49f0e8d94b2b9b9347c9fa408146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa8c99f119a434ba141f3582ed4392d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b000c676279f42f1881881dc24bf7801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42019e625903477da0250a86e803d46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec18b00d69e44dab894104cb2dc4996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f8b59baf134d488d48cf087cdc07f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e01535535a8c4c1a90f82f953d99c04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_943e60adc33049cca17bcccbee7539e4",
              "IPY_MODEL_aaa01e878d4e4ba98bbde56794e07b88",
              "IPY_MODEL_62b7c563ba014e0d9028af838f0a01e9"
            ],
            "layout": "IPY_MODEL_c566fda5cb5746aba4b9a3abb9ace2ae"
          }
        },
        "943e60adc33049cca17bcccbee7539e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7559dfb657b242f291bd057d72317c23",
            "placeholder": "​",
            "style": "IPY_MODEL_a9dba276ad924fcdb5a27c04d36f37f9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "aaa01e878d4e4ba98bbde56794e07b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec94637cec684245b1b96a04e8aca3b8",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51cfd9d5e05245779d8d4e6be61e80ef",
            "value": 366
          }
        },
        "62b7c563ba014e0d9028af838f0a01e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17978e524634ac38ab0e72c7039e34e",
            "placeholder": "​",
            "style": "IPY_MODEL_06a16e526ea545ee9bc73376bcde2fc5",
            "value": " 366/366 [00:00&lt;00:00, 26.9kB/s]"
          }
        },
        "c566fda5cb5746aba4b9a3abb9ace2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7559dfb657b242f291bd057d72317c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9dba276ad924fcdb5a27c04d36f37f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec94637cec684245b1b96a04e8aca3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51cfd9d5e05245779d8d4e6be61e80ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b17978e524634ac38ab0e72c7039e34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06a16e526ea545ee9bc73376bcde2fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c1831679935415ca79ecb05a342c7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41b2b6f8d1194851a098ab5cb91d00d2",
              "IPY_MODEL_ba5d273634384e87a6f18177b4e3e4d6",
              "IPY_MODEL_bb7ca2868bf745249980ac34edf6a1da"
            ],
            "layout": "IPY_MODEL_417c7c2bfe014a94b6c1efa37d679906"
          }
        },
        "41b2b6f8d1194851a098ab5cb91d00d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d50a1bceac424836a2d3d514613166f8",
            "placeholder": "​",
            "style": "IPY_MODEL_7cd2eb162aa74b929735da4441448e85",
            "value": "vocab.txt: 100%"
          }
        },
        "ba5d273634384e87a6f18177b4e3e4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b7a67827634effa663471b7e50273a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_137e0917c2b34b5b857d4c1c068fbcdf",
            "value": 231508
          }
        },
        "bb7ca2868bf745249980ac34edf6a1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34202830c654a5d9b4bf5cc955dcfc0",
            "placeholder": "​",
            "style": "IPY_MODEL_63db7001ce514f0a890b5aa81dde918c",
            "value": " 232k/232k [00:00&lt;00:00, 11.7MB/s]"
          }
        },
        "417c7c2bfe014a94b6c1efa37d679906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50a1bceac424836a2d3d514613166f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd2eb162aa74b929735da4441448e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4b7a67827634effa663471b7e50273a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137e0917c2b34b5b857d4c1c068fbcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f34202830c654a5d9b4bf5cc955dcfc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63db7001ce514f0a890b5aa81dde918c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af600747b25042a5b4f37e8aa2209ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb5f85fa412c4803adf854d21471e2e9",
              "IPY_MODEL_0c52e4ff871b4e53a37b2dcc2b819194",
              "IPY_MODEL_4d7721728a074b78ba166811f132e84f"
            ],
            "layout": "IPY_MODEL_e69e41ab6d734f9e9974486f9f123f88"
          }
        },
        "cb5f85fa412c4803adf854d21471e2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_832fce08921e4abb9c7231c9e1d4b7e3",
            "placeholder": "​",
            "style": "IPY_MODEL_04098c319a2945e7bb33d67163f4ea41",
            "value": "tokenizer.json: 100%"
          }
        },
        "0c52e4ff871b4e53a37b2dcc2b819194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25ba56af6d42471687571987d0924a4f",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bfa72d10bc24e0abd38b8407b225397",
            "value": 711396
          }
        },
        "4d7721728a074b78ba166811f132e84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3410212cb61246968ffdf4536f238feb",
            "placeholder": "​",
            "style": "IPY_MODEL_76d4c42ec93d423b90ec1e8bef91a768",
            "value": " 711k/711k [00:00&lt;00:00, 11.7MB/s]"
          }
        },
        "e69e41ab6d734f9e9974486f9f123f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832fce08921e4abb9c7231c9e1d4b7e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04098c319a2945e7bb33d67163f4ea41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25ba56af6d42471687571987d0924a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bfa72d10bc24e0abd38b8407b225397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3410212cb61246968ffdf4536f238feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d4c42ec93d423b90ec1e8bef91a768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cc2f3d6e91f48a3ba7dd628076c3e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b4ca00530ed41729383f3bac13b1878",
              "IPY_MODEL_ce1f20c592c54641aaee425399d720d7",
              "IPY_MODEL_e6bb55c70ffc4d0ab3fd9cccb71fb7b4"
            ],
            "layout": "IPY_MODEL_d1b1556f578e4145894248528953eb80"
          }
        },
        "4b4ca00530ed41729383f3bac13b1878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af3fe298ae2f45e19dacf6ceb8935ecf",
            "placeholder": "​",
            "style": "IPY_MODEL_91d537a0f2c94368a5fa6c54f8778405",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ce1f20c592c54641aaee425399d720d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a46d5ce753bf48e6913cac32eab95a6b",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc98aa38c43649169f969bd7e31ddef0",
            "value": 125
          }
        },
        "e6bb55c70ffc4d0ab3fd9cccb71fb7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25958817b176497596e061c5c9a41716",
            "placeholder": "​",
            "style": "IPY_MODEL_cf090b1b278f49bcac441597ce6c60a8",
            "value": " 125/125 [00:00&lt;00:00, 9.96kB/s]"
          }
        },
        "d1b1556f578e4145894248528953eb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3fe298ae2f45e19dacf6ceb8935ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d537a0f2c94368a5fa6c54f8778405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a46d5ce753bf48e6913cac32eab95a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc98aa38c43649169f969bd7e31ddef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25958817b176497596e061c5c9a41716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf090b1b278f49bcac441597ce6c60a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09195407eea9424ba9361a1ec94bc081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff857e90e0054fb1a28830d4196069ad",
              "IPY_MODEL_7745873979844dd9a8589ff9b6d2ec0d",
              "IPY_MODEL_da8ac054b6c64333a78f3957d04ae70c"
            ],
            "layout": "IPY_MODEL_e6cefb1f11f948059c33f811bafed2ab"
          }
        },
        "ff857e90e0054fb1a28830d4196069ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5f70bf0f78047b6acd2a17a6c4f4cfd",
            "placeholder": "​",
            "style": "IPY_MODEL_68de20ef66c44dcfac0017b23166ba97",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "7745873979844dd9a8589ff9b6d2ec0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9658e296bd1641cfb482ebaa82a07a5f",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b76db09b41841d897a3f236048d157f",
            "value": 190
          }
        },
        "da8ac054b6c64333a78f3957d04ae70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7982e441c444a2d8934510cf317ed66",
            "placeholder": "​",
            "style": "IPY_MODEL_1c832d121e6641df9a7645835fdd19bd",
            "value": " 190/190 [00:00&lt;00:00, 12.2kB/s]"
          }
        },
        "e6cefb1f11f948059c33f811bafed2ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5f70bf0f78047b6acd2a17a6c4f4cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68de20ef66c44dcfac0017b23166ba97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9658e296bd1641cfb482ebaa82a07a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b76db09b41841d897a3f236048d157f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7982e441c444a2d8934510cf317ed66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c832d121e6641df9a7645835fdd19bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}